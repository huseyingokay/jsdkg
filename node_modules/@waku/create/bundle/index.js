/**
 * To guarantee Uint8Array semantics, convert nodejs Buffers
 * into vanilla Uint8Arrays
 */
function asUint8Array(buf) {
    if (globalThis.Buffer != null) {
        return new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength);
    }
    return buf;
}

/**
 * Returns a `Uint8Array` of the requested size. Referenced memory will
 * be initialized to 0.
 */
function alloc$1(size = 0) {
    if (globalThis.Buffer?.alloc != null) {
        return asUint8Array(globalThis.Buffer.alloc(size));
    }
    return new Uint8Array(size);
}
/**
 * Where possible returns a Uint8Array of the requested size that references
 * uninitialized memory. Only use if you are certain you will immediately
 * overwrite every value in the returned `Uint8Array`.
 */
function allocUnsafe$3(size = 0) {
    if (globalThis.Buffer?.allocUnsafe != null) {
        return asUint8Array(globalThis.Buffer.allocUnsafe(size));
    }
    return new Uint8Array(size);
}

/**
 * Returns a new Uint8Array created by concatenating the passed ArrayLikes
 */
function concat(arrays, length) {
    if (length == null) {
        length = arrays.reduce((acc, curr) => acc + curr.length, 0);
    }
    const output = allocUnsafe$3(length);
    let offset = 0;
    for (const arr of arrays) {
        output.set(arr, offset);
        offset += arr.length;
    }
    return asUint8Array(output);
}

/**
 * Returns true if the two passed Uint8Arrays have the same content
 */
function equals$2(a, b) {
    if (a === b) {
        return true;
    }
    if (a.byteLength !== b.byteLength) {
        return false;
    }
    for (let i = 0; i < a.byteLength; i++) {
        if (a[i] !== b[i]) {
            return false;
        }
    }
    return true;
}

const symbol$6 = Symbol.for('@achingbrain/uint8arraylist');
function findBufAndOffset(bufs, index) {
    if (index == null || index < 0) {
        throw new RangeError('index is out of bounds');
    }
    let offset = 0;
    for (const buf of bufs) {
        const bufEnd = offset + buf.byteLength;
        if (index < bufEnd) {
            return {
                buf,
                index: index - offset
            };
        }
        offset = bufEnd;
    }
    throw new RangeError('index is out of bounds');
}
/**
 * Check if object is a CID instance
 *
 * @example
 *
 * ```js
 * import { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist'
 *
 * isUint8ArrayList(true) // false
 * isUint8ArrayList([]) // false
 * isUint8ArrayList(new Uint8ArrayList()) // true
 * ```
 */
function isUint8ArrayList(value) {
    return Boolean(value?.[symbol$6]);
}
class Uint8ArrayList {
    constructor(...data) {
        // Define symbol
        Object.defineProperty(this, symbol$6, { value: true });
        this.bufs = [];
        this.length = 0;
        if (data.length > 0) {
            this.appendAll(data);
        }
    }
    *[Symbol.iterator]() {
        yield* this.bufs;
    }
    get byteLength() {
        return this.length;
    }
    /**
     * Add one or more `bufs` to the end of this Uint8ArrayList
     */
    append(...bufs) {
        this.appendAll(bufs);
    }
    /**
     * Add all `bufs` to the end of this Uint8ArrayList
     */
    appendAll(bufs) {
        let length = 0;
        for (const buf of bufs) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.push(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.push(...buf.bufs);
            }
            else {
                throw new Error('Could not append value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Add one or more `bufs` to the start of this Uint8ArrayList
     */
    prepend(...bufs) {
        this.prependAll(bufs);
    }
    /**
     * Add all `bufs` to the start of this Uint8ArrayList
     */
    prependAll(bufs) {
        let length = 0;
        for (const buf of bufs.reverse()) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.unshift(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.unshift(...buf.bufs);
            }
            else {
                throw new Error('Could not prepend value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Read the value at `index`
     */
    get(index) {
        const res = findBufAndOffset(this.bufs, index);
        return res.buf[res.index];
    }
    /**
     * Set the value at `index` to `value`
     */
    set(index, value) {
        const res = findBufAndOffset(this.bufs, index);
        res.buf[res.index] = value;
    }
    /**
     * Copy bytes from `buf` to the index specified by `offset`
     */
    write(buf, offset = 0) {
        if (buf instanceof Uint8Array) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf[i]);
            }
        }
        else if (isUint8ArrayList(buf)) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf.get(i));
            }
        }
        else {
            throw new Error('Could not write value, must be an Uint8Array or a Uint8ArrayList');
        }
    }
    /**
     * Remove bytes from the front of the pool
     */
    consume(bytes) {
        // first, normalize the argument, in accordance with how Buffer does it
        bytes = Math.trunc(bytes);
        // do nothing if not a positive number
        if (Number.isNaN(bytes) || bytes <= 0) {
            return;
        }
        // if consuming all bytes, skip iterating
        if (bytes === this.byteLength) {
            this.bufs = [];
            this.length = 0;
            return;
        }
        while (this.bufs.length > 0) {
            if (bytes >= this.bufs[0].byteLength) {
                bytes -= this.bufs[0].byteLength;
                this.length -= this.bufs[0].byteLength;
                this.bufs.shift();
            }
            else {
                this.bufs[0] = this.bufs[0].subarray(bytes);
                this.length -= bytes;
                break;
            }
        }
    }
    /**
     * Extracts a section of an array and returns a new array.
     *
     * This is a copy operation as it is with Uint8Arrays and Arrays
     * - note this is different to the behaviour of Node Buffers.
     */
    slice(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        return concat(bufs, length);
    }
    /**
     * Returns a alloc from the given start and end element index.
     *
     * In the best case where the data extracted comes from a single Uint8Array
     * internally this is a no-copy operation otherwise it is a copy operation.
     */
    subarray(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        if (bufs.length === 1) {
            return bufs[0];
        }
        return concat(bufs, length);
    }
    /**
     * Returns a allocList from the given start and end element index.
     *
     * This is a no-copy operation.
     */
    sublist(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        const list = new Uint8ArrayList();
        list.length = length;
        // don't loop, just set the bufs
        list.bufs = bufs;
        return list;
    }
    _subList(beginInclusive, endExclusive) {
        beginInclusive = beginInclusive ?? 0;
        endExclusive = endExclusive ?? this.length;
        if (beginInclusive < 0) {
            beginInclusive = this.length + beginInclusive;
        }
        if (endExclusive < 0) {
            endExclusive = this.length + endExclusive;
        }
        if (beginInclusive < 0 || endExclusive > this.length) {
            throw new RangeError('index is out of bounds');
        }
        if (beginInclusive === endExclusive) {
            return { bufs: [], length: 0 };
        }
        if (beginInclusive === 0 && endExclusive === this.length) {
            return { bufs: [...this.bufs], length: this.length };
        }
        const bufs = [];
        let offset = 0;
        for (let i = 0; i < this.bufs.length; i++) {
            const buf = this.bufs[i];
            const bufStart = offset;
            const bufEnd = bufStart + buf.byteLength;
            // for next loop
            offset = bufEnd;
            if (beginInclusive >= bufEnd) {
                // start after this buf
                continue;
            }
            const sliceStartInBuf = beginInclusive >= bufStart && beginInclusive < bufEnd;
            const sliceEndsInBuf = endExclusive > bufStart && endExclusive <= bufEnd;
            if (sliceStartInBuf && sliceEndsInBuf) {
                // slice is wholly contained within this buffer
                if (beginInclusive === bufStart && endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                const start = beginInclusive - bufStart;
                bufs.push(buf.subarray(start, start + (endExclusive - beginInclusive)));
                break;
            }
            if (sliceStartInBuf) {
                // slice starts in this buffer
                if (beginInclusive === 0) {
                    // requested whole buffer
                    bufs.push(buf);
                    continue;
                }
                // requested part of buffer
                bufs.push(buf.subarray(beginInclusive - bufStart));
                continue;
            }
            if (sliceEndsInBuf) {
                if (endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                bufs.push(buf.subarray(0, endExclusive - bufStart));
                break;
            }
            // slice started before this buffer and ends after it
            bufs.push(buf);
        }
        return { bufs, length: endExclusive - beginInclusive };
    }
    indexOf(search, offset = 0) {
        if (!isUint8ArrayList(search) && !(search instanceof Uint8Array)) {
            throw new TypeError('The "value" argument must be a Uint8ArrayList or Uint8Array');
        }
        const needle = search instanceof Uint8Array ? search : search.subarray();
        offset = Number(offset ?? 0);
        if (isNaN(offset)) {
            offset = 0;
        }
        if (offset < 0) {
            offset = this.length + offset;
        }
        if (offset < 0) {
            offset = 0;
        }
        if (search.length === 0) {
            return offset > this.length ? this.length : offset;
        }
        // https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm
        const M = needle.byteLength;
        if (M === 0) {
            throw new TypeError('search must be at least 1 byte long');
        }
        // radix
        const radix = 256;
        const rightmostPositions = new Int32Array(radix);
        // position of the rightmost occurrence of the byte c in the pattern
        for (let c = 0; c < radix; c++) {
            // -1 for bytes not in pattern
            rightmostPositions[c] = -1;
        }
        for (let j = 0; j < M; j++) {
            // rightmost position for bytes in pattern
            rightmostPositions[needle[j]] = j;
        }
        // Return offset of first match, -1 if no match
        const right = rightmostPositions;
        const lastIndex = this.byteLength - needle.byteLength;
        const lastPatIndex = needle.byteLength - 1;
        let skip;
        for (let i = offset; i <= lastIndex; i += skip) {
            skip = 0;
            for (let j = lastPatIndex; j >= 0; j--) {
                const char = this.get(i + j);
                if (needle[j] !== char) {
                    skip = Math.max(1, j - right[char]);
                    break;
                }
            }
            if (skip === 0) {
                return i;
            }
        }
        return -1;
    }
    getInt8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt8(0);
    }
    setInt8(byteOffset, value) {
        const buf = allocUnsafe$3(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt8(0, value);
        this.write(buf, byteOffset);
    }
    getInt16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt16(0, littleEndian);
    }
    setInt16(byteOffset, value, littleEndian) {
        const buf = alloc$1(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getInt32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt32(0, littleEndian);
    }
    setInt32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigInt64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigInt64(0, littleEndian);
    }
    setBigInt64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigInt64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint8(0);
    }
    setUint8(byteOffset, value) {
        const buf = allocUnsafe$3(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint8(0, value);
        this.write(buf, byteOffset);
    }
    getUint16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint16(0, littleEndian);
    }
    setUint16(byteOffset, value, littleEndian) {
        const buf = alloc$1(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint32(0, littleEndian);
    }
    setUint32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigUint64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigUint64(0, littleEndian);
    }
    setBigUint64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigUint64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat32(0, littleEndian);
    }
    setFloat32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat64(0, littleEndian);
    }
    setFloat64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (!(other instanceof Uint8ArrayList)) {
            return false;
        }
        if (other.bufs.length !== this.bufs.length) {
            return false;
        }
        for (let i = 0; i < this.bufs.length; i++) {
            if (!equals$2(this.bufs[i], other.bufs[i])) {
                return false;
            }
        }
        return true;
    }
    /**
     * Create a Uint8ArrayList from a pre-existing list of Uint8Arrays.  Use this
     * method if you know the total size of all the Uint8Arrays ahead of time.
     */
    static fromUint8Arrays(bufs, length) {
        const list = new Uint8ArrayList();
        list.bufs = bufs;
        if (length == null) {
            length = bufs.reduce((acc, curr) => acc + curr.byteLength, 0);
        }
        list.length = length;
        return list;
    }
}
/*
function indexOf (needle: Uint8Array, haystack: Uint8Array, offset = 0) {
  for (let i = offset; i < haystack.byteLength; i++) {
    for (let j = 0; j < needle.length; j++) {
      if (haystack[i + j] !== needle[j]) {
        break
      }

      if (j === needle.byteLength -1) {
        return i
      }
    }

    if (haystack.byteLength - i < needle.byteLength) {
      break
    }
  }

  return -1
}
*/

/**
 * Returns an `AsyncGenerator` that allows reading a set number of bytes from the passed source.
 *
 * @example
 *
 * ```javascript
 * import { reader } from 'it-reader'
 *
 * const stream = reader(source)
 *
 * // read 10 bytes from the stream
 * const { done, value } = await stream.next(10)
 *
 * if (done === true) {
 *   // stream finished
 * }
 *
 * if (value != null) {
 *   // do something with value
 * }
 * ```
 */
function reader$d(source) {
    const reader = (async function* () {
        // @ts-expect-error first yield in stream is ignored
        let bytes = yield; // Allows us to receive 8 when reader.next(8) is called
        let bl = new Uint8ArrayList();
        for await (const chunk of source) {
            if (bytes == null) {
                bl.append(chunk);
                bytes = yield bl;
                bl = new Uint8ArrayList();
                continue;
            }
            bl.append(chunk);
            while (bl.length >= bytes) {
                const data = bl.sublist(0, bytes);
                bl.consume(bytes);
                bytes = yield data;
                // If we no longer want a specific byte length, we yield the rest now
                if (bytes == null) {
                    if (bl.length > 0) {
                        bytes = yield bl;
                        bl = new Uint8ArrayList();
                    }
                    break; // bytes is null and/or no more buffer to yield
                }
            }
        }
        // Consumer wants more bytes but the source has ended and our buffer
        // is not big enough to satisfy.
        if (bytes != null) {
            throw Object.assign(new Error(`stream ended before ${bytes} bytes became available`), { code: 'ERR_UNDER_READ', buffer: bl });
        }
    })();
    void reader.next();
    return reader;
}

// ported from https://www.npmjs.com/package/fast-fifo
let FixedFIFO$1 = class FixedFIFO {
    constructor(hwm) {
        if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) {
            throw new Error('Max size for a FixedFIFO should be a power of two');
        }
        this.buffer = new Array(hwm);
        this.mask = hwm - 1;
        this.top = 0;
        this.btm = 0;
        this.next = null;
    }
    push(data) {
        if (this.buffer[this.top] !== undefined) {
            return false;
        }
        this.buffer[this.top] = data;
        this.top = (this.top + 1) & this.mask;
        return true;
    }
    shift() {
        const last = this.buffer[this.btm];
        if (last === undefined) {
            return undefined;
        }
        this.buffer[this.btm] = undefined;
        this.btm = (this.btm + 1) & this.mask;
        return last;
    }
    isEmpty() {
        return this.buffer[this.btm] === undefined;
    }
};
class FIFO {
    constructor(options = {}) {
        this.hwm = options.splitLimit ?? 16;
        this.head = new FixedFIFO$1(this.hwm);
        this.tail = this.head;
        this.size = 0;
    }
    calculateSize(obj) {
        if (obj?.byteLength != null) {
            return obj.byteLength;
        }
        return 1;
    }
    push(val) {
        if (val?.value != null) {
            this.size += this.calculateSize(val.value);
        }
        if (!this.head.push(val)) {
            const prev = this.head;
            this.head = prev.next = new FixedFIFO$1(2 * this.head.buffer.length);
            this.head.push(val);
        }
    }
    shift() {
        let val = this.tail.shift();
        if (val === undefined && (this.tail.next != null)) {
            const next = this.tail.next;
            this.tail.next = null;
            this.tail = next;
            val = this.tail.shift();
        }
        if (val?.value != null) {
            this.size -= this.calculateSize(val.value);
        }
        return val;
    }
    isEmpty() {
        return this.head.isEmpty();
    }
}

/**
 * @packageDocumentation
 *
 * An iterable that you can push values into.
 *
 * @example
 *
 * ```js
 * import { pushable } from 'it-pushable'
 *
 * const source = pushable()
 *
 * setTimeout(() => source.push('hello'), 100)
 * setTimeout(() => source.push('world'), 200)
 * setTimeout(() => source.end(), 300)
 *
 * const start = Date.now()
 *
 * for await (const value of source) {
 *   console.log(`got "${value}" after ${Date.now() - start}ms`)
 * }
 * console.log(`done after ${Date.now() - start}ms`)
 *
 * // Output:
 * // got "hello" after 105ms
 * // got "world" after 207ms
 * // done after 309ms
 * ```
 *
 * @example
 *
 * ```js
 * import { pushableV } from 'it-pushable'
 * import all from 'it-all'
 *
 * const source = pushableV()
 *
 * source.push(1)
 * source.push(2)
 * source.push(3)
 * source.end()
 *
 * console.info(await all(source))
 *
 * // Output:
 * // [ [1, 2, 3] ]
 * ```
 */
function pushable(options = {}) {
    const getNext = (buffer) => {
        const next = buffer.shift();
        if (next == null) {
            return { done: true };
        }
        if (next.error != null) {
            throw next.error;
        }
        return {
            done: next.done === true,
            // @ts-expect-error
            value: next.value
        };
    };
    return _pushable(getNext, options);
}
function pushableV(options = {}) {
    const getNext = (buffer) => {
        let next;
        const values = [];
        while (!buffer.isEmpty()) {
            next = buffer.shift();
            if (next == null) {
                break;
            }
            if (next.error != null) {
                throw next.error;
            }
            if (next.done === false) {
                // @ts-expect-error
                values.push(next.value);
            }
        }
        if (next == null) {
            return { done: true };
        }
        return {
            done: next.done === true,
            value: values
        };
    };
    return _pushable(getNext, options);
}
function _pushable(getNext, options) {
    options = options ?? {};
    let onEnd = options.onEnd;
    let buffer = new FIFO();
    let pushable;
    let onNext;
    let ended;
    const waitNext = async () => {
        if (!buffer.isEmpty()) {
            return getNext(buffer);
        }
        if (ended) {
            return { done: true };
        }
        return await new Promise((resolve, reject) => {
            onNext = (next) => {
                onNext = null;
                buffer.push(next);
                try {
                    resolve(getNext(buffer));
                }
                catch (err) {
                    reject(err);
                }
                return pushable;
            };
        });
    };
    const bufferNext = (next) => {
        if (onNext != null) {
            return onNext(next);
        }
        buffer.push(next);
        return pushable;
    };
    const bufferError = (err) => {
        buffer = new FIFO();
        if (onNext != null) {
            return onNext({ error: err });
        }
        buffer.push({ error: err });
        return pushable;
    };
    const push = (value) => {
        if (ended) {
            return pushable;
        }
        // @ts-expect-error `byteLength` is not declared on PushType
        if (options?.objectMode !== true && value?.byteLength == null) {
            throw new Error('objectMode was not true but tried to push non-Uint8Array value');
        }
        return bufferNext({ done: false, value });
    };
    const end = (err) => {
        if (ended)
            return pushable;
        ended = true;
        return (err != null) ? bufferError(err) : bufferNext({ done: true });
    };
    const _return = () => {
        buffer = new FIFO();
        end();
        return { done: true };
    };
    const _throw = (err) => {
        end(err);
        return { done: true };
    };
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next: waitNext,
        return: _return,
        throw: _throw,
        push,
        end,
        get readableLength() {
            return buffer.size;
        }
    };
    if (onEnd == null) {
        return pushable;
    }
    const _pushable = pushable;
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next() {
            return _pushable.next();
        },
        throw(err) {
            _pushable.throw(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return { done: true };
        },
        return() {
            _pushable.return();
            if (onEnd != null) {
                onEnd();
                onEnd = undefined;
            }
            return { done: true };
        },
        push,
        end(err) {
            _pushable.end(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return pushable;
        },
        get readableLength() {
            return _pushable.readableLength;
        }
    };
    return pushable;
}

function pDefer$1() {
	const deferred = {};

	deferred.promise = new Promise((resolve, reject) => {
		deferred.resolve = resolve;
		deferred.reject = reject;
	});

	return deferred;
}

// Convert a duplex stream into a reader and writer and rest stream
function handshake(stream) {
    const writer = pushable(); // Write bytes on demand to the sink
    const source = reader$d(stream.source); // Read bytes on demand from the source
    // Waits for a source to be passed to the rest stream's sink
    const sourcePromise = pDefer$1();
    let sinkErr;
    const sinkPromise = stream.sink((async function* () {
        yield* writer;
        const source = await sourcePromise.promise;
        yield* source;
    })());
    sinkPromise.catch(err => {
        sinkErr = err;
    });
    const rest = {
        sink: async (source) => {
            if (sinkErr != null) {
                return await Promise.reject(sinkErr);
            }
            sourcePromise.resolve(source);
            return await sinkPromise;
        },
        source
    };
    return {
        reader: source,
        writer,
        stream: rest,
        rest: () => writer.end(),
        write: writer.push,
        read: async () => {
            const res = await source.next();
            if (res.value != null) {
                return res.value;
            }
        }
    };
}

function accessor(buf) {
    if (buf instanceof Uint8Array) {
        return {
            get(index) {
                return buf[index];
            },
            set(index, value) {
                buf[index] = value;
            }
        };
    }
    return {
        get(index) {
            return buf.get(index);
        },
        set(index, value) {
            buf.set(index, value);
        }
    };
}

const TWO_32 = 4294967296;
let LongBits$e = class LongBits {
    constructor(hi = 0, lo = 0) {
        this.hi = hi;
        this.lo = lo;
    }
    /**
     * Returns these hi/lo bits as a BigInt
     */
    toBigInt(unsigned) {
        if (unsigned === true) {
            return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);
        }
        if ((this.hi >>> 31) !== 0) {
            const lo = ~this.lo + 1 >>> 0;
            let hi = ~this.hi >>> 0;
            if (lo === 0) {
                hi = hi + 1 >>> 0;
            }
            return -(BigInt(lo) + (BigInt(hi) << 32n));
        }
        return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);
    }
    /**
     * Returns these hi/lo bits as a Number - this may overflow, toBigInt
     * should be preferred
     */
    toNumber(unsigned) {
        return Number(this.toBigInt(unsigned));
    }
    /**
     * ZigZag decode a LongBits object
     */
    zzDecode() {
        const mask = -(this.lo & 1);
        const lo = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
        const hi = (this.hi >>> 1 ^ mask) >>> 0;
        return new LongBits(hi, lo);
    }
    /**
     * ZigZag encode a LongBits object
     */
    zzEncode() {
        const mask = this.hi >> 31;
        const hi = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
        const lo = (this.lo << 1 ^ mask) >>> 0;
        return new LongBits(hi, lo);
    }
    /**
     * Encode a LongBits object as a varint byte array
     */
    toBytes(buf, offset = 0) {
        const access = accessor(buf);
        while (this.hi > 0) {
            access.set(offset++, this.lo & 127 | 128);
            this.lo = (this.lo >>> 7 | this.hi << 25) >>> 0;
            this.hi >>>= 7;
        }
        while (this.lo > 127) {
            access.set(offset++, this.lo & 127 | 128);
            this.lo = this.lo >>> 7;
        }
        access.set(offset++, this.lo);
    }
    /**
     * Parse a LongBits object from a BigInt
     */
    static fromBigInt(value) {
        if (value === 0n) {
            return new LongBits();
        }
        const negative = value < 0;
        if (negative) {
            value = -value;
        }
        let hi = Number(value >> 32n) | 0;
        let lo = Number(value - (BigInt(hi) << 32n)) | 0;
        if (negative) {
            hi = ~hi >>> 0;
            lo = ~lo >>> 0;
            if (++lo > TWO_32) {
                lo = 0;
                if (++hi > TWO_32) {
                    hi = 0;
                }
            }
        }
        return new LongBits(hi, lo);
    }
    /**
     * Parse a LongBits object from a Number
     */
    static fromNumber(value) {
        if (value === 0) {
            return new LongBits();
        }
        const sign = value < 0;
        if (sign) {
            value = -value;
        }
        let lo = value >>> 0;
        let hi = (value - lo) / 4294967296 >>> 0;
        if (sign) {
            hi = ~hi >>> 0;
            lo = ~lo >>> 0;
            if (++lo > 4294967295) {
                lo = 0;
                if (++hi > 4294967295) {
                    hi = 0;
                }
            }
        }
        return new LongBits(hi, lo);
    }
    /**
     * Parse a LongBits object from a varint byte array
     */
    static fromBytes(buf, offset = 0) {
        const access = accessor(buf);
        // tends to deopt with local vars for octet etc.
        const bits = new LongBits();
        let i = 0;
        if (buf.length - offset > 4) { // fast route (lo)
            for (; i < 4; ++i) {
                // 1st..4th
                bits.lo = (bits.lo | (access.get(offset) & 127) << i * 7) >>> 0;
                if (access.get(offset++) < 128) {
                    return bits;
                }
            }
            // 5th
            bits.lo = (bits.lo | (access.get(offset) & 127) << 28) >>> 0;
            bits.hi = (bits.hi | (access.get(offset) & 127) >> 4) >>> 0;
            if (access.get(offset++) < 128) {
                return bits;
            }
            i = 0;
        }
        else {
            for (; i < 4; ++i) {
                /* istanbul ignore if */
                if (offset >= buf.length) {
                    throw RangeError(`index out of range: ${offset} > ${buf.length}`);
                }
                // 1st..4th
                bits.lo = (bits.lo | (access.get(offset) & 127) << i * 7) >>> 0;
                if (access.get(offset++) < 128) {
                    return bits;
                }
            }
        }
        if (buf.length - offset > 4) { // fast route (hi)
            for (; i < 5; ++i) {
                // 6th..10th
                bits.hi = (bits.hi | (access.get(offset) & 127) << i * 7 + 3) >>> 0;
                if (access.get(offset++) < 128) {
                    return bits;
                }
            }
        }
        else if (offset < buf.byteLength) {
            for (; i < 5; ++i) {
                /* istanbul ignore if */
                if (offset >= buf.length) {
                    throw RangeError(`index out of range: ${offset} > ${buf.length}`);
                }
                // 6th..10th
                bits.hi = (bits.hi | (access.get(offset) & 127) << i * 7 + 3) >>> 0;
                if (access.get(offset++) < 128) {
                    return bits;
                }
            }
        }
        /* istanbul ignore next */
        throw RangeError('invalid varint encoding');
    }
};

const N1$2 = Math.pow(2, 7);
const N2$2 = Math.pow(2, 14);
const N3$2 = Math.pow(2, 21);
const N4$2 = Math.pow(2, 28);
const N5$2 = Math.pow(2, 35);
const N6$2 = Math.pow(2, 42);
const N7$2 = Math.pow(2, 49);
const N8$2 = Math.pow(2, 56);
const N9$2 = Math.pow(2, 63);
const unsigned = {
    encodingLength(value) {
        if (value < N1$2) {
            return 1;
        }
        if (value < N2$2) {
            return 2;
        }
        if (value < N3$2) {
            return 3;
        }
        if (value < N4$2) {
            return 4;
        }
        if (value < N5$2) {
            return 5;
        }
        if (value < N6$2) {
            return 6;
        }
        if (value < N7$2) {
            return 7;
        }
        if (value < N8$2) {
            return 8;
        }
        if (value < N9$2) {
            return 9;
        }
        return 10;
    },
    encode(value, buf, offset = 0) {
        if (Number.MAX_SAFE_INTEGER != null && value > Number.MAX_SAFE_INTEGER) {
            throw new RangeError('Could not encode varint');
        }
        if (buf == null) {
            buf = allocUnsafe$3(unsigned.encodingLength(value));
        }
        LongBits$e.fromNumber(value).toBytes(buf, offset);
        return buf;
    },
    decode(buf, offset = 0) {
        return LongBits$e.fromBytes(buf, offset).toNumber(true);
    }
};

function allocUnsafe$2(len) {
    if (globalThis?.Buffer?.allocUnsafe != null) {
        return globalThis.Buffer.allocUnsafe(len);
    }
    return new Uint8Array(len);
}

const defaultEncoder = (length) => {
    const lengthLength = unsigned.encodingLength(length);
    const lengthBuf = allocUnsafe$2(lengthLength);
    unsigned.encode(length, lengthBuf);
    defaultEncoder.bytes = lengthLength;
    return lengthBuf;
};
defaultEncoder.bytes = 0;
function encode$b(options) {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    const encoder = async function* (source) {
        for await (const chunk of source) {
            // length + data
            const length = encodeLength(chunk.byteLength);
            // yield only Uint8Arrays
            if (length instanceof Uint8Array) {
                yield length;
            }
            else {
                yield* length;
            }
            // yield only Uint8Arrays
            if (chunk instanceof Uint8Array) {
                yield chunk;
            }
            else {
                yield* chunk;
            }
        }
    };
    return encoder;
}
encode$b.single = (chunk, options) => {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    return new Uint8ArrayList(encodeLength(chunk.byteLength), chunk);
};

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

function getAugmentedNamespace(n) {
  if (n.__esModule) return n;
  var f = n.default;
	if (typeof f == "function") {
		var a = function a () {
			if (this instanceof a) {
				var args = [null];
				args.push.apply(args, arguments);
				var Ctor = Function.bind.apply(f, args);
				return new Ctor();
			}
			return f.apply(this, arguments);
		};
		a.prototype = f.prototype;
  } else a = {};
  Object.defineProperty(a, '__esModule', {value: true});
	Object.keys(n).forEach(function (k) {
		var d = Object.getOwnPropertyDescriptor(n, k);
		Object.defineProperty(a, k, d.get ? d : {
			enumerable: true,
			get: function () {
				return n[k];
			}
		});
	});
	return a;
}

/**
 * @typedef {{ [key: string]: any }} Extensions
 * @typedef {Error} Err
 * @property {string} message
 */

/**
 *
 * @param {Error} obj
 * @param {Extensions} props
 * @returns {Error & Extensions}
 */
function assign(obj, props) {
    for (const key in props) {
        Object.defineProperty(obj, key, {
            value: props[key],
            enumerable: true,
            configurable: true,
        });
    }

    return obj;
}

/**
 *
 * @param {any} err - An Error
 * @param {string|Extensions} code - A string code or props to set on the error
 * @param {Extensions} [props] - Props to set on the error
 * @returns {Error & Extensions}
 */
function createError(err, code, props) {
    if (!err || typeof err === 'string') {
        throw new TypeError('Please pass an Error to err-code');
    }

    if (!props) {
        props = {};
    }

    if (typeof code === 'object') {
        props = code;
        code = '';
    }

    if (code) {
        props.code = code;
    }

    try {
        return assign(err, props);
    } catch (_) {
        props.message = err.message;
        props.stack = err.stack;

        const ErrClass = function () {};

        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));

        // @ts-ignore
        const output = assign(new ErrClass(), props);

        return output;
    }
}

var errCode = createError;

/* eslint max-depth: ["error", 6] */
// Maximum length of the length section of the message
const MAX_LENGTH_LENGTH = 8; // Varint.encode(Number.MAX_SAFE_INTEGER).length
// Maximum length of the data section of the message
const MAX_DATA_LENGTH = 1024 * 1024 * 4;
var ReadMode;
(function (ReadMode) {
    ReadMode[ReadMode["LENGTH"] = 0] = "LENGTH";
    ReadMode[ReadMode["DATA"] = 1] = "DATA";
})(ReadMode || (ReadMode = {}));
const defaultDecoder = (buf) => {
    const length = unsigned.decode(buf);
    defaultDecoder.bytes = unsigned.encodingLength(length);
    return length;
};
defaultDecoder.bytes = 0;
function decode$a(options) {
    const decoder = async function* (source) {
        const buffer = new Uint8ArrayList();
        let mode = ReadMode.LENGTH;
        let dataLength = -1;
        const lengthDecoder = options?.lengthDecoder ?? defaultDecoder;
        const maxLengthLength = options?.maxLengthLength ?? MAX_LENGTH_LENGTH;
        const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH;
        for await (const buf of source) {
            buffer.append(buf);
            while (buffer.byteLength > 0) {
                if (mode === ReadMode.LENGTH) {
                    // read length, ignore errors for short reads
                    try {
                        dataLength = lengthDecoder(buffer);
                        if (dataLength < 0) {
                            throw errCode(new Error('invalid message length'), 'ERR_INVALID_MSG_LENGTH');
                        }
                        if (dataLength > maxDataLength) {
                            throw errCode(new Error('message length too long'), 'ERR_MSG_DATA_TOO_LONG');
                        }
                        const dataLengthLength = lengthDecoder.bytes;
                        buffer.consume(dataLengthLength);
                        if (options?.onLength != null) {
                            options.onLength(dataLength);
                        }
                        mode = ReadMode.DATA;
                    }
                    catch (err) {
                        if (err instanceof RangeError) {
                            if (buffer.byteLength > maxLengthLength) {
                                throw errCode(new Error('message length length too long'), 'ERR_MSG_LENGTH_TOO_LONG');
                            }
                            break;
                        }
                        throw err;
                    }
                }
                if (mode === ReadMode.DATA) {
                    if (buffer.byteLength < dataLength) {
                        // not enough data, wait for more
                        break;
                    }
                    const data = buffer.sublist(0, dataLength);
                    buffer.consume(dataLength);
                    if (options?.onData != null) {
                        options.onData(data);
                    }
                    yield data;
                    mode = ReadMode.LENGTH;
                }
            }
        }
        if (buffer.byteLength > 0) {
            throw errCode(new Error('unexpected end of input'), 'ERR_UNEXPECTED_EOF');
        }
    };
    return decoder;
}
/**
 * @param {*} reader
 * @param {import('./types').DecoderOptions} [options]
 * @returns
 */
decode$a.fromReader = (reader, options) => {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = (async function* () {
        while (true) {
            try {
                const { done, value } = await reader.next(byteLength);
                if (done === true) {
                    return;
                }
                if (value != null) {
                    yield value;
                }
            }
            catch (err) {
                if (err.code === 'ERR_UNDER_READ') {
                    return { done: true, value: null };
                }
                throw err;
            }
            finally {
                // Reset the byteLength so we continue to check for varints
                byteLength = 1;
            }
        }
    }());
    /**
     * Once the length has been parsed, read chunk for that length
     */
    const onLength = (l) => { byteLength = l; };
    return decode$a({
        ...(options ?? {}),
        onLength
    })(varByteSource);
};

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive Protobuf encoded messages over
 * streams.
 *
 * @example
 *
 * ```typescript
 * import { pbStream } from 'it-pb-stream'
 * import { MessageType } from './src/my-message-type.js'
 *
 * // RequestType and ResponseType have been generate from `.proto` files and have
 * // `.encode` and `.decode` methods for serialization/deserialization
 *
 * const stream = pbStream(duplex)
 * stream.writePB({
 *   foo: 'bar'
 * }, MessageType)
 * const res = await stream.readPB(MessageType)
 * ```
 */
function pbStream(duplex, opts = {}) {
    const shake = handshake(duplex);
    const lpReader = decode$a.fromReader(shake.reader, opts);
    const W = {
        read: async (bytes) => {
            // just read
            const { value } = await shake.reader.next(bytes);
            if (value == null) {
                throw new Error('Value is null');
            }
            return value;
        },
        readLP: async () => {
            // read, decode
            // @ts-expect-error .next is part of the generator interface
            const { value } = await lpReader.next();
            if (value == null) {
                throw new Error('Value is null');
            }
            return value;
        },
        readPB: async (proto) => {
            // readLP, decode
            const value = await W.readLP();
            if (value == null) {
                throw new Error('Value is null');
            }
            // Is this a buffer?
            const buf = value instanceof Uint8Array ? value : value.subarray();
            return proto.decode(buf);
        },
        write: (data) => {
            // just write
            if (data instanceof Uint8Array) {
                shake.writer.push(data);
            }
            else {
                shake.writer.push(data.subarray());
            }
        },
        writeLP: (data) => {
            // encode, write
            W.write(encode$b.single(data, opts));
        },
        writePB: (data, proto) => {
            // encode, writeLP
            W.writeLP(proto.encode(data));
        },
        pb: (proto) => {
            return {
                read: async () => await W.readPB(proto),
                write: (d) => { W.writePB(d, proto); }
            };
        },
        unwrap: () => {
            // returns vanilla duplex again, terminates all reads/writes from this object
            shake.rest();
            return shake.stream;
        }
    };
    return W;
}

/**
 * A pair of streams where one drains from the other
 */
function pair() {
    const deferred = pDefer$1();
    let piped = false;
    return {
        sink: async (source) => {
            if (piped) {
                throw new Error('already piped');
            }
            piped = true;
            deferred.resolve(source);
        },
        source: (async function* () {
            const source = await deferred.promise;
            yield* source;
        }())
    };
}

/**
 * Two duplex streams that are attached to each other
 */
function duplexPair() {
    const a = pair();
    const b = pair();
    return [
        {
            source: a.source,
            sink: b.sink
        },
        {
            source: b.source,
            sink: a.sink
        }
    ];
}

/**
 * Treat one or more iterables as a single iterable.
 *
 * Nb. sources are iterated over in parallel so the
 * order of emitted items is not guaranteed.
 */
async function* merge$1(...sources) {
    const output = pushable({
        objectMode: true
    });
    void Promise.resolve().then(async () => {
        try {
            await Promise.all(sources.map(async (source) => {
                for await (const item of source) {
                    output.push(item);
                }
            }));
            output.end();
        }
        catch (err) {
            output.end(err);
        }
    });
    yield* output;
}

const rawPipe = (...fns) => {
    let res;
    while (fns.length > 0) {
        res = fns.shift()(res);
    }
    return res;
};
const isIterable = (obj) => {
    return obj != null && (typeof obj[Symbol.asyncIterator] === 'function' ||
        typeof obj[Symbol.iterator] === 'function' ||
        typeof obj.next === 'function' // Probably, right?
    );
};
const isDuplex = (obj) => {
    return obj != null && typeof obj.sink === 'function' && isIterable(obj.source);
};
const duplexPipelineFn = (duplex) => {
    return (source) => {
        const p = duplex.sink(source);
        if (p.then != null) {
            const stream = pushable({
                objectMode: true
            });
            p.then(() => {
                stream.end();
            }, (err) => {
                stream.end(err);
            });
            const sourceWrap = async function* () {
                yield* duplex.source;
                stream.end();
            };
            return merge$1(stream, sourceWrap());
        }
        return duplex.source;
    };
};
function pipe(first, ...rest) {
    // Duplex at start: wrap in function and return duplex source
    if (isDuplex(first)) {
        const duplex = first;
        first = () => duplex.source;
        // Iterable at start: wrap in function
    }
    else if (isIterable(first)) {
        const source = first;
        first = () => source;
    }
    const fns = [first, ...rest];
    if (fns.length > 1) {
        // Duplex at end: use duplex sink
        if (isDuplex(fns[fns.length - 1])) {
            fns[fns.length - 1] = fns[fns.length - 1].sink;
        }
    }
    if (fns.length > 2) {
        // Duplex in the middle, consume source with duplex sink and return duplex source
        for (let i = 1; i < fns.length - 1; i++) {
            if (isDuplex(fns[i])) {
                fns[i] = duplexPipelineFn(fns[i]);
            }
        }
    }
    return rawPipe(...fns);
}

const NOISE_MSG_MAX_LENGTH_BYTES = 65535;
const NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG = NOISE_MSG_MAX_LENGTH_BYTES - 16;
const DUMP_SESSION_KEYS = Boolean(globalThis.process?.env?.DUMP_SESSION_KEYS);

var hkdf = {};

var hmac$2 = {};

var hash$2 = {};

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(hash$2, "__esModule", { value: true });
function isSerializableHash(h) {
    return (typeof h.saveState !== "undefined" &&
        typeof h.restoreState !== "undefined" &&
        typeof h.cleanSavedState !== "undefined");
}
hash$2.isSerializableHash = isSerializableHash;

var constantTime = {};

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(constantTime, "__esModule", { value: true });
/**
 * Package constant-time provides functions for performing algorithmically constant-time operations.
 */
/**
 * NOTE! Due to the inability to guarantee real constant time evaluation of
 * anything in JavaScript VM, this is module is the best effort.
 */
/**
 * Returns resultIfOne if subject is 1, or resultIfZero if subject is 0.
 *
 * Supports only 32-bit integers, so resultIfOne or resultIfZero are not
 * integers, they'll be converted to them with bitwise operations.
 */
function select$1(subject, resultIfOne, resultIfZero) {
    return (~(subject - 1) & resultIfOne) | ((subject - 1) & resultIfZero);
}
constantTime.select = select$1;
/**
 * Returns 1 if a <= b, or 0 if not.
 * Arguments must be positive 32-bit integers less than or equal to 2^31 - 1.
 */
function lessOrEqual(a, b) {
    return (((a | 0) - (b | 0) - 1) >>> 31) & 1;
}
constantTime.lessOrEqual = lessOrEqual;
/**
 * Returns 1 if a and b are of equal length and their contents
 * are equal, or 0 otherwise.
 *
 * Note that unlike in equal(), zero-length inputs are considered
 * the same, so this function will return 1.
 */
function compare(a, b) {
    if (a.length !== b.length) {
        return 0;
    }
    var result = 0;
    for (var i = 0; i < a.length; i++) {
        result |= a[i] ^ b[i];
    }
    return (1 & ((result - 1) >>> 8));
}
constantTime.compare = compare;
/**
 * Returns true if a and b are of equal non-zero length,
 * and their contents are equal, or false otherwise.
 *
 * Note that unlike in compare() zero-length inputs are considered
 * _not_ equal, so this function will return false.
 */
function equal(a, b) {
    if (a.length === 0 || b.length === 0) {
        return false;
    }
    return compare(a, b) !== 0;
}
constantTime.equal = equal;

var wipe$1 = {};

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(wipe$1, "__esModule", { value: true });
/**
 * Sets all values in the given array to zero and returns it.
 *
 * The fact that it sets bytes to zero can be relied on.
 *
 * There is no guarantee that this function makes data disappear from memory,
 * as runtime implementation can, for example, have copying garbage collector
 * that will make copies of sensitive data before we wipe it. Or that an
 * operating system will write our data to swap or sleep image. Another thing
 * is that an optimizing compiler can remove calls to this function or make it
 * no-op. There's nothing we can do with it, so we just do our best and hope
 * that everything will be okay and good will triumph over evil.
 */
function wipe(array) {
    // Right now it's similar to array.fill(0). If it turns
    // out that runtimes optimize this call away, maybe
    // we can try something else.
    for (var i = 0; i < array.length; i++) {
        array[i] = 0;
    }
    return array;
}
wipe$1.wipe = wipe;

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(hmac$2, "__esModule", { value: true });
/**
 * Package hmac implements HMAC algorithm.
 */
var hash_1 = hash$2;
var constant_time_1 = constantTime;
var wipe_1$3 = wipe$1;
/**
 *  HMAC implements hash-based message authentication algorithm.
 */
var HMAC = /** @class */ (function () {
    /**
     * Constructs a new HMAC with the given Hash and secret key.
     */
    function HMAC(hash, key) {
        this._finished = false; // true if HMAC was finalized
        // Initialize inner and outer hashes.
        this._inner = new hash();
        this._outer = new hash();
        // Set block and digest sizes for this HMAC
        // instance to values from the hash.
        this.blockSize = this._outer.blockSize;
        this.digestLength = this._outer.digestLength;
        // Pad temporary stores a key (or its hash) padded with zeroes.
        var pad = new Uint8Array(this.blockSize);
        if (key.length > this.blockSize) {
            // If key is bigger than hash block size, it must be
            // hashed and this hash is used as a key instead.
            this._inner.update(key).finish(pad).clean();
        }
        else {
            // Otherwise, copy the key into pad.
            pad.set(key);
        }
        // Now two different keys are derived from padded key
        // by xoring a different byte value to each.
        // To make inner hash key, xor byte 0x36 into pad.
        for (var i = 0; i < pad.length; i++) {
            pad[i] ^= 0x36;
        }
        // Update inner hash with the result.
        this._inner.update(pad);
        // To make outer hash key, xor byte 0x5c into pad.
        // But since we already xored 0x36 there, we must
        // first undo this by xoring it again.
        for (var i = 0; i < pad.length; i++) {
            pad[i] ^= 0x36 ^ 0x5c;
        }
        // Update outer hash with the result.
        this._outer.update(pad);
        // Save states of both hashes, so that we can quickly restore
        // them later in reset() without the need to remember the actual
        // key and perform this initialization again.
        if (hash_1.isSerializableHash(this._inner) && hash_1.isSerializableHash(this._outer)) {
            this._innerKeyedState = this._inner.saveState();
            this._outerKeyedState = this._outer.saveState();
        }
        // Clean pad.
        wipe_1$3.wipe(pad);
    }
    /**
     * Returns HMAC state to the state initialized with key
     * to make it possible to run HMAC over the other data with the same
     * key without creating a new instance.
     */
    HMAC.prototype.reset = function () {
        if (!hash_1.isSerializableHash(this._inner) || !hash_1.isSerializableHash(this._outer)) {
            throw new Error("hmac: can't reset() because hash doesn't implement restoreState()");
        }
        // Restore keyed states of inner and outer hashes.
        this._inner.restoreState(this._innerKeyedState);
        this._outer.restoreState(this._outerKeyedState);
        this._finished = false;
        return this;
    };
    /**
     * Cleans HMAC state.
     */
    HMAC.prototype.clean = function () {
        if (hash_1.isSerializableHash(this._inner)) {
            this._inner.cleanSavedState(this._innerKeyedState);
        }
        if (hash_1.isSerializableHash(this._outer)) {
            this._outer.cleanSavedState(this._outerKeyedState);
        }
        this._inner.clean();
        this._outer.clean();
    };
    /**
     * Updates state with provided data.
     */
    HMAC.prototype.update = function (data) {
        this._inner.update(data);
        return this;
    };
    /**
     * Finalizes HMAC and puts the result in out.
     */
    HMAC.prototype.finish = function (out) {
        if (this._finished) {
            // If HMAC was finalized, outer hash is also finalized,
            // so it produces the same digest it produced when it
            // was finalized.
            this._outer.finish(out);
            return this;
        }
        // Finalize inner hash and store the result temporarily.
        this._inner.finish(out);
        // Update outer hash with digest of inner hash and and finalize it.
        this._outer.update(out.subarray(0, this.digestLength)).finish(out);
        this._finished = true;
        return this;
    };
    /**
     * Returns the computed message authentication code.
     */
    HMAC.prototype.digest = function () {
        var out = new Uint8Array(this.digestLength);
        this.finish(out);
        return out;
    };
    /**
     * Saves HMAC state.
     * This function is needed for PBKDF2 optimization.
     */
    HMAC.prototype.saveState = function () {
        if (!hash_1.isSerializableHash(this._inner)) {
            throw new Error("hmac: can't saveState() because hash doesn't implement it");
        }
        return this._inner.saveState();
    };
    HMAC.prototype.restoreState = function (savedState) {
        if (!hash_1.isSerializableHash(this._inner) || !hash_1.isSerializableHash(this._outer)) {
            throw new Error("hmac: can't restoreState() because hash doesn't implement it");
        }
        this._inner.restoreState(savedState);
        this._outer.restoreState(this._outerKeyedState);
        this._finished = false;
        return this;
    };
    HMAC.prototype.cleanSavedState = function (savedState) {
        if (!hash_1.isSerializableHash(this._inner)) {
            throw new Error("hmac: can't cleanSavedState() because hash doesn't implement it");
        }
        this._inner.cleanSavedState(savedState);
    };
    return HMAC;
}());
hmac$2.HMAC = HMAC;
/**
 * Returns HMAC using the given hash constructor for the key over data.
 */
function hmac$1(hash, key, data) {
    var h = new HMAC(hash, key);
    h.update(data);
    var digest = h.digest();
    h.clean();
    return digest;
}
hmac$2.hmac = hmac$1;
/**
 * Returns true if two HMAC digests are equal.
 * Uses constant-time comparison to avoid leaking timing information.
 *
 * Example:
 *
 *    const receivedDigest = ...
 *    const realDigest = hmac(SHA256, key, data);
 *    if (!equal(receivedDigest, realDigest)) {
 *        throw new Error("Authentication error");
 *    }
 */
hmac$2.equal = constant_time_1.equal;

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(hkdf, "__esModule", { value: true });
var hmac_1 = hmac$2;
var wipe_1$2 = wipe$1;
/**
 * HMAC-based Extract-and-Expand Key Derivation Function.
 *
 * Implements HKDF from RFC5869.
 *
 * Expands the given master key with salt and info into
 * a limited stream of key material.
 */
var HKDF = /** @class */ (function () {
    /**
     * Create a new HKDF instance for the given hash function
     * with the master key, optional salt, and info.
     *
     * - Master key is a high-entropy secret key (not a password).
     * - Salt is a non-secret random value.
     * - Info is application- and/or context-specific information.
     */
    function HKDF(hash, key, salt, info) {
        if (salt === void 0) { salt = new Uint8Array(0); }
        this._counter = new Uint8Array(1); // starts with zero
        this._hash = hash;
        this._info = info;
        // HKDF-Extract uses salt as HMAC key, and key as data.
        var okm = hmac_1.hmac(this._hash, salt, key);
        // Initialize HMAC for expanding with extracted key.
        this._hmac = new hmac_1.HMAC(hash, okm);
        // Allocate buffer.
        this._buffer = new Uint8Array(this._hmac.digestLength);
        this._bufpos = this._buffer.length;
    }
    // Fill buffer with new block of HKDF-Extract output.
    HKDF.prototype._fillBuffer = function () {
        // Increment counter.
        this._counter[0]++;
        var ctr = this._counter[0];
        // Check if counter overflowed.
        if (ctr === 0) {
            throw new Error("hkdf: cannot expand more");
        }
        // Prepare HMAC instance for new data with old key.
        this._hmac.reset();
        // Hash in previous output if it was generated
        // (i.e. counter is greater than 1).
        if (ctr > 1) {
            this._hmac.update(this._buffer);
        }
        // Hash in info if it exists.
        if (this._info) {
            this._hmac.update(this._info);
        }
        // Hash in the counter.
        this._hmac.update(this._counter);
        // Output result to buffer and clean HMAC instance.
        this._hmac.finish(this._buffer);
        // Reset buffer position.
        this._bufpos = 0;
    };
    /**
     * Expand returns next key material of the given length.
     *
     * It throws if expansion limit is reached (which is
     * 254 digests of the underlying HMAC function).
     */
    HKDF.prototype.expand = function (length) {
        var out = new Uint8Array(length);
        for (var i = 0; i < out.length; i++) {
            if (this._bufpos === this._buffer.length) {
                this._fillBuffer();
            }
            out[i] = this._buffer[this._bufpos++];
        }
        return out;
    };
    HKDF.prototype.clean = function () {
        this._hmac.clean();
        wipe_1$2.wipe(this._buffer);
        wipe_1$2.wipe(this._counter);
        this._bufpos = 0;
    };
    return HKDF;
}());
var HKDF_1 = hkdf.HKDF = HKDF;

var x25519 = {};

var random = {};

var system = {};

var browser$3 = {};

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(browser$3, "__esModule", { value: true });
browser$3.BrowserRandomSource = void 0;
const QUOTA = 65536;
class BrowserRandomSource {
    constructor() {
        this.isAvailable = false;
        this.isInstantiated = false;
        const browserCrypto = typeof self !== 'undefined'
            ? (self.crypto || self.msCrypto) // IE11 has msCrypto
            : null;
        if (browserCrypto && browserCrypto.getRandomValues !== undefined) {
            this._crypto = browserCrypto;
            this.isAvailable = true;
            this.isInstantiated = true;
        }
    }
    randomBytes(length) {
        if (!this.isAvailable || !this._crypto) {
            throw new Error("Browser random byte generator is not available.");
        }
        const out = new Uint8Array(length);
        for (let i = 0; i < out.length; i += QUOTA) {
            this._crypto.getRandomValues(out.subarray(i, i + Math.min(out.length - i, QUOTA)));
        }
        return out;
    }
}
browser$3.BrowserRandomSource = BrowserRandomSource;

function commonjsRequire(path) {
	throw new Error('Could not dynamically require "' + path + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}

var node = {};

var _nodeResolve_empty = {};

var nodeCrypto = /*#__PURE__*/Object.freeze({
    __proto__: null,
    default: _nodeResolve_empty
});

var require$$1 = /*@__PURE__*/getAugmentedNamespace(nodeCrypto);

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(node, "__esModule", { value: true });
node.NodeRandomSource = void 0;
const wipe_1$1 = wipe$1;
class NodeRandomSource {
    constructor() {
        this.isAvailable = false;
        this.isInstantiated = false;
        if (typeof commonjsRequire !== "undefined") {
            const nodeCrypto = require$$1;
            if (nodeCrypto && nodeCrypto.randomBytes) {
                this._crypto = nodeCrypto;
                this.isAvailable = true;
                this.isInstantiated = true;
            }
        }
    }
    randomBytes(length) {
        if (!this.isAvailable || !this._crypto) {
            throw new Error("Node.js random byte generator is not available.");
        }
        // Get random bytes (result is Buffer).
        let buffer = this._crypto.randomBytes(length);
        // Make sure we got the length that we requested.
        if (buffer.length !== length) {
            throw new Error("NodeRandomSource: got fewer bytes than requested");
        }
        // Allocate output array.
        const out = new Uint8Array(length);
        // Copy bytes from buffer to output.
        for (let i = 0; i < out.length; i++) {
            out[i] = buffer[i];
        }
        // Cleanup.
        (0, wipe_1$1.wipe)(buffer);
        return out;
    }
}
node.NodeRandomSource = NodeRandomSource;

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(system, "__esModule", { value: true });
system.SystemRandomSource = void 0;
const browser_1 = browser$3;
const node_1 = node;
class SystemRandomSource {
    constructor() {
        this.isAvailable = false;
        this.name = "";
        // Try browser.
        this._source = new browser_1.BrowserRandomSource();
        if (this._source.isAvailable) {
            this.isAvailable = true;
            this.name = "Browser";
            return;
        }
        // If no browser source, try Node.
        this._source = new node_1.NodeRandomSource();
        if (this._source.isAvailable) {
            this.isAvailable = true;
            this.name = "Node";
            return;
        }
        // No sources, we're out of options.
    }
    randomBytes(length) {
        if (!this.isAvailable) {
            throw new Error("System random byte generator is not available.");
        }
        return this._source.randomBytes(length);
    }
}
system.SystemRandomSource = SystemRandomSource;

var binary = {};

var int = {};

(function (exports) {
	// Copyright (C) 2016 Dmitry Chestnykh
	// MIT License. See LICENSE file for details.
	Object.defineProperty(exports, "__esModule", { value: true });
	/**
	 * Package int provides helper functions for integerss.
	 */
	// Shim using 16-bit pieces.
	function imulShim(a, b) {
	    var ah = (a >>> 16) & 0xffff, al = a & 0xffff;
	    var bh = (b >>> 16) & 0xffff, bl = b & 0xffff;
	    return ((al * bl) + (((ah * bl + al * bh) << 16) >>> 0) | 0);
	}
	/** 32-bit integer multiplication.  */
	// Use system Math.imul if available, otherwise use our shim.
	exports.mul = Math.imul || imulShim;
	/** 32-bit integer addition.  */
	function add(a, b) {
	    return (a + b) | 0;
	}
	exports.add = add;
	/**  32-bit integer subtraction.  */
	function sub(a, b) {
	    return (a - b) | 0;
	}
	exports.sub = sub;
	/** 32-bit integer left rotation */
	function rotl(x, n) {
	    return x << n | x >>> (32 - n);
	}
	exports.rotl = rotl;
	/** 32-bit integer left rotation */
	function rotr(x, n) {
	    return x << (32 - n) | x >>> n;
	}
	exports.rotr = rotr;
	function isIntegerShim(n) {
	    return typeof n === "number" && isFinite(n) && Math.floor(n) === n;
	}
	/**
	 * Returns true if the argument is an integer number.
	 *
	 * In ES2015, Number.isInteger.
	 */
	exports.isInteger = Number.isInteger || isIntegerShim;
	/**
	 *  Math.pow(2, 53) - 1
	 *
	 *  In ES2015 Number.MAX_SAFE_INTEGER.
	 */
	exports.MAX_SAFE_INTEGER = 9007199254740991;
	/**
	 * Returns true if the argument is a safe integer number
	 * (-MIN_SAFE_INTEGER < number <= MAX_SAFE_INTEGER)
	 *
	 * In ES2015, Number.isSafeInteger.
	 */
	exports.isSafeInteger = function (n) {
	    return exports.isInteger(n) && (n >= -exports.MAX_SAFE_INTEGER && n <= exports.MAX_SAFE_INTEGER);
	};
	
} (int));

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(binary, "__esModule", { value: true });
/**
 * Package binary provides functions for encoding and decoding numbers in byte arrays.
 */
var int_1 = int;
// TODO(dchest): add asserts for correct value ranges and array offsets.
/**
 * Reads 2 bytes from array starting at offset as big-endian
 * signed 16-bit integer and returns it.
 */
function readInt16BE(array, offset) {
    if (offset === void 0) { offset = 0; }
    return (((array[offset + 0] << 8) | array[offset + 1]) << 16) >> 16;
}
binary.readInt16BE = readInt16BE;
/**
 * Reads 2 bytes from array starting at offset as big-endian
 * unsigned 16-bit integer and returns it.
 */
function readUint16BE(array, offset) {
    if (offset === void 0) { offset = 0; }
    return ((array[offset + 0] << 8) | array[offset + 1]) >>> 0;
}
binary.readUint16BE = readUint16BE;
/**
 * Reads 2 bytes from array starting at offset as little-endian
 * signed 16-bit integer and returns it.
 */
function readInt16LE(array, offset) {
    if (offset === void 0) { offset = 0; }
    return (((array[offset + 1] << 8) | array[offset]) << 16) >> 16;
}
binary.readInt16LE = readInt16LE;
/**
 * Reads 2 bytes from array starting at offset as little-endian
 * unsigned 16-bit integer and returns it.
 */
function readUint16LE(array, offset) {
    if (offset === void 0) { offset = 0; }
    return ((array[offset + 1] << 8) | array[offset]) >>> 0;
}
binary.readUint16LE = readUint16LE;
/**
 * Writes 2-byte big-endian representation of 16-bit unsigned
 * value to byte array starting at offset.
 *
 * If byte array is not given, creates a new 2-byte one.
 *
 * Returns the output byte array.
 */
function writeUint16BE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(2); }
    if (offset === void 0) { offset = 0; }
    out[offset + 0] = value >>> 8;
    out[offset + 1] = value >>> 0;
    return out;
}
binary.writeUint16BE = writeUint16BE;
binary.writeInt16BE = writeUint16BE;
/**
 * Writes 2-byte little-endian representation of 16-bit unsigned
 * value to array starting at offset.
 *
 * If byte array is not given, creates a new 2-byte one.
 *
 * Returns the output byte array.
 */
function writeUint16LE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(2); }
    if (offset === void 0) { offset = 0; }
    out[offset + 0] = value >>> 0;
    out[offset + 1] = value >>> 8;
    return out;
}
binary.writeUint16LE = writeUint16LE;
binary.writeInt16LE = writeUint16LE;
/**
 * Reads 4 bytes from array starting at offset as big-endian
 * signed 32-bit integer and returns it.
 */
function readInt32BE(array, offset) {
    if (offset === void 0) { offset = 0; }
    return (array[offset] << 24) |
        (array[offset + 1] << 16) |
        (array[offset + 2] << 8) |
        array[offset + 3];
}
binary.readInt32BE = readInt32BE;
/**
 * Reads 4 bytes from array starting at offset as big-endian
 * unsigned 32-bit integer and returns it.
 */
function readUint32BE(array, offset) {
    if (offset === void 0) { offset = 0; }
    return ((array[offset] << 24) |
        (array[offset + 1] << 16) |
        (array[offset + 2] << 8) |
        array[offset + 3]) >>> 0;
}
binary.readUint32BE = readUint32BE;
/**
 * Reads 4 bytes from array starting at offset as little-endian
 * signed 32-bit integer and returns it.
 */
function readInt32LE(array, offset) {
    if (offset === void 0) { offset = 0; }
    return (array[offset + 3] << 24) |
        (array[offset + 2] << 16) |
        (array[offset + 1] << 8) |
        array[offset];
}
binary.readInt32LE = readInt32LE;
/**
 * Reads 4 bytes from array starting at offset as little-endian
 * unsigned 32-bit integer and returns it.
 */
function readUint32LE(array, offset) {
    if (offset === void 0) { offset = 0; }
    return ((array[offset + 3] << 24) |
        (array[offset + 2] << 16) |
        (array[offset + 1] << 8) |
        array[offset]) >>> 0;
}
binary.readUint32LE = readUint32LE;
/**
 * Writes 4-byte big-endian representation of 32-bit unsigned
 * value to byte array starting at offset.
 *
 * If byte array is not given, creates a new 4-byte one.
 *
 * Returns the output byte array.
 */
function writeUint32BE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(4); }
    if (offset === void 0) { offset = 0; }
    out[offset + 0] = value >>> 24;
    out[offset + 1] = value >>> 16;
    out[offset + 2] = value >>> 8;
    out[offset + 3] = value >>> 0;
    return out;
}
binary.writeUint32BE = writeUint32BE;
binary.writeInt32BE = writeUint32BE;
/**
 * Writes 4-byte little-endian representation of 32-bit unsigned
 * value to array starting at offset.
 *
 * If byte array is not given, creates a new 4-byte one.
 *
 * Returns the output byte array.
 */
function writeUint32LE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(4); }
    if (offset === void 0) { offset = 0; }
    out[offset + 0] = value >>> 0;
    out[offset + 1] = value >>> 8;
    out[offset + 2] = value >>> 16;
    out[offset + 3] = value >>> 24;
    return out;
}
binary.writeUint32LE = writeUint32LE;
binary.writeInt32LE = writeUint32LE;
/**
 * Reads 8 bytes from array starting at offset as big-endian
 * signed 64-bit integer and returns it.
 *
 * IMPORTANT: due to JavaScript limitation, supports exact
 * numbers in range -9007199254740991 to 9007199254740991.
 * If the number stored in the byte array is outside this range,
 * the result is not exact.
 */
function readInt64BE(array, offset) {
    if (offset === void 0) { offset = 0; }
    var hi = readInt32BE(array, offset);
    var lo = readInt32BE(array, offset + 4);
    return hi * 0x100000000 + lo - ((lo >> 31) * 0x100000000);
}
binary.readInt64BE = readInt64BE;
/**
 * Reads 8 bytes from array starting at offset as big-endian
 * unsigned 64-bit integer and returns it.
 *
 * IMPORTANT: due to JavaScript limitation, supports values up to 2^53-1.
 */
function readUint64BE(array, offset) {
    if (offset === void 0) { offset = 0; }
    var hi = readUint32BE(array, offset);
    var lo = readUint32BE(array, offset + 4);
    return hi * 0x100000000 + lo;
}
binary.readUint64BE = readUint64BE;
/**
 * Reads 8 bytes from array starting at offset as little-endian
 * signed 64-bit integer and returns it.
 *
 * IMPORTANT: due to JavaScript limitation, supports exact
 * numbers in range -9007199254740991 to 9007199254740991.
 * If the number stored in the byte array is outside this range,
 * the result is not exact.
 */
function readInt64LE(array, offset) {
    if (offset === void 0) { offset = 0; }
    var lo = readInt32LE(array, offset);
    var hi = readInt32LE(array, offset + 4);
    return hi * 0x100000000 + lo - ((lo >> 31) * 0x100000000);
}
binary.readInt64LE = readInt64LE;
/**
 * Reads 8 bytes from array starting at offset as little-endian
 * unsigned 64-bit integer and returns it.
 *
 * IMPORTANT: due to JavaScript limitation, supports values up to 2^53-1.
 */
function readUint64LE(array, offset) {
    if (offset === void 0) { offset = 0; }
    var lo = readUint32LE(array, offset);
    var hi = readUint32LE(array, offset + 4);
    return hi * 0x100000000 + lo;
}
binary.readUint64LE = readUint64LE;
/**
 * Writes 8-byte big-endian representation of 64-bit unsigned
 * value to byte array starting at offset.
 *
 * Due to JavaScript limitation, supports values up to 2^53-1.
 *
 * If byte array is not given, creates a new 8-byte one.
 *
 * Returns the output byte array.
 */
function writeUint64BE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(8); }
    if (offset === void 0) { offset = 0; }
    writeUint32BE(value / 0x100000000 >>> 0, out, offset);
    writeUint32BE(value >>> 0, out, offset + 4);
    return out;
}
binary.writeUint64BE = writeUint64BE;
binary.writeInt64BE = writeUint64BE;
/**
 * Writes 8-byte little-endian representation of 64-bit unsigned
 * value to byte array starting at offset.
 *
 * Due to JavaScript limitation, supports values up to 2^53-1.
 *
 * If byte array is not given, creates a new 8-byte one.
 *
 * Returns the output byte array.
 */
function writeUint64LE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(8); }
    if (offset === void 0) { offset = 0; }
    writeUint32LE(value >>> 0, out, offset);
    writeUint32LE(value / 0x100000000 >>> 0, out, offset + 4);
    return out;
}
binary.writeUint64LE = writeUint64LE;
binary.writeInt64LE = writeUint64LE;
/**
 * Reads bytes from array starting at offset as big-endian
 * unsigned bitLen-bit integer and returns it.
 *
 * Supports bit lengths divisible by 8, up to 48.
 */
function readUintBE$1(bitLength, array, offset) {
    if (offset === void 0) { offset = 0; }
    // TODO(dchest): implement support for bitLengths non-divisible by 8
    if (bitLength % 8 !== 0) {
        throw new Error("readUintBE supports only bitLengths divisible by 8");
    }
    if (bitLength / 8 > array.length - offset) {
        throw new Error("readUintBE: array is too short for the given bitLength");
    }
    var result = 0;
    var mul = 1;
    for (var i = bitLength / 8 + offset - 1; i >= offset; i--) {
        result += array[i] * mul;
        mul *= 256;
    }
    return result;
}
binary.readUintBE = readUintBE$1;
/**
 * Reads bytes from array starting at offset as little-endian
 * unsigned bitLen-bit integer and returns it.
 *
 * Supports bit lengths divisible by 8, up to 48.
 */
function readUintLE$1(bitLength, array, offset) {
    if (offset === void 0) { offset = 0; }
    // TODO(dchest): implement support for bitLengths non-divisible by 8
    if (bitLength % 8 !== 0) {
        throw new Error("readUintLE supports only bitLengths divisible by 8");
    }
    if (bitLength / 8 > array.length - offset) {
        throw new Error("readUintLE: array is too short for the given bitLength");
    }
    var result = 0;
    var mul = 1;
    for (var i = offset; i < offset + bitLength / 8; i++) {
        result += array[i] * mul;
        mul *= 256;
    }
    return result;
}
binary.readUintLE = readUintLE$1;
/**
 * Writes a big-endian representation of bitLen-bit unsigned
 * value to array starting at offset.
 *
 * Supports bit lengths divisible by 8, up to 48.
 *
 * If byte array is not given, creates a new one.
 *
 * Returns the output byte array.
 */
function writeUintBE$1(bitLength, value, out, offset) {
    if (out === void 0) { out = new Uint8Array(bitLength / 8); }
    if (offset === void 0) { offset = 0; }
    // TODO(dchest): implement support for bitLengths non-divisible by 8
    if (bitLength % 8 !== 0) {
        throw new Error("writeUintBE supports only bitLengths divisible by 8");
    }
    if (!int_1.isSafeInteger(value)) {
        throw new Error("writeUintBE value must be an integer");
    }
    var div = 1;
    for (var i = bitLength / 8 + offset - 1; i >= offset; i--) {
        out[i] = (value / div) & 0xff;
        div *= 256;
    }
    return out;
}
binary.writeUintBE = writeUintBE$1;
/**
 * Writes a little-endian representation of bitLen-bit unsigned
 * value to array starting at offset.
 *
 * Supports bit lengths divisible by 8, up to 48.
 *
 * If byte array is not given, creates a new one.
 *
 * Returns the output byte array.
 */
function writeUintLE$1(bitLength, value, out, offset) {
    if (out === void 0) { out = new Uint8Array(bitLength / 8); }
    if (offset === void 0) { offset = 0; }
    // TODO(dchest): implement support for bitLengths non-divisible by 8
    if (bitLength % 8 !== 0) {
        throw new Error("writeUintLE supports only bitLengths divisible by 8");
    }
    if (!int_1.isSafeInteger(value)) {
        throw new Error("writeUintLE value must be an integer");
    }
    var div = 1;
    for (var i = offset; i < offset + bitLength / 8; i++) {
        out[i] = (value / div) & 0xff;
        div *= 256;
    }
    return out;
}
binary.writeUintLE = writeUintLE$1;
/**
 * Reads 4 bytes from array starting at offset as big-endian
 * 32-bit floating-point number and returns it.
 */
function readFloat32BE(array, offset) {
    if (offset === void 0) { offset = 0; }
    var view = new DataView(array.buffer, array.byteOffset, array.byteLength);
    return view.getFloat32(offset);
}
binary.readFloat32BE = readFloat32BE;
/**
 * Reads 4 bytes from array starting at offset as little-endian
 * 32-bit floating-point number and returns it.
 */
function readFloat32LE(array, offset) {
    if (offset === void 0) { offset = 0; }
    var view = new DataView(array.buffer, array.byteOffset, array.byteLength);
    return view.getFloat32(offset, true);
}
binary.readFloat32LE = readFloat32LE;
/**
 * Reads 8 bytes from array starting at offset as big-endian
 * 64-bit floating-point number ("double") and returns it.
 */
function readFloat64BE(array, offset) {
    if (offset === void 0) { offset = 0; }
    var view = new DataView(array.buffer, array.byteOffset, array.byteLength);
    return view.getFloat64(offset);
}
binary.readFloat64BE = readFloat64BE;
/**
 * Reads 8 bytes from array starting at offset as little-endian
 * 64-bit floating-point number ("double") and returns it.
 */
function readFloat64LE(array, offset) {
    if (offset === void 0) { offset = 0; }
    var view = new DataView(array.buffer, array.byteOffset, array.byteLength);
    return view.getFloat64(offset, true);
}
binary.readFloat64LE = readFloat64LE;
/**
 * Writes 4-byte big-endian floating-point representation of value
 * to byte array starting at offset.
 *
 * If byte array is not given, creates a new 4-byte one.
 *
 * Returns the output byte array.
 */
function writeFloat32BE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(4); }
    if (offset === void 0) { offset = 0; }
    var view = new DataView(out.buffer, out.byteOffset, out.byteLength);
    view.setFloat32(offset, value);
    return out;
}
binary.writeFloat32BE = writeFloat32BE;
/**
 * Writes 4-byte little-endian floating-point representation of value
 * to byte array starting at offset.
 *
 * If byte array is not given, creates a new 4-byte one.
 *
 * Returns the output byte array.
 */
function writeFloat32LE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(4); }
    if (offset === void 0) { offset = 0; }
    var view = new DataView(out.buffer, out.byteOffset, out.byteLength);
    view.setFloat32(offset, value, true);
    return out;
}
binary.writeFloat32LE = writeFloat32LE;
/**
 * Writes 8-byte big-endian floating-point representation of value
 * to byte array starting at offset.
 *
 * If byte array is not given, creates a new 8-byte one.
 *
 * Returns the output byte array.
 */
function writeFloat64BE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(8); }
    if (offset === void 0) { offset = 0; }
    var view = new DataView(out.buffer, out.byteOffset, out.byteLength);
    view.setFloat64(offset, value);
    return out;
}
binary.writeFloat64BE = writeFloat64BE;
/**
 * Writes 8-byte little-endian floating-point representation of value
 * to byte array starting at offset.
 *
 * If byte array is not given, creates a new 8-byte one.
 *
 * Returns the output byte array.
 */
function writeFloat64LE(value, out, offset) {
    if (out === void 0) { out = new Uint8Array(8); }
    if (offset === void 0) { offset = 0; }
    var view = new DataView(out.buffer, out.byteOffset, out.byteLength);
    view.setFloat64(offset, value, true);
    return out;
}
binary.writeFloat64LE = writeFloat64LE;

(function (exports) {
	// Copyright (C) 2016 Dmitry Chestnykh
	// MIT License. See LICENSE file for details.
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.randomStringForEntropy = exports.randomString = exports.randomUint32 = exports.randomBytes = exports.defaultRandomSource = void 0;
	const system_1 = system;
	const binary_1 = binary;
	const wipe_1 = wipe$1;
	exports.defaultRandomSource = new system_1.SystemRandomSource();
	function randomBytes(length, prng = exports.defaultRandomSource) {
	    return prng.randomBytes(length);
	}
	exports.randomBytes = randomBytes;
	/**
	 * Returns a uniformly random unsigned 32-bit integer.
	 */
	function randomUint32(prng = exports.defaultRandomSource) {
	    // Generate 4-byte random buffer.
	    const buf = randomBytes(4, prng);
	    // Convert bytes from buffer into a 32-bit integer.
	    // It's not important which byte order to use, since
	    // the result is random.
	    const result = (0, binary_1.readUint32LE)(buf);
	    // Clean the buffer.
	    (0, wipe_1.wipe)(buf);
	    return result;
	}
	exports.randomUint32 = randomUint32;
	/** 62 alphanumeric characters for default charset of randomString() */
	const ALPHANUMERIC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz";
	/**
	 * Returns a uniform random string of the given length
	 * with characters from the given charset.
	 *
	 * Charset must not have more than 256 characters.
	 *
	 * Default charset generates case-sensitive alphanumeric
	 * strings (0-9, A-Z, a-z).
	 */
	function randomString(length, charset = ALPHANUMERIC, prng = exports.defaultRandomSource) {
	    if (charset.length < 2) {
	        throw new Error("randomString charset is too short");
	    }
	    if (charset.length > 256) {
	        throw new Error("randomString charset is too long");
	    }
	    let out = '';
	    const charsLen = charset.length;
	    const maxByte = 256 - (256 % charsLen);
	    while (length > 0) {
	        const buf = randomBytes(Math.ceil(length * 256 / maxByte), prng);
	        for (let i = 0; i < buf.length && length > 0; i++) {
	            const randomByte = buf[i];
	            if (randomByte < maxByte) {
	                out += charset.charAt(randomByte % charsLen);
	                length--;
	            }
	        }
	        (0, wipe_1.wipe)(buf);
	    }
	    return out;
	}
	exports.randomString = randomString;
	/**
	 * Returns uniform random string containing at least the given
	 * number of bits of entropy.
	 *
	 * For example, randomStringForEntropy(128) will return a 22-character
	 * alphanumeric string, while randomStringForEntropy(128, "0123456789")
	 * will return a 39-character numeric string, both will contain at
	 * least 128 bits of entropy.
	 *
	 * Default charset generates case-sensitive alphanumeric
	 * strings (0-9, A-Z, a-z).
	 */
	function randomStringForEntropy(bits, charset = ALPHANUMERIC, prng = exports.defaultRandomSource) {
	    const length = Math.ceil(bits / (Math.log(charset.length) / Math.LN2));
	    return randomString(length, charset, prng);
	}
	exports.randomStringForEntropy = randomStringForEntropy;
	
} (random));

(function (exports) {
	// Copyright (C) 2016 Dmitry Chestnykh
	// MIT License. See LICENSE file for details.
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.sharedKey = exports.generateKeyPair = exports.generateKeyPairFromSeed = exports.scalarMultBase = exports.scalarMult = exports.SHARED_KEY_LENGTH = exports.SECRET_KEY_LENGTH = exports.PUBLIC_KEY_LENGTH = void 0;
	/**
	 * Package x25519 implements X25519 key agreement.
	 */
	const random_1 = random;
	const wipe_1 = wipe$1;
	exports.PUBLIC_KEY_LENGTH = 32;
	exports.SECRET_KEY_LENGTH = 32;
	exports.SHARED_KEY_LENGTH = 32;
	// Returns new zero-filled 16-element GF (Float64Array).
	// If passed an array of numbers, prefills the returned
	// array with them.
	//
	// We use Float64Array, because we need 48-bit numbers
	// for this implementation.
	function gf(init) {
	    const r = new Float64Array(16);
	    if (init) {
	        for (let i = 0; i < init.length; i++) {
	            r[i] = init[i];
	        }
	    }
	    return r;
	}
	// Base point.
	const _9 = new Uint8Array(32);
	_9[0] = 9;
	const _121665 = gf([0xdb41, 1]);
	function car25519(o) {
	    let c = 1;
	    for (let i = 0; i < 16; i++) {
	        let v = o[i] + c + 65535;
	        c = Math.floor(v / 65536);
	        o[i] = v - c * 65536;
	    }
	    o[0] += c - 1 + 37 * (c - 1);
	}
	function sel25519(p, q, b) {
	    const c = ~(b - 1);
	    for (let i = 0; i < 16; i++) {
	        const t = c & (p[i] ^ q[i]);
	        p[i] ^= t;
	        q[i] ^= t;
	    }
	}
	function pack25519(o, n) {
	    const m = gf();
	    const t = gf();
	    for (let i = 0; i < 16; i++) {
	        t[i] = n[i];
	    }
	    car25519(t);
	    car25519(t);
	    car25519(t);
	    for (let j = 0; j < 2; j++) {
	        m[0] = t[0] - 0xffed;
	        for (let i = 1; i < 15; i++) {
	            m[i] = t[i] - 0xffff - ((m[i - 1] >> 16) & 1);
	            m[i - 1] &= 0xffff;
	        }
	        m[15] = t[15] - 0x7fff - ((m[14] >> 16) & 1);
	        const b = (m[15] >> 16) & 1;
	        m[14] &= 0xffff;
	        sel25519(t, m, 1 - b);
	    }
	    for (let i = 0; i < 16; i++) {
	        o[2 * i] = t[i] & 0xff;
	        o[2 * i + 1] = t[i] >> 8;
	    }
	}
	function unpack25519(o, n) {
	    for (let i = 0; i < 16; i++) {
	        o[i] = n[2 * i] + (n[2 * i + 1] << 8);
	    }
	    o[15] &= 0x7fff;
	}
	function add(o, a, b) {
	    for (let i = 0; i < 16; i++) {
	        o[i] = a[i] + b[i];
	    }
	}
	function sub(o, a, b) {
	    for (let i = 0; i < 16; i++) {
	        o[i] = a[i] - b[i];
	    }
	}
	function mul(o, a, b) {
	    let v, c, t0 = 0, t1 = 0, t2 = 0, t3 = 0, t4 = 0, t5 = 0, t6 = 0, t7 = 0, t8 = 0, t9 = 0, t10 = 0, t11 = 0, t12 = 0, t13 = 0, t14 = 0, t15 = 0, t16 = 0, t17 = 0, t18 = 0, t19 = 0, t20 = 0, t21 = 0, t22 = 0, t23 = 0, t24 = 0, t25 = 0, t26 = 0, t27 = 0, t28 = 0, t29 = 0, t30 = 0, b0 = b[0], b1 = b[1], b2 = b[2], b3 = b[3], b4 = b[4], b5 = b[5], b6 = b[6], b7 = b[7], b8 = b[8], b9 = b[9], b10 = b[10], b11 = b[11], b12 = b[12], b13 = b[13], b14 = b[14], b15 = b[15];
	    v = a[0];
	    t0 += v * b0;
	    t1 += v * b1;
	    t2 += v * b2;
	    t3 += v * b3;
	    t4 += v * b4;
	    t5 += v * b5;
	    t6 += v * b6;
	    t7 += v * b7;
	    t8 += v * b8;
	    t9 += v * b9;
	    t10 += v * b10;
	    t11 += v * b11;
	    t12 += v * b12;
	    t13 += v * b13;
	    t14 += v * b14;
	    t15 += v * b15;
	    v = a[1];
	    t1 += v * b0;
	    t2 += v * b1;
	    t3 += v * b2;
	    t4 += v * b3;
	    t5 += v * b4;
	    t6 += v * b5;
	    t7 += v * b6;
	    t8 += v * b7;
	    t9 += v * b8;
	    t10 += v * b9;
	    t11 += v * b10;
	    t12 += v * b11;
	    t13 += v * b12;
	    t14 += v * b13;
	    t15 += v * b14;
	    t16 += v * b15;
	    v = a[2];
	    t2 += v * b0;
	    t3 += v * b1;
	    t4 += v * b2;
	    t5 += v * b3;
	    t6 += v * b4;
	    t7 += v * b5;
	    t8 += v * b6;
	    t9 += v * b7;
	    t10 += v * b8;
	    t11 += v * b9;
	    t12 += v * b10;
	    t13 += v * b11;
	    t14 += v * b12;
	    t15 += v * b13;
	    t16 += v * b14;
	    t17 += v * b15;
	    v = a[3];
	    t3 += v * b0;
	    t4 += v * b1;
	    t5 += v * b2;
	    t6 += v * b3;
	    t7 += v * b4;
	    t8 += v * b5;
	    t9 += v * b6;
	    t10 += v * b7;
	    t11 += v * b8;
	    t12 += v * b9;
	    t13 += v * b10;
	    t14 += v * b11;
	    t15 += v * b12;
	    t16 += v * b13;
	    t17 += v * b14;
	    t18 += v * b15;
	    v = a[4];
	    t4 += v * b0;
	    t5 += v * b1;
	    t6 += v * b2;
	    t7 += v * b3;
	    t8 += v * b4;
	    t9 += v * b5;
	    t10 += v * b6;
	    t11 += v * b7;
	    t12 += v * b8;
	    t13 += v * b9;
	    t14 += v * b10;
	    t15 += v * b11;
	    t16 += v * b12;
	    t17 += v * b13;
	    t18 += v * b14;
	    t19 += v * b15;
	    v = a[5];
	    t5 += v * b0;
	    t6 += v * b1;
	    t7 += v * b2;
	    t8 += v * b3;
	    t9 += v * b4;
	    t10 += v * b5;
	    t11 += v * b6;
	    t12 += v * b7;
	    t13 += v * b8;
	    t14 += v * b9;
	    t15 += v * b10;
	    t16 += v * b11;
	    t17 += v * b12;
	    t18 += v * b13;
	    t19 += v * b14;
	    t20 += v * b15;
	    v = a[6];
	    t6 += v * b0;
	    t7 += v * b1;
	    t8 += v * b2;
	    t9 += v * b3;
	    t10 += v * b4;
	    t11 += v * b5;
	    t12 += v * b6;
	    t13 += v * b7;
	    t14 += v * b8;
	    t15 += v * b9;
	    t16 += v * b10;
	    t17 += v * b11;
	    t18 += v * b12;
	    t19 += v * b13;
	    t20 += v * b14;
	    t21 += v * b15;
	    v = a[7];
	    t7 += v * b0;
	    t8 += v * b1;
	    t9 += v * b2;
	    t10 += v * b3;
	    t11 += v * b4;
	    t12 += v * b5;
	    t13 += v * b6;
	    t14 += v * b7;
	    t15 += v * b8;
	    t16 += v * b9;
	    t17 += v * b10;
	    t18 += v * b11;
	    t19 += v * b12;
	    t20 += v * b13;
	    t21 += v * b14;
	    t22 += v * b15;
	    v = a[8];
	    t8 += v * b0;
	    t9 += v * b1;
	    t10 += v * b2;
	    t11 += v * b3;
	    t12 += v * b4;
	    t13 += v * b5;
	    t14 += v * b6;
	    t15 += v * b7;
	    t16 += v * b8;
	    t17 += v * b9;
	    t18 += v * b10;
	    t19 += v * b11;
	    t20 += v * b12;
	    t21 += v * b13;
	    t22 += v * b14;
	    t23 += v * b15;
	    v = a[9];
	    t9 += v * b0;
	    t10 += v * b1;
	    t11 += v * b2;
	    t12 += v * b3;
	    t13 += v * b4;
	    t14 += v * b5;
	    t15 += v * b6;
	    t16 += v * b7;
	    t17 += v * b8;
	    t18 += v * b9;
	    t19 += v * b10;
	    t20 += v * b11;
	    t21 += v * b12;
	    t22 += v * b13;
	    t23 += v * b14;
	    t24 += v * b15;
	    v = a[10];
	    t10 += v * b0;
	    t11 += v * b1;
	    t12 += v * b2;
	    t13 += v * b3;
	    t14 += v * b4;
	    t15 += v * b5;
	    t16 += v * b6;
	    t17 += v * b7;
	    t18 += v * b8;
	    t19 += v * b9;
	    t20 += v * b10;
	    t21 += v * b11;
	    t22 += v * b12;
	    t23 += v * b13;
	    t24 += v * b14;
	    t25 += v * b15;
	    v = a[11];
	    t11 += v * b0;
	    t12 += v * b1;
	    t13 += v * b2;
	    t14 += v * b3;
	    t15 += v * b4;
	    t16 += v * b5;
	    t17 += v * b6;
	    t18 += v * b7;
	    t19 += v * b8;
	    t20 += v * b9;
	    t21 += v * b10;
	    t22 += v * b11;
	    t23 += v * b12;
	    t24 += v * b13;
	    t25 += v * b14;
	    t26 += v * b15;
	    v = a[12];
	    t12 += v * b0;
	    t13 += v * b1;
	    t14 += v * b2;
	    t15 += v * b3;
	    t16 += v * b4;
	    t17 += v * b5;
	    t18 += v * b6;
	    t19 += v * b7;
	    t20 += v * b8;
	    t21 += v * b9;
	    t22 += v * b10;
	    t23 += v * b11;
	    t24 += v * b12;
	    t25 += v * b13;
	    t26 += v * b14;
	    t27 += v * b15;
	    v = a[13];
	    t13 += v * b0;
	    t14 += v * b1;
	    t15 += v * b2;
	    t16 += v * b3;
	    t17 += v * b4;
	    t18 += v * b5;
	    t19 += v * b6;
	    t20 += v * b7;
	    t21 += v * b8;
	    t22 += v * b9;
	    t23 += v * b10;
	    t24 += v * b11;
	    t25 += v * b12;
	    t26 += v * b13;
	    t27 += v * b14;
	    t28 += v * b15;
	    v = a[14];
	    t14 += v * b0;
	    t15 += v * b1;
	    t16 += v * b2;
	    t17 += v * b3;
	    t18 += v * b4;
	    t19 += v * b5;
	    t20 += v * b6;
	    t21 += v * b7;
	    t22 += v * b8;
	    t23 += v * b9;
	    t24 += v * b10;
	    t25 += v * b11;
	    t26 += v * b12;
	    t27 += v * b13;
	    t28 += v * b14;
	    t29 += v * b15;
	    v = a[15];
	    t15 += v * b0;
	    t16 += v * b1;
	    t17 += v * b2;
	    t18 += v * b3;
	    t19 += v * b4;
	    t20 += v * b5;
	    t21 += v * b6;
	    t22 += v * b7;
	    t23 += v * b8;
	    t24 += v * b9;
	    t25 += v * b10;
	    t26 += v * b11;
	    t27 += v * b12;
	    t28 += v * b13;
	    t29 += v * b14;
	    t30 += v * b15;
	    t0 += 38 * t16;
	    t1 += 38 * t17;
	    t2 += 38 * t18;
	    t3 += 38 * t19;
	    t4 += 38 * t20;
	    t5 += 38 * t21;
	    t6 += 38 * t22;
	    t7 += 38 * t23;
	    t8 += 38 * t24;
	    t9 += 38 * t25;
	    t10 += 38 * t26;
	    t11 += 38 * t27;
	    t12 += 38 * t28;
	    t13 += 38 * t29;
	    t14 += 38 * t30;
	    // t15 left as is
	    // first car
	    c = 1;
	    v = t0 + c + 65535;
	    c = Math.floor(v / 65536);
	    t0 = v - c * 65536;
	    v = t1 + c + 65535;
	    c = Math.floor(v / 65536);
	    t1 = v - c * 65536;
	    v = t2 + c + 65535;
	    c = Math.floor(v / 65536);
	    t2 = v - c * 65536;
	    v = t3 + c + 65535;
	    c = Math.floor(v / 65536);
	    t3 = v - c * 65536;
	    v = t4 + c + 65535;
	    c = Math.floor(v / 65536);
	    t4 = v - c * 65536;
	    v = t5 + c + 65535;
	    c = Math.floor(v / 65536);
	    t5 = v - c * 65536;
	    v = t6 + c + 65535;
	    c = Math.floor(v / 65536);
	    t6 = v - c * 65536;
	    v = t7 + c + 65535;
	    c = Math.floor(v / 65536);
	    t7 = v - c * 65536;
	    v = t8 + c + 65535;
	    c = Math.floor(v / 65536);
	    t8 = v - c * 65536;
	    v = t9 + c + 65535;
	    c = Math.floor(v / 65536);
	    t9 = v - c * 65536;
	    v = t10 + c + 65535;
	    c = Math.floor(v / 65536);
	    t10 = v - c * 65536;
	    v = t11 + c + 65535;
	    c = Math.floor(v / 65536);
	    t11 = v - c * 65536;
	    v = t12 + c + 65535;
	    c = Math.floor(v / 65536);
	    t12 = v - c * 65536;
	    v = t13 + c + 65535;
	    c = Math.floor(v / 65536);
	    t13 = v - c * 65536;
	    v = t14 + c + 65535;
	    c = Math.floor(v / 65536);
	    t14 = v - c * 65536;
	    v = t15 + c + 65535;
	    c = Math.floor(v / 65536);
	    t15 = v - c * 65536;
	    t0 += c - 1 + 37 * (c - 1);
	    // second car
	    c = 1;
	    v = t0 + c + 65535;
	    c = Math.floor(v / 65536);
	    t0 = v - c * 65536;
	    v = t1 + c + 65535;
	    c = Math.floor(v / 65536);
	    t1 = v - c * 65536;
	    v = t2 + c + 65535;
	    c = Math.floor(v / 65536);
	    t2 = v - c * 65536;
	    v = t3 + c + 65535;
	    c = Math.floor(v / 65536);
	    t3 = v - c * 65536;
	    v = t4 + c + 65535;
	    c = Math.floor(v / 65536);
	    t4 = v - c * 65536;
	    v = t5 + c + 65535;
	    c = Math.floor(v / 65536);
	    t5 = v - c * 65536;
	    v = t6 + c + 65535;
	    c = Math.floor(v / 65536);
	    t6 = v - c * 65536;
	    v = t7 + c + 65535;
	    c = Math.floor(v / 65536);
	    t7 = v - c * 65536;
	    v = t8 + c + 65535;
	    c = Math.floor(v / 65536);
	    t8 = v - c * 65536;
	    v = t9 + c + 65535;
	    c = Math.floor(v / 65536);
	    t9 = v - c * 65536;
	    v = t10 + c + 65535;
	    c = Math.floor(v / 65536);
	    t10 = v - c * 65536;
	    v = t11 + c + 65535;
	    c = Math.floor(v / 65536);
	    t11 = v - c * 65536;
	    v = t12 + c + 65535;
	    c = Math.floor(v / 65536);
	    t12 = v - c * 65536;
	    v = t13 + c + 65535;
	    c = Math.floor(v / 65536);
	    t13 = v - c * 65536;
	    v = t14 + c + 65535;
	    c = Math.floor(v / 65536);
	    t14 = v - c * 65536;
	    v = t15 + c + 65535;
	    c = Math.floor(v / 65536);
	    t15 = v - c * 65536;
	    t0 += c - 1 + 37 * (c - 1);
	    o[0] = t0;
	    o[1] = t1;
	    o[2] = t2;
	    o[3] = t3;
	    o[4] = t4;
	    o[5] = t5;
	    o[6] = t6;
	    o[7] = t7;
	    o[8] = t8;
	    o[9] = t9;
	    o[10] = t10;
	    o[11] = t11;
	    o[12] = t12;
	    o[13] = t13;
	    o[14] = t14;
	    o[15] = t15;
	}
	function square(o, a) {
	    mul(o, a, a);
	}
	function inv25519(o, inp) {
	    const c = gf();
	    for (let i = 0; i < 16; i++) {
	        c[i] = inp[i];
	    }
	    for (let i = 253; i >= 0; i--) {
	        square(c, c);
	        if (i !== 2 && i !== 4) {
	            mul(c, c, inp);
	        }
	    }
	    for (let i = 0; i < 16; i++) {
	        o[i] = c[i];
	    }
	}
	function scalarMult(n, p) {
	    const z = new Uint8Array(32);
	    const x = new Float64Array(80);
	    const a = gf(), b = gf(), c = gf(), d = gf(), e = gf(), f = gf();
	    for (let i = 0; i < 31; i++) {
	        z[i] = n[i];
	    }
	    z[31] = (n[31] & 127) | 64;
	    z[0] &= 248;
	    unpack25519(x, p);
	    for (let i = 0; i < 16; i++) {
	        b[i] = x[i];
	    }
	    a[0] = d[0] = 1;
	    for (let i = 254; i >= 0; --i) {
	        const r = (z[i >>> 3] >>> (i & 7)) & 1;
	        sel25519(a, b, r);
	        sel25519(c, d, r);
	        add(e, a, c);
	        sub(a, a, c);
	        add(c, b, d);
	        sub(b, b, d);
	        square(d, e);
	        square(f, a);
	        mul(a, c, a);
	        mul(c, b, e);
	        add(e, a, c);
	        sub(a, a, c);
	        square(b, a);
	        sub(c, d, f);
	        mul(a, c, _121665);
	        add(a, a, d);
	        mul(c, c, a);
	        mul(a, d, f);
	        mul(d, b, x);
	        square(b, e);
	        sel25519(a, b, r);
	        sel25519(c, d, r);
	    }
	    for (let i = 0; i < 16; i++) {
	        x[i + 16] = a[i];
	        x[i + 32] = c[i];
	        x[i + 48] = b[i];
	        x[i + 64] = d[i];
	    }
	    const x32 = x.subarray(32);
	    const x16 = x.subarray(16);
	    inv25519(x32, x32);
	    mul(x16, x16, x32);
	    const q = new Uint8Array(32);
	    pack25519(q, x16);
	    return q;
	}
	exports.scalarMult = scalarMult;
	function scalarMultBase(n) {
	    return scalarMult(n, _9);
	}
	exports.scalarMultBase = scalarMultBase;
	function generateKeyPairFromSeed(seed) {
	    if (seed.length !== exports.SECRET_KEY_LENGTH) {
	        throw new Error(`x25519: seed must be ${exports.SECRET_KEY_LENGTH} bytes`);
	    }
	    const secretKey = new Uint8Array(seed);
	    const publicKey = scalarMultBase(secretKey);
	    return {
	        publicKey,
	        secretKey
	    };
	}
	exports.generateKeyPairFromSeed = generateKeyPairFromSeed;
	function generateKeyPair(prng) {
	    const seed = (0, random_1.randomBytes)(32, prng);
	    const result = generateKeyPairFromSeed(seed);
	    (0, wipe_1.wipe)(seed);
	    return result;
	}
	exports.generateKeyPair = generateKeyPair;
	/**
	 * Returns a shared key between our secret key and a peer's public key.
	 *
	 * Throws an error if the given keys are of wrong length.
	 *
	 * If rejectZero is true throws if the calculated shared key is all-zero.
	 * From RFC 7748:
	 *
	 * > Protocol designers using Diffie-Hellman over the curves defined in
	 * > this document must not assume "contributory behavior".  Specially,
	 * > contributory behavior means that both parties' private keys
	 * > contribute to the resulting shared key.  Since curve25519 and
	 * > curve448 have cofactors of 8 and 4 (respectively), an input point of
	 * > small order will eliminate any contribution from the other party's
	 * > private key.  This situation can be detected by checking for the all-
	 * > zero output, which implementations MAY do, as specified in Section 6.
	 * > However, a large number of existing implementations do not do this.
	 *
	 * IMPORTANT: the returned key is a raw result of scalar multiplication.
	 * To use it as a key material, hash it with a cryptographic hash function.
	 */
	function sharedKey(mySecretKey, theirPublicKey, rejectZero = false) {
	    if (mySecretKey.length !== exports.PUBLIC_KEY_LENGTH) {
	        throw new Error("X25519: incorrect secret key length");
	    }
	    if (theirPublicKey.length !== exports.PUBLIC_KEY_LENGTH) {
	        throw new Error("X25519: incorrect public key length");
	    }
	    const result = scalarMult(mySecretKey, theirPublicKey);
	    if (rejectZero) {
	        let zeros = 0;
	        for (let i = 0; i < result.length; i++) {
	            zeros |= result[i];
	        }
	        if (zeros === 0) {
	            throw new Error("X25519: invalid shared key");
	        }
	    }
	    return result;
	}
	exports.sharedKey = sharedKey;
	
} (x25519));

var sha256$2 = {};

(function (exports) {
	// Copyright (C) 2016 Dmitry Chestnykh
	// MIT License. See LICENSE file for details.
	Object.defineProperty(exports, "__esModule", { value: true });
	var binary_1 = binary;
	var wipe_1 = wipe$1;
	exports.DIGEST_LENGTH = 32;
	exports.BLOCK_SIZE = 64;
	/**
	 * SHA2-256 cryptographic hash algorithm.
	 */
	var SHA256 = /** @class */ (function () {
	    function SHA256() {
	        /** Length of hash output */
	        this.digestLength = exports.DIGEST_LENGTH;
	        /** Block size */
	        this.blockSize = exports.BLOCK_SIZE;
	        // Note: Int32Array is used instead of Uint32Array for performance reasons.
	        this._state = new Int32Array(8); // hash state
	        this._temp = new Int32Array(64); // temporary state
	        this._buffer = new Uint8Array(128); // buffer for data to hash
	        this._bufferLength = 0; // number of bytes in buffer
	        this._bytesHashed = 0; // number of total bytes hashed
	        this._finished = false; // indicates whether the hash was finalized
	        this.reset();
	    }
	    SHA256.prototype._initState = function () {
	        this._state[0] = 0x6a09e667;
	        this._state[1] = 0xbb67ae85;
	        this._state[2] = 0x3c6ef372;
	        this._state[3] = 0xa54ff53a;
	        this._state[4] = 0x510e527f;
	        this._state[5] = 0x9b05688c;
	        this._state[6] = 0x1f83d9ab;
	        this._state[7] = 0x5be0cd19;
	    };
	    /**
	     * Resets hash state making it possible
	     * to re-use this instance to hash other data.
	     */
	    SHA256.prototype.reset = function () {
	        this._initState();
	        this._bufferLength = 0;
	        this._bytesHashed = 0;
	        this._finished = false;
	        return this;
	    };
	    /**
	     * Cleans internal buffers and resets hash state.
	     */
	    SHA256.prototype.clean = function () {
	        wipe_1.wipe(this._buffer);
	        wipe_1.wipe(this._temp);
	        this.reset();
	    };
	    /**
	     * Updates hash state with the given data.
	     *
	     * Throws error when trying to update already finalized hash:
	     * instance must be reset to update it again.
	     */
	    SHA256.prototype.update = function (data, dataLength) {
	        if (dataLength === void 0) { dataLength = data.length; }
	        if (this._finished) {
	            throw new Error("SHA256: can't update because hash was finished.");
	        }
	        var dataPos = 0;
	        this._bytesHashed += dataLength;
	        if (this._bufferLength > 0) {
	            while (this._bufferLength < this.blockSize && dataLength > 0) {
	                this._buffer[this._bufferLength++] = data[dataPos++];
	                dataLength--;
	            }
	            if (this._bufferLength === this.blockSize) {
	                hashBlocks(this._temp, this._state, this._buffer, 0, this.blockSize);
	                this._bufferLength = 0;
	            }
	        }
	        if (dataLength >= this.blockSize) {
	            dataPos = hashBlocks(this._temp, this._state, data, dataPos, dataLength);
	            dataLength %= this.blockSize;
	        }
	        while (dataLength > 0) {
	            this._buffer[this._bufferLength++] = data[dataPos++];
	            dataLength--;
	        }
	        return this;
	    };
	    /**
	     * Finalizes hash state and puts hash into out.
	     * If hash was already finalized, puts the same value.
	     */
	    SHA256.prototype.finish = function (out) {
	        if (!this._finished) {
	            var bytesHashed = this._bytesHashed;
	            var left = this._bufferLength;
	            var bitLenHi = (bytesHashed / 0x20000000) | 0;
	            var bitLenLo = bytesHashed << 3;
	            var padLength = (bytesHashed % 64 < 56) ? 64 : 128;
	            this._buffer[left] = 0x80;
	            for (var i = left + 1; i < padLength - 8; i++) {
	                this._buffer[i] = 0;
	            }
	            binary_1.writeUint32BE(bitLenHi, this._buffer, padLength - 8);
	            binary_1.writeUint32BE(bitLenLo, this._buffer, padLength - 4);
	            hashBlocks(this._temp, this._state, this._buffer, 0, padLength);
	            this._finished = true;
	        }
	        for (var i = 0; i < this.digestLength / 4; i++) {
	            binary_1.writeUint32BE(this._state[i], out, i * 4);
	        }
	        return this;
	    };
	    /**
	     * Returns the final hash digest.
	     */
	    SHA256.prototype.digest = function () {
	        var out = new Uint8Array(this.digestLength);
	        this.finish(out);
	        return out;
	    };
	    /**
	     * Function useful for HMAC/PBKDF2 optimization.
	     * Returns hash state to be used with restoreState().
	     * Only chain value is saved, not buffers or other
	     * state variables.
	     */
	    SHA256.prototype.saveState = function () {
	        if (this._finished) {
	            throw new Error("SHA256: cannot save finished state");
	        }
	        return {
	            state: new Int32Array(this._state),
	            buffer: this._bufferLength > 0 ? new Uint8Array(this._buffer) : undefined,
	            bufferLength: this._bufferLength,
	            bytesHashed: this._bytesHashed
	        };
	    };
	    /**
	     * Function useful for HMAC/PBKDF2 optimization.
	     * Restores state saved by saveState() and sets bytesHashed
	     * to the given value.
	     */
	    SHA256.prototype.restoreState = function (savedState) {
	        this._state.set(savedState.state);
	        this._bufferLength = savedState.bufferLength;
	        if (savedState.buffer) {
	            this._buffer.set(savedState.buffer);
	        }
	        this._bytesHashed = savedState.bytesHashed;
	        this._finished = false;
	        return this;
	    };
	    /**
	     * Cleans state returned by saveState().
	     */
	    SHA256.prototype.cleanSavedState = function (savedState) {
	        wipe_1.wipe(savedState.state);
	        if (savedState.buffer) {
	            wipe_1.wipe(savedState.buffer);
	        }
	        savedState.bufferLength = 0;
	        savedState.bytesHashed = 0;
	    };
	    return SHA256;
	}());
	exports.SHA256 = SHA256;
	// Constants
	var K = new Int32Array([
	    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b,
	    0x59f111f1, 0x923f82a4, 0xab1c5ed5, 0xd807aa98, 0x12835b01,
	    0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7,
	    0xc19bf174, 0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,
	    0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da, 0x983e5152,
	    0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147,
	    0x06ca6351, 0x14292967, 0x27b70a85, 0x2e1b2138, 0x4d2c6dfc,
	    0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
	    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819,
	    0xd6990624, 0xf40e3585, 0x106aa070, 0x19a4c116, 0x1e376c08,
	    0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f,
	    0x682e6ff3, 0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
	    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
	]);
	function hashBlocks(w, v, p, pos, len) {
	    while (len >= 64) {
	        var a = v[0];
	        var b = v[1];
	        var c = v[2];
	        var d = v[3];
	        var e = v[4];
	        var f = v[5];
	        var g = v[6];
	        var h = v[7];
	        for (var i = 0; i < 16; i++) {
	            var j = pos + i * 4;
	            w[i] = binary_1.readUint32BE(p, j);
	        }
	        for (var i = 16; i < 64; i++) {
	            var u = w[i - 2];
	            var t1 = (u >>> 17 | u << (32 - 17)) ^ (u >>> 19 | u << (32 - 19)) ^ (u >>> 10);
	            u = w[i - 15];
	            var t2 = (u >>> 7 | u << (32 - 7)) ^ (u >>> 18 | u << (32 - 18)) ^ (u >>> 3);
	            w[i] = (t1 + w[i - 7] | 0) + (t2 + w[i - 16] | 0);
	        }
	        for (var i = 0; i < 64; i++) {
	            var t1 = (((((e >>> 6 | e << (32 - 6)) ^ (e >>> 11 | e << (32 - 11)) ^
	                (e >>> 25 | e << (32 - 25))) + ((e & f) ^ (~e & g))) | 0) +
	                ((h + ((K[i] + w[i]) | 0)) | 0)) | 0;
	            var t2 = (((a >>> 2 | a << (32 - 2)) ^ (a >>> 13 | a << (32 - 13)) ^
	                (a >>> 22 | a << (32 - 22))) + ((a & b) ^ (a & c) ^ (b & c))) | 0;
	            h = g;
	            g = f;
	            f = e;
	            e = (d + t1) | 0;
	            d = c;
	            c = b;
	            b = a;
	            a = (t1 + t2) | 0;
	        }
	        v[0] += a;
	        v[1] += b;
	        v[2] += c;
	        v[3] += d;
	        v[4] += e;
	        v[5] += f;
	        v[6] += g;
	        v[7] += h;
	        pos += 64;
	        len -= 64;
	    }
	    return pos;
	}
	function hash(data) {
	    var h = new SHA256();
	    h.update(data);
	    var digest = h.digest();
	    h.clean();
	    return digest;
	}
	exports.hash = hash;
	
} (sha256$2));

var chacha20poly1305 = {};

var chacha = {};

// Copyright (C) 2016 Dmitry Chestnykh
// MIT License. See LICENSE file for details.
Object.defineProperty(chacha, "__esModule", { value: true });
/**
 * Package chacha implements ChaCha stream cipher.
 */
var binary_1 = binary;
var wipe_1 = wipe$1;
// Number of ChaCha rounds (ChaCha20).
var ROUNDS = 20;
// Applies the ChaCha core function to 16-byte input,
// 32-byte key key, and puts the result into 64-byte array out.
function core(out, input, key) {
    var j0 = 0x61707865; // "expa"  -- ChaCha's "sigma" constant
    var j1 = 0x3320646E; // "nd 3"     for 32-byte keys
    var j2 = 0x79622D32; // "2-by"
    var j3 = 0x6B206574; // "te k"
    var j4 = (key[3] << 24) | (key[2] << 16) | (key[1] << 8) | key[0];
    var j5 = (key[7] << 24) | (key[6] << 16) | (key[5] << 8) | key[4];
    var j6 = (key[11] << 24) | (key[10] << 16) | (key[9] << 8) | key[8];
    var j7 = (key[15] << 24) | (key[14] << 16) | (key[13] << 8) | key[12];
    var j8 = (key[19] << 24) | (key[18] << 16) | (key[17] << 8) | key[16];
    var j9 = (key[23] << 24) | (key[22] << 16) | (key[21] << 8) | key[20];
    var j10 = (key[27] << 24) | (key[26] << 16) | (key[25] << 8) | key[24];
    var j11 = (key[31] << 24) | (key[30] << 16) | (key[29] << 8) | key[28];
    var j12 = (input[3] << 24) | (input[2] << 16) | (input[1] << 8) | input[0];
    var j13 = (input[7] << 24) | (input[6] << 16) | (input[5] << 8) | input[4];
    var j14 = (input[11] << 24) | (input[10] << 16) | (input[9] << 8) | input[8];
    var j15 = (input[15] << 24) | (input[14] << 16) | (input[13] << 8) | input[12];
    var x0 = j0;
    var x1 = j1;
    var x2 = j2;
    var x3 = j3;
    var x4 = j4;
    var x5 = j5;
    var x6 = j6;
    var x7 = j7;
    var x8 = j8;
    var x9 = j9;
    var x10 = j10;
    var x11 = j11;
    var x12 = j12;
    var x13 = j13;
    var x14 = j14;
    var x15 = j15;
    for (var i = 0; i < ROUNDS; i += 2) {
        x0 = x0 + x4 | 0;
        x12 ^= x0;
        x12 = x12 >>> (32 - 16) | x12 << 16;
        x8 = x8 + x12 | 0;
        x4 ^= x8;
        x4 = x4 >>> (32 - 12) | x4 << 12;
        x1 = x1 + x5 | 0;
        x13 ^= x1;
        x13 = x13 >>> (32 - 16) | x13 << 16;
        x9 = x9 + x13 | 0;
        x5 ^= x9;
        x5 = x5 >>> (32 - 12) | x5 << 12;
        x2 = x2 + x6 | 0;
        x14 ^= x2;
        x14 = x14 >>> (32 - 16) | x14 << 16;
        x10 = x10 + x14 | 0;
        x6 ^= x10;
        x6 = x6 >>> (32 - 12) | x6 << 12;
        x3 = x3 + x7 | 0;
        x15 ^= x3;
        x15 = x15 >>> (32 - 16) | x15 << 16;
        x11 = x11 + x15 | 0;
        x7 ^= x11;
        x7 = x7 >>> (32 - 12) | x7 << 12;
        x2 = x2 + x6 | 0;
        x14 ^= x2;
        x14 = x14 >>> (32 - 8) | x14 << 8;
        x10 = x10 + x14 | 0;
        x6 ^= x10;
        x6 = x6 >>> (32 - 7) | x6 << 7;
        x3 = x3 + x7 | 0;
        x15 ^= x3;
        x15 = x15 >>> (32 - 8) | x15 << 8;
        x11 = x11 + x15 | 0;
        x7 ^= x11;
        x7 = x7 >>> (32 - 7) | x7 << 7;
        x1 = x1 + x5 | 0;
        x13 ^= x1;
        x13 = x13 >>> (32 - 8) | x13 << 8;
        x9 = x9 + x13 | 0;
        x5 ^= x9;
        x5 = x5 >>> (32 - 7) | x5 << 7;
        x0 = x0 + x4 | 0;
        x12 ^= x0;
        x12 = x12 >>> (32 - 8) | x12 << 8;
        x8 = x8 + x12 | 0;
        x4 ^= x8;
        x4 = x4 >>> (32 - 7) | x4 << 7;
        x0 = x0 + x5 | 0;
        x15 ^= x0;
        x15 = x15 >>> (32 - 16) | x15 << 16;
        x10 = x10 + x15 | 0;
        x5 ^= x10;
        x5 = x5 >>> (32 - 12) | x5 << 12;
        x1 = x1 + x6 | 0;
        x12 ^= x1;
        x12 = x12 >>> (32 - 16) | x12 << 16;
        x11 = x11 + x12 | 0;
        x6 ^= x11;
        x6 = x6 >>> (32 - 12) | x6 << 12;
        x2 = x2 + x7 | 0;
        x13 ^= x2;
        x13 = x13 >>> (32 - 16) | x13 << 16;
        x8 = x8 + x13 | 0;
        x7 ^= x8;
        x7 = x7 >>> (32 - 12) | x7 << 12;
        x3 = x3 + x4 | 0;
        x14 ^= x3;
        x14 = x14 >>> (32 - 16) | x14 << 16;
        x9 = x9 + x14 | 0;
        x4 ^= x9;
        x4 = x4 >>> (32 - 12) | x4 << 12;
        x2 = x2 + x7 | 0;
        x13 ^= x2;
        x13 = x13 >>> (32 - 8) | x13 << 8;
        x8 = x8 + x13 | 0;
        x7 ^= x8;
        x7 = x7 >>> (32 - 7) | x7 << 7;
        x3 = x3 + x4 | 0;
        x14 ^= x3;
        x14 = x14 >>> (32 - 8) | x14 << 8;
        x9 = x9 + x14 | 0;
        x4 ^= x9;
        x4 = x4 >>> (32 - 7) | x4 << 7;
        x1 = x1 + x6 | 0;
        x12 ^= x1;
        x12 = x12 >>> (32 - 8) | x12 << 8;
        x11 = x11 + x12 | 0;
        x6 ^= x11;
        x6 = x6 >>> (32 - 7) | x6 << 7;
        x0 = x0 + x5 | 0;
        x15 ^= x0;
        x15 = x15 >>> (32 - 8) | x15 << 8;
        x10 = x10 + x15 | 0;
        x5 ^= x10;
        x5 = x5 >>> (32 - 7) | x5 << 7;
    }
    binary_1.writeUint32LE(x0 + j0 | 0, out, 0);
    binary_1.writeUint32LE(x1 + j1 | 0, out, 4);
    binary_1.writeUint32LE(x2 + j2 | 0, out, 8);
    binary_1.writeUint32LE(x3 + j3 | 0, out, 12);
    binary_1.writeUint32LE(x4 + j4 | 0, out, 16);
    binary_1.writeUint32LE(x5 + j5 | 0, out, 20);
    binary_1.writeUint32LE(x6 + j6 | 0, out, 24);
    binary_1.writeUint32LE(x7 + j7 | 0, out, 28);
    binary_1.writeUint32LE(x8 + j8 | 0, out, 32);
    binary_1.writeUint32LE(x9 + j9 | 0, out, 36);
    binary_1.writeUint32LE(x10 + j10 | 0, out, 40);
    binary_1.writeUint32LE(x11 + j11 | 0, out, 44);
    binary_1.writeUint32LE(x12 + j12 | 0, out, 48);
    binary_1.writeUint32LE(x13 + j13 | 0, out, 52);
    binary_1.writeUint32LE(x14 + j14 | 0, out, 56);
    binary_1.writeUint32LE(x15 + j15 | 0, out, 60);
}
/**
 * Encrypt src with ChaCha20 stream generated for the given 32-byte key and
 * 8-byte (as in original implementation) or 12-byte (as in RFC7539) nonce and
 * write the result into dst and return it.
 *
 * dst and src may be the same, but otherwise must not overlap.
 *
 * If nonce is 12 bytes, users should not encrypt more than 256 GiB with the
 * same key and nonce, otherwise the stream will repeat. The function will
 * throw error if counter overflows to prevent this.
 *
 * If nonce is 8 bytes, the output is practically unlimited (2^70 bytes, which
 * is more than a million petabytes). However, it is not recommended to
 * generate 8-byte nonces randomly, as the chance of collision is high.
 *
 * Never use the same key and nonce to encrypt more than one message.
 *
 * If nonceInplaceCounterLength is not 0, the nonce is assumed to be a 16-byte
 * array with stream counter in first nonceInplaceCounterLength bytes and nonce
 * in the last remaining bytes. The counter will be incremented inplace for
 * each ChaCha block. This is useful if you need to encrypt one stream of data
 * in chunks.
 */
function streamXOR(key, nonce, src, dst, nonceInplaceCounterLength) {
    if (nonceInplaceCounterLength === void 0) { nonceInplaceCounterLength = 0; }
    // We only support 256-bit keys.
    if (key.length !== 32) {
        throw new Error("ChaCha: key size must be 32 bytes");
    }
    if (dst.length < src.length) {
        throw new Error("ChaCha: destination is shorter than source");
    }
    var nc;
    var counterLength;
    if (nonceInplaceCounterLength === 0) {
        if (nonce.length !== 8 && nonce.length !== 12) {
            throw new Error("ChaCha nonce must be 8 or 12 bytes");
        }
        nc = new Uint8Array(16);
        // First counterLength bytes of nc are counter, starting with zero.
        counterLength = nc.length - nonce.length;
        // Last bytes of nc after counterLength are nonce, set them.
        nc.set(nonce, counterLength);
    }
    else {
        if (nonce.length !== 16) {
            throw new Error("ChaCha nonce with counter must be 16 bytes");
        }
        // This will update passed nonce with counter inplace.
        nc = nonce;
        counterLength = nonceInplaceCounterLength;
    }
    // Allocate temporary space for ChaCha block.
    var block = new Uint8Array(64);
    for (var i = 0; i < src.length; i += 64) {
        // Generate a block.
        core(block, nc, key);
        // XOR block bytes with src into dst.
        for (var j = i; j < i + 64 && j < src.length; j++) {
            dst[j] = src[j] ^ block[j - i];
        }
        // Increment counter.
        incrementCounter(nc, 0, counterLength);
    }
    // Cleanup temporary space.
    wipe_1.wipe(block);
    if (nonceInplaceCounterLength === 0) {
        // Cleanup counter.
        wipe_1.wipe(nc);
    }
    return dst;
}
chacha.streamXOR = streamXOR;
/**
 * Generate ChaCha20 stream for the given 32-byte key and 8-byte or 12-byte
 * nonce and write it into dst and return it.
 *
 * Never use the same key and nonce to generate more than one stream.
 *
 * If nonceInplaceCounterLength is not 0, it behaves the same with respect to
 * the nonce as described in the streamXOR documentation.
 *
 * stream is like streamXOR with all-zero src.
 */
function stream(key, nonce, dst, nonceInplaceCounterLength) {
    if (nonceInplaceCounterLength === void 0) { nonceInplaceCounterLength = 0; }
    wipe_1.wipe(dst);
    return streamXOR(key, nonce, dst, dst, nonceInplaceCounterLength);
}
chacha.stream = stream;
function incrementCounter(counter, pos, len) {
    var carry = 1;
    while (len--) {
        carry = carry + (counter[pos] & 0xff) | 0;
        counter[pos] = carry & 0xff;
        carry >>>= 8;
        pos++;
    }
    if (carry > 0) {
        throw new Error("ChaCha: counter overflow");
    }
}

var poly1305 = {};

(function (exports) {
	// Copyright (C) 2016 Dmitry Chestnykh
	// MIT License. See LICENSE file for details.
	Object.defineProperty(exports, "__esModule", { value: true });
	/**
	 * Package poly1305 implements Poly1305 one-time message authentication algorithm.
	 */
	var constant_time_1 = constantTime;
	var wipe_1 = wipe$1;
	exports.DIGEST_LENGTH = 16;
	// Port of Andrew Moon's Poly1305-donna-16. Public domain.
	// https://github.com/floodyberry/poly1305-donna
	/**
	 * Poly1305 computes 16-byte authenticator of message using
	 * a one-time 32-byte key.
	 *
	 * Important: key should be used for only one message,
	 * it should never repeat.
	 */
	var Poly1305 = /** @class */ (function () {
	    function Poly1305(key) {
	        this.digestLength = exports.DIGEST_LENGTH;
	        this._buffer = new Uint8Array(16);
	        this._r = new Uint16Array(10);
	        this._h = new Uint16Array(10);
	        this._pad = new Uint16Array(8);
	        this._leftover = 0;
	        this._fin = 0;
	        this._finished = false;
	        var t0 = key[0] | key[1] << 8;
	        this._r[0] = (t0) & 0x1fff;
	        var t1 = key[2] | key[3] << 8;
	        this._r[1] = ((t0 >>> 13) | (t1 << 3)) & 0x1fff;
	        var t2 = key[4] | key[5] << 8;
	        this._r[2] = ((t1 >>> 10) | (t2 << 6)) & 0x1f03;
	        var t3 = key[6] | key[7] << 8;
	        this._r[3] = ((t2 >>> 7) | (t3 << 9)) & 0x1fff;
	        var t4 = key[8] | key[9] << 8;
	        this._r[4] = ((t3 >>> 4) | (t4 << 12)) & 0x00ff;
	        this._r[5] = ((t4 >>> 1)) & 0x1ffe;
	        var t5 = key[10] | key[11] << 8;
	        this._r[6] = ((t4 >>> 14) | (t5 << 2)) & 0x1fff;
	        var t6 = key[12] | key[13] << 8;
	        this._r[7] = ((t5 >>> 11) | (t6 << 5)) & 0x1f81;
	        var t7 = key[14] | key[15] << 8;
	        this._r[8] = ((t6 >>> 8) | (t7 << 8)) & 0x1fff;
	        this._r[9] = ((t7 >>> 5)) & 0x007f;
	        this._pad[0] = key[16] | key[17] << 8;
	        this._pad[1] = key[18] | key[19] << 8;
	        this._pad[2] = key[20] | key[21] << 8;
	        this._pad[3] = key[22] | key[23] << 8;
	        this._pad[4] = key[24] | key[25] << 8;
	        this._pad[5] = key[26] | key[27] << 8;
	        this._pad[6] = key[28] | key[29] << 8;
	        this._pad[7] = key[30] | key[31] << 8;
	    }
	    Poly1305.prototype._blocks = function (m, mpos, bytes) {
	        var hibit = this._fin ? 0 : 1 << 11;
	        var h0 = this._h[0], h1 = this._h[1], h2 = this._h[2], h3 = this._h[3], h4 = this._h[4], h5 = this._h[5], h6 = this._h[6], h7 = this._h[7], h8 = this._h[8], h9 = this._h[9];
	        var r0 = this._r[0], r1 = this._r[1], r2 = this._r[2], r3 = this._r[3], r4 = this._r[4], r5 = this._r[5], r6 = this._r[6], r7 = this._r[7], r8 = this._r[8], r9 = this._r[9];
	        while (bytes >= 16) {
	            var t0 = m[mpos + 0] | m[mpos + 1] << 8;
	            h0 += (t0) & 0x1fff;
	            var t1 = m[mpos + 2] | m[mpos + 3] << 8;
	            h1 += ((t0 >>> 13) | (t1 << 3)) & 0x1fff;
	            var t2 = m[mpos + 4] | m[mpos + 5] << 8;
	            h2 += ((t1 >>> 10) | (t2 << 6)) & 0x1fff;
	            var t3 = m[mpos + 6] | m[mpos + 7] << 8;
	            h3 += ((t2 >>> 7) | (t3 << 9)) & 0x1fff;
	            var t4 = m[mpos + 8] | m[mpos + 9] << 8;
	            h4 += ((t3 >>> 4) | (t4 << 12)) & 0x1fff;
	            h5 += ((t4 >>> 1)) & 0x1fff;
	            var t5 = m[mpos + 10] | m[mpos + 11] << 8;
	            h6 += ((t4 >>> 14) | (t5 << 2)) & 0x1fff;
	            var t6 = m[mpos + 12] | m[mpos + 13] << 8;
	            h7 += ((t5 >>> 11) | (t6 << 5)) & 0x1fff;
	            var t7 = m[mpos + 14] | m[mpos + 15] << 8;
	            h8 += ((t6 >>> 8) | (t7 << 8)) & 0x1fff;
	            h9 += ((t7 >>> 5)) | hibit;
	            var c = 0;
	            var d0 = c;
	            d0 += h0 * r0;
	            d0 += h1 * (5 * r9);
	            d0 += h2 * (5 * r8);
	            d0 += h3 * (5 * r7);
	            d0 += h4 * (5 * r6);
	            c = (d0 >>> 13);
	            d0 &= 0x1fff;
	            d0 += h5 * (5 * r5);
	            d0 += h6 * (5 * r4);
	            d0 += h7 * (5 * r3);
	            d0 += h8 * (5 * r2);
	            d0 += h9 * (5 * r1);
	            c += (d0 >>> 13);
	            d0 &= 0x1fff;
	            var d1 = c;
	            d1 += h0 * r1;
	            d1 += h1 * r0;
	            d1 += h2 * (5 * r9);
	            d1 += h3 * (5 * r8);
	            d1 += h4 * (5 * r7);
	            c = (d1 >>> 13);
	            d1 &= 0x1fff;
	            d1 += h5 * (5 * r6);
	            d1 += h6 * (5 * r5);
	            d1 += h7 * (5 * r4);
	            d1 += h8 * (5 * r3);
	            d1 += h9 * (5 * r2);
	            c += (d1 >>> 13);
	            d1 &= 0x1fff;
	            var d2 = c;
	            d2 += h0 * r2;
	            d2 += h1 * r1;
	            d2 += h2 * r0;
	            d2 += h3 * (5 * r9);
	            d2 += h4 * (5 * r8);
	            c = (d2 >>> 13);
	            d2 &= 0x1fff;
	            d2 += h5 * (5 * r7);
	            d2 += h6 * (5 * r6);
	            d2 += h7 * (5 * r5);
	            d2 += h8 * (5 * r4);
	            d2 += h9 * (5 * r3);
	            c += (d2 >>> 13);
	            d2 &= 0x1fff;
	            var d3 = c;
	            d3 += h0 * r3;
	            d3 += h1 * r2;
	            d3 += h2 * r1;
	            d3 += h3 * r0;
	            d3 += h4 * (5 * r9);
	            c = (d3 >>> 13);
	            d3 &= 0x1fff;
	            d3 += h5 * (5 * r8);
	            d3 += h6 * (5 * r7);
	            d3 += h7 * (5 * r6);
	            d3 += h8 * (5 * r5);
	            d3 += h9 * (5 * r4);
	            c += (d3 >>> 13);
	            d3 &= 0x1fff;
	            var d4 = c;
	            d4 += h0 * r4;
	            d4 += h1 * r3;
	            d4 += h2 * r2;
	            d4 += h3 * r1;
	            d4 += h4 * r0;
	            c = (d4 >>> 13);
	            d4 &= 0x1fff;
	            d4 += h5 * (5 * r9);
	            d4 += h6 * (5 * r8);
	            d4 += h7 * (5 * r7);
	            d4 += h8 * (5 * r6);
	            d4 += h9 * (5 * r5);
	            c += (d4 >>> 13);
	            d4 &= 0x1fff;
	            var d5 = c;
	            d5 += h0 * r5;
	            d5 += h1 * r4;
	            d5 += h2 * r3;
	            d5 += h3 * r2;
	            d5 += h4 * r1;
	            c = (d5 >>> 13);
	            d5 &= 0x1fff;
	            d5 += h5 * r0;
	            d5 += h6 * (5 * r9);
	            d5 += h7 * (5 * r8);
	            d5 += h8 * (5 * r7);
	            d5 += h9 * (5 * r6);
	            c += (d5 >>> 13);
	            d5 &= 0x1fff;
	            var d6 = c;
	            d6 += h0 * r6;
	            d6 += h1 * r5;
	            d6 += h2 * r4;
	            d6 += h3 * r3;
	            d6 += h4 * r2;
	            c = (d6 >>> 13);
	            d6 &= 0x1fff;
	            d6 += h5 * r1;
	            d6 += h6 * r0;
	            d6 += h7 * (5 * r9);
	            d6 += h8 * (5 * r8);
	            d6 += h9 * (5 * r7);
	            c += (d6 >>> 13);
	            d6 &= 0x1fff;
	            var d7 = c;
	            d7 += h0 * r7;
	            d7 += h1 * r6;
	            d7 += h2 * r5;
	            d7 += h3 * r4;
	            d7 += h4 * r3;
	            c = (d7 >>> 13);
	            d7 &= 0x1fff;
	            d7 += h5 * r2;
	            d7 += h6 * r1;
	            d7 += h7 * r0;
	            d7 += h8 * (5 * r9);
	            d7 += h9 * (5 * r8);
	            c += (d7 >>> 13);
	            d7 &= 0x1fff;
	            var d8 = c;
	            d8 += h0 * r8;
	            d8 += h1 * r7;
	            d8 += h2 * r6;
	            d8 += h3 * r5;
	            d8 += h4 * r4;
	            c = (d8 >>> 13);
	            d8 &= 0x1fff;
	            d8 += h5 * r3;
	            d8 += h6 * r2;
	            d8 += h7 * r1;
	            d8 += h8 * r0;
	            d8 += h9 * (5 * r9);
	            c += (d8 >>> 13);
	            d8 &= 0x1fff;
	            var d9 = c;
	            d9 += h0 * r9;
	            d9 += h1 * r8;
	            d9 += h2 * r7;
	            d9 += h3 * r6;
	            d9 += h4 * r5;
	            c = (d9 >>> 13);
	            d9 &= 0x1fff;
	            d9 += h5 * r4;
	            d9 += h6 * r3;
	            d9 += h7 * r2;
	            d9 += h8 * r1;
	            d9 += h9 * r0;
	            c += (d9 >>> 13);
	            d9 &= 0x1fff;
	            c = (((c << 2) + c)) | 0;
	            c = (c + d0) | 0;
	            d0 = c & 0x1fff;
	            c = (c >>> 13);
	            d1 += c;
	            h0 = d0;
	            h1 = d1;
	            h2 = d2;
	            h3 = d3;
	            h4 = d4;
	            h5 = d5;
	            h6 = d6;
	            h7 = d7;
	            h8 = d8;
	            h9 = d9;
	            mpos += 16;
	            bytes -= 16;
	        }
	        this._h[0] = h0;
	        this._h[1] = h1;
	        this._h[2] = h2;
	        this._h[3] = h3;
	        this._h[4] = h4;
	        this._h[5] = h5;
	        this._h[6] = h6;
	        this._h[7] = h7;
	        this._h[8] = h8;
	        this._h[9] = h9;
	    };
	    Poly1305.prototype.finish = function (mac, macpos) {
	        if (macpos === void 0) { macpos = 0; }
	        var g = new Uint16Array(10);
	        var c;
	        var mask;
	        var f;
	        var i;
	        if (this._leftover) {
	            i = this._leftover;
	            this._buffer[i++] = 1;
	            for (; i < 16; i++) {
	                this._buffer[i] = 0;
	            }
	            this._fin = 1;
	            this._blocks(this._buffer, 0, 16);
	        }
	        c = this._h[1] >>> 13;
	        this._h[1] &= 0x1fff;
	        for (i = 2; i < 10; i++) {
	            this._h[i] += c;
	            c = this._h[i] >>> 13;
	            this._h[i] &= 0x1fff;
	        }
	        this._h[0] += (c * 5);
	        c = this._h[0] >>> 13;
	        this._h[0] &= 0x1fff;
	        this._h[1] += c;
	        c = this._h[1] >>> 13;
	        this._h[1] &= 0x1fff;
	        this._h[2] += c;
	        g[0] = this._h[0] + 5;
	        c = g[0] >>> 13;
	        g[0] &= 0x1fff;
	        for (i = 1; i < 10; i++) {
	            g[i] = this._h[i] + c;
	            c = g[i] >>> 13;
	            g[i] &= 0x1fff;
	        }
	        g[9] -= (1 << 13);
	        mask = (c ^ 1) - 1;
	        for (i = 0; i < 10; i++) {
	            g[i] &= mask;
	        }
	        mask = ~mask;
	        for (i = 0; i < 10; i++) {
	            this._h[i] = (this._h[i] & mask) | g[i];
	        }
	        this._h[0] = ((this._h[0]) | (this._h[1] << 13)) & 0xffff;
	        this._h[1] = ((this._h[1] >>> 3) | (this._h[2] << 10)) & 0xffff;
	        this._h[2] = ((this._h[2] >>> 6) | (this._h[3] << 7)) & 0xffff;
	        this._h[3] = ((this._h[3] >>> 9) | (this._h[4] << 4)) & 0xffff;
	        this._h[4] = ((this._h[4] >>> 12) | (this._h[5] << 1) | (this._h[6] << 14)) & 0xffff;
	        this._h[5] = ((this._h[6] >>> 2) | (this._h[7] << 11)) & 0xffff;
	        this._h[6] = ((this._h[7] >>> 5) | (this._h[8] << 8)) & 0xffff;
	        this._h[7] = ((this._h[8] >>> 8) | (this._h[9] << 5)) & 0xffff;
	        f = this._h[0] + this._pad[0];
	        this._h[0] = f & 0xffff;
	        for (i = 1; i < 8; i++) {
	            f = (((this._h[i] + this._pad[i]) | 0) + (f >>> 16)) | 0;
	            this._h[i] = f & 0xffff;
	        }
	        mac[macpos + 0] = this._h[0] >>> 0;
	        mac[macpos + 1] = this._h[0] >>> 8;
	        mac[macpos + 2] = this._h[1] >>> 0;
	        mac[macpos + 3] = this._h[1] >>> 8;
	        mac[macpos + 4] = this._h[2] >>> 0;
	        mac[macpos + 5] = this._h[2] >>> 8;
	        mac[macpos + 6] = this._h[3] >>> 0;
	        mac[macpos + 7] = this._h[3] >>> 8;
	        mac[macpos + 8] = this._h[4] >>> 0;
	        mac[macpos + 9] = this._h[4] >>> 8;
	        mac[macpos + 10] = this._h[5] >>> 0;
	        mac[macpos + 11] = this._h[5] >>> 8;
	        mac[macpos + 12] = this._h[6] >>> 0;
	        mac[macpos + 13] = this._h[6] >>> 8;
	        mac[macpos + 14] = this._h[7] >>> 0;
	        mac[macpos + 15] = this._h[7] >>> 8;
	        this._finished = true;
	        return this;
	    };
	    Poly1305.prototype.update = function (m) {
	        var mpos = 0;
	        var bytes = m.length;
	        var want;
	        if (this._leftover) {
	            want = (16 - this._leftover);
	            if (want > bytes) {
	                want = bytes;
	            }
	            for (var i = 0; i < want; i++) {
	                this._buffer[this._leftover + i] = m[mpos + i];
	            }
	            bytes -= want;
	            mpos += want;
	            this._leftover += want;
	            if (this._leftover < 16) {
	                return this;
	            }
	            this._blocks(this._buffer, 0, 16);
	            this._leftover = 0;
	        }
	        if (bytes >= 16) {
	            want = bytes - (bytes % 16);
	            this._blocks(m, mpos, want);
	            mpos += want;
	            bytes -= want;
	        }
	        if (bytes) {
	            for (var i = 0; i < bytes; i++) {
	                this._buffer[this._leftover + i] = m[mpos + i];
	            }
	            this._leftover += bytes;
	        }
	        return this;
	    };
	    Poly1305.prototype.digest = function () {
	        // TODO(dchest): it behaves differently than other hashes/HMAC,
	        // because it throws when finished  others just return saved result.
	        if (this._finished) {
	            throw new Error("Poly1305 was finished");
	        }
	        var mac = new Uint8Array(16);
	        this.finish(mac);
	        return mac;
	    };
	    Poly1305.prototype.clean = function () {
	        wipe_1.wipe(this._buffer);
	        wipe_1.wipe(this._r);
	        wipe_1.wipe(this._h);
	        wipe_1.wipe(this._pad);
	        this._leftover = 0;
	        this._fin = 0;
	        this._finished = true; // mark as finished even if not
	        return this;
	    };
	    return Poly1305;
	}());
	exports.Poly1305 = Poly1305;
	/**
	 * Returns 16-byte authenticator of data using a one-time 32-byte key.
	 *
	 * Important: key should be used for only one message, it should never repeat.
	 */
	function oneTimeAuth(key, data) {
	    var h = new Poly1305(key);
	    h.update(data);
	    var digest = h.digest();
	    h.clean();
	    return digest;
	}
	exports.oneTimeAuth = oneTimeAuth;
	/**
	 * Returns true if two authenticators are 16-byte long and equal.
	 * Uses contant-time comparison to avoid leaking timing information.
	 */
	function equal(a, b) {
	    if (a.length !== exports.DIGEST_LENGTH || b.length !== exports.DIGEST_LENGTH) {
	        return false;
	    }
	    return constant_time_1.equal(a, b);
	}
	exports.equal = equal;
	
} (poly1305));

(function (exports) {
	// Copyright (C) 2016 Dmitry Chestnykh
	// MIT License. See LICENSE file for details.
	Object.defineProperty(exports, "__esModule", { value: true });
	var chacha_1 = chacha;
	var poly1305_1 = poly1305;
	var wipe_1 = wipe$1;
	var binary_1 = binary;
	var constant_time_1 = constantTime;
	exports.KEY_LENGTH = 32;
	exports.NONCE_LENGTH = 12;
	exports.TAG_LENGTH = 16;
	var ZEROS = new Uint8Array(16);
	/**
	 * ChaCha20-Poly1305 Authenticated Encryption with Associated Data.
	 *
	 * Defined in RFC7539.
	 */
	var ChaCha20Poly1305 = /** @class */ (function () {
	    /**
	     * Creates a new instance with the given 32-byte key.
	     */
	    function ChaCha20Poly1305(key) {
	        this.nonceLength = exports.NONCE_LENGTH;
	        this.tagLength = exports.TAG_LENGTH;
	        if (key.length !== exports.KEY_LENGTH) {
	            throw new Error("ChaCha20Poly1305 needs 32-byte key");
	        }
	        // Copy key.
	        this._key = new Uint8Array(key);
	    }
	    /**
	     * Encrypts and authenticates plaintext, authenticates associated data,
	     * and returns sealed ciphertext, which includes authentication tag.
	     *
	     * RFC7539 specifies 12 bytes for nonce. It may be this 12-byte nonce
	     * ("IV"), or full 16-byte counter (called "32-bit fixed-common part")
	     * and nonce.
	     *
	     * If dst is given (it must be the size of plaintext + the size of tag
	     * length) the result will be put into it. Dst and plaintext must not
	     * overlap.
	     */
	    ChaCha20Poly1305.prototype.seal = function (nonce, plaintext, associatedData, dst) {
	        if (nonce.length > 16) {
	            throw new Error("ChaCha20Poly1305: incorrect nonce length");
	        }
	        // Allocate space for counter, and set nonce as last bytes of it.
	        var counter = new Uint8Array(16);
	        counter.set(nonce, counter.length - nonce.length);
	        // Generate authentication key by taking first 32-bytes of stream.
	        // We pass full counter, which has 12-byte nonce and 4-byte block counter,
	        // and it will get incremented after generating the block, which is
	        // exactly what we need: we only use the first 32 bytes of 64-byte
	        // ChaCha block and discard the next 32 bytes.
	        var authKey = new Uint8Array(32);
	        chacha_1.stream(this._key, counter, authKey, 4);
	        // Allocate space for sealed ciphertext.
	        var resultLength = plaintext.length + this.tagLength;
	        var result;
	        if (dst) {
	            if (dst.length !== resultLength) {
	                throw new Error("ChaCha20Poly1305: incorrect destination length");
	            }
	            result = dst;
	        }
	        else {
	            result = new Uint8Array(resultLength);
	        }
	        // Encrypt plaintext.
	        chacha_1.streamXOR(this._key, counter, plaintext, result, 4);
	        // Authenticate.
	        // XXX: can "simplify" here: pass full result (which is already padded
	        // due to zeroes prepared for tag), and ciphertext length instead of
	        // subarray of result.
	        this._authenticate(result.subarray(result.length - this.tagLength, result.length), authKey, result.subarray(0, result.length - this.tagLength), associatedData);
	        // Cleanup.
	        wipe_1.wipe(counter);
	        return result;
	    };
	    /**
	     * Authenticates sealed ciphertext (which includes authentication tag) and
	     * associated data, decrypts ciphertext and returns decrypted plaintext.
	     *
	     * RFC7539 specifies 12 bytes for nonce. It may be this 12-byte nonce
	     * ("IV"), or full 16-byte counter (called "32-bit fixed-common part")
	     * and nonce.
	     *
	     * If authentication fails, it returns null.
	     *
	     * If dst is given (it must be of ciphertext length minus tag length),
	     * the result will be put into it. Dst and plaintext must not overlap.
	     */
	    ChaCha20Poly1305.prototype.open = function (nonce, sealed, associatedData, dst) {
	        if (nonce.length > 16) {
	            throw new Error("ChaCha20Poly1305: incorrect nonce length");
	        }
	        // Sealed ciphertext should at least contain tag.
	        if (sealed.length < this.tagLength) {
	            // TODO(dchest): should we throw here instead?
	            return null;
	        }
	        // Allocate space for counter, and set nonce as last bytes of it.
	        var counter = new Uint8Array(16);
	        counter.set(nonce, counter.length - nonce.length);
	        // Generate authentication key by taking first 32-bytes of stream.
	        var authKey = new Uint8Array(32);
	        chacha_1.stream(this._key, counter, authKey, 4);
	        // Authenticate.
	        // XXX: can simplify and avoid allocation: since authenticate()
	        // already allocates tag (from Poly1305.digest(), it can return)
	        // it instead of copying to calculatedTag. But then in seal()
	        // we'll need to copy it.
	        var calculatedTag = new Uint8Array(this.tagLength);
	        this._authenticate(calculatedTag, authKey, sealed.subarray(0, sealed.length - this.tagLength), associatedData);
	        // Constant-time compare tags and return null if they differ.
	        if (!constant_time_1.equal(calculatedTag, sealed.subarray(sealed.length - this.tagLength, sealed.length))) {
	            return null;
	        }
	        // Allocate space for decrypted plaintext.
	        var resultLength = sealed.length - this.tagLength;
	        var result;
	        if (dst) {
	            if (dst.length !== resultLength) {
	                throw new Error("ChaCha20Poly1305: incorrect destination length");
	            }
	            result = dst;
	        }
	        else {
	            result = new Uint8Array(resultLength);
	        }
	        // Decrypt.
	        chacha_1.streamXOR(this._key, counter, sealed.subarray(0, sealed.length - this.tagLength), result, 4);
	        // Cleanup.
	        wipe_1.wipe(counter);
	        return result;
	    };
	    ChaCha20Poly1305.prototype.clean = function () {
	        wipe_1.wipe(this._key);
	        return this;
	    };
	    ChaCha20Poly1305.prototype._authenticate = function (tagOut, authKey, ciphertext, associatedData) {
	        // Initialize Poly1305 with authKey.
	        var h = new poly1305_1.Poly1305(authKey);
	        // Authenticate padded associated data.
	        if (associatedData) {
	            h.update(associatedData);
	            if (associatedData.length % 16 > 0) {
	                h.update(ZEROS.subarray(associatedData.length % 16));
	            }
	        }
	        // Authenticate padded ciphertext.
	        h.update(ciphertext);
	        if (ciphertext.length % 16 > 0) {
	            h.update(ZEROS.subarray(ciphertext.length % 16));
	        }
	        // Authenticate length of associated data.
	        // XXX: can avoid allocation here?
	        var length = new Uint8Array(8);
	        if (associatedData) {
	            binary_1.writeUint64LE(associatedData.length, length);
	        }
	        h.update(length);
	        // Authenticate length of ciphertext.
	        binary_1.writeUint64LE(ciphertext.length, length);
	        h.update(length);
	        // Get tag and copy it into tagOut.
	        var tag = h.digest();
	        for (var i = 0; i < tag.length; i++) {
	            tagOut[i] = tag[i];
	        }
	        // Cleanup.
	        h.clean();
	        wipe_1.wipe(tag);
	        wipe_1.wipe(length);
	    };
	    return ChaCha20Poly1305;
	}());
	exports.ChaCha20Poly1305 = ChaCha20Poly1305;
	
} (chacha20poly1305));

const stablelib = {
    hashSHA256(data) {
        return sha256$2.hash(data);
    },
    getHKDF(ck, ikm) {
        const hkdf = new HKDF_1(sha256$2.SHA256, ikm, ck);
        const okmU8Array = hkdf.expand(96);
        const okm = okmU8Array;
        const k1 = okm.subarray(0, 32);
        const k2 = okm.subarray(32, 64);
        const k3 = okm.subarray(64, 96);
        return [k1, k2, k3];
    },
    generateX25519KeyPair() {
        const keypair = x25519.generateKeyPair();
        return {
            publicKey: keypair.publicKey,
            privateKey: keypair.secretKey
        };
    },
    generateX25519KeyPairFromSeed(seed) {
        const keypair = x25519.generateKeyPairFromSeed(seed);
        return {
            publicKey: keypair.publicKey,
            privateKey: keypair.secretKey
        };
    },
    generateX25519SharedKey(privateKey, publicKey) {
        return x25519.sharedKey(privateKey, publicKey);
    },
    chaCha20Poly1305Encrypt(plaintext, nonce, ad, k) {
        const ctx = new chacha20poly1305.ChaCha20Poly1305(k);
        return ctx.seal(nonce, plaintext, ad);
    },
    chaCha20Poly1305Decrypt(ciphertext, nonce, ad, k, dst) {
        const ctx = new chacha20poly1305.ChaCha20Poly1305(k);
        return ctx.open(nonce, ciphertext, ad, dst);
    }
};

const allocUnsafe$1 = (len) => {
    if (globalThis.Buffer) {
        return globalThis.Buffer.allocUnsafe(len);
    }
    return new Uint8Array(len);
};
const uint16BEEncode = (value) => {
    const target = allocUnsafe$1(2);
    new DataView(target.buffer, target.byteOffset, target.byteLength).setUint16(0, value, false);
    return target;
};
uint16BEEncode.bytes = 2;
const uint16BEDecode = (data) => {
    if (data.length < 2)
        throw RangeError('Could not decode int16BE');
    if (data instanceof Uint8Array) {
        return new DataView(data.buffer, data.byteOffset, data.byteLength).getUint16(0, false);
    }
    return data.getUint16(0);
};
uint16BEDecode.bytes = 2;
// Note: IK and XX encoder usage is opposite (XX uses in stages encode0 where IK uses encode1)
function encode0(message) {
    return concat([message.ne, message.ciphertext], message.ne.length + message.ciphertext.length);
}
function encode1(message) {
    return concat([message.ne, message.ns, message.ciphertext], message.ne.length + message.ns.length + message.ciphertext.length);
}
function encode2(message) {
    return concat([message.ns, message.ciphertext], message.ns.length + message.ciphertext.length);
}
function decode0(input) {
    if (input.length < 32) {
        throw new Error('Cannot decode stage 0 MessageBuffer: length less than 32 bytes.');
    }
    return {
        ne: input.subarray(0, 32),
        ciphertext: input.subarray(32, input.length),
        ns: new Uint8Array(0)
    };
}
function decode1(input) {
    if (input.length < 80) {
        throw new Error('Cannot decode stage 1 MessageBuffer: length less than 80 bytes.');
    }
    return {
        ne: input.subarray(0, 32),
        ns: input.subarray(32, 80),
        ciphertext: input.subarray(80, input.length)
    };
}
function decode2(input) {
    if (input.length < 48) {
        throw new Error('Cannot decode stage 2 MessageBuffer: length less than 48 bytes.');
    }
    return {
        ne: new Uint8Array(0),
        ns: input.subarray(0, 48),
        ciphertext: input.subarray(48, input.length)
    };
}

// Returns generator that encrypts payload from the user
function encryptStream(handshake, metrics) {
    return async function* (source) {
        for await (const chunk of source) {
            for (let i = 0; i < chunk.length; i += NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG) {
                let end = i + NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG;
                if (end > chunk.length) {
                    end = chunk.length;
                }
                const data = handshake.encrypt(chunk.subarray(i, end), handshake.session);
                metrics?.encryptedPackets.increment();
                yield uint16BEEncode(data.byteLength);
                yield data;
            }
        }
    };
}
// Decrypt received payload to the user
function decryptStream(handshake, metrics) {
    return async function* (source) {
        for await (const chunk of source) {
            for (let i = 0; i < chunk.length; i += NOISE_MSG_MAX_LENGTH_BYTES) {
                let end = i + NOISE_MSG_MAX_LENGTH_BYTES;
                if (end > chunk.length) {
                    end = chunk.length;
                }
                if (end - chacha20poly1305.TAG_LENGTH < i) {
                    throw new Error('Invalid chunk');
                }
                const encrypted = chunk.subarray(i, end);
                // memory allocation is not cheap so reuse the encrypted Uint8Array
                // see https://github.com/ChainSafe/js-libp2p-noise/pull/242#issue-1422126164
                // this is ok because chacha20 reads bytes one by one and don't reread after that
                // it's also tested in https://github.com/ChainSafe/as-chacha20poly1305/pull/1/files#diff-25252846b58979dcaf4e41d47b3eadd7e4f335e7fb98da6c049b1f9cd011f381R48
                const dst = chunk.subarray(i, end - chacha20poly1305.TAG_LENGTH);
                const { plaintext: decrypted, valid } = handshake.decrypt(encrypted, handshake.session, dst);
                if (!valid) {
                    metrics?.decryptErrors.increment();
                    throw new Error('Failed to validate decrypted chunk');
                }
                metrics?.decryptedPackets.increment();
                yield decrypted;
            }
        }
    };
}

class UnexpectedPeerError extends Error {
    constructor(message = 'Unexpected Peer') {
        super(message);
        this.code = UnexpectedPeerError.code;
    }
    static get code() {
        return 'ERR_UNEXPECTED_PEER';
    }
}
class InvalidCryptoExchangeError extends Error {
    constructor(message = 'Invalid crypto exchange') {
        super(message);
        this.code = InvalidCryptoExchangeError.code;
    }
    static get code() {
        return 'ERR_INVALID_CRYPTO_EXCHANGE';
    }
}

var minimal$7 = {};

var aspromise = asPromise;

/**
 * Callback as used by {@link util.asPromise}.
 * @typedef asPromiseCallback
 * @type {function}
 * @param {Error|null} error Error, if any
 * @param {...*} params Additional arguments
 * @returns {undefined}
 */

/**
 * Returns a promise from a node-style callback function.
 * @memberof util
 * @param {asPromiseCallback} fn Function to call
 * @param {*} ctx Function context
 * @param {...*} params Function arguments
 * @returns {Promise<*>} Promisified function
 */
function asPromise(fn, ctx/*, varargs */) {
    var params  = new Array(arguments.length - 1),
        offset  = 0,
        index   = 2,
        pending = true;
    while (index < arguments.length)
        params[offset++] = arguments[index++];
    return new Promise(function executor(resolve, reject) {
        params[offset] = function callback(err/*, varargs */) {
            if (pending) {
                pending = false;
                if (err)
                    reject(err);
                else {
                    var params = new Array(arguments.length - 1),
                        offset = 0;
                    while (offset < params.length)
                        params[offset++] = arguments[offset];
                    resolve.apply(null, params);
                }
            }
        };
        try {
            fn.apply(ctx || null, params);
        } catch (err) {
            if (pending) {
                pending = false;
                reject(err);
            }
        }
    });
}

var base64$9 = {};

(function (exports) {

	/**
	 * A minimal base64 implementation for number arrays.
	 * @memberof util
	 * @namespace
	 */
	var base64 = exports;

	/**
	 * Calculates the byte length of a base64 encoded string.
	 * @param {string} string Base64 encoded string
	 * @returns {number} Byte length
	 */
	base64.length = function length(string) {
	    var p = string.length;
	    if (!p)
	        return 0;
	    var n = 0;
	    while (--p % 4 > 1 && string.charAt(p) === "=")
	        ++n;
	    return Math.ceil(string.length * 3) / 4 - n;
	};

	// Base64 encoding table
	var b64 = new Array(64);

	// Base64 decoding table
	var s64 = new Array(123);

	// 65..90, 97..122, 48..57, 43, 47
	for (var i = 0; i < 64;)
	    s64[b64[i] = i < 26 ? i + 65 : i < 52 ? i + 71 : i < 62 ? i - 4 : i - 59 | 43] = i++;

	/**
	 * Encodes a buffer to a base64 encoded string.
	 * @param {Uint8Array} buffer Source buffer
	 * @param {number} start Source start
	 * @param {number} end Source end
	 * @returns {string} Base64 encoded string
	 */
	base64.encode = function encode(buffer, start, end) {
	    var parts = null,
	        chunk = [];
	    var i = 0, // output index
	        j = 0, // goto index
	        t;     // temporary
	    while (start < end) {
	        var b = buffer[start++];
	        switch (j) {
	            case 0:
	                chunk[i++] = b64[b >> 2];
	                t = (b & 3) << 4;
	                j = 1;
	                break;
	            case 1:
	                chunk[i++] = b64[t | b >> 4];
	                t = (b & 15) << 2;
	                j = 2;
	                break;
	            case 2:
	                chunk[i++] = b64[t | b >> 6];
	                chunk[i++] = b64[b & 63];
	                j = 0;
	                break;
	        }
	        if (i > 8191) {
	            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));
	            i = 0;
	        }
	    }
	    if (j) {
	        chunk[i++] = b64[t];
	        chunk[i++] = 61;
	        if (j === 1)
	            chunk[i++] = 61;
	    }
	    if (parts) {
	        if (i)
	            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));
	        return parts.join("");
	    }
	    return String.fromCharCode.apply(String, chunk.slice(0, i));
	};

	var invalidEncoding = "invalid encoding";

	/**
	 * Decodes a base64 encoded string to a buffer.
	 * @param {string} string Source string
	 * @param {Uint8Array} buffer Destination buffer
	 * @param {number} offset Destination offset
	 * @returns {number} Number of bytes written
	 * @throws {Error} If encoding is invalid
	 */
	base64.decode = function decode(string, buffer, offset) {
	    var start = offset;
	    var j = 0, // goto index
	        t;     // temporary
	    for (var i = 0; i < string.length;) {
	        var c = string.charCodeAt(i++);
	        if (c === 61 && j > 1)
	            break;
	        if ((c = s64[c]) === undefined)
	            throw Error(invalidEncoding);
	        switch (j) {
	            case 0:
	                t = c;
	                j = 1;
	                break;
	            case 1:
	                buffer[offset++] = t << 2 | (c & 48) >> 4;
	                t = c;
	                j = 2;
	                break;
	            case 2:
	                buffer[offset++] = (t & 15) << 4 | (c & 60) >> 2;
	                t = c;
	                j = 3;
	                break;
	            case 3:
	                buffer[offset++] = (t & 3) << 6 | c;
	                j = 0;
	                break;
	        }
	    }
	    if (j === 1)
	        throw Error(invalidEncoding);
	    return offset - start;
	};

	/**
	 * Tests if the specified string appears to be base64 encoded.
	 * @param {string} string String to test
	 * @returns {boolean} `true` if probably base64 encoded, otherwise false
	 */
	base64.test = function test(string) {
	    return /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(string);
	};
} (base64$9));

var eventemitter = EventEmitter$2;

/**
 * Constructs a new event emitter instance.
 * @classdesc A minimal event emitter.
 * @memberof util
 * @constructor
 */
function EventEmitter$2() {

    /**
     * Registered listeners.
     * @type {Object.<string,*>}
     * @private
     */
    this._listeners = {};
}

/**
 * Registers an event listener.
 * @param {string} evt Event name
 * @param {function} fn Listener
 * @param {*} [ctx] Listener context
 * @returns {util.EventEmitter} `this`
 */
EventEmitter$2.prototype.on = function on(evt, fn, ctx) {
    (this._listeners[evt] || (this._listeners[evt] = [])).push({
        fn  : fn,
        ctx : ctx || this
    });
    return this;
};

/**
 * Removes an event listener or any matching listeners if arguments are omitted.
 * @param {string} [evt] Event name. Removes all listeners if omitted.
 * @param {function} [fn] Listener to remove. Removes all listeners of `evt` if omitted.
 * @returns {util.EventEmitter} `this`
 */
EventEmitter$2.prototype.off = function off(evt, fn) {
    if (evt === undefined)
        this._listeners = {};
    else {
        if (fn === undefined)
            this._listeners[evt] = [];
        else {
            var listeners = this._listeners[evt];
            for (var i = 0; i < listeners.length;)
                if (listeners[i].fn === fn)
                    listeners.splice(i, 1);
                else
                    ++i;
        }
    }
    return this;
};

/**
 * Emits an event by calling its listeners with the specified arguments.
 * @param {string} evt Event name
 * @param {...*} args Arguments
 * @returns {util.EventEmitter} `this`
 */
EventEmitter$2.prototype.emit = function emit(evt) {
    var listeners = this._listeners[evt];
    if (listeners) {
        var args = [],
            i = 1;
        for (; i < arguments.length;)
            args.push(arguments[i++]);
        for (i = 0; i < listeners.length;)
            listeners[i].fn.apply(listeners[i++].ctx, args);
    }
    return this;
};

var float = factory(factory);

/**
 * Reads / writes floats / doubles from / to buffers.
 * @name util.float
 * @namespace
 */

/**
 * Writes a 32 bit float to a buffer using little endian byte order.
 * @name util.float.writeFloatLE
 * @function
 * @param {number} val Value to write
 * @param {Uint8Array} buf Target buffer
 * @param {number} pos Target buffer offset
 * @returns {undefined}
 */

/**
 * Writes a 32 bit float to a buffer using big endian byte order.
 * @name util.float.writeFloatBE
 * @function
 * @param {number} val Value to write
 * @param {Uint8Array} buf Target buffer
 * @param {number} pos Target buffer offset
 * @returns {undefined}
 */

/**
 * Reads a 32 bit float from a buffer using little endian byte order.
 * @name util.float.readFloatLE
 * @function
 * @param {Uint8Array} buf Source buffer
 * @param {number} pos Source buffer offset
 * @returns {number} Value read
 */

/**
 * Reads a 32 bit float from a buffer using big endian byte order.
 * @name util.float.readFloatBE
 * @function
 * @param {Uint8Array} buf Source buffer
 * @param {number} pos Source buffer offset
 * @returns {number} Value read
 */

/**
 * Writes a 64 bit double to a buffer using little endian byte order.
 * @name util.float.writeDoubleLE
 * @function
 * @param {number} val Value to write
 * @param {Uint8Array} buf Target buffer
 * @param {number} pos Target buffer offset
 * @returns {undefined}
 */

/**
 * Writes a 64 bit double to a buffer using big endian byte order.
 * @name util.float.writeDoubleBE
 * @function
 * @param {number} val Value to write
 * @param {Uint8Array} buf Target buffer
 * @param {number} pos Target buffer offset
 * @returns {undefined}
 */

/**
 * Reads a 64 bit double from a buffer using little endian byte order.
 * @name util.float.readDoubleLE
 * @function
 * @param {Uint8Array} buf Source buffer
 * @param {number} pos Source buffer offset
 * @returns {number} Value read
 */

/**
 * Reads a 64 bit double from a buffer using big endian byte order.
 * @name util.float.readDoubleBE
 * @function
 * @param {Uint8Array} buf Source buffer
 * @param {number} pos Source buffer offset
 * @returns {number} Value read
 */

// Factory function for the purpose of node-based testing in modified global environments
function factory(exports) {

    // float: typed array
    if (typeof Float32Array !== "undefined") (function() {

        var f32 = new Float32Array([ -0 ]),
            f8b = new Uint8Array(f32.buffer),
            le  = f8b[3] === 128;

        function writeFloat_f32_cpy(val, buf, pos) {
            f32[0] = val;
            buf[pos    ] = f8b[0];
            buf[pos + 1] = f8b[1];
            buf[pos + 2] = f8b[2];
            buf[pos + 3] = f8b[3];
        }

        function writeFloat_f32_rev(val, buf, pos) {
            f32[0] = val;
            buf[pos    ] = f8b[3];
            buf[pos + 1] = f8b[2];
            buf[pos + 2] = f8b[1];
            buf[pos + 3] = f8b[0];
        }

        /* istanbul ignore next */
        exports.writeFloatLE = le ? writeFloat_f32_cpy : writeFloat_f32_rev;
        /* istanbul ignore next */
        exports.writeFloatBE = le ? writeFloat_f32_rev : writeFloat_f32_cpy;

        function readFloat_f32_cpy(buf, pos) {
            f8b[0] = buf[pos    ];
            f8b[1] = buf[pos + 1];
            f8b[2] = buf[pos + 2];
            f8b[3] = buf[pos + 3];
            return f32[0];
        }

        function readFloat_f32_rev(buf, pos) {
            f8b[3] = buf[pos    ];
            f8b[2] = buf[pos + 1];
            f8b[1] = buf[pos + 2];
            f8b[0] = buf[pos + 3];
            return f32[0];
        }

        /* istanbul ignore next */
        exports.readFloatLE = le ? readFloat_f32_cpy : readFloat_f32_rev;
        /* istanbul ignore next */
        exports.readFloatBE = le ? readFloat_f32_rev : readFloat_f32_cpy;

    // float: ieee754
    })(); else (function() {

        function writeFloat_ieee754(writeUint, val, buf, pos) {
            var sign = val < 0 ? 1 : 0;
            if (sign)
                val = -val;
            if (val === 0)
                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos);
            else if (isNaN(val))
                writeUint(2143289344, buf, pos);
            else if (val > 3.4028234663852886e+38) // +-Infinity
                writeUint((sign << 31 | 2139095040) >>> 0, buf, pos);
            else if (val < 1.1754943508222875e-38) // denormal
                writeUint((sign << 31 | Math.round(val / 1.401298464324817e-45)) >>> 0, buf, pos);
            else {
                var exponent = Math.floor(Math.log(val) / Math.LN2),
                    mantissa = Math.round(val * Math.pow(2, -exponent) * 8388608) & 8388607;
                writeUint((sign << 31 | exponent + 127 << 23 | mantissa) >>> 0, buf, pos);
            }
        }

        exports.writeFloatLE = writeFloat_ieee754.bind(null, writeUintLE);
        exports.writeFloatBE = writeFloat_ieee754.bind(null, writeUintBE);

        function readFloat_ieee754(readUint, buf, pos) {
            var uint = readUint(buf, pos),
                sign = (uint >> 31) * 2 + 1,
                exponent = uint >>> 23 & 255,
                mantissa = uint & 8388607;
            return exponent === 255
                ? mantissa
                ? NaN
                : sign * Infinity
                : exponent === 0 // denormal
                ? sign * 1.401298464324817e-45 * mantissa
                : sign * Math.pow(2, exponent - 150) * (mantissa + 8388608);
        }

        exports.readFloatLE = readFloat_ieee754.bind(null, readUintLE);
        exports.readFloatBE = readFloat_ieee754.bind(null, readUintBE);

    })();

    // double: typed array
    if (typeof Float64Array !== "undefined") (function() {

        var f64 = new Float64Array([-0]),
            f8b = new Uint8Array(f64.buffer),
            le  = f8b[7] === 128;

        function writeDouble_f64_cpy(val, buf, pos) {
            f64[0] = val;
            buf[pos    ] = f8b[0];
            buf[pos + 1] = f8b[1];
            buf[pos + 2] = f8b[2];
            buf[pos + 3] = f8b[3];
            buf[pos + 4] = f8b[4];
            buf[pos + 5] = f8b[5];
            buf[pos + 6] = f8b[6];
            buf[pos + 7] = f8b[7];
        }

        function writeDouble_f64_rev(val, buf, pos) {
            f64[0] = val;
            buf[pos    ] = f8b[7];
            buf[pos + 1] = f8b[6];
            buf[pos + 2] = f8b[5];
            buf[pos + 3] = f8b[4];
            buf[pos + 4] = f8b[3];
            buf[pos + 5] = f8b[2];
            buf[pos + 6] = f8b[1];
            buf[pos + 7] = f8b[0];
        }

        /* istanbul ignore next */
        exports.writeDoubleLE = le ? writeDouble_f64_cpy : writeDouble_f64_rev;
        /* istanbul ignore next */
        exports.writeDoubleBE = le ? writeDouble_f64_rev : writeDouble_f64_cpy;

        function readDouble_f64_cpy(buf, pos) {
            f8b[0] = buf[pos    ];
            f8b[1] = buf[pos + 1];
            f8b[2] = buf[pos + 2];
            f8b[3] = buf[pos + 3];
            f8b[4] = buf[pos + 4];
            f8b[5] = buf[pos + 5];
            f8b[6] = buf[pos + 6];
            f8b[7] = buf[pos + 7];
            return f64[0];
        }

        function readDouble_f64_rev(buf, pos) {
            f8b[7] = buf[pos    ];
            f8b[6] = buf[pos + 1];
            f8b[5] = buf[pos + 2];
            f8b[4] = buf[pos + 3];
            f8b[3] = buf[pos + 4];
            f8b[2] = buf[pos + 5];
            f8b[1] = buf[pos + 6];
            f8b[0] = buf[pos + 7];
            return f64[0];
        }

        /* istanbul ignore next */
        exports.readDoubleLE = le ? readDouble_f64_cpy : readDouble_f64_rev;
        /* istanbul ignore next */
        exports.readDoubleBE = le ? readDouble_f64_rev : readDouble_f64_cpy;

    // double: ieee754
    })(); else (function() {

        function writeDouble_ieee754(writeUint, off0, off1, val, buf, pos) {
            var sign = val < 0 ? 1 : 0;
            if (sign)
                val = -val;
            if (val === 0) {
                writeUint(0, buf, pos + off0);
                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos + off1);
            } else if (isNaN(val)) {
                writeUint(0, buf, pos + off0);
                writeUint(2146959360, buf, pos + off1);
            } else if (val > 1.7976931348623157e+308) { // +-Infinity
                writeUint(0, buf, pos + off0);
                writeUint((sign << 31 | 2146435072) >>> 0, buf, pos + off1);
            } else {
                var mantissa;
                if (val < 2.2250738585072014e-308) { // denormal
                    mantissa = val / 5e-324;
                    writeUint(mantissa >>> 0, buf, pos + off0);
                    writeUint((sign << 31 | mantissa / 4294967296) >>> 0, buf, pos + off1);
                } else {
                    var exponent = Math.floor(Math.log(val) / Math.LN2);
                    if (exponent === 1024)
                        exponent = 1023;
                    mantissa = val * Math.pow(2, -exponent);
                    writeUint(mantissa * 4503599627370496 >>> 0, buf, pos + off0);
                    writeUint((sign << 31 | exponent + 1023 << 20 | mantissa * 1048576 & 1048575) >>> 0, buf, pos + off1);
                }
            }
        }

        exports.writeDoubleLE = writeDouble_ieee754.bind(null, writeUintLE, 0, 4);
        exports.writeDoubleBE = writeDouble_ieee754.bind(null, writeUintBE, 4, 0);

        function readDouble_ieee754(readUint, off0, off1, buf, pos) {
            var lo = readUint(buf, pos + off0),
                hi = readUint(buf, pos + off1);
            var sign = (hi >> 31) * 2 + 1,
                exponent = hi >>> 20 & 2047,
                mantissa = 4294967296 * (hi & 1048575) + lo;
            return exponent === 2047
                ? mantissa
                ? NaN
                : sign * Infinity
                : exponent === 0 // denormal
                ? sign * 5e-324 * mantissa
                : sign * Math.pow(2, exponent - 1075) * (mantissa + 4503599627370496);
        }

        exports.readDoubleLE = readDouble_ieee754.bind(null, readUintLE, 0, 4);
        exports.readDoubleBE = readDouble_ieee754.bind(null, readUintBE, 4, 0);

    })();

    return exports;
}

// uint helpers

function writeUintLE(val, buf, pos) {
    buf[pos    ] =  val        & 255;
    buf[pos + 1] =  val >>> 8  & 255;
    buf[pos + 2] =  val >>> 16 & 255;
    buf[pos + 3] =  val >>> 24;
}

function writeUintBE(val, buf, pos) {
    buf[pos    ] =  val >>> 24;
    buf[pos + 1] =  val >>> 16 & 255;
    buf[pos + 2] =  val >>> 8  & 255;
    buf[pos + 3] =  val        & 255;
}

function readUintLE(buf, pos) {
    return (buf[pos    ]
          | buf[pos + 1] << 8
          | buf[pos + 2] << 16
          | buf[pos + 3] << 24) >>> 0;
}

function readUintBE(buf, pos) {
    return (buf[pos    ] << 24
          | buf[pos + 1] << 16
          | buf[pos + 2] << 8
          | buf[pos + 3]) >>> 0;
}

var inquire_1 = inquire;

/**
 * Requires a module only if available.
 * @memberof util
 * @param {string} moduleName Module to require
 * @returns {?Object} Required module if available and not empty, otherwise `null`
 */
function inquire(moduleName) {
    try {
        var mod = eval("quire".replace(/^/,"re"))(moduleName); // eslint-disable-line no-eval
        if (mod && (mod.length || Object.keys(mod).length))
            return mod;
    } catch (e) {} // eslint-disable-line no-empty
    return null;
}

var utf8$e = {};

(function (exports) {

	/**
	 * A minimal UTF8 implementation for number arrays.
	 * @memberof util
	 * @namespace
	 */
	var utf8 = exports;

	/**
	 * Calculates the UTF8 byte length of a string.
	 * @param {string} string String
	 * @returns {number} Byte length
	 */
	utf8.length = function utf8_length(string) {
	    var len = 0,
	        c = 0;
	    for (var i = 0; i < string.length; ++i) {
	        c = string.charCodeAt(i);
	        if (c < 128)
	            len += 1;
	        else if (c < 2048)
	            len += 2;
	        else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {
	            ++i;
	            len += 4;
	        } else
	            len += 3;
	    }
	    return len;
	};

	/**
	 * Reads UTF8 bytes as a string.
	 * @param {Uint8Array} buffer Source buffer
	 * @param {number} start Source start
	 * @param {number} end Source end
	 * @returns {string} String read
	 */
	utf8.read = function utf8_read(buffer, start, end) {
	    var len = end - start;
	    if (len < 1)
	        return "";
	    var parts = null,
	        chunk = [],
	        i = 0, // char offset
	        t;     // temporary
	    while (start < end) {
	        t = buffer[start++];
	        if (t < 128)
	            chunk[i++] = t;
	        else if (t > 191 && t < 224)
	            chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;
	        else if (t > 239 && t < 365) {
	            t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;
	            chunk[i++] = 0xD800 + (t >> 10);
	            chunk[i++] = 0xDC00 + (t & 1023);
	        } else
	            chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;
	        if (i > 8191) {
	            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));
	            i = 0;
	        }
	    }
	    if (parts) {
	        if (i)
	            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));
	        return parts.join("");
	    }
	    return String.fromCharCode.apply(String, chunk.slice(0, i));
	};

	/**
	 * Writes a string as UTF8 bytes.
	 * @param {string} string Source string
	 * @param {Uint8Array} buffer Destination buffer
	 * @param {number} offset Destination offset
	 * @returns {number} Bytes written
	 */
	utf8.write = function utf8_write(string, buffer, offset) {
	    var start = offset,
	        c1, // character 1
	        c2; // character 2
	    for (var i = 0; i < string.length; ++i) {
	        c1 = string.charCodeAt(i);
	        if (c1 < 128) {
	            buffer[offset++] = c1;
	        } else if (c1 < 2048) {
	            buffer[offset++] = c1 >> 6       | 192;
	            buffer[offset++] = c1       & 63 | 128;
	        } else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {
	            c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);
	            ++i;
	            buffer[offset++] = c1 >> 18      | 240;
	            buffer[offset++] = c1 >> 12 & 63 | 128;
	            buffer[offset++] = c1 >> 6  & 63 | 128;
	            buffer[offset++] = c1       & 63 | 128;
	        } else {
	            buffer[offset++] = c1 >> 12      | 224;
	            buffer[offset++] = c1 >> 6  & 63 | 128;
	            buffer[offset++] = c1       & 63 | 128;
	        }
	    }
	    return offset - start;
	};
} (utf8$e));

var pool_1 = pool;

/**
 * An allocator as used by {@link util.pool}.
 * @typedef PoolAllocator
 * @type {function}
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */

/**
 * A slicer as used by {@link util.pool}.
 * @typedef PoolSlicer
 * @type {function}
 * @param {number} start Start offset
 * @param {number} end End offset
 * @returns {Uint8Array} Buffer slice
 * @this {Uint8Array}
 */

/**
 * A general purpose buffer pool.
 * @memberof util
 * @function
 * @param {PoolAllocator} alloc Allocator
 * @param {PoolSlicer} slice Slicer
 * @param {number} [size=8192] Slab size
 * @returns {PoolAllocator} Pooled allocator
 */
function pool(alloc, slice, size) {
    var SIZE   = size || 8192;
    var MAX    = SIZE >>> 1;
    var slab   = null;
    var offset = SIZE;
    return function pool_alloc(size) {
        if (size < 1 || size > MAX)
            return alloc(size);
        if (offset + size > SIZE) {
            slab = alloc(SIZE);
            offset = 0;
        }
        var buf = slice.call(slab, offset, offset += size);
        if (offset & 7) // align to 32 bit
            offset = (offset | 7) + 1;
        return buf;
    };
}

var longbits$6;
var hasRequiredLongbits$6;

function requireLongbits$6 () {
	if (hasRequiredLongbits$6) return longbits$6;
	hasRequiredLongbits$6 = 1;
	longbits$6 = LongBits;

	var util = requireMinimal$6();

	/**
	 * Constructs new long bits.
	 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
	 * @memberof util
	 * @constructor
	 * @param {number} lo Low 32 bits, unsigned
	 * @param {number} hi High 32 bits, unsigned
	 */
	function LongBits(lo, hi) {

	    // note that the casts below are theoretically unnecessary as of today, but older statically
	    // generated converter code might still call the ctor with signed 32bits. kept for compat.

	    /**
	     * Low bits.
	     * @type {number}
	     */
	    this.lo = lo >>> 0;

	    /**
	     * High bits.
	     * @type {number}
	     */
	    this.hi = hi >>> 0;
	}

	/**
	 * Zero bits.
	 * @memberof util.LongBits
	 * @type {util.LongBits}
	 */
	var zero = LongBits.zero = new LongBits(0, 0);

	zero.toNumber = function() { return 0; };
	zero.zzEncode = zero.zzDecode = function() { return this; };
	zero.length = function() { return 1; };

	/**
	 * Zero hash.
	 * @memberof util.LongBits
	 * @type {string}
	 */
	var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

	/**
	 * Constructs new long bits from the specified number.
	 * @param {number} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.fromNumber = function fromNumber(value) {
	    if (value === 0)
	        return zero;
	    var sign = value < 0;
	    if (sign)
	        value = -value;
	    var lo = value >>> 0,
	        hi = (value - lo) / 4294967296 >>> 0;
	    if (sign) {
	        hi = ~hi >>> 0;
	        lo = ~lo >>> 0;
	        if (++lo > 4294967295) {
	            lo = 0;
	            if (++hi > 4294967295)
	                hi = 0;
	        }
	    }
	    return new LongBits(lo, hi);
	};

	/**
	 * Constructs new long bits from a number, long or string.
	 * @param {Long|number|string} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.from = function from(value) {
	    if (typeof value === "number")
	        return LongBits.fromNumber(value);
	    if (util.isString(value)) {
	        /* istanbul ignore else */
	        if (util.Long)
	            value = util.Long.fromString(value);
	        else
	            return LongBits.fromNumber(parseInt(value, 10));
	    }
	    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
	};

	/**
	 * Converts this long bits to a possibly unsafe JavaScript number.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {number} Possibly unsafe number
	 */
	LongBits.prototype.toNumber = function toNumber(unsigned) {
	    if (!unsigned && this.hi >>> 31) {
	        var lo = ~this.lo + 1 >>> 0,
	            hi = ~this.hi     >>> 0;
	        if (!lo)
	            hi = hi + 1 >>> 0;
	        return -(lo + hi * 4294967296);
	    }
	    return this.lo + this.hi * 4294967296;
	};

	/**
	 * Converts this long bits to a long.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {Long} Long
	 */
	LongBits.prototype.toLong = function toLong(unsigned) {
	    return util.Long
	        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
	        /* istanbul ignore next */
	        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
	};

	var charCodeAt = String.prototype.charCodeAt;

	/**
	 * Constructs new long bits from the specified 8 characters long hash.
	 * @param {string} hash Hash
	 * @returns {util.LongBits} Bits
	 */
	LongBits.fromHash = function fromHash(hash) {
	    if (hash === zeroHash)
	        return zero;
	    return new LongBits(
	        ( charCodeAt.call(hash, 0)
	        | charCodeAt.call(hash, 1) << 8
	        | charCodeAt.call(hash, 2) << 16
	        | charCodeAt.call(hash, 3) << 24) >>> 0
	    ,
	        ( charCodeAt.call(hash, 4)
	        | charCodeAt.call(hash, 5) << 8
	        | charCodeAt.call(hash, 6) << 16
	        | charCodeAt.call(hash, 7) << 24) >>> 0
	    );
	};

	/**
	 * Converts this long bits to a 8 characters long hash.
	 * @returns {string} Hash
	 */
	LongBits.prototype.toHash = function toHash() {
	    return String.fromCharCode(
	        this.lo        & 255,
	        this.lo >>> 8  & 255,
	        this.lo >>> 16 & 255,
	        this.lo >>> 24      ,
	        this.hi        & 255,
	        this.hi >>> 8  & 255,
	        this.hi >>> 16 & 255,
	        this.hi >>> 24
	    );
	};

	/**
	 * Zig-zag encodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzEncode = function zzEncode() {
	    var mask =   this.hi >> 31;
	    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
	    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Zig-zag decodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzDecode = function zzDecode() {
	    var mask = -(this.lo & 1);
	    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
	    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Calculates the length of this longbits when encoded as a varint.
	 * @returns {number} Length
	 */
	LongBits.prototype.length = function length() {
	    var part0 =  this.lo,
	        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
	        part2 =  this.hi >>> 24;
	    return part2 === 0
	         ? part1 === 0
	           ? part0 < 16384
	             ? part0 < 128 ? 1 : 2
	             : part0 < 2097152 ? 3 : 4
	           : part1 < 16384
	             ? part1 < 128 ? 5 : 6
	             : part1 < 2097152 ? 7 : 8
	         : part2 < 128 ? 9 : 10;
	};
	return longbits$6;
}

var hasRequiredMinimal$6;

function requireMinimal$6 () {
	if (hasRequiredMinimal$6) return minimal$7;
	hasRequiredMinimal$6 = 1;
	(function (exports) {
		var util = exports;

		// used to return a Promise where callback is omitted
		util.asPromise = aspromise;

		// converts to / from base64 encoded strings
		util.base64 = base64$9;

		// base class of rpc.Service
		util.EventEmitter = eventemitter;

		// float handling accross browsers
		util.float = float;

		// requires modules optionally and hides the call from bundlers
		util.inquire = inquire_1;

		// converts to / from utf8 encoded strings
		util.utf8 = utf8$e;

		// provides a node-like buffer pool in the browser
		util.pool = pool_1;

		// utility to work with the low and high bits of a 64 bit value
		util.LongBits = requireLongbits$6();

		/**
		 * Whether running within node or not.
		 * @memberof util
		 * @type {boolean}
		 */
		util.isNode = Boolean(typeof commonjsGlobal !== "undefined"
		                   && commonjsGlobal
		                   && commonjsGlobal.process
		                   && commonjsGlobal.process.versions
		                   && commonjsGlobal.process.versions.node);

		/**
		 * Global object reference.
		 * @memberof util
		 * @type {Object}
		 */
		util.global = util.isNode && commonjsGlobal
		           || typeof window !== "undefined" && window
		           || typeof self   !== "undefined" && self
		           || commonjsGlobal; // eslint-disable-line no-invalid-this

		/**
		 * An immuable empty array.
		 * @memberof util
		 * @type {Array.<*>}
		 * @const
		 */
		util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

		/**
		 * An immutable empty object.
		 * @type {Object}
		 * @const
		 */
		util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

		/**
		 * Tests if the specified value is an integer.
		 * @function
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is an integer
		 */
		util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
		    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
		};

		/**
		 * Tests if the specified value is a string.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a string
		 */
		util.isString = function isString(value) {
		    return typeof value === "string" || value instanceof String;
		};

		/**
		 * Tests if the specified value is a non-null object.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a non-null object
		 */
		util.isObject = function isObject(value) {
		    return value && typeof value === "object";
		};

		/**
		 * Checks if a property on a message is considered to be present.
		 * This is an alias of {@link util.isSet}.
		 * @function
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isset =

		/**
		 * Checks if a property on a message is considered to be present.
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isSet = function isSet(obj, prop) {
		    var value = obj[prop];
		    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
		        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
		    return false;
		};

		/**
		 * Any compatible Buffer instance.
		 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
		 * @interface Buffer
		 * @extends Uint8Array
		 */

		/**
		 * Node's Buffer class if available.
		 * @type {Constructor<Buffer>}
		 */
		util.Buffer = (function() {
		    try {
		        var Buffer = util.inquire("buffer").Buffer;
		        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
		        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
		    } catch (e) {
		        /* istanbul ignore next */
		        return null;
		    }
		})();

		// Internal alias of or polyfull for Buffer.from.
		util._Buffer_from = null;

		// Internal alias of or polyfill for Buffer.allocUnsafe.
		util._Buffer_allocUnsafe = null;

		/**
		 * Creates a new buffer of whatever type supported by the environment.
		 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
		 * @returns {Uint8Array|Buffer} Buffer
		 */
		util.newBuffer = function newBuffer(sizeOrArray) {
		    /* istanbul ignore next */
		    return typeof sizeOrArray === "number"
		        ? util.Buffer
		            ? util._Buffer_allocUnsafe(sizeOrArray)
		            : new util.Array(sizeOrArray)
		        : util.Buffer
		            ? util._Buffer_from(sizeOrArray)
		            : typeof Uint8Array === "undefined"
		                ? sizeOrArray
		                : new Uint8Array(sizeOrArray);
		};

		/**
		 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
		 * @type {Constructor<Uint8Array>}
		 */
		util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

		/**
		 * Any compatible Long instance.
		 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
		 * @interface Long
		 * @property {number} low Low bits
		 * @property {number} high High bits
		 * @property {boolean} unsigned Whether unsigned or not
		 */

		/**
		 * Long.js's Long class if available.
		 * @type {Constructor<Long>}
		 */
		util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
		         || /* istanbul ignore next */ util.global.Long
		         || util.inquire("long");

		/**
		 * Regular expression used to verify 2 bit (`bool`) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key2Re = /^true|false|0|1$/;

		/**
		 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

		/**
		 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

		/**
		 * Converts a number or long to an 8 characters long hash string.
		 * @param {Long|number} value Value to convert
		 * @returns {string} Hash
		 */
		util.longToHash = function longToHash(value) {
		    return value
		        ? util.LongBits.from(value).toHash()
		        : util.LongBits.zeroHash;
		};

		/**
		 * Converts an 8 characters long hash string to a long or number.
		 * @param {string} hash Hash
		 * @param {boolean} [unsigned=false] Whether unsigned or not
		 * @returns {Long|number} Original value
		 */
		util.longFromHash = function longFromHash(hash, unsigned) {
		    var bits = util.LongBits.fromHash(hash);
		    if (util.Long)
		        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
		    return bits.toNumber(Boolean(unsigned));
		};

		/**
		 * Merges the properties of the source object into the destination object.
		 * @memberof util
		 * @param {Object.<string,*>} dst Destination object
		 * @param {Object.<string,*>} src Source object
		 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
		 * @returns {Object.<string,*>} Destination object
		 */
		function merge(dst, src, ifNotSet) { // used by converters
		    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
		        if (dst[keys[i]] === undefined || !ifNotSet)
		            dst[keys[i]] = src[keys[i]];
		    return dst;
		}

		util.merge = merge;

		/**
		 * Converts the first character of a string to lower case.
		 * @param {string} str String to convert
		 * @returns {string} Converted string
		 */
		util.lcFirst = function lcFirst(str) {
		    return str.charAt(0).toLowerCase() + str.substring(1);
		};

		/**
		 * Creates a custom error constructor.
		 * @memberof util
		 * @param {string} name Error name
		 * @returns {Constructor<Error>} Custom error constructor
		 */
		function newError(name) {

		    function CustomError(message, properties) {

		        if (!(this instanceof CustomError))
		            return new CustomError(message, properties);

		        // Error.call(this, message);
		        // ^ just returns a new error instance because the ctor can be called as a function

		        Object.defineProperty(this, "message", { get: function() { return message; } });

		        /* istanbul ignore next */
		        if (Error.captureStackTrace) // node
		            Error.captureStackTrace(this, CustomError);
		        else
		            Object.defineProperty(this, "stack", { value: new Error().stack || "" });

		        if (properties)
		            merge(this, properties);
		    }

		    CustomError.prototype = Object.create(Error.prototype, {
		        constructor: {
		            value: CustomError,
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		        name: {
		            get: function get() { return name; },
		            set: undefined,
		            enumerable: false,
		            // configurable: false would accurately preserve the behavior of
		            // the original, but I'm guessing that was not intentional.
		            // For an actual error subclass, this property would
		            // be configurable.
		            configurable: true,
		        },
		        toString: {
		            value: function value() { return this.name + ": " + this.message; },
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		    });

		    return CustomError;
		}

		util.newError = newError;

		/**
		 * Constructs a new protocol error.
		 * @classdesc Error subclass indicating a protocol specifc error.
		 * @memberof util
		 * @extends Error
		 * @template T extends Message<T>
		 * @constructor
		 * @param {string} message Error message
		 * @param {Object.<string,*>} [properties] Additional properties
		 * @example
		 * try {
		 *     MyMessage.decode(someBuffer); // throws if required fields are missing
		 * } catch (e) {
		 *     if (e instanceof ProtocolError && e.instance)
		 *         console.log("decoded so far: " + JSON.stringify(e.instance));
		 * }
		 */
		util.ProtocolError = newError("ProtocolError");

		/**
		 * So far decoded message instance.
		 * @name util.ProtocolError#instance
		 * @type {Message<T>}
		 */

		/**
		 * A OneOf getter as returned by {@link util.oneOfGetter}.
		 * @typedef OneOfGetter
		 * @type {function}
		 * @returns {string|undefined} Set field name, if any
		 */

		/**
		 * Builds a getter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfGetter} Unbound getter
		 */
		util.oneOfGetter = function getOneOf(fieldNames) {
		    var fieldMap = {};
		    for (var i = 0; i < fieldNames.length; ++i)
		        fieldMap[fieldNames[i]] = 1;

		    /**
		     * @returns {string|undefined} Set field name, if any
		     * @this Object
		     * @ignore
		     */
		    return function() { // eslint-disable-line consistent-return
		        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
		            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
		                return keys[i];
		    };
		};

		/**
		 * A OneOf setter as returned by {@link util.oneOfSetter}.
		 * @typedef OneOfSetter
		 * @type {function}
		 * @param {string|undefined} value Field name
		 * @returns {undefined}
		 */

		/**
		 * Builds a setter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfSetter} Unbound setter
		 */
		util.oneOfSetter = function setOneOf(fieldNames) {

		    /**
		     * @param {string} name Field name
		     * @returns {undefined}
		     * @this Object
		     * @ignore
		     */
		    return function(name) {
		        for (var i = 0; i < fieldNames.length; ++i)
		            if (fieldNames[i] !== name)
		                delete this[fieldNames[i]];
		    };
		};

		/**
		 * Default conversion options used for {@link Message#toJSON} implementations.
		 *
		 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
		 *
		 * - Longs become strings
		 * - Enums become string keys
		 * - Bytes become base64 encoded strings
		 * - (Sub-)Messages become plain objects
		 * - Maps become plain objects with all string keys
		 * - Repeated fields become arrays
		 * - NaN and Infinity for float and double fields become strings
		 *
		 * @type {IConversionOptions}
		 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
		 */
		util.toJSONOptions = {
		    longs: String,
		    enums: String,
		    bytes: String,
		    json: true
		};

		// Sets up buffer utility according to the environment (called in index-minimal)
		util._configure = function() {
		    var Buffer = util.Buffer;
		    /* istanbul ignore if */
		    if (!Buffer) {
		        util._Buffer_from = util._Buffer_allocUnsafe = null;
		        return;
		    }
		    // because node 4.x buffers are incompatible & immutable
		    // see: https://github.com/dcodeIO/protobuf.js/pull/665
		    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
		        /* istanbul ignore next */
		        function Buffer_from(value, encoding) {
		            return new Buffer(value, encoding);
		        };
		    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
		        /* istanbul ignore next */
		        function Buffer_allocUnsafe(size) {
		            return new Buffer(size);
		        };
		};
} (minimal$7));
	return minimal$7;
}

var reader$c = Reader$d;

var util$B      = requireMinimal$6();

var BufferReader$d; // cyclic

var LongBits$d  = util$B.LongBits,
    utf8$d      = util$B.utf8;

/* istanbul ignore next */
function indexOutOfRange$6(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader$d(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array$6 = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader$d(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader$d(buffer);
        throw Error("illegal buffer");
    };

var create$f = function create() {
    return util$B.Buffer
        ? function create_buffer_setup(buffer) {
            return (Reader$d.create = function create_buffer(buffer) {
                return util$B.Buffer.isBuffer(buffer)
                    ? new BufferReader$d(buffer)
                    /* istanbul ignore next */
                    : create_array$6(buffer);
            })(buffer);
        }
        /* istanbul ignore next */
        : create_array$6;
};

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader$d.create = create$f();

Reader$d.prototype._slice = util$B.Array.prototype.subarray || /* istanbul ignore next */ util$B.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader$d.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange$6(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$d.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$d.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint$6() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits$d(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$6(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$6(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader$d.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end$6(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader$d.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$6(this, 4);

    return readFixed32_end$6(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader$d.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$6(this, 4);

    return readFixed32_end$6(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64$6(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$6(this, 8);

    return new LongBits$d(readFixed32_end$6(this.buf, this.pos += 4), readFixed32_end$6(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$d.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$6(this, 4);

    var value = util$B.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$d.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$6(this, 4);

    var value = util$B.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader$d.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange$6(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader$d.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8$d.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader$d.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange$6(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$6(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader$d.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader$d._configure = function(BufferReader_) {
    BufferReader$d = BufferReader_;
    Reader$d.create = create$f();
    BufferReader$d._configure();

    var fn = util$B.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util$B.merge(Reader$d.prototype, {

        int64: function read_int64() {
            return readLongVarint$6.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint$6.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint$6.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64$6.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64$6.call(this)[fn](false);
        }

    });
};

var reader_buffer$6 = BufferReader$c;

// extends Reader
var Reader$c = reader$c;
(BufferReader$c.prototype = Object.create(Reader$c.prototype)).constructor = BufferReader$c;

var util$A = requireMinimal$6();

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader$c(buffer) {
    Reader$c.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

BufferReader$c._configure = function () {
    /* istanbul ignore else */
    if (util$A.Buffer)
        BufferReader$c.prototype._slice = util$A.Buffer.prototype.slice;
};


/**
 * @override
 */
BufferReader$c.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice
        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))
        : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

BufferReader$c._configure();

var minimalExports$6 = requireMinimal$6();
var util$z = /*@__PURE__*/getDefaultExportFromCjs(minimalExports$6);

var writer$c = Writer$d;

var util$y      = requireMinimal$6();

var BufferWriter$d; // cyclic

var LongBits$c  = util$y.LongBits,
    base64$8    = util$y.base64,
    utf8$c      = util$y.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op$6(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop$9() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State$6(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer$d() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op$6(noop$9, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

var create$e = function create() {
    return util$y.Buffer
        ? function create_buffer_setup() {
            return (Writer$d.create = function create_buffer() {
                return new BufferWriter$d();
            })();
        }
        /* istanbul ignore next */
        : function create_array() {
            return new Writer$d();
        };
};

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer$d.create = create$e();

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer$d.alloc = function alloc(size) {
    return new util$y.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util$y.Array !== Array)
    Writer$d.alloc = util$y.pool(Writer$d.alloc, util$y.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer$d.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op$6(fn, len, val);
    this.len += len;
    return this;
};

function writeByte$6(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32$6(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp$6(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp$6.prototype = Object.create(Op$6.prototype);
VarintOp$6.prototype.fn = writeVarint32$6;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp$6(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64$6, 10, LongBits$c.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64$6(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$d.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits$c.from(value);
    return this._push(writeVarint64$6, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$d.prototype.int64 = Writer$d.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$d.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits$c.from(value).zzEncode();
    return this._push(writeVarint64$6, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.bool = function write_bool(value) {
    return this._push(writeByte$6, 1, value ? 1 : 0);
};

function writeFixed32$6(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32$6, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.sfixed32 = Writer$d.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$d.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits$c.from(value);
    return this._push(writeFixed32$6, 4, bits.lo)._push(writeFixed32$6, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$d.prototype.sfixed64 = Writer$d.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.float = function write_float(value) {
    return this._push(util$y.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.double = function write_double(value) {
    return this._push(util$y.float.writeDoubleLE, 8, value);
};

var writeBytes$6 = util$y.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte$6, 1, 0);
    if (util$y.isString(value)) {
        var buf = Writer$d.alloc(len = base64$8.length(value));
        base64$8.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes$6, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer$d.prototype.string = function write_string(value) {
    var len = utf8$c.length(value);
    return len
        ? this.uint32(len)._push(utf8$c.write, len, value)
        : this._push(writeByte$6, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer$d.prototype.fork = function fork() {
    this.states = new State$6(this);
    this.head = this.tail = new Op$6(noop$9, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer$d.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op$6(noop$9, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer$d.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer$d.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer$d._configure = function(BufferWriter_) {
    BufferWriter$d = BufferWriter_;
    Writer$d.create = create$e();
    BufferWriter$d._configure();
};

var writer_buffer$6 = BufferWriter$c;

// extends Writer
var Writer$c = writer$c;
(BufferWriter$c.prototype = Object.create(Writer$c.prototype)).constructor = BufferWriter$c;

var util$x = requireMinimal$6();

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter$c() {
    Writer$c.call(this);
}

BufferWriter$c._configure = function () {
    /**
     * Allocates a buffer of the specified size.
     * @function
     * @param {number} size Buffer size
     * @returns {Buffer} Buffer
     */
    BufferWriter$c.alloc = util$x._Buffer_allocUnsafe;

    BufferWriter$c.writeBytesBuffer = util$x.Buffer && util$x.Buffer.prototype instanceof Uint8Array && util$x.Buffer.prototype.set.name === "set"
        ? function writeBytesBuffer_set(val, buf, pos) {
          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
          // also works for plain array values
        }
        /* istanbul ignore next */
        : function writeBytesBuffer_copy(val, buf, pos) {
          if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
          else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
        };
};


/**
 * @override
 */
BufferWriter$c.prototype.bytes = function write_bytes_buffer(value) {
    if (util$x.isString(value))
        value = util$x._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(BufferWriter$c.writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer$6(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util$x.utf8.write(val, buf, pos);
    else if (buf.utf8Write)
        buf.utf8Write(val, pos);
    else
        buf.write(val, pos);
}

/**
 * @override
 */
BufferWriter$c.prototype.string = function write_string_buffer(value) {
    var len = util$x.Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer$6, len, value);
    return this;
};


/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

BufferWriter$c._configure();

// @ts-expect-error no types
function configure$5() {
    util$z._configure();
    reader$c._configure(reader_buffer$6);
    writer$c._configure(writer_buffer$6);
}
// Set up buffer utility according to the environment
configure$5();
// monkey patch the reader to add native bigint support
const methods$5 = [
    'uint64', 'int64', 'sint64', 'fixed64', 'sfixed64'
];
function patchReader$5(obj) {
    for (const method of methods$5) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function () {
            return BigInt(original.call(this).toString());
        };
    }
    return obj;
}
function reader$b(buf) {
    return patchReader$5(new reader$c(buf));
}
function patchWriter$5(obj) {
    for (const method of methods$5) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function (val) {
            return original.call(this, val.toString());
        };
    }
    return obj;
}
function writer$b() {
    return patchWriter$5(writer$c.create());
}

function decodeMessage$6(buf, codec) {
    const r = reader$b(buf instanceof Uint8Array ? buf : buf.subarray());
    return codec.decode(r);
}

function encodeMessage$5(message, codec) {
    const w = writer$b();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES$5;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES$5 || (CODEC_TYPES$5 = {}));
function createCodec$6(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function enumeration$2(v) {
    function findValue(val) {
        // Use the reverse mapping to look up the enum key for the stored value
        // https://www.typescriptlang.org/docs/handbook/enums.html#reverse-mappings
        if (v[val.toString()] == null) {
            throw new Error('Invalid enum value');
        }
        return v[val];
    }
    const encode = function enumEncode(val, writer) {
        const enumValue = findValue(val);
        writer.int32(enumValue);
    };
    const decode = function enumDecode(reader) {
        const val = reader.int32();
        return findValue(val);
    };
    // @ts-expect-error yeah yeah
    return createCodec$6('enum', CODEC_TYPES$5.VARINT, encode, decode);
}

function message$5(encode, decode) {
    return createCodec$6('message', CODEC_TYPES$5.LENGTH_DELIMITED, encode, decode);
}

/* eslint-disable import/export */
var KeyType;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType || (KeyType = {}));
var __KeyTypeValues;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues || (__KeyTypeValues = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration$2(__KeyTypeValues);
    };
})(KeyType || (KeyType = {}));
var PublicKey;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$5((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage$5(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$6(buf, PublicKey.codec());
    };
})(PublicKey || (PublicKey = {}));
var PrivateKey;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$5((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage$5(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$6(buf, PrivateKey.codec());
    };
})(PrivateKey || (PrivateKey = {}));

/**
 * Node.js module for Forge.
 *
 * @author Dave Longley
 *
 * Copyright 2011-2016 Digital Bazaar, Inc.
 */

var forge$s = {
  // default options
  options: {
    usePureJavaScript: false
  }
};

var utilExports = {};
var util$w = {
  get exports(){ return utilExports; },
  set exports(v){ utilExports = v; },
};

/**
 * Base-N/Base-X encoding/decoding functions.
 *
 * Original implementation from base-x:
 * https://github.com/cryptocoinjs/base-x
 *
 * Which is MIT licensed:
 *
 * The MIT License (MIT)
 *
 * Copyright base-x contributors (c) 2016
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */

var api = {};
var baseN$1 = api;

// baseN alphabet indexes
var _reverseAlphabets = {};

/**
 * BaseN-encodes a Uint8Array using the given alphabet.
 *
 * @param input the Uint8Array to encode.
 * @param maxline the maximum number of encoded characters per line to use,
 *          defaults to none.
 *
 * @return the baseN-encoded output string.
 */
api.encode = function(input, alphabet, maxline) {
  if(typeof alphabet !== 'string') {
    throw new TypeError('"alphabet" must be a string.');
  }
  if(maxline !== undefined && typeof maxline !== 'number') {
    throw new TypeError('"maxline" must be a number.');
  }

  var output = '';

  if(!(input instanceof Uint8Array)) {
    // assume forge byte buffer
    output = _encodeWithByteBuffer(input, alphabet);
  } else {
    var i = 0;
    var base = alphabet.length;
    var first = alphabet.charAt(0);
    var digits = [0];
    for(i = 0; i < input.length; ++i) {
      for(var j = 0, carry = input[i]; j < digits.length; ++j) {
        carry += digits[j] << 8;
        digits[j] = carry % base;
        carry = (carry / base) | 0;
      }

      while(carry > 0) {
        digits.push(carry % base);
        carry = (carry / base) | 0;
      }
    }

    // deal with leading zeros
    for(i = 0; input[i] === 0 && i < input.length - 1; ++i) {
      output += first;
    }
    // convert digits to a string
    for(i = digits.length - 1; i >= 0; --i) {
      output += alphabet[digits[i]];
    }
  }

  if(maxline) {
    var regex = new RegExp('.{1,' + maxline + '}', 'g');
    output = output.match(regex).join('\r\n');
  }

  return output;
};

/**
 * Decodes a baseN-encoded (using the given alphabet) string to a
 * Uint8Array.
 *
 * @param input the baseN-encoded input string.
 *
 * @return the Uint8Array.
 */
api.decode = function(input, alphabet) {
  if(typeof input !== 'string') {
    throw new TypeError('"input" must be a string.');
  }
  if(typeof alphabet !== 'string') {
    throw new TypeError('"alphabet" must be a string.');
  }

  var table = _reverseAlphabets[alphabet];
  if(!table) {
    // compute reverse alphabet
    table = _reverseAlphabets[alphabet] = [];
    for(var i = 0; i < alphabet.length; ++i) {
      table[alphabet.charCodeAt(i)] = i;
    }
  }

  // remove whitespace characters
  input = input.replace(/\s/g, '');

  var base = alphabet.length;
  var first = alphabet.charAt(0);
  var bytes = [0];
  for(var i = 0; i < input.length; i++) {
    var value = table[input.charCodeAt(i)];
    if(value === undefined) {
      return;
    }

    for(var j = 0, carry = value; j < bytes.length; ++j) {
      carry += bytes[j] * base;
      bytes[j] = carry & 0xff;
      carry >>= 8;
    }

    while(carry > 0) {
      bytes.push(carry & 0xff);
      carry >>= 8;
    }
  }

  // deal with leading zeros
  for(var k = 0; input[k] === first && k < input.length - 1; ++k) {
    bytes.push(0);
  }

  if(typeof Buffer !== 'undefined') {
    return Buffer.from(bytes.reverse());
  }

  return new Uint8Array(bytes.reverse());
};

function _encodeWithByteBuffer(input, alphabet) {
  var i = 0;
  var base = alphabet.length;
  var first = alphabet.charAt(0);
  var digits = [0];
  for(i = 0; i < input.length(); ++i) {
    for(var j = 0, carry = input.at(i); j < digits.length; ++j) {
      carry += digits[j] << 8;
      digits[j] = carry % base;
      carry = (carry / base) | 0;
    }

    while(carry > 0) {
      digits.push(carry % base);
      carry = (carry / base) | 0;
    }
  }

  var output = '';

  // deal with leading zeros
  for(i = 0; input.at(i) === 0 && i < input.length() - 1; ++i) {
    output += first;
  }
  // convert digits to a string
  for(i = digits.length - 1; i >= 0; --i) {
    output += alphabet[digits[i]];
  }

  return output;
}

/**
 * Utility functions for web applications.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2018 Digital Bazaar, Inc.
 */

var forge$r = forge$s;
var baseN = baseN$1;

/* Utilities API */
var util$v = util$w.exports = forge$r.util = forge$r.util || {};

// define setImmediate and nextTick
(function() {
  // use native nextTick (unless we're in webpack)
  // webpack (or better node-libs-browser polyfill) sets process.browser.
  // this way we can detect webpack properly
  if(typeof process !== 'undefined' && process.nextTick && !process.browser) {
    util$v.nextTick = process.nextTick;
    if(typeof setImmediate === 'function') {
      util$v.setImmediate = setImmediate;
    } else {
      // polyfill setImmediate with nextTick, older versions of node
      // (those w/o setImmediate) won't totally starve IO
      util$v.setImmediate = util$v.nextTick;
    }
    return;
  }

  // polyfill nextTick with native setImmediate
  if(typeof setImmediate === 'function') {
    util$v.setImmediate = function() { return setImmediate.apply(undefined, arguments); };
    util$v.nextTick = function(callback) {
      return setImmediate(callback);
    };
    return;
  }

  /* Note: A polyfill upgrade pattern is used here to allow combining
  polyfills. For example, MutationObserver is fast, but blocks UI updates,
  so it needs to allow UI updates periodically, so it falls back on
  postMessage or setTimeout. */

  // polyfill with setTimeout
  util$v.setImmediate = function(callback) {
    setTimeout(callback, 0);
  };

  // upgrade polyfill to use postMessage
  if(typeof window !== 'undefined' &&
    typeof window.postMessage === 'function') {
    var msg = 'forge.setImmediate';
    var callbacks = [];
    util$v.setImmediate = function(callback) {
      callbacks.push(callback);
      // only send message when one hasn't been sent in
      // the current turn of the event loop
      if(callbacks.length === 1) {
        window.postMessage(msg, '*');
      }
    };
    function handler(event) {
      if(event.source === window && event.data === msg) {
        event.stopPropagation();
        var copy = callbacks.slice();
        callbacks.length = 0;
        copy.forEach(function(callback) {
          callback();
        });
      }
    }
    window.addEventListener('message', handler, true);
  }

  // upgrade polyfill to use MutationObserver
  if(typeof MutationObserver !== 'undefined') {
    // polyfill with MutationObserver
    var now = Date.now();
    var attr = true;
    var div = document.createElement('div');
    var callbacks = [];
    new MutationObserver(function() {
      var copy = callbacks.slice();
      callbacks.length = 0;
      copy.forEach(function(callback) {
        callback();
      });
    }).observe(div, {attributes: true});
    var oldSetImmediate = util$v.setImmediate;
    util$v.setImmediate = function(callback) {
      if(Date.now() - now > 15) {
        now = Date.now();
        oldSetImmediate(callback);
      } else {
        callbacks.push(callback);
        // only trigger observer when it hasn't been triggered in
        // the current turn of the event loop
        if(callbacks.length === 1) {
          div.setAttribute('a', attr = !attr);
        }
      }
    };
  }

  util$v.nextTick = util$v.setImmediate;
})();

// check if running under Node.js
util$v.isNodejs =
  typeof process !== 'undefined' && process.versions && process.versions.node;


// 'self' will also work in Web Workers (instance of WorkerGlobalScope) while
// it will point to `window` in the main thread.
// To remain compatible with older browsers, we fall back to 'window' if 'self'
// is not available.
util$v.globalScope = (function() {
  if(util$v.isNodejs) {
    return commonjsGlobal;
  }

  return typeof self === 'undefined' ? window : self;
})();

// define isArray
util$v.isArray = Array.isArray || function(x) {
  return Object.prototype.toString.call(x) === '[object Array]';
};

// define isArrayBuffer
util$v.isArrayBuffer = function(x) {
  return typeof ArrayBuffer !== 'undefined' && x instanceof ArrayBuffer;
};

// define isArrayBufferView
util$v.isArrayBufferView = function(x) {
  return x && util$v.isArrayBuffer(x.buffer) && x.byteLength !== undefined;
};

/**
 * Ensure a bits param is 8, 16, 24, or 32. Used to validate input for
 * algorithms where bit manipulation, JavaScript limitations, and/or algorithm
 * design only allow for byte operations of a limited size.
 *
 * @param n number of bits.
 *
 * Throw Error if n invalid.
 */
function _checkBitsParam(n) {
  if(!(n === 8 || n === 16 || n === 24 || n === 32)) {
    throw new Error('Only 8, 16, 24, or 32 bits supported: ' + n);
  }
}

// TODO: set ByteBuffer to best available backing
util$v.ByteBuffer = ByteStringBuffer;

/** Buffer w/BinaryString backing */

/**
 * Constructor for a binary string backed byte buffer.
 *
 * @param [b] the bytes to wrap (either encoded as string, one byte per
 *          character, or as an ArrayBuffer or Typed Array).
 */
function ByteStringBuffer(b) {
  // TODO: update to match DataBuffer API

  // the data in this buffer
  this.data = '';
  // the pointer for reading from this buffer
  this.read = 0;

  if(typeof b === 'string') {
    this.data = b;
  } else if(util$v.isArrayBuffer(b) || util$v.isArrayBufferView(b)) {
    if(typeof Buffer !== 'undefined' && b instanceof Buffer) {
      this.data = b.toString('binary');
    } else {
      // convert native buffer to forge buffer
      // FIXME: support native buffers internally instead
      var arr = new Uint8Array(b);
      try {
        this.data = String.fromCharCode.apply(null, arr);
      } catch(e) {
        for(var i = 0; i < arr.length; ++i) {
          this.putByte(arr[i]);
        }
      }
    }
  } else if(b instanceof ByteStringBuffer ||
    (typeof b === 'object' && typeof b.data === 'string' &&
    typeof b.read === 'number')) {
    // copy existing buffer
    this.data = b.data;
    this.read = b.read;
  }

  // used for v8 optimization
  this._constructedStringLength = 0;
}
util$v.ByteStringBuffer = ByteStringBuffer;

/* Note: This is an optimization for V8-based browsers. When V8 concatenates
  a string, the strings are only joined logically using a "cons string" or
  "constructed/concatenated string". These containers keep references to one
  another and can result in very large memory usage. For example, if a 2MB
  string is constructed by concatenating 4 bytes together at a time, the
  memory usage will be ~44MB; so ~22x increase. The strings are only joined
  together when an operation requiring their joining takes place, such as
  substr(). This function is called when adding data to this buffer to ensure
  these types of strings are periodically joined to reduce the memory
  footprint. */
var _MAX_CONSTRUCTED_STRING_LENGTH = 4096;
util$v.ByteStringBuffer.prototype._optimizeConstructedString = function(x) {
  this._constructedStringLength += x;
  if(this._constructedStringLength > _MAX_CONSTRUCTED_STRING_LENGTH) {
    // this substr() should cause the constructed string to join
    this.data.substr(0, 1);
    this._constructedStringLength = 0;
  }
};

/**
 * Gets the number of bytes in this buffer.
 *
 * @return the number of bytes in this buffer.
 */
util$v.ByteStringBuffer.prototype.length = function() {
  return this.data.length - this.read;
};

/**
 * Gets whether or not this buffer is empty.
 *
 * @return true if this buffer is empty, false if not.
 */
util$v.ByteStringBuffer.prototype.isEmpty = function() {
  return this.length() <= 0;
};

/**
 * Puts a byte in this buffer.
 *
 * @param b the byte to put.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putByte = function(b) {
  return this.putBytes(String.fromCharCode(b));
};

/**
 * Puts a byte in this buffer N times.
 *
 * @param b the byte to put.
 * @param n the number of bytes of value b to put.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.fillWithByte = function(b, n) {
  b = String.fromCharCode(b);
  var d = this.data;
  while(n > 0) {
    if(n & 1) {
      d += b;
    }
    n >>>= 1;
    if(n > 0) {
      b += b;
    }
  }
  this.data = d;
  this._optimizeConstructedString(n);
  return this;
};

/**
 * Puts bytes in this buffer.
 *
 * @param bytes the bytes (as a binary encoded string) to put.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putBytes = function(bytes) {
  this.data += bytes;
  this._optimizeConstructedString(bytes.length);
  return this;
};

/**
 * Puts a UTF-16 encoded string into this buffer.
 *
 * @param str the string to put.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putString = function(str) {
  return this.putBytes(util$v.encodeUtf8(str));
};

/**
 * Puts a 16-bit integer in this buffer in big-endian order.
 *
 * @param i the 16-bit integer.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putInt16 = function(i) {
  return this.putBytes(
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i & 0xFF));
};

/**
 * Puts a 24-bit integer in this buffer in big-endian order.
 *
 * @param i the 24-bit integer.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putInt24 = function(i) {
  return this.putBytes(
    String.fromCharCode(i >> 16 & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i & 0xFF));
};

/**
 * Puts a 32-bit integer in this buffer in big-endian order.
 *
 * @param i the 32-bit integer.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putInt32 = function(i) {
  return this.putBytes(
    String.fromCharCode(i >> 24 & 0xFF) +
    String.fromCharCode(i >> 16 & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i & 0xFF));
};

/**
 * Puts a 16-bit integer in this buffer in little-endian order.
 *
 * @param i the 16-bit integer.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putInt16Le = function(i) {
  return this.putBytes(
    String.fromCharCode(i & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF));
};

/**
 * Puts a 24-bit integer in this buffer in little-endian order.
 *
 * @param i the 24-bit integer.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putInt24Le = function(i) {
  return this.putBytes(
    String.fromCharCode(i & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i >> 16 & 0xFF));
};

/**
 * Puts a 32-bit integer in this buffer in little-endian order.
 *
 * @param i the 32-bit integer.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putInt32Le = function(i) {
  return this.putBytes(
    String.fromCharCode(i & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i >> 16 & 0xFF) +
    String.fromCharCode(i >> 24 & 0xFF));
};

/**
 * Puts an n-bit integer in this buffer in big-endian order.
 *
 * @param i the n-bit integer.
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putInt = function(i, n) {
  _checkBitsParam(n);
  var bytes = '';
  do {
    n -= 8;
    bytes += String.fromCharCode((i >> n) & 0xFF);
  } while(n > 0);
  return this.putBytes(bytes);
};

/**
 * Puts a signed n-bit integer in this buffer in big-endian order. Two's
 * complement representation is used.
 *
 * @param i the n-bit integer.
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putSignedInt = function(i, n) {
  // putInt checks n
  if(i < 0) {
    i += 2 << (n - 1);
  }
  return this.putInt(i, n);
};

/**
 * Puts the given buffer into this buffer.
 *
 * @param buffer the buffer to put into this one.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.putBuffer = function(buffer) {
  return this.putBytes(buffer.getBytes());
};

/**
 * Gets a byte from this buffer and advances the read pointer by 1.
 *
 * @return the byte.
 */
util$v.ByteStringBuffer.prototype.getByte = function() {
  return this.data.charCodeAt(this.read++);
};

/**
 * Gets a uint16 from this buffer in big-endian order and advances the read
 * pointer by 2.
 *
 * @return the uint16.
 */
util$v.ByteStringBuffer.prototype.getInt16 = function() {
  var rval = (
    this.data.charCodeAt(this.read) << 8 ^
    this.data.charCodeAt(this.read + 1));
  this.read += 2;
  return rval;
};

/**
 * Gets a uint24 from this buffer in big-endian order and advances the read
 * pointer by 3.
 *
 * @return the uint24.
 */
util$v.ByteStringBuffer.prototype.getInt24 = function() {
  var rval = (
    this.data.charCodeAt(this.read) << 16 ^
    this.data.charCodeAt(this.read + 1) << 8 ^
    this.data.charCodeAt(this.read + 2));
  this.read += 3;
  return rval;
};

/**
 * Gets a uint32 from this buffer in big-endian order and advances the read
 * pointer by 4.
 *
 * @return the word.
 */
util$v.ByteStringBuffer.prototype.getInt32 = function() {
  var rval = (
    this.data.charCodeAt(this.read) << 24 ^
    this.data.charCodeAt(this.read + 1) << 16 ^
    this.data.charCodeAt(this.read + 2) << 8 ^
    this.data.charCodeAt(this.read + 3));
  this.read += 4;
  return rval;
};

/**
 * Gets a uint16 from this buffer in little-endian order and advances the read
 * pointer by 2.
 *
 * @return the uint16.
 */
util$v.ByteStringBuffer.prototype.getInt16Le = function() {
  var rval = (
    this.data.charCodeAt(this.read) ^
    this.data.charCodeAt(this.read + 1) << 8);
  this.read += 2;
  return rval;
};

/**
 * Gets a uint24 from this buffer in little-endian order and advances the read
 * pointer by 3.
 *
 * @return the uint24.
 */
util$v.ByteStringBuffer.prototype.getInt24Le = function() {
  var rval = (
    this.data.charCodeAt(this.read) ^
    this.data.charCodeAt(this.read + 1) << 8 ^
    this.data.charCodeAt(this.read + 2) << 16);
  this.read += 3;
  return rval;
};

/**
 * Gets a uint32 from this buffer in little-endian order and advances the read
 * pointer by 4.
 *
 * @return the word.
 */
util$v.ByteStringBuffer.prototype.getInt32Le = function() {
  var rval = (
    this.data.charCodeAt(this.read) ^
    this.data.charCodeAt(this.read + 1) << 8 ^
    this.data.charCodeAt(this.read + 2) << 16 ^
    this.data.charCodeAt(this.read + 3) << 24);
  this.read += 4;
  return rval;
};

/**
 * Gets an n-bit integer from this buffer in big-endian order and advances the
 * read pointer by ceil(n/8).
 *
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return the integer.
 */
util$v.ByteStringBuffer.prototype.getInt = function(n) {
  _checkBitsParam(n);
  var rval = 0;
  do {
    // TODO: Use (rval * 0x100) if adding support for 33 to 53 bits.
    rval = (rval << 8) + this.data.charCodeAt(this.read++);
    n -= 8;
  } while(n > 0);
  return rval;
};

/**
 * Gets a signed n-bit integer from this buffer in big-endian order, using
 * two's complement, and advances the read pointer by n/8.
 *
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return the integer.
 */
util$v.ByteStringBuffer.prototype.getSignedInt = function(n) {
  // getInt checks n
  var x = this.getInt(n);
  var max = 2 << (n - 2);
  if(x >= max) {
    x -= max << 1;
  }
  return x;
};

/**
 * Reads bytes out as a binary encoded string and clears them from the
 * buffer. Note that the resulting string is binary encoded (in node.js this
 * encoding is referred to as `binary`, it is *not* `utf8`).
 *
 * @param count the number of bytes to read, undefined or null for all.
 *
 * @return a binary encoded string of bytes.
 */
util$v.ByteStringBuffer.prototype.getBytes = function(count) {
  var rval;
  if(count) {
    // read count bytes
    count = Math.min(this.length(), count);
    rval = this.data.slice(this.read, this.read + count);
    this.read += count;
  } else if(count === 0) {
    rval = '';
  } else {
    // read all bytes, optimize to only copy when needed
    rval = (this.read === 0) ? this.data : this.data.slice(this.read);
    this.clear();
  }
  return rval;
};

/**
 * Gets a binary encoded string of the bytes from this buffer without
 * modifying the read pointer.
 *
 * @param count the number of bytes to get, omit to get all.
 *
 * @return a string full of binary encoded characters.
 */
util$v.ByteStringBuffer.prototype.bytes = function(count) {
  return (typeof(count) === 'undefined' ?
    this.data.slice(this.read) :
    this.data.slice(this.read, this.read + count));
};

/**
 * Gets a byte at the given index without modifying the read pointer.
 *
 * @param i the byte index.
 *
 * @return the byte.
 */
util$v.ByteStringBuffer.prototype.at = function(i) {
  return this.data.charCodeAt(this.read + i);
};

/**
 * Puts a byte at the given index without modifying the read pointer.
 *
 * @param i the byte index.
 * @param b the byte to put.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.setAt = function(i, b) {
  this.data = this.data.substr(0, this.read + i) +
    String.fromCharCode(b) +
    this.data.substr(this.read + i + 1);
  return this;
};

/**
 * Gets the last byte without modifying the read pointer.
 *
 * @return the last byte.
 */
util$v.ByteStringBuffer.prototype.last = function() {
  return this.data.charCodeAt(this.data.length - 1);
};

/**
 * Creates a copy of this buffer.
 *
 * @return the copy.
 */
util$v.ByteStringBuffer.prototype.copy = function() {
  var c = util$v.createBuffer(this.data);
  c.read = this.read;
  return c;
};

/**
 * Compacts this buffer.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.compact = function() {
  if(this.read > 0) {
    this.data = this.data.slice(this.read);
    this.read = 0;
  }
  return this;
};

/**
 * Clears this buffer.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.clear = function() {
  this.data = '';
  this.read = 0;
  return this;
};

/**
 * Shortens this buffer by triming bytes off of the end of this buffer.
 *
 * @param count the number of bytes to trim off.
 *
 * @return this buffer.
 */
util$v.ByteStringBuffer.prototype.truncate = function(count) {
  var len = Math.max(0, this.length() - count);
  this.data = this.data.substr(this.read, len);
  this.read = 0;
  return this;
};

/**
 * Converts this buffer to a hexadecimal string.
 *
 * @return a hexadecimal string.
 */
util$v.ByteStringBuffer.prototype.toHex = function() {
  var rval = '';
  for(var i = this.read; i < this.data.length; ++i) {
    var b = this.data.charCodeAt(i);
    if(b < 16) {
      rval += '0';
    }
    rval += b.toString(16);
  }
  return rval;
};

/**
 * Converts this buffer to a UTF-16 string (standard JavaScript string).
 *
 * @return a UTF-16 string.
 */
util$v.ByteStringBuffer.prototype.toString = function() {
  return util$v.decodeUtf8(this.bytes());
};

/** End Buffer w/BinaryString backing */

/** Buffer w/UInt8Array backing */

/**
 * FIXME: Experimental. Do not use yet.
 *
 * Constructor for an ArrayBuffer-backed byte buffer.
 *
 * The buffer may be constructed from a string, an ArrayBuffer, DataView, or a
 * TypedArray.
 *
 * If a string is given, its encoding should be provided as an option,
 * otherwise it will default to 'binary'. A 'binary' string is encoded such
 * that each character is one byte in length and size.
 *
 * If an ArrayBuffer, DataView, or TypedArray is given, it will be used
 * *directly* without any copying. Note that, if a write to the buffer requires
 * more space, the buffer will allocate a new backing ArrayBuffer to
 * accommodate. The starting read and write offsets for the buffer may be
 * given as options.
 *
 * @param [b] the initial bytes for this buffer.
 * @param options the options to use:
 *          [readOffset] the starting read offset to use (default: 0).
 *          [writeOffset] the starting write offset to use (default: the
 *            length of the first parameter).
 *          [growSize] the minimum amount, in bytes, to grow the buffer by to
 *            accommodate writes (default: 1024).
 *          [encoding] the encoding ('binary', 'utf8', 'utf16', 'hex') for the
 *            first parameter, if it is a string (default: 'binary').
 */
function DataBuffer(b, options) {
  // default options
  options = options || {};

  // pointers for read from/write to buffer
  this.read = options.readOffset || 0;
  this.growSize = options.growSize || 1024;

  var isArrayBuffer = util$v.isArrayBuffer(b);
  var isArrayBufferView = util$v.isArrayBufferView(b);
  if(isArrayBuffer || isArrayBufferView) {
    // use ArrayBuffer directly
    if(isArrayBuffer) {
      this.data = new DataView(b);
    } else {
      // TODO: adjust read/write offset based on the type of view
      // or specify that this must be done in the options ... that the
      // offsets are byte-based
      this.data = new DataView(b.buffer, b.byteOffset, b.byteLength);
    }
    this.write = ('writeOffset' in options ?
      options.writeOffset : this.data.byteLength);
    return;
  }

  // initialize to empty array buffer and add any given bytes using putBytes
  this.data = new DataView(new ArrayBuffer(0));
  this.write = 0;

  if(b !== null && b !== undefined) {
    this.putBytes(b);
  }

  if('writeOffset' in options) {
    this.write = options.writeOffset;
  }
}
util$v.DataBuffer = DataBuffer;

/**
 * Gets the number of bytes in this buffer.
 *
 * @return the number of bytes in this buffer.
 */
util$v.DataBuffer.prototype.length = function() {
  return this.write - this.read;
};

/**
 * Gets whether or not this buffer is empty.
 *
 * @return true if this buffer is empty, false if not.
 */
util$v.DataBuffer.prototype.isEmpty = function() {
  return this.length() <= 0;
};

/**
 * Ensures this buffer has enough empty space to accommodate the given number
 * of bytes. An optional parameter may be given that indicates a minimum
 * amount to grow the buffer if necessary. If the parameter is not given,
 * the buffer will be grown by some previously-specified default amount
 * or heuristic.
 *
 * @param amount the number of bytes to accommodate.
 * @param [growSize] the minimum amount, in bytes, to grow the buffer by if
 *          necessary.
 */
util$v.DataBuffer.prototype.accommodate = function(amount, growSize) {
  if(this.length() >= amount) {
    return this;
  }
  growSize = Math.max(growSize || this.growSize, amount);

  // grow buffer
  var src = new Uint8Array(
    this.data.buffer, this.data.byteOffset, this.data.byteLength);
  var dst = new Uint8Array(this.length() + growSize);
  dst.set(src);
  this.data = new DataView(dst.buffer);

  return this;
};

/**
 * Puts a byte in this buffer.
 *
 * @param b the byte to put.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putByte = function(b) {
  this.accommodate(1);
  this.data.setUint8(this.write++, b);
  return this;
};

/**
 * Puts a byte in this buffer N times.
 *
 * @param b the byte to put.
 * @param n the number of bytes of value b to put.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.fillWithByte = function(b, n) {
  this.accommodate(n);
  for(var i = 0; i < n; ++i) {
    this.data.setUint8(b);
  }
  return this;
};

/**
 * Puts bytes in this buffer. The bytes may be given as a string, an
 * ArrayBuffer, a DataView, or a TypedArray.
 *
 * @param bytes the bytes to put.
 * @param [encoding] the encoding for the first parameter ('binary', 'utf8',
 *          'utf16', 'hex'), if it is a string (default: 'binary').
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putBytes = function(bytes, encoding) {
  if(util$v.isArrayBufferView(bytes)) {
    var src = new Uint8Array(bytes.buffer, bytes.byteOffset, bytes.byteLength);
    var len = src.byteLength - src.byteOffset;
    this.accommodate(len);
    var dst = new Uint8Array(this.data.buffer, this.write);
    dst.set(src);
    this.write += len;
    return this;
  }

  if(util$v.isArrayBuffer(bytes)) {
    var src = new Uint8Array(bytes);
    this.accommodate(src.byteLength);
    var dst = new Uint8Array(this.data.buffer);
    dst.set(src, this.write);
    this.write += src.byteLength;
    return this;
  }

  // bytes is a util.DataBuffer or equivalent
  if(bytes instanceof util$v.DataBuffer ||
    (typeof bytes === 'object' &&
    typeof bytes.read === 'number' && typeof bytes.write === 'number' &&
    util$v.isArrayBufferView(bytes.data))) {
    var src = new Uint8Array(bytes.data.byteLength, bytes.read, bytes.length());
    this.accommodate(src.byteLength);
    var dst = new Uint8Array(bytes.data.byteLength, this.write);
    dst.set(src);
    this.write += src.byteLength;
    return this;
  }

  if(bytes instanceof util$v.ByteStringBuffer) {
    // copy binary string and process as the same as a string parameter below
    bytes = bytes.data;
    encoding = 'binary';
  }

  // string conversion
  encoding = encoding || 'binary';
  if(typeof bytes === 'string') {
    var view;

    // decode from string
    if(encoding === 'hex') {
      this.accommodate(Math.ceil(bytes.length / 2));
      view = new Uint8Array(this.data.buffer, this.write);
      this.write += util$v.binary.hex.decode(bytes, view, this.write);
      return this;
    }
    if(encoding === 'base64') {
      this.accommodate(Math.ceil(bytes.length / 4) * 3);
      view = new Uint8Array(this.data.buffer, this.write);
      this.write += util$v.binary.base64.decode(bytes, view, this.write);
      return this;
    }

    // encode text as UTF-8 bytes
    if(encoding === 'utf8') {
      // encode as UTF-8 then decode string as raw binary
      bytes = util$v.encodeUtf8(bytes);
      encoding = 'binary';
    }

    // decode string as raw binary
    if(encoding === 'binary' || encoding === 'raw') {
      // one byte per character
      this.accommodate(bytes.length);
      view = new Uint8Array(this.data.buffer, this.write);
      this.write += util$v.binary.raw.decode(view);
      return this;
    }

    // encode text as UTF-16 bytes
    if(encoding === 'utf16') {
      // two bytes per character
      this.accommodate(bytes.length * 2);
      view = new Uint16Array(this.data.buffer, this.write);
      this.write += util$v.text.utf16.encode(view);
      return this;
    }

    throw new Error('Invalid encoding: ' + encoding);
  }

  throw Error('Invalid parameter: ' + bytes);
};

/**
 * Puts the given buffer into this buffer.
 *
 * @param buffer the buffer to put into this one.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putBuffer = function(buffer) {
  this.putBytes(buffer);
  buffer.clear();
  return this;
};

/**
 * Puts a string into this buffer.
 *
 * @param str the string to put.
 * @param [encoding] the encoding for the string (default: 'utf16').
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putString = function(str) {
  return this.putBytes(str, 'utf16');
};

/**
 * Puts a 16-bit integer in this buffer in big-endian order.
 *
 * @param i the 16-bit integer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putInt16 = function(i) {
  this.accommodate(2);
  this.data.setInt16(this.write, i);
  this.write += 2;
  return this;
};

/**
 * Puts a 24-bit integer in this buffer in big-endian order.
 *
 * @param i the 24-bit integer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putInt24 = function(i) {
  this.accommodate(3);
  this.data.setInt16(this.write, i >> 8 & 0xFFFF);
  this.data.setInt8(this.write, i >> 16 & 0xFF);
  this.write += 3;
  return this;
};

/**
 * Puts a 32-bit integer in this buffer in big-endian order.
 *
 * @param i the 32-bit integer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putInt32 = function(i) {
  this.accommodate(4);
  this.data.setInt32(this.write, i);
  this.write += 4;
  return this;
};

/**
 * Puts a 16-bit integer in this buffer in little-endian order.
 *
 * @param i the 16-bit integer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putInt16Le = function(i) {
  this.accommodate(2);
  this.data.setInt16(this.write, i, true);
  this.write += 2;
  return this;
};

/**
 * Puts a 24-bit integer in this buffer in little-endian order.
 *
 * @param i the 24-bit integer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putInt24Le = function(i) {
  this.accommodate(3);
  this.data.setInt8(this.write, i >> 16 & 0xFF);
  this.data.setInt16(this.write, i >> 8 & 0xFFFF, true);
  this.write += 3;
  return this;
};

/**
 * Puts a 32-bit integer in this buffer in little-endian order.
 *
 * @param i the 32-bit integer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putInt32Le = function(i) {
  this.accommodate(4);
  this.data.setInt32(this.write, i, true);
  this.write += 4;
  return this;
};

/**
 * Puts an n-bit integer in this buffer in big-endian order.
 *
 * @param i the n-bit integer.
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putInt = function(i, n) {
  _checkBitsParam(n);
  this.accommodate(n / 8);
  do {
    n -= 8;
    this.data.setInt8(this.write++, (i >> n) & 0xFF);
  } while(n > 0);
  return this;
};

/**
 * Puts a signed n-bit integer in this buffer in big-endian order. Two's
 * complement representation is used.
 *
 * @param i the n-bit integer.
 * @param n the number of bits in the integer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.putSignedInt = function(i, n) {
  _checkBitsParam(n);
  this.accommodate(n / 8);
  if(i < 0) {
    i += 2 << (n - 1);
  }
  return this.putInt(i, n);
};

/**
 * Gets a byte from this buffer and advances the read pointer by 1.
 *
 * @return the byte.
 */
util$v.DataBuffer.prototype.getByte = function() {
  return this.data.getInt8(this.read++);
};

/**
 * Gets a uint16 from this buffer in big-endian order and advances the read
 * pointer by 2.
 *
 * @return the uint16.
 */
util$v.DataBuffer.prototype.getInt16 = function() {
  var rval = this.data.getInt16(this.read);
  this.read += 2;
  return rval;
};

/**
 * Gets a uint24 from this buffer in big-endian order and advances the read
 * pointer by 3.
 *
 * @return the uint24.
 */
util$v.DataBuffer.prototype.getInt24 = function() {
  var rval = (
    this.data.getInt16(this.read) << 8 ^
    this.data.getInt8(this.read + 2));
  this.read += 3;
  return rval;
};

/**
 * Gets a uint32 from this buffer in big-endian order and advances the read
 * pointer by 4.
 *
 * @return the word.
 */
util$v.DataBuffer.prototype.getInt32 = function() {
  var rval = this.data.getInt32(this.read);
  this.read += 4;
  return rval;
};

/**
 * Gets a uint16 from this buffer in little-endian order and advances the read
 * pointer by 2.
 *
 * @return the uint16.
 */
util$v.DataBuffer.prototype.getInt16Le = function() {
  var rval = this.data.getInt16(this.read, true);
  this.read += 2;
  return rval;
};

/**
 * Gets a uint24 from this buffer in little-endian order and advances the read
 * pointer by 3.
 *
 * @return the uint24.
 */
util$v.DataBuffer.prototype.getInt24Le = function() {
  var rval = (
    this.data.getInt8(this.read) ^
    this.data.getInt16(this.read + 1, true) << 8);
  this.read += 3;
  return rval;
};

/**
 * Gets a uint32 from this buffer in little-endian order and advances the read
 * pointer by 4.
 *
 * @return the word.
 */
util$v.DataBuffer.prototype.getInt32Le = function() {
  var rval = this.data.getInt32(this.read, true);
  this.read += 4;
  return rval;
};

/**
 * Gets an n-bit integer from this buffer in big-endian order and advances the
 * read pointer by n/8.
 *
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return the integer.
 */
util$v.DataBuffer.prototype.getInt = function(n) {
  _checkBitsParam(n);
  var rval = 0;
  do {
    // TODO: Use (rval * 0x100) if adding support for 33 to 53 bits.
    rval = (rval << 8) + this.data.getInt8(this.read++);
    n -= 8;
  } while(n > 0);
  return rval;
};

/**
 * Gets a signed n-bit integer from this buffer in big-endian order, using
 * two's complement, and advances the read pointer by n/8.
 *
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return the integer.
 */
util$v.DataBuffer.prototype.getSignedInt = function(n) {
  // getInt checks n
  var x = this.getInt(n);
  var max = 2 << (n - 2);
  if(x >= max) {
    x -= max << 1;
  }
  return x;
};

/**
 * Reads bytes out as a binary encoded string and clears them from the
 * buffer.
 *
 * @param count the number of bytes to read, undefined or null for all.
 *
 * @return a binary encoded string of bytes.
 */
util$v.DataBuffer.prototype.getBytes = function(count) {
  // TODO: deprecate this method, it is poorly named and
  // this.toString('binary') replaces it
  // add a toTypedArray()/toArrayBuffer() function
  var rval;
  if(count) {
    // read count bytes
    count = Math.min(this.length(), count);
    rval = this.data.slice(this.read, this.read + count);
    this.read += count;
  } else if(count === 0) {
    rval = '';
  } else {
    // read all bytes, optimize to only copy when needed
    rval = (this.read === 0) ? this.data : this.data.slice(this.read);
    this.clear();
  }
  return rval;
};

/**
 * Gets a binary encoded string of the bytes from this buffer without
 * modifying the read pointer.
 *
 * @param count the number of bytes to get, omit to get all.
 *
 * @return a string full of binary encoded characters.
 */
util$v.DataBuffer.prototype.bytes = function(count) {
  // TODO: deprecate this method, it is poorly named, add "getString()"
  return (typeof(count) === 'undefined' ?
    this.data.slice(this.read) :
    this.data.slice(this.read, this.read + count));
};

/**
 * Gets a byte at the given index without modifying the read pointer.
 *
 * @param i the byte index.
 *
 * @return the byte.
 */
util$v.DataBuffer.prototype.at = function(i) {
  return this.data.getUint8(this.read + i);
};

/**
 * Puts a byte at the given index without modifying the read pointer.
 *
 * @param i the byte index.
 * @param b the byte to put.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.setAt = function(i, b) {
  this.data.setUint8(i, b);
  return this;
};

/**
 * Gets the last byte without modifying the read pointer.
 *
 * @return the last byte.
 */
util$v.DataBuffer.prototype.last = function() {
  return this.data.getUint8(this.write - 1);
};

/**
 * Creates a copy of this buffer.
 *
 * @return the copy.
 */
util$v.DataBuffer.prototype.copy = function() {
  return new util$v.DataBuffer(this);
};

/**
 * Compacts this buffer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.compact = function() {
  if(this.read > 0) {
    var src = new Uint8Array(this.data.buffer, this.read);
    var dst = new Uint8Array(src.byteLength);
    dst.set(src);
    this.data = new DataView(dst);
    this.write -= this.read;
    this.read = 0;
  }
  return this;
};

/**
 * Clears this buffer.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.clear = function() {
  this.data = new DataView(new ArrayBuffer(0));
  this.read = this.write = 0;
  return this;
};

/**
 * Shortens this buffer by triming bytes off of the end of this buffer.
 *
 * @param count the number of bytes to trim off.
 *
 * @return this buffer.
 */
util$v.DataBuffer.prototype.truncate = function(count) {
  this.write = Math.max(0, this.length() - count);
  this.read = Math.min(this.read, this.write);
  return this;
};

/**
 * Converts this buffer to a hexadecimal string.
 *
 * @return a hexadecimal string.
 */
util$v.DataBuffer.prototype.toHex = function() {
  var rval = '';
  for(var i = this.read; i < this.data.byteLength; ++i) {
    var b = this.data.getUint8(i);
    if(b < 16) {
      rval += '0';
    }
    rval += b.toString(16);
  }
  return rval;
};

/**
 * Converts this buffer to a string, using the given encoding. If no
 * encoding is given, 'utf8' (UTF-8) is used.
 *
 * @param [encoding] the encoding to use: 'binary', 'utf8', 'utf16', 'hex',
 *          'base64' (default: 'utf8').
 *
 * @return a string representation of the bytes in this buffer.
 */
util$v.DataBuffer.prototype.toString = function(encoding) {
  var view = new Uint8Array(this.data, this.read, this.length());
  encoding = encoding || 'utf8';

  // encode to string
  if(encoding === 'binary' || encoding === 'raw') {
    return util$v.binary.raw.encode(view);
  }
  if(encoding === 'hex') {
    return util$v.binary.hex.encode(view);
  }
  if(encoding === 'base64') {
    return util$v.binary.base64.encode(view);
  }

  // decode to text
  if(encoding === 'utf8') {
    return util$v.text.utf8.decode(view);
  }
  if(encoding === 'utf16') {
    return util$v.text.utf16.decode(view);
  }

  throw new Error('Invalid encoding: ' + encoding);
};

/** End Buffer w/UInt8Array backing */

/**
 * Creates a buffer that stores bytes. A value may be given to populate the
 * buffer with data. This value can either be string of encoded bytes or a
 * regular string of characters. When passing a string of binary encoded
 * bytes, the encoding `raw` should be given. This is also the default. When
 * passing a string of characters, the encoding `utf8` should be given.
 *
 * @param [input] a string with encoded bytes to store in the buffer.
 * @param [encoding] (default: 'raw', other: 'utf8').
 */
util$v.createBuffer = function(input, encoding) {
  // TODO: deprecate, use new ByteBuffer() instead
  encoding = encoding || 'raw';
  if(input !== undefined && encoding === 'utf8') {
    input = util$v.encodeUtf8(input);
  }
  return new util$v.ByteBuffer(input);
};

/**
 * Fills a string with a particular value. If you want the string to be a byte
 * string, pass in String.fromCharCode(theByte).
 *
 * @param c the character to fill the string with, use String.fromCharCode
 *          to fill the string with a byte value.
 * @param n the number of characters of value c to fill with.
 *
 * @return the filled string.
 */
util$v.fillString = function(c, n) {
  var s = '';
  while(n > 0) {
    if(n & 1) {
      s += c;
    }
    n >>>= 1;
    if(n > 0) {
      c += c;
    }
  }
  return s;
};

/**
 * Performs a per byte XOR between two byte strings and returns the result as a
 * string of bytes.
 *
 * @param s1 first string of bytes.
 * @param s2 second string of bytes.
 * @param n the number of bytes to XOR.
 *
 * @return the XOR'd result.
 */
util$v.xorBytes = function(s1, s2, n) {
  var s3 = '';
  var b = '';
  var t = '';
  var i = 0;
  var c = 0;
  for(; n > 0; --n, ++i) {
    b = s1.charCodeAt(i) ^ s2.charCodeAt(i);
    if(c >= 10) {
      s3 += t;
      t = '';
      c = 0;
    }
    t += String.fromCharCode(b);
    ++c;
  }
  s3 += t;
  return s3;
};

/**
 * Converts a hex string into a 'binary' encoded string of bytes.
 *
 * @param hex the hexadecimal string to convert.
 *
 * @return the binary-encoded string of bytes.
 */
util$v.hexToBytes = function(hex) {
  // TODO: deprecate: "Deprecated. Use util.binary.hex.decode instead."
  var rval = '';
  var i = 0;
  if(hex.length & 1 == 1) {
    // odd number of characters, convert first character alone
    i = 1;
    rval += String.fromCharCode(parseInt(hex[0], 16));
  }
  // convert 2 characters (1 byte) at a time
  for(; i < hex.length; i += 2) {
    rval += String.fromCharCode(parseInt(hex.substr(i, 2), 16));
  }
  return rval;
};

/**
 * Converts a 'binary' encoded string of bytes to hex.
 *
 * @param bytes the byte string to convert.
 *
 * @return the string of hexadecimal characters.
 */
util$v.bytesToHex = function(bytes) {
  // TODO: deprecate: "Deprecated. Use util.binary.hex.encode instead."
  return util$v.createBuffer(bytes).toHex();
};

/**
 * Converts an 32-bit integer to 4-big-endian byte string.
 *
 * @param i the integer.
 *
 * @return the byte string.
 */
util$v.int32ToBytes = function(i) {
  return (
    String.fromCharCode(i >> 24 & 0xFF) +
    String.fromCharCode(i >> 16 & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i & 0xFF));
};

// base64 characters, reverse mapping
var _base64 =
  'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=';
var _base64Idx = [
/*43 -43 = 0*/
/*'+',  1,  2,  3,'/' */
   62, -1, -1, -1, 63,

/*'0','1','2','3','4','5','6','7','8','9' */
   52, 53, 54, 55, 56, 57, 58, 59, 60, 61,

/*15, 16, 17,'=', 19, 20, 21 */
  -1, -1, -1, 64, -1, -1, -1,

/*65 - 43 = 22*/
/*'A','B','C','D','E','F','G','H','I','J','K','L','M', */
   0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,

/*'N','O','P','Q','R','S','T','U','V','W','X','Y','Z' */
   13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,

/*91 - 43 = 48 */
/*48, 49, 50, 51, 52, 53 */
  -1, -1, -1, -1, -1, -1,

/*97 - 43 = 54*/
/*'a','b','c','d','e','f','g','h','i','j','k','l','m' */
   26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,

/*'n','o','p','q','r','s','t','u','v','w','x','y','z' */
   39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51
];

// base58 characters (Bitcoin alphabet)
var _base58 = '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz';

/**
 * Base64 encodes a 'binary' encoded string of bytes.
 *
 * @param input the binary encoded string of bytes to base64-encode.
 * @param maxline the maximum number of encoded characters per line to use,
 *          defaults to none.
 *
 * @return the base64-encoded output.
 */
util$v.encode64 = function(input, maxline) {
  // TODO: deprecate: "Deprecated. Use util.binary.base64.encode instead."
  var line = '';
  var output = '';
  var chr1, chr2, chr3;
  var i = 0;
  while(i < input.length) {
    chr1 = input.charCodeAt(i++);
    chr2 = input.charCodeAt(i++);
    chr3 = input.charCodeAt(i++);

    // encode 4 character group
    line += _base64.charAt(chr1 >> 2);
    line += _base64.charAt(((chr1 & 3) << 4) | (chr2 >> 4));
    if(isNaN(chr2)) {
      line += '==';
    } else {
      line += _base64.charAt(((chr2 & 15) << 2) | (chr3 >> 6));
      line += isNaN(chr3) ? '=' : _base64.charAt(chr3 & 63);
    }

    if(maxline && line.length > maxline) {
      output += line.substr(0, maxline) + '\r\n';
      line = line.substr(maxline);
    }
  }
  output += line;
  return output;
};

/**
 * Base64 decodes a string into a 'binary' encoded string of bytes.
 *
 * @param input the base64-encoded input.
 *
 * @return the binary encoded string.
 */
util$v.decode64 = function(input) {
  // TODO: deprecate: "Deprecated. Use util.binary.base64.decode instead."

  // remove all non-base64 characters
  input = input.replace(/[^A-Za-z0-9\+\/\=]/g, '');

  var output = '';
  var enc1, enc2, enc3, enc4;
  var i = 0;

  while(i < input.length) {
    enc1 = _base64Idx[input.charCodeAt(i++) - 43];
    enc2 = _base64Idx[input.charCodeAt(i++) - 43];
    enc3 = _base64Idx[input.charCodeAt(i++) - 43];
    enc4 = _base64Idx[input.charCodeAt(i++) - 43];

    output += String.fromCharCode((enc1 << 2) | (enc2 >> 4));
    if(enc3 !== 64) {
      // decoded at least 2 bytes
      output += String.fromCharCode(((enc2 & 15) << 4) | (enc3 >> 2));
      if(enc4 !== 64) {
        // decoded 3 bytes
        output += String.fromCharCode(((enc3 & 3) << 6) | enc4);
      }
    }
  }

  return output;
};

/**
 * Encodes the given string of characters (a standard JavaScript
 * string) as a binary encoded string where the bytes represent
 * a UTF-8 encoded string of characters. Non-ASCII characters will be
 * encoded as multiple bytes according to UTF-8.
 *
 * @param str a standard string of characters to encode.
 *
 * @return the binary encoded string.
 */
util$v.encodeUtf8 = function(str) {
  return unescape(encodeURIComponent(str));
};

/**
 * Decodes a binary encoded string that contains bytes that
 * represent a UTF-8 encoded string of characters -- into a
 * string of characters (a standard JavaScript string).
 *
 * @param str the binary encoded string to decode.
 *
 * @return the resulting standard string of characters.
 */
util$v.decodeUtf8 = function(str) {
  return decodeURIComponent(escape(str));
};

// binary encoding/decoding tools
// FIXME: Experimental. Do not use yet.
util$v.binary = {
  raw: {},
  hex: {},
  base64: {},
  base58: {},
  baseN : {
    encode: baseN.encode,
    decode: baseN.decode
  }
};

/**
 * Encodes a Uint8Array as a binary-encoded string. This encoding uses
 * a value between 0 and 255 for each character.
 *
 * @param bytes the Uint8Array to encode.
 *
 * @return the binary-encoded string.
 */
util$v.binary.raw.encode = function(bytes) {
  return String.fromCharCode.apply(null, bytes);
};

/**
 * Decodes a binary-encoded string to a Uint8Array. This encoding uses
 * a value between 0 and 255 for each character.
 *
 * @param str the binary-encoded string to decode.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$v.binary.raw.decode = function(str, output, offset) {
  var out = output;
  if(!out) {
    out = new Uint8Array(str.length);
  }
  offset = offset || 0;
  var j = offset;
  for(var i = 0; i < str.length; ++i) {
    out[j++] = str.charCodeAt(i);
  }
  return output ? (j - offset) : out;
};

/**
 * Encodes a 'binary' string, ArrayBuffer, DataView, TypedArray, or
 * ByteBuffer as a string of hexadecimal characters.
 *
 * @param bytes the bytes to convert.
 *
 * @return the string of hexadecimal characters.
 */
util$v.binary.hex.encode = util$v.bytesToHex;

/**
 * Decodes a hex-encoded string to a Uint8Array.
 *
 * @param hex the hexadecimal string to convert.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$v.binary.hex.decode = function(hex, output, offset) {
  var out = output;
  if(!out) {
    out = new Uint8Array(Math.ceil(hex.length / 2));
  }
  offset = offset || 0;
  var i = 0, j = offset;
  if(hex.length & 1) {
    // odd number of characters, convert first character alone
    i = 1;
    out[j++] = parseInt(hex[0], 16);
  }
  // convert 2 characters (1 byte) at a time
  for(; i < hex.length; i += 2) {
    out[j++] = parseInt(hex.substr(i, 2), 16);
  }
  return output ? (j - offset) : out;
};

/**
 * Base64-encodes a Uint8Array.
 *
 * @param input the Uint8Array to encode.
 * @param maxline the maximum number of encoded characters per line to use,
 *          defaults to none.
 *
 * @return the base64-encoded output string.
 */
util$v.binary.base64.encode = function(input, maxline) {
  var line = '';
  var output = '';
  var chr1, chr2, chr3;
  var i = 0;
  while(i < input.byteLength) {
    chr1 = input[i++];
    chr2 = input[i++];
    chr3 = input[i++];

    // encode 4 character group
    line += _base64.charAt(chr1 >> 2);
    line += _base64.charAt(((chr1 & 3) << 4) | (chr2 >> 4));
    if(isNaN(chr2)) {
      line += '==';
    } else {
      line += _base64.charAt(((chr2 & 15) << 2) | (chr3 >> 6));
      line += isNaN(chr3) ? '=' : _base64.charAt(chr3 & 63);
    }

    if(maxline && line.length > maxline) {
      output += line.substr(0, maxline) + '\r\n';
      line = line.substr(maxline);
    }
  }
  output += line;
  return output;
};

/**
 * Decodes a base64-encoded string to a Uint8Array.
 *
 * @param input the base64-encoded input string.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$v.binary.base64.decode = function(input, output, offset) {
  var out = output;
  if(!out) {
    out = new Uint8Array(Math.ceil(input.length / 4) * 3);
  }

  // remove all non-base64 characters
  input = input.replace(/[^A-Za-z0-9\+\/\=]/g, '');

  offset = offset || 0;
  var enc1, enc2, enc3, enc4;
  var i = 0, j = offset;

  while(i < input.length) {
    enc1 = _base64Idx[input.charCodeAt(i++) - 43];
    enc2 = _base64Idx[input.charCodeAt(i++) - 43];
    enc3 = _base64Idx[input.charCodeAt(i++) - 43];
    enc4 = _base64Idx[input.charCodeAt(i++) - 43];

    out[j++] = (enc1 << 2) | (enc2 >> 4);
    if(enc3 !== 64) {
      // decoded at least 2 bytes
      out[j++] = ((enc2 & 15) << 4) | (enc3 >> 2);
      if(enc4 !== 64) {
        // decoded 3 bytes
        out[j++] = ((enc3 & 3) << 6) | enc4;
      }
    }
  }

  // make sure result is the exact decoded length
  return output ? (j - offset) : out.subarray(0, j);
};

// add support for base58 encoding/decoding with Bitcoin alphabet
util$v.binary.base58.encode = function(input, maxline) {
  return util$v.binary.baseN.encode(input, _base58, maxline);
};
util$v.binary.base58.decode = function(input, maxline) {
  return util$v.binary.baseN.decode(input, _base58, maxline);
};

// text encoding/decoding tools
// FIXME: Experimental. Do not use yet.
util$v.text = {
  utf8: {},
  utf16: {}
};

/**
 * Encodes the given string as UTF-8 in a Uint8Array.
 *
 * @param str the string to encode.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$v.text.utf8.encode = function(str, output, offset) {
  str = util$v.encodeUtf8(str);
  var out = output;
  if(!out) {
    out = new Uint8Array(str.length);
  }
  offset = offset || 0;
  var j = offset;
  for(var i = 0; i < str.length; ++i) {
    out[j++] = str.charCodeAt(i);
  }
  return output ? (j - offset) : out;
};

/**
 * Decodes the UTF-8 contents from a Uint8Array.
 *
 * @param bytes the Uint8Array to decode.
 *
 * @return the resulting string.
 */
util$v.text.utf8.decode = function(bytes) {
  return util$v.decodeUtf8(String.fromCharCode.apply(null, bytes));
};

/**
 * Encodes the given string as UTF-16 in a Uint8Array.
 *
 * @param str the string to encode.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$v.text.utf16.encode = function(str, output, offset) {
  var out = output;
  if(!out) {
    out = new Uint8Array(str.length * 2);
  }
  var view = new Uint16Array(out.buffer);
  offset = offset || 0;
  var j = offset;
  var k = offset;
  for(var i = 0; i < str.length; ++i) {
    view[k++] = str.charCodeAt(i);
    j += 2;
  }
  return output ? (j - offset) : out;
};

/**
 * Decodes the UTF-16 contents from a Uint8Array.
 *
 * @param bytes the Uint8Array to decode.
 *
 * @return the resulting string.
 */
util$v.text.utf16.decode = function(bytes) {
  return String.fromCharCode.apply(null, new Uint16Array(bytes.buffer));
};

/**
 * Deflates the given data using a flash interface.
 *
 * @param api the flash interface.
 * @param bytes the data.
 * @param raw true to return only raw deflate data, false to include zlib
 *          header and trailer.
 *
 * @return the deflated data as a string.
 */
util$v.deflate = function(api, bytes, raw) {
  bytes = util$v.decode64(api.deflate(util$v.encode64(bytes)).rval);

  // strip zlib header and trailer if necessary
  if(raw) {
    // zlib header is 2 bytes (CMF,FLG) where FLG indicates that
    // there is a 4-byte DICT (alder-32) block before the data if
    // its 5th bit is set
    var start = 2;
    var flg = bytes.charCodeAt(1);
    if(flg & 0x20) {
      start = 6;
    }
    // zlib trailer is 4 bytes of adler-32
    bytes = bytes.substring(start, bytes.length - 4);
  }

  return bytes;
};

/**
 * Inflates the given data using a flash interface.
 *
 * @param api the flash interface.
 * @param bytes the data.
 * @param raw true if the incoming data has no zlib header or trailer and is
 *          raw DEFLATE data.
 *
 * @return the inflated data as a string, null on error.
 */
util$v.inflate = function(api, bytes, raw) {
  // TODO: add zlib header and trailer if necessary/possible
  var rval = api.inflate(util$v.encode64(bytes)).rval;
  return (rval === null) ? null : util$v.decode64(rval);
};

/**
 * Sets a storage object.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 * @param obj the storage object, null to remove.
 */
var _setStorageObject = function(api, id, obj) {
  if(!api) {
    throw new Error('WebStorage not available.');
  }

  var rval;
  if(obj === null) {
    rval = api.removeItem(id);
  } else {
    // json-encode and base64-encode object
    obj = util$v.encode64(JSON.stringify(obj));
    rval = api.setItem(id, obj);
  }

  // handle potential flash error
  if(typeof(rval) !== 'undefined' && rval.rval !== true) {
    var error = new Error(rval.error.message);
    error.id = rval.error.id;
    error.name = rval.error.name;
    throw error;
  }
};

/**
 * Gets a storage object.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 *
 * @return the storage object entry or null if none exists.
 */
var _getStorageObject = function(api, id) {
  if(!api) {
    throw new Error('WebStorage not available.');
  }

  // get the existing entry
  var rval = api.getItem(id);

  /* Note: We check api.init because we can't do (api == localStorage)
    on IE because of "Class doesn't support Automation" exception. Only
    the flash api has an init method so this works too, but we need a
    better solution in the future. */

  // flash returns item wrapped in an object, handle special case
  if(api.init) {
    if(rval.rval === null) {
      if(rval.error) {
        var error = new Error(rval.error.message);
        error.id = rval.error.id;
        error.name = rval.error.name;
        throw error;
      }
      // no error, but also no item
      rval = null;
    } else {
      rval = rval.rval;
    }
  }

  // handle decoding
  if(rval !== null) {
    // base64-decode and json-decode data
    rval = JSON.parse(util$v.decode64(rval));
  }

  return rval;
};

/**
 * Stores an item in local storage.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 * @param key the key for the item.
 * @param data the data for the item (any javascript object/primitive).
 */
var _setItem = function(api, id, key, data) {
  // get storage object
  var obj = _getStorageObject(api, id);
  if(obj === null) {
    // create a new storage object
    obj = {};
  }
  // update key
  obj[key] = data;

  // set storage object
  _setStorageObject(api, id, obj);
};

/**
 * Gets an item from local storage.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 * @param key the key for the item.
 *
 * @return the item.
 */
var _getItem = function(api, id, key) {
  // get storage object
  var rval = _getStorageObject(api, id);
  if(rval !== null) {
    // return data at key
    rval = (key in rval) ? rval[key] : null;
  }

  return rval;
};

/**
 * Removes an item from local storage.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 * @param key the key for the item.
 */
var _removeItem = function(api, id, key) {
  // get storage object
  var obj = _getStorageObject(api, id);
  if(obj !== null && key in obj) {
    // remove key
    delete obj[key];

    // see if entry has no keys remaining
    var empty = true;
    for(var prop in obj) {
      empty = false;
      break;
    }
    if(empty) {
      // remove entry entirely if no keys are left
      obj = null;
    }

    // set storage object
    _setStorageObject(api, id, obj);
  }
};

/**
 * Clears the local disk storage identified by the given ID.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 */
var _clearItems = function(api, id) {
  _setStorageObject(api, id, null);
};

/**
 * Calls a storage function.
 *
 * @param func the function to call.
 * @param args the arguments for the function.
 * @param location the location argument.
 *
 * @return the return value from the function.
 */
var _callStorageFunction = function(func, args, location) {
  var rval = null;

  // default storage types
  if(typeof(location) === 'undefined') {
    location = ['web', 'flash'];
  }

  // apply storage types in order of preference
  var type;
  var done = false;
  var exception = null;
  for(var idx in location) {
    type = location[idx];
    try {
      if(type === 'flash' || type === 'both') {
        if(args[0] === null) {
          throw new Error('Flash local storage not available.');
        }
        rval = func.apply(this, args);
        done = (type === 'flash');
      }
      if(type === 'web' || type === 'both') {
        args[0] = localStorage;
        rval = func.apply(this, args);
        done = true;
      }
    } catch(ex) {
      exception = ex;
    }
    if(done) {
      break;
    }
  }

  if(!done) {
    throw exception;
  }

  return rval;
};

/**
 * Stores an item on local disk.
 *
 * The available types of local storage include 'flash', 'web', and 'both'.
 *
 * The type 'flash' refers to flash local storage (SharedObject). In order
 * to use flash local storage, the 'api' parameter must be valid. The type
 * 'web' refers to WebStorage, if supported by the browser. The type 'both'
 * refers to storing using both 'flash' and 'web', not just one or the
 * other.
 *
 * The location array should list the storage types to use in order of
 * preference:
 *
 * ['flash']: flash only storage
 * ['web']: web only storage
 * ['both']: try to store in both
 * ['flash','web']: store in flash first, but if not available, 'web'
 * ['web','flash']: store in web first, but if not available, 'flash'
 *
 * The location array defaults to: ['web', 'flash']
 *
 * @param api the flash interface, null to use only WebStorage.
 * @param id the storage ID to use.
 * @param key the key for the item.
 * @param data the data for the item (any javascript object/primitive).
 * @param location an array with the preferred types of storage to use.
 */
util$v.setItem = function(api, id, key, data, location) {
  _callStorageFunction(_setItem, arguments, location);
};

/**
 * Gets an item on local disk.
 *
 * Set setItem() for details on storage types.
 *
 * @param api the flash interface, null to use only WebStorage.
 * @param id the storage ID to use.
 * @param key the key for the item.
 * @param location an array with the preferred types of storage to use.
 *
 * @return the item.
 */
util$v.getItem = function(api, id, key, location) {
  return _callStorageFunction(_getItem, arguments, location);
};

/**
 * Removes an item on local disk.
 *
 * Set setItem() for details on storage types.
 *
 * @param api the flash interface.
 * @param id the storage ID to use.
 * @param key the key for the item.
 * @param location an array with the preferred types of storage to use.
 */
util$v.removeItem = function(api, id, key, location) {
  _callStorageFunction(_removeItem, arguments, location);
};

/**
 * Clears the local disk storage identified by the given ID.
 *
 * Set setItem() for details on storage types.
 *
 * @param api the flash interface if flash is available.
 * @param id the storage ID to use.
 * @param location an array with the preferred types of storage to use.
 */
util$v.clearItems = function(api, id, location) {
  _callStorageFunction(_clearItems, arguments, location);
};

/**
 * Check if an object is empty.
 *
 * Taken from:
 * http://stackoverflow.com/questions/679915/how-do-i-test-for-an-empty-javascript-object-from-json/679937#679937
 *
 * @param object the object to check.
 */
util$v.isEmpty = function(obj) {
  for(var prop in obj) {
    if(obj.hasOwnProperty(prop)) {
      return false;
    }
  }
  return true;
};

/**
 * Format with simple printf-style interpolation.
 *
 * %%: literal '%'
 * %s,%o: convert next argument into a string.
 *
 * @param format the string to format.
 * @param ... arguments to interpolate into the format string.
 */
util$v.format = function(format) {
  var re = /%./g;
  // current match
  var match;
  // current part
  var part;
  // current arg index
  var argi = 0;
  // collected parts to recombine later
  var parts = [];
  // last index found
  var last = 0;
  // loop while matches remain
  while((match = re.exec(format))) {
    part = format.substring(last, re.lastIndex - 2);
    // don't add empty strings (ie, parts between %s%s)
    if(part.length > 0) {
      parts.push(part);
    }
    last = re.lastIndex;
    // switch on % code
    var code = match[0][1];
    switch(code) {
    case 's':
    case 'o':
      // check if enough arguments were given
      if(argi < arguments.length) {
        parts.push(arguments[argi++ + 1]);
      } else {
        parts.push('<?>');
      }
      break;
    // FIXME: do proper formating for numbers, etc
    //case 'f':
    //case 'd':
    case '%':
      parts.push('%');
      break;
    default:
      parts.push('<%' + code + '?>');
    }
  }
  // add trailing part of format string
  parts.push(format.substring(last));
  return parts.join('');
};

/**
 * Formats a number.
 *
 * http://snipplr.com/view/5945/javascript-numberformat--ported-from-php/
 */
util$v.formatNumber = function(number, decimals, dec_point, thousands_sep) {
  // http://kevin.vanzonneveld.net
  // +   original by: Jonas Raoni Soares Silva (http://www.jsfromhell.com)
  // +   improved by: Kevin van Zonneveld (http://kevin.vanzonneveld.net)
  // +     bugfix by: Michael White (http://crestidg.com)
  // +     bugfix by: Benjamin Lupton
  // +     bugfix by: Allan Jensen (http://www.winternet.no)
  // +    revised by: Jonas Raoni Soares Silva (http://www.jsfromhell.com)
  // *     example 1: number_format(1234.5678, 2, '.', '');
  // *     returns 1: 1234.57

  var n = number, c = isNaN(decimals = Math.abs(decimals)) ? 2 : decimals;
  var d = dec_point === undefined ? ',' : dec_point;
  var t = thousands_sep === undefined ?
   '.' : thousands_sep, s = n < 0 ? '-' : '';
  var i = parseInt((n = Math.abs(+n || 0).toFixed(c)), 10) + '';
  var j = (i.length > 3) ? i.length % 3 : 0;
  return s + (j ? i.substr(0, j) + t : '') +
    i.substr(j).replace(/(\d{3})(?=\d)/g, '$1' + t) +
    (c ? d + Math.abs(n - i).toFixed(c).slice(2) : '');
};

/**
 * Formats a byte size.
 *
 * http://snipplr.com/view/5949/format-humanize-file-byte-size-presentation-in-javascript/
 */
util$v.formatSize = function(size) {
  if(size >= 1073741824) {
    size = util$v.formatNumber(size / 1073741824, 2, '.', '') + ' GiB';
  } else if(size >= 1048576) {
    size = util$v.formatNumber(size / 1048576, 2, '.', '') + ' MiB';
  } else if(size >= 1024) {
    size = util$v.formatNumber(size / 1024, 0) + ' KiB';
  } else {
    size = util$v.formatNumber(size, 0) + ' bytes';
  }
  return size;
};

/**
 * Converts an IPv4 or IPv6 string representation into bytes (in network order).
 *
 * @param ip the IPv4 or IPv6 address to convert.
 *
 * @return the 4-byte IPv6 or 16-byte IPv6 address or null if the address can't
 *         be parsed.
 */
util$v.bytesFromIP = function(ip) {
  if(ip.indexOf('.') !== -1) {
    return util$v.bytesFromIPv4(ip);
  }
  if(ip.indexOf(':') !== -1) {
    return util$v.bytesFromIPv6(ip);
  }
  return null;
};

/**
 * Converts an IPv4 string representation into bytes (in network order).
 *
 * @param ip the IPv4 address to convert.
 *
 * @return the 4-byte address or null if the address can't be parsed.
 */
util$v.bytesFromIPv4 = function(ip) {
  ip = ip.split('.');
  if(ip.length !== 4) {
    return null;
  }
  var b = util$v.createBuffer();
  for(var i = 0; i < ip.length; ++i) {
    var num = parseInt(ip[i], 10);
    if(isNaN(num)) {
      return null;
    }
    b.putByte(num);
  }
  return b.getBytes();
};

/**
 * Converts an IPv6 string representation into bytes (in network order).
 *
 * @param ip the IPv6 address to convert.
 *
 * @return the 16-byte address or null if the address can't be parsed.
 */
util$v.bytesFromIPv6 = function(ip) {
  var blanks = 0;
  ip = ip.split(':').filter(function(e) {
    if(e.length === 0) ++blanks;
    return true;
  });
  var zeros = (8 - ip.length + blanks) * 2;
  var b = util$v.createBuffer();
  for(var i = 0; i < 8; ++i) {
    if(!ip[i] || ip[i].length === 0) {
      b.fillWithByte(0, zeros);
      zeros = 0;
      continue;
    }
    var bytes = util$v.hexToBytes(ip[i]);
    if(bytes.length < 2) {
      b.putByte(0);
    }
    b.putBytes(bytes);
  }
  return b.getBytes();
};

/**
 * Converts 4-bytes into an IPv4 string representation or 16-bytes into
 * an IPv6 string representation. The bytes must be in network order.
 *
 * @param bytes the bytes to convert.
 *
 * @return the IPv4 or IPv6 string representation if 4 or 16 bytes,
 *         respectively, are given, otherwise null.
 */
util$v.bytesToIP = function(bytes) {
  if(bytes.length === 4) {
    return util$v.bytesToIPv4(bytes);
  }
  if(bytes.length === 16) {
    return util$v.bytesToIPv6(bytes);
  }
  return null;
};

/**
 * Converts 4-bytes into an IPv4 string representation. The bytes must be
 * in network order.
 *
 * @param bytes the bytes to convert.
 *
 * @return the IPv4 string representation or null for an invalid # of bytes.
 */
util$v.bytesToIPv4 = function(bytes) {
  if(bytes.length !== 4) {
    return null;
  }
  var ip = [];
  for(var i = 0; i < bytes.length; ++i) {
    ip.push(bytes.charCodeAt(i));
  }
  return ip.join('.');
};

/**
 * Converts 16-bytes into an IPv16 string representation. The bytes must be
 * in network order.
 *
 * @param bytes the bytes to convert.
 *
 * @return the IPv16 string representation or null for an invalid # of bytes.
 */
util$v.bytesToIPv6 = function(bytes) {
  if(bytes.length !== 16) {
    return null;
  }
  var ip = [];
  var zeroGroups = [];
  var zeroMaxGroup = 0;
  for(var i = 0; i < bytes.length; i += 2) {
    var hex = util$v.bytesToHex(bytes[i] + bytes[i + 1]);
    // canonicalize zero representation
    while(hex[0] === '0' && hex !== '0') {
      hex = hex.substr(1);
    }
    if(hex === '0') {
      var last = zeroGroups[zeroGroups.length - 1];
      var idx = ip.length;
      if(!last || idx !== last.end + 1) {
        zeroGroups.push({start: idx, end: idx});
      } else {
        last.end = idx;
        if((last.end - last.start) >
          (zeroGroups[zeroMaxGroup].end - zeroGroups[zeroMaxGroup].start)) {
          zeroMaxGroup = zeroGroups.length - 1;
        }
      }
    }
    ip.push(hex);
  }
  if(zeroGroups.length > 0) {
    var group = zeroGroups[zeroMaxGroup];
    // only shorten group of length > 0
    if(group.end - group.start > 0) {
      ip.splice(group.start, group.end - group.start + 1, '');
      if(group.start === 0) {
        ip.unshift('');
      }
      if(group.end === 7) {
        ip.push('');
      }
    }
  }
  return ip.join(':');
};

/**
 * Estimates the number of processes that can be run concurrently. If
 * creating Web Workers, keep in mind that the main JavaScript process needs
 * its own core.
 *
 * @param options the options to use:
 *          update true to force an update (not use the cached value).
 * @param callback(err, max) called once the operation completes.
 */
util$v.estimateCores = function(options, callback) {
  if(typeof options === 'function') {
    callback = options;
    options = {};
  }
  options = options || {};
  if('cores' in util$v && !options.update) {
    return callback(null, util$v.cores);
  }
  if(typeof navigator !== 'undefined' &&
    'hardwareConcurrency' in navigator &&
    navigator.hardwareConcurrency > 0) {
    util$v.cores = navigator.hardwareConcurrency;
    return callback(null, util$v.cores);
  }
  if(typeof Worker === 'undefined') {
    // workers not available
    util$v.cores = 1;
    return callback(null, util$v.cores);
  }
  if(typeof Blob === 'undefined') {
    // can't estimate, default to 2
    util$v.cores = 2;
    return callback(null, util$v.cores);
  }

  // create worker concurrency estimation code as blob
  var blobUrl = URL.createObjectURL(new Blob(['(',
    function() {
      self.addEventListener('message', function(e) {
        // run worker for 4 ms
        var st = Date.now();
        var et = st + 4;
        self.postMessage({st: st, et: et});
      });
    }.toString(),
  ')()'], {type: 'application/javascript'}));

  // take 5 samples using 16 workers
  sample([], 5, 16);

  function sample(max, samples, numWorkers) {
    if(samples === 0) {
      // get overlap average
      var avg = Math.floor(max.reduce(function(avg, x) {
        return avg + x;
      }, 0) / max.length);
      util$v.cores = Math.max(1, avg);
      URL.revokeObjectURL(blobUrl);
      return callback(null, util$v.cores);
    }
    map(numWorkers, function(err, results) {
      max.push(reduce(numWorkers, results));
      sample(max, samples - 1, numWorkers);
    });
  }

  function map(numWorkers, callback) {
    var workers = [];
    var results = [];
    for(var i = 0; i < numWorkers; ++i) {
      var worker = new Worker(blobUrl);
      worker.addEventListener('message', function(e) {
        results.push(e.data);
        if(results.length === numWorkers) {
          for(var i = 0; i < numWorkers; ++i) {
            workers[i].terminate();
          }
          callback(null, results);
        }
      });
      workers.push(worker);
    }
    for(var i = 0; i < numWorkers; ++i) {
      workers[i].postMessage(i);
    }
  }

  function reduce(numWorkers, results) {
    // find overlapping time windows
    var overlaps = [];
    for(var n = 0; n < numWorkers; ++n) {
      var r1 = results[n];
      var overlap = overlaps[n] = [];
      for(var i = 0; i < numWorkers; ++i) {
        if(n === i) {
          continue;
        }
        var r2 = results[i];
        if((r1.st > r2.st && r1.st < r2.et) ||
          (r2.st > r1.st && r2.st < r1.et)) {
          overlap.push(i);
        }
      }
    }
    // get maximum overlaps ... don't include overlapping worker itself
    // as the main JS process was also being scheduled during the work and
    // would have to be subtracted from the estimate anyway
    return overlaps.reduce(function(max, overlap) {
      return Math.max(max, overlap.length);
    }, 0);
  }
};

/**
 * Object IDs for ASN.1.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2013 Digital Bazaar, Inc.
 */

var forge$q = forge$s;

forge$q.pki = forge$q.pki || {};
var oids$2 = forge$q.pki.oids = forge$q.oids = forge$q.oids || {};

// set id to name mapping and name to id mapping
function _IN(id, name) {
  oids$2[id] = name;
  oids$2[name] = id;
}
// set id to name mapping only
function _I_(id, name) {
  oids$2[id] = name;
}

// algorithm OIDs
_IN('1.2.840.113549.1.1.1', 'rsaEncryption');
// Note: md2 & md4 not implemented
//_IN('1.2.840.113549.1.1.2', 'md2WithRSAEncryption');
//_IN('1.2.840.113549.1.1.3', 'md4WithRSAEncryption');
_IN('1.2.840.113549.1.1.4', 'md5WithRSAEncryption');
_IN('1.2.840.113549.1.1.5', 'sha1WithRSAEncryption');
_IN('1.2.840.113549.1.1.7', 'RSAES-OAEP');
_IN('1.2.840.113549.1.1.8', 'mgf1');
_IN('1.2.840.113549.1.1.9', 'pSpecified');
_IN('1.2.840.113549.1.1.10', 'RSASSA-PSS');
_IN('1.2.840.113549.1.1.11', 'sha256WithRSAEncryption');
_IN('1.2.840.113549.1.1.12', 'sha384WithRSAEncryption');
_IN('1.2.840.113549.1.1.13', 'sha512WithRSAEncryption');
// Edwards-curve Digital Signature Algorithm (EdDSA) Ed25519
_IN('1.3.101.112', 'EdDSA25519');

_IN('1.2.840.10040.4.3', 'dsa-with-sha1');

_IN('1.3.14.3.2.7', 'desCBC');

_IN('1.3.14.3.2.26', 'sha1');
// Deprecated equivalent of sha1WithRSAEncryption
_IN('1.3.14.3.2.29', 'sha1WithRSASignature');
_IN('2.16.840.1.101.3.4.2.1', 'sha256');
_IN('2.16.840.1.101.3.4.2.2', 'sha384');
_IN('2.16.840.1.101.3.4.2.3', 'sha512');
_IN('2.16.840.1.101.3.4.2.4', 'sha224');
_IN('2.16.840.1.101.3.4.2.5', 'sha512-224');
_IN('2.16.840.1.101.3.4.2.6', 'sha512-256');
_IN('1.2.840.113549.2.2', 'md2');
_IN('1.2.840.113549.2.5', 'md5');

// pkcs#7 content types
_IN('1.2.840.113549.1.7.1', 'data');
_IN('1.2.840.113549.1.7.2', 'signedData');
_IN('1.2.840.113549.1.7.3', 'envelopedData');
_IN('1.2.840.113549.1.7.4', 'signedAndEnvelopedData');
_IN('1.2.840.113549.1.7.5', 'digestedData');
_IN('1.2.840.113549.1.7.6', 'encryptedData');

// pkcs#9 oids
_IN('1.2.840.113549.1.9.1', 'emailAddress');
_IN('1.2.840.113549.1.9.2', 'unstructuredName');
_IN('1.2.840.113549.1.9.3', 'contentType');
_IN('1.2.840.113549.1.9.4', 'messageDigest');
_IN('1.2.840.113549.1.9.5', 'signingTime');
_IN('1.2.840.113549.1.9.6', 'counterSignature');
_IN('1.2.840.113549.1.9.7', 'challengePassword');
_IN('1.2.840.113549.1.9.8', 'unstructuredAddress');
_IN('1.2.840.113549.1.9.14', 'extensionRequest');

_IN('1.2.840.113549.1.9.20', 'friendlyName');
_IN('1.2.840.113549.1.9.21', 'localKeyId');
_IN('1.2.840.113549.1.9.22.1', 'x509Certificate');

// pkcs#12 safe bags
_IN('1.2.840.113549.1.12.10.1.1', 'keyBag');
_IN('1.2.840.113549.1.12.10.1.2', 'pkcs8ShroudedKeyBag');
_IN('1.2.840.113549.1.12.10.1.3', 'certBag');
_IN('1.2.840.113549.1.12.10.1.4', 'crlBag');
_IN('1.2.840.113549.1.12.10.1.5', 'secretBag');
_IN('1.2.840.113549.1.12.10.1.6', 'safeContentsBag');

// password-based-encryption for pkcs#12
_IN('1.2.840.113549.1.5.13', 'pkcs5PBES2');
_IN('1.2.840.113549.1.5.12', 'pkcs5PBKDF2');

_IN('1.2.840.113549.1.12.1.1', 'pbeWithSHAAnd128BitRC4');
_IN('1.2.840.113549.1.12.1.2', 'pbeWithSHAAnd40BitRC4');
_IN('1.2.840.113549.1.12.1.3', 'pbeWithSHAAnd3-KeyTripleDES-CBC');
_IN('1.2.840.113549.1.12.1.4', 'pbeWithSHAAnd2-KeyTripleDES-CBC');
_IN('1.2.840.113549.1.12.1.5', 'pbeWithSHAAnd128BitRC2-CBC');
_IN('1.2.840.113549.1.12.1.6', 'pbewithSHAAnd40BitRC2-CBC');

// hmac OIDs
_IN('1.2.840.113549.2.7', 'hmacWithSHA1');
_IN('1.2.840.113549.2.8', 'hmacWithSHA224');
_IN('1.2.840.113549.2.9', 'hmacWithSHA256');
_IN('1.2.840.113549.2.10', 'hmacWithSHA384');
_IN('1.2.840.113549.2.11', 'hmacWithSHA512');

// symmetric key algorithm oids
_IN('1.2.840.113549.3.7', 'des-EDE3-CBC');
_IN('2.16.840.1.101.3.4.1.2', 'aes128-CBC');
_IN('2.16.840.1.101.3.4.1.22', 'aes192-CBC');
_IN('2.16.840.1.101.3.4.1.42', 'aes256-CBC');

// certificate issuer/subject OIDs
_IN('2.5.4.3', 'commonName');
_IN('2.5.4.4', 'surname');
_IN('2.5.4.5', 'serialNumber');
_IN('2.5.4.6', 'countryName');
_IN('2.5.4.7', 'localityName');
_IN('2.5.4.8', 'stateOrProvinceName');
_IN('2.5.4.9', 'streetAddress');
_IN('2.5.4.10', 'organizationName');
_IN('2.5.4.11', 'organizationalUnitName');
_IN('2.5.4.12', 'title');
_IN('2.5.4.13', 'description');
_IN('2.5.4.15', 'businessCategory');
_IN('2.5.4.17', 'postalCode');
_IN('2.5.4.42', 'givenName');
_IN('1.3.6.1.4.1.311.60.2.1.2', 'jurisdictionOfIncorporationStateOrProvinceName');
_IN('1.3.6.1.4.1.311.60.2.1.3', 'jurisdictionOfIncorporationCountryName');

// X.509 extension OIDs
_IN('2.16.840.1.113730.1.1', 'nsCertType');
_IN('2.16.840.1.113730.1.13', 'nsComment'); // deprecated in theory; still widely used
_I_('2.5.29.1', 'authorityKeyIdentifier'); // deprecated, use .35
_I_('2.5.29.2', 'keyAttributes'); // obsolete use .37 or .15
_I_('2.5.29.3', 'certificatePolicies'); // deprecated, use .32
_I_('2.5.29.4', 'keyUsageRestriction'); // obsolete use .37 or .15
_I_('2.5.29.5', 'policyMapping'); // deprecated use .33
_I_('2.5.29.6', 'subtreesConstraint'); // obsolete use .30
_I_('2.5.29.7', 'subjectAltName'); // deprecated use .17
_I_('2.5.29.8', 'issuerAltName'); // deprecated use .18
_I_('2.5.29.9', 'subjectDirectoryAttributes');
_I_('2.5.29.10', 'basicConstraints'); // deprecated use .19
_I_('2.5.29.11', 'nameConstraints'); // deprecated use .30
_I_('2.5.29.12', 'policyConstraints'); // deprecated use .36
_I_('2.5.29.13', 'basicConstraints'); // deprecated use .19
_IN('2.5.29.14', 'subjectKeyIdentifier');
_IN('2.5.29.15', 'keyUsage');
_I_('2.5.29.16', 'privateKeyUsagePeriod');
_IN('2.5.29.17', 'subjectAltName');
_IN('2.5.29.18', 'issuerAltName');
_IN('2.5.29.19', 'basicConstraints');
_I_('2.5.29.20', 'cRLNumber');
_I_('2.5.29.21', 'cRLReason');
_I_('2.5.29.22', 'expirationDate');
_I_('2.5.29.23', 'instructionCode');
_I_('2.5.29.24', 'invalidityDate');
_I_('2.5.29.25', 'cRLDistributionPoints'); // deprecated use .31
_I_('2.5.29.26', 'issuingDistributionPoint'); // deprecated use .28
_I_('2.5.29.27', 'deltaCRLIndicator');
_I_('2.5.29.28', 'issuingDistributionPoint');
_I_('2.5.29.29', 'certificateIssuer');
_I_('2.5.29.30', 'nameConstraints');
_IN('2.5.29.31', 'cRLDistributionPoints');
_IN('2.5.29.32', 'certificatePolicies');
_I_('2.5.29.33', 'policyMappings');
_I_('2.5.29.34', 'policyConstraints'); // deprecated use .36
_IN('2.5.29.35', 'authorityKeyIdentifier');
_I_('2.5.29.36', 'policyConstraints');
_IN('2.5.29.37', 'extKeyUsage');
_I_('2.5.29.46', 'freshestCRL');
_I_('2.5.29.54', 'inhibitAnyPolicy');

// extKeyUsage purposes
_IN('1.3.6.1.4.1.11129.2.4.2', 'timestampList');
_IN('1.3.6.1.5.5.7.1.1', 'authorityInfoAccess');
_IN('1.3.6.1.5.5.7.3.1', 'serverAuth');
_IN('1.3.6.1.5.5.7.3.2', 'clientAuth');
_IN('1.3.6.1.5.5.7.3.3', 'codeSigning');
_IN('1.3.6.1.5.5.7.3.4', 'emailProtection');
_IN('1.3.6.1.5.5.7.3.8', 'timeStamping');

/**
 * Javascript implementation of Abstract Syntax Notation Number One.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2015 Digital Bazaar, Inc.
 *
 * An API for storing data using the Abstract Syntax Notation Number One
 * format using DER (Distinguished Encoding Rules) encoding. This encoding is
 * commonly used to store data for PKI, i.e. X.509 Certificates, and this
 * implementation exists for that purpose.
 *
 * Abstract Syntax Notation Number One (ASN.1) is used to define the abstract
 * syntax of information without restricting the way the information is encoded
 * for transmission. It provides a standard that allows for open systems
 * communication. ASN.1 defines the syntax of information data and a number of
 * simple data types as well as a notation for describing them and specifying
 * values for them.
 *
 * The RSA algorithm creates public and private keys that are often stored in
 * X.509 or PKCS#X formats -- which use ASN.1 (encoded in DER format). This
 * class provides the most basic functionality required to store and load DSA
 * keys that are encoded according to ASN.1.
 *
 * The most common binary encodings for ASN.1 are BER (Basic Encoding Rules)
 * and DER (Distinguished Encoding Rules). DER is just a subset of BER that
 * has stricter requirements for how data must be encoded.
 *
 * Each ASN.1 structure has a tag (a byte identifying the ASN.1 structure type)
 * and a byte array for the value of this ASN1 structure which may be data or a
 * list of ASN.1 structures.
 *
 * Each ASN.1 structure using BER is (Tag-Length-Value):
 *
 * | byte 0 | bytes X | bytes Y |
 * |--------|---------|----------
 * |  tag   | length  |  value  |
 *
 * ASN.1 allows for tags to be of "High-tag-number form" which allows a tag to
 * be two or more octets, but that is not supported by this class. A tag is
 * only 1 byte. Bits 1-5 give the tag number (ie the data type within a
 * particular 'class'), 6 indicates whether or not the ASN.1 value is
 * constructed from other ASN.1 values, and bits 7 and 8 give the 'class'. If
 * bits 7 and 8 are both zero, the class is UNIVERSAL. If only bit 7 is set,
 * then the class is APPLICATION. If only bit 8 is set, then the class is
 * CONTEXT_SPECIFIC. If both bits 7 and 8 are set, then the class is PRIVATE.
 * The tag numbers for the data types for the class UNIVERSAL are listed below:
 *
 * UNIVERSAL 0 Reserved for use by the encoding rules
 * UNIVERSAL 1 Boolean type
 * UNIVERSAL 2 Integer type
 * UNIVERSAL 3 Bitstring type
 * UNIVERSAL 4 Octetstring type
 * UNIVERSAL 5 Null type
 * UNIVERSAL 6 Object identifier type
 * UNIVERSAL 7 Object descriptor type
 * UNIVERSAL 8 External type and Instance-of type
 * UNIVERSAL 9 Real type
 * UNIVERSAL 10 Enumerated type
 * UNIVERSAL 11 Embedded-pdv type
 * UNIVERSAL 12 UTF8String type
 * UNIVERSAL 13 Relative object identifier type
 * UNIVERSAL 14-15 Reserved for future editions
 * UNIVERSAL 16 Sequence and Sequence-of types
 * UNIVERSAL 17 Set and Set-of types
 * UNIVERSAL 18-22, 25-30 Character string types
 * UNIVERSAL 23-24 Time types
 *
 * The length of an ASN.1 structure is specified after the tag identifier.
 * There is a definite form and an indefinite form. The indefinite form may
 * be used if the encoding is constructed and not all immediately available.
 * The indefinite form is encoded using a length byte with only the 8th bit
 * set. The end of the constructed object is marked using end-of-contents
 * octets (two zero bytes).
 *
 * The definite form looks like this:
 *
 * The length may take up 1 or more bytes, it depends on the length of the
 * value of the ASN.1 structure. DER encoding requires that if the ASN.1
 * structure has a value that has a length greater than 127, more than 1 byte
 * will be used to store its length, otherwise just one byte will be used.
 * This is strict.
 *
 * In the case that the length of the ASN.1 value is less than 127, 1 octet
 * (byte) is used to store the "short form" length. The 8th bit has a value of
 * 0 indicating the length is "short form" and not "long form" and bits 7-1
 * give the length of the data. (The 8th bit is the left-most, most significant
 * bit: also known as big endian or network format).
 *
 * In the case that the length of the ASN.1 value is greater than 127, 2 to
 * 127 octets (bytes) are used to store the "long form" length. The first
 * byte's 8th bit is set to 1 to indicate the length is "long form." Bits 7-1
 * give the number of additional octets. All following octets are in base 256
 * with the most significant digit first (typical big-endian binary unsigned
 * integer storage). So, for instance, if the length of a value was 257, the
 * first byte would be set to:
 *
 * 10000010 = 130 = 0x82.
 *
 * This indicates there are 2 octets (base 256) for the length. The second and
 * third bytes (the octets just mentioned) would store the length in base 256:
 *
 * octet 2: 00000001 = 1 * 256^1 = 256
 * octet 3: 00000001 = 1 * 256^0 = 1
 * total = 257
 *
 * The algorithm for converting a js integer value of 257 to base-256 is:
 *
 * var value = 257;
 * var bytes = [];
 * bytes[0] = (value >>> 8) & 0xFF; // most significant byte first
 * bytes[1] = value & 0xFF;        // least significant byte last
 *
 * On the ASN.1 UNIVERSAL Object Identifier (OID) type:
 *
 * An OID can be written like: "value1.value2.value3...valueN"
 *
 * The DER encoding rules:
 *
 * The first byte has the value 40 * value1 + value2.
 * The following bytes, if any, encode the remaining values. Each value is
 * encoded in base 128, most significant digit first (big endian), with as
 * few digits as possible, and the most significant bit of each byte set
 * to 1 except the last in each value's encoding. For example: Given the
 * OID "1.2.840.113549", its DER encoding is (remember each byte except the
 * last one in each encoding is OR'd with 0x80):
 *
 * byte 1: 40 * 1 + 2 = 42 = 0x2A.
 * bytes 2-3: 128 * 6 + 72 = 840 = 6 72 = 6 72 = 0x0648 = 0x8648
 * bytes 4-6: 16384 * 6 + 128 * 119 + 13 = 6 119 13 = 0x06770D = 0x86F70D
 *
 * The final value is: 0x2A864886F70D.
 * The full OID (including ASN.1 tag and length of 6 bytes) is:
 * 0x06062A864886F70D
 */

var forge$p = forge$s;



/* ASN.1 API */
var asn1$5 = forge$p.asn1 = forge$p.asn1 || {};

/**
 * ASN.1 classes.
 */
asn1$5.Class = {
  UNIVERSAL:        0x00,
  APPLICATION:      0x40,
  CONTEXT_SPECIFIC: 0x80,
  PRIVATE:          0xC0
};

/**
 * ASN.1 types. Not all types are supported by this implementation, only
 * those necessary to implement a simple PKI are implemented.
 */
asn1$5.Type = {
  NONE:             0,
  BOOLEAN:          1,
  INTEGER:          2,
  BITSTRING:        3,
  OCTETSTRING:      4,
  NULL:             5,
  OID:              6,
  ODESC:            7,
  EXTERNAL:         8,
  REAL:             9,
  ENUMERATED:      10,
  EMBEDDED:        11,
  UTF8:            12,
  ROID:            13,
  SEQUENCE:        16,
  SET:             17,
  PRINTABLESTRING: 19,
  IA5STRING:       22,
  UTCTIME:         23,
  GENERALIZEDTIME: 24,
  BMPSTRING:       30
};

/**
 * Creates a new asn1 object.
 *
 * @param tagClass the tag class for the object.
 * @param type the data type (tag number) for the object.
 * @param constructed true if the asn1 object is in constructed form.
 * @param value the value for the object, if it is not constructed.
 * @param [options] the options to use:
 *          [bitStringContents] the plain BIT STRING content including padding
 *            byte.
 *
 * @return the asn1 object.
 */
asn1$5.create = function(tagClass, type, constructed, value, options) {
  /* An asn1 object has a tagClass, a type, a constructed flag, and a
    value. The value's type depends on the constructed flag. If
    constructed, it will contain a list of other asn1 objects. If not,
    it will contain the ASN.1 value as an array of bytes formatted
    according to the ASN.1 data type. */

  // remove undefined values
  if(forge$p.util.isArray(value)) {
    var tmp = [];
    for(var i = 0; i < value.length; ++i) {
      if(value[i] !== undefined) {
        tmp.push(value[i]);
      }
    }
    value = tmp;
  }

  var obj = {
    tagClass: tagClass,
    type: type,
    constructed: constructed,
    composed: constructed || forge$p.util.isArray(value),
    value: value
  };
  if(options && 'bitStringContents' in options) {
    // TODO: copy byte buffer if it's a buffer not a string
    obj.bitStringContents = options.bitStringContents;
    // TODO: add readonly flag to avoid this overhead
    // save copy to detect changes
    obj.original = asn1$5.copy(obj);
  }
  return obj;
};

/**
 * Copies an asn1 object.
 *
 * @param obj the asn1 object.
 * @param [options] copy options:
 *          [excludeBitStringContents] true to not copy bitStringContents
 *
 * @return the a copy of the asn1 object.
 */
asn1$5.copy = function(obj, options) {
  var copy;

  if(forge$p.util.isArray(obj)) {
    copy = [];
    for(var i = 0; i < obj.length; ++i) {
      copy.push(asn1$5.copy(obj[i], options));
    }
    return copy;
  }

  if(typeof obj === 'string') {
    // TODO: copy byte buffer if it's a buffer not a string
    return obj;
  }

  copy = {
    tagClass: obj.tagClass,
    type: obj.type,
    constructed: obj.constructed,
    composed: obj.composed,
    value: asn1$5.copy(obj.value, options)
  };
  if(options && !options.excludeBitStringContents) {
    // TODO: copy byte buffer if it's a buffer not a string
    copy.bitStringContents = obj.bitStringContents;
  }
  return copy;
};

/**
 * Compares asn1 objects for equality.
 *
 * Note this function does not run in constant time.
 *
 * @param obj1 the first asn1 object.
 * @param obj2 the second asn1 object.
 * @param [options] compare options:
 *          [includeBitStringContents] true to compare bitStringContents
 *
 * @return true if the asn1 objects are equal.
 */
asn1$5.equals = function(obj1, obj2, options) {
  if(forge$p.util.isArray(obj1)) {
    if(!forge$p.util.isArray(obj2)) {
      return false;
    }
    if(obj1.length !== obj2.length) {
      return false;
    }
    for(var i = 0; i < obj1.length; ++i) {
      if(!asn1$5.equals(obj1[i], obj2[i])) {
        return false;
      }
    }
    return true;
  }

  if(typeof obj1 !== typeof obj2) {
    return false;
  }

  if(typeof obj1 === 'string') {
    return obj1 === obj2;
  }

  var equal = obj1.tagClass === obj2.tagClass &&
    obj1.type === obj2.type &&
    obj1.constructed === obj2.constructed &&
    obj1.composed === obj2.composed &&
    asn1$5.equals(obj1.value, obj2.value);
  if(options && options.includeBitStringContents) {
    equal = equal && (obj1.bitStringContents === obj2.bitStringContents);
  }

  return equal;
};

/**
 * Gets the length of a BER-encoded ASN.1 value.
 *
 * In case the length is not specified, undefined is returned.
 *
 * @param b the BER-encoded ASN.1 byte buffer, starting with the first
 *          length byte.
 *
 * @return the length of the BER-encoded ASN.1 value or undefined.
 */
asn1$5.getBerValueLength = function(b) {
  // TODO: move this function and related DER/BER functions to a der.js
  // file; better abstract ASN.1 away from der/ber.
  var b2 = b.getByte();
  if(b2 === 0x80) {
    return undefined;
  }

  // see if the length is "short form" or "long form" (bit 8 set)
  var length;
  var longForm = b2 & 0x80;
  if(!longForm) {
    // length is just the first byte
    length = b2;
  } else {
    // the number of bytes the length is specified in bits 7 through 1
    // and each length byte is in big-endian base-256
    length = b.getInt((b2 & 0x7F) << 3);
  }
  return length;
};

/**
 * Check if the byte buffer has enough bytes. Throws an Error if not.
 *
 * @param bytes the byte buffer to parse from.
 * @param remaining the bytes remaining in the current parsing state.
 * @param n the number of bytes the buffer must have.
 */
function _checkBufferLength(bytes, remaining, n) {
  if(n > remaining) {
    var error = new Error('Too few bytes to parse DER.');
    error.available = bytes.length();
    error.remaining = remaining;
    error.requested = n;
    throw error;
  }
}

/**
 * Gets the length of a BER-encoded ASN.1 value.
 *
 * In case the length is not specified, undefined is returned.
 *
 * @param bytes the byte buffer to parse from.
 * @param remaining the bytes remaining in the current parsing state.
 *
 * @return the length of the BER-encoded ASN.1 value or undefined.
 */
var _getValueLength = function(bytes, remaining) {
  // TODO: move this function and related DER/BER functions to a der.js
  // file; better abstract ASN.1 away from der/ber.
  // fromDer already checked that this byte exists
  var b2 = bytes.getByte();
  remaining--;
  if(b2 === 0x80) {
    return undefined;
  }

  // see if the length is "short form" or "long form" (bit 8 set)
  var length;
  var longForm = b2 & 0x80;
  if(!longForm) {
    // length is just the first byte
    length = b2;
  } else {
    // the number of bytes the length is specified in bits 7 through 1
    // and each length byte is in big-endian base-256
    var longFormBytes = b2 & 0x7F;
    _checkBufferLength(bytes, remaining, longFormBytes);
    length = bytes.getInt(longFormBytes << 3);
  }
  // FIXME: this will only happen for 32 bit getInt with high bit set
  if(length < 0) {
    throw new Error('Negative length: ' + length);
  }
  return length;
};

/**
 * Parses an asn1 object from a byte buffer in DER format.
 *
 * @param bytes the byte buffer to parse from.
 * @param [strict] true to be strict when checking value lengths, false to
 *          allow truncated values (default: true).
 * @param [options] object with options or boolean strict flag
 *          [strict] true to be strict when checking value lengths, false to
 *            allow truncated values (default: true).
 *          [parseAllBytes] true to ensure all bytes are parsed
 *            (default: true)
 *          [decodeBitStrings] true to attempt to decode the content of
 *            BIT STRINGs (not OCTET STRINGs) using strict mode. Note that
 *            without schema support to understand the data context this can
 *            erroneously decode values that happen to be valid ASN.1. This
 *            flag will be deprecated or removed as soon as schema support is
 *            available. (default: true)
 *
 * @throws Will throw an error for various malformed input conditions.
 *
 * @return the parsed asn1 object.
 */
asn1$5.fromDer = function(bytes, options) {
  if(options === undefined) {
    options = {
      strict: true,
      parseAllBytes: true,
      decodeBitStrings: true
    };
  }
  if(typeof options === 'boolean') {
    options = {
      strict: options,
      parseAllBytes: true,
      decodeBitStrings: true
    };
  }
  if(!('strict' in options)) {
    options.strict = true;
  }
  if(!('parseAllBytes' in options)) {
    options.parseAllBytes = true;
  }
  if(!('decodeBitStrings' in options)) {
    options.decodeBitStrings = true;
  }

  // wrap in buffer if needed
  if(typeof bytes === 'string') {
    bytes = forge$p.util.createBuffer(bytes);
  }

  var byteCount = bytes.length();
  var value = _fromDer(bytes, bytes.length(), 0, options);
  if(options.parseAllBytes && bytes.length() !== 0) {
    var error = new Error('Unparsed DER bytes remain after ASN.1 parsing.');
    error.byteCount = byteCount;
    error.remaining = bytes.length();
    throw error;
  }
  return value;
};

/**
 * Internal function to parse an asn1 object from a byte buffer in DER format.
 *
 * @param bytes the byte buffer to parse from.
 * @param remaining the number of bytes remaining for this chunk.
 * @param depth the current parsing depth.
 * @param options object with same options as fromDer().
 *
 * @return the parsed asn1 object.
 */
function _fromDer(bytes, remaining, depth, options) {
  // temporary storage for consumption calculations
  var start;

  // minimum length for ASN.1 DER structure is 2
  _checkBufferLength(bytes, remaining, 2);

  // get the first byte
  var b1 = bytes.getByte();
  // consumed one byte
  remaining--;

  // get the tag class
  var tagClass = (b1 & 0xC0);

  // get the type (bits 1-5)
  var type = b1 & 0x1F;

  // get the variable value length and adjust remaining bytes
  start = bytes.length();
  var length = _getValueLength(bytes, remaining);
  remaining -= start - bytes.length();

  // ensure there are enough bytes to get the value
  if(length !== undefined && length > remaining) {
    if(options.strict) {
      var error = new Error('Too few bytes to read ASN.1 value.');
      error.available = bytes.length();
      error.remaining = remaining;
      error.requested = length;
      throw error;
    }
    // Note: be lenient with truncated values and use remaining state bytes
    length = remaining;
  }

  // value storage
  var value;
  // possible BIT STRING contents storage
  var bitStringContents;

  // constructed flag is bit 6 (32 = 0x20) of the first byte
  var constructed = ((b1 & 0x20) === 0x20);
  if(constructed) {
    // parse child asn1 objects from the value
    value = [];
    if(length === undefined) {
      // asn1 object of indefinite length, read until end tag
      for(;;) {
        _checkBufferLength(bytes, remaining, 2);
        if(bytes.bytes(2) === String.fromCharCode(0, 0)) {
          bytes.getBytes(2);
          remaining -= 2;
          break;
        }
        start = bytes.length();
        value.push(_fromDer(bytes, remaining, depth + 1, options));
        remaining -= start - bytes.length();
      }
    } else {
      // parsing asn1 object of definite length
      while(length > 0) {
        start = bytes.length();
        value.push(_fromDer(bytes, length, depth + 1, options));
        remaining -= start - bytes.length();
        length -= start - bytes.length();
      }
    }
  }

  // if a BIT STRING, save the contents including padding
  if(value === undefined && tagClass === asn1$5.Class.UNIVERSAL &&
    type === asn1$5.Type.BITSTRING) {
    bitStringContents = bytes.bytes(length);
  }

  // determine if a non-constructed value should be decoded as a composed
  // value that contains other ASN.1 objects. BIT STRINGs (and OCTET STRINGs)
  // can be used this way.
  if(value === undefined && options.decodeBitStrings &&
    tagClass === asn1$5.Class.UNIVERSAL &&
    // FIXME: OCTET STRINGs not yet supported here
    // .. other parts of forge expect to decode OCTET STRINGs manually
    (type === asn1$5.Type.BITSTRING /*|| type === asn1.Type.OCTETSTRING*/) &&
    length > 1) {
    // save read position
    var savedRead = bytes.read;
    var savedRemaining = remaining;
    var unused = 0;
    if(type === asn1$5.Type.BITSTRING) {
      /* The first octet gives the number of bits by which the length of the
        bit string is less than the next multiple of eight (this is called
        the "number of unused bits").

        The second and following octets give the value of the bit string
        converted to an octet string. */
      _checkBufferLength(bytes, remaining, 1);
      unused = bytes.getByte();
      remaining--;
    }
    // if all bits are used, maybe the BIT/OCTET STRING holds ASN.1 objs
    if(unused === 0) {
      try {
        // attempt to parse child asn1 object from the value
        // (stored in array to signal composed value)
        start = bytes.length();
        var subOptions = {
          // enforce strict mode to avoid parsing ASN.1 from plain data
          strict: true,
          decodeBitStrings: true
        };
        var composed = _fromDer(bytes, remaining, depth + 1, subOptions);
        var used = start - bytes.length();
        remaining -= used;
        if(type == asn1$5.Type.BITSTRING) {
          used++;
        }

        // if the data all decoded and the class indicates UNIVERSAL or
        // CONTEXT_SPECIFIC then assume we've got an encapsulated ASN.1 object
        var tc = composed.tagClass;
        if(used === length &&
          (tc === asn1$5.Class.UNIVERSAL || tc === asn1$5.Class.CONTEXT_SPECIFIC)) {
          value = [composed];
        }
      } catch(ex) {
      }
    }
    if(value === undefined) {
      // restore read position
      bytes.read = savedRead;
      remaining = savedRemaining;
    }
  }

  if(value === undefined) {
    // asn1 not constructed or composed, get raw value
    // TODO: do DER to OID conversion and vice-versa in .toDer?

    if(length === undefined) {
      if(options.strict) {
        throw new Error('Non-constructed ASN.1 object of indefinite length.');
      }
      // be lenient and use remaining state bytes
      length = remaining;
    }

    if(type === asn1$5.Type.BMPSTRING) {
      value = '';
      for(; length > 0; length -= 2) {
        _checkBufferLength(bytes, remaining, 2);
        value += String.fromCharCode(bytes.getInt16());
        remaining -= 2;
      }
    } else {
      value = bytes.getBytes(length);
      remaining -= length;
    }
  }

  // add BIT STRING contents if available
  var asn1Options = bitStringContents === undefined ? null : {
    bitStringContents: bitStringContents
  };

  // create and return asn1 object
  return asn1$5.create(tagClass, type, constructed, value, asn1Options);
}

/**
 * Converts the given asn1 object to a buffer of bytes in DER format.
 *
 * @param asn1 the asn1 object to convert to bytes.
 *
 * @return the buffer of bytes.
 */
asn1$5.toDer = function(obj) {
  var bytes = forge$p.util.createBuffer();

  // build the first byte
  var b1 = obj.tagClass | obj.type;

  // for storing the ASN.1 value
  var value = forge$p.util.createBuffer();

  // use BIT STRING contents if available and data not changed
  var useBitStringContents = false;
  if('bitStringContents' in obj) {
    useBitStringContents = true;
    if(obj.original) {
      useBitStringContents = asn1$5.equals(obj, obj.original);
    }
  }

  if(useBitStringContents) {
    value.putBytes(obj.bitStringContents);
  } else if(obj.composed) {
    // if composed, use each child asn1 object's DER bytes as value
    // turn on 6th bit (0x20 = 32) to indicate asn1 is constructed
    // from other asn1 objects
    if(obj.constructed) {
      b1 |= 0x20;
    } else {
      // type is a bit string, add unused bits of 0x00
      value.putByte(0x00);
    }

    // add all of the child DER bytes together
    for(var i = 0; i < obj.value.length; ++i) {
      if(obj.value[i] !== undefined) {
        value.putBuffer(asn1$5.toDer(obj.value[i]));
      }
    }
  } else {
    // use asn1.value directly
    if(obj.type === asn1$5.Type.BMPSTRING) {
      for(var i = 0; i < obj.value.length; ++i) {
        value.putInt16(obj.value.charCodeAt(i));
      }
    } else {
      // ensure integer is minimally-encoded
      // TODO: should all leading bytes be stripped vs just one?
      // .. ex '00 00 01' => '01'?
      if(obj.type === asn1$5.Type.INTEGER &&
        obj.value.length > 1 &&
        // leading 0x00 for positive integer
        ((obj.value.charCodeAt(0) === 0 &&
        (obj.value.charCodeAt(1) & 0x80) === 0) ||
        // leading 0xFF for negative integer
        (obj.value.charCodeAt(0) === 0xFF &&
        (obj.value.charCodeAt(1) & 0x80) === 0x80))) {
        value.putBytes(obj.value.substr(1));
      } else {
        value.putBytes(obj.value);
      }
    }
  }

  // add tag byte
  bytes.putByte(b1);

  // use "short form" encoding
  if(value.length() <= 127) {
    // one byte describes the length
    // bit 8 = 0 and bits 7-1 = length
    bytes.putByte(value.length() & 0x7F);
  } else {
    // use "long form" encoding
    // 2 to 127 bytes describe the length
    // first byte: bit 8 = 1 and bits 7-1 = # of additional bytes
    // other bytes: length in base 256, big-endian
    var len = value.length();
    var lenBytes = '';
    do {
      lenBytes += String.fromCharCode(len & 0xFF);
      len = len >>> 8;
    } while(len > 0);

    // set first byte to # bytes used to store the length and turn on
    // bit 8 to indicate long-form length is used
    bytes.putByte(lenBytes.length | 0x80);

    // concatenate length bytes in reverse since they were generated
    // little endian and we need big endian
    for(var i = lenBytes.length - 1; i >= 0; --i) {
      bytes.putByte(lenBytes.charCodeAt(i));
    }
  }

  // concatenate value bytes
  bytes.putBuffer(value);
  return bytes;
};

/**
 * Converts an OID dot-separated string to a byte buffer. The byte buffer
 * contains only the DER-encoded value, not any tag or length bytes.
 *
 * @param oid the OID dot-separated string.
 *
 * @return the byte buffer.
 */
asn1$5.oidToDer = function(oid) {
  // split OID into individual values
  var values = oid.split('.');
  var bytes = forge$p.util.createBuffer();

  // first byte is 40 * value1 + value2
  bytes.putByte(40 * parseInt(values[0], 10) + parseInt(values[1], 10));
  // other bytes are each value in base 128 with 8th bit set except for
  // the last byte for each value
  var last, valueBytes, value, b;
  for(var i = 2; i < values.length; ++i) {
    // produce value bytes in reverse because we don't know how many
    // bytes it will take to store the value
    last = true;
    valueBytes = [];
    value = parseInt(values[i], 10);
    do {
      b = value & 0x7F;
      value = value >>> 7;
      // if value is not last, then turn on 8th bit
      if(!last) {
        b |= 0x80;
      }
      valueBytes.push(b);
      last = false;
    } while(value > 0);

    // add value bytes in reverse (needs to be in big endian)
    for(var n = valueBytes.length - 1; n >= 0; --n) {
      bytes.putByte(valueBytes[n]);
    }
  }

  return bytes;
};

/**
 * Converts a DER-encoded byte buffer to an OID dot-separated string. The
 * byte buffer should contain only the DER-encoded value, not any tag or
 * length bytes.
 *
 * @param bytes the byte buffer.
 *
 * @return the OID dot-separated string.
 */
asn1$5.derToOid = function(bytes) {
  var oid;

  // wrap in buffer if needed
  if(typeof bytes === 'string') {
    bytes = forge$p.util.createBuffer(bytes);
  }

  // first byte is 40 * value1 + value2
  var b = bytes.getByte();
  oid = Math.floor(b / 40) + '.' + (b % 40);

  // other bytes are each value in base 128 with 8th bit set except for
  // the last byte for each value
  var value = 0;
  while(bytes.length() > 0) {
    b = bytes.getByte();
    value = value << 7;
    // not the last byte for the value
    if(b & 0x80) {
      value += b & 0x7F;
    } else {
      // last byte
      oid += '.' + (value + b);
      value = 0;
    }
  }

  return oid;
};

/**
 * Converts a UTCTime value to a date.
 *
 * Note: GeneralizedTime has 4 digits for the year and is used for X.509
 * dates past 2049. Parsing that structure hasn't been implemented yet.
 *
 * @param utc the UTCTime value to convert.
 *
 * @return the date.
 */
asn1$5.utcTimeToDate = function(utc) {
  /* The following formats can be used:

    YYMMDDhhmmZ
    YYMMDDhhmm+hh'mm'
    YYMMDDhhmm-hh'mm'
    YYMMDDhhmmssZ
    YYMMDDhhmmss+hh'mm'
    YYMMDDhhmmss-hh'mm'

    Where:

    YY is the least significant two digits of the year
    MM is the month (01 to 12)
    DD is the day (01 to 31)
    hh is the hour (00 to 23)
    mm are the minutes (00 to 59)
    ss are the seconds (00 to 59)
    Z indicates that local time is GMT, + indicates that local time is
    later than GMT, and - indicates that local time is earlier than GMT
    hh' is the absolute value of the offset from GMT in hours
    mm' is the absolute value of the offset from GMT in minutes */
  var date = new Date();

  // if YY >= 50 use 19xx, if YY < 50 use 20xx
  var year = parseInt(utc.substr(0, 2), 10);
  year = (year >= 50) ? 1900 + year : 2000 + year;
  var MM = parseInt(utc.substr(2, 2), 10) - 1; // use 0-11 for month
  var DD = parseInt(utc.substr(4, 2), 10);
  var hh = parseInt(utc.substr(6, 2), 10);
  var mm = parseInt(utc.substr(8, 2), 10);
  var ss = 0;

  // not just YYMMDDhhmmZ
  if(utc.length > 11) {
    // get character after minutes
    var c = utc.charAt(10);
    var end = 10;

    // see if seconds are present
    if(c !== '+' && c !== '-') {
      // get seconds
      ss = parseInt(utc.substr(10, 2), 10);
      end += 2;
    }
  }

  // update date
  date.setUTCFullYear(year, MM, DD);
  date.setUTCHours(hh, mm, ss, 0);

  if(end) {
    // get +/- after end of time
    c = utc.charAt(end);
    if(c === '+' || c === '-') {
      // get hours+minutes offset
      var hhoffset = parseInt(utc.substr(end + 1, 2), 10);
      var mmoffset = parseInt(utc.substr(end + 4, 2), 10);

      // calculate offset in milliseconds
      var offset = hhoffset * 60 + mmoffset;
      offset *= 60000;

      // apply offset
      if(c === '+') {
        date.setTime(+date - offset);
      } else {
        date.setTime(+date + offset);
      }
    }
  }

  return date;
};

/**
 * Converts a GeneralizedTime value to a date.
 *
 * @param gentime the GeneralizedTime value to convert.
 *
 * @return the date.
 */
asn1$5.generalizedTimeToDate = function(gentime) {
  /* The following formats can be used:

    YYYYMMDDHHMMSS
    YYYYMMDDHHMMSS.fff
    YYYYMMDDHHMMSSZ
    YYYYMMDDHHMMSS.fffZ
    YYYYMMDDHHMMSS+hh'mm'
    YYYYMMDDHHMMSS.fff+hh'mm'
    YYYYMMDDHHMMSS-hh'mm'
    YYYYMMDDHHMMSS.fff-hh'mm'

    Where:

    YYYY is the year
    MM is the month (01 to 12)
    DD is the day (01 to 31)
    hh is the hour (00 to 23)
    mm are the minutes (00 to 59)
    ss are the seconds (00 to 59)
    .fff is the second fraction, accurate to three decimal places
    Z indicates that local time is GMT, + indicates that local time is
    later than GMT, and - indicates that local time is earlier than GMT
    hh' is the absolute value of the offset from GMT in hours
    mm' is the absolute value of the offset from GMT in minutes */
  var date = new Date();

  var YYYY = parseInt(gentime.substr(0, 4), 10);
  var MM = parseInt(gentime.substr(4, 2), 10) - 1; // use 0-11 for month
  var DD = parseInt(gentime.substr(6, 2), 10);
  var hh = parseInt(gentime.substr(8, 2), 10);
  var mm = parseInt(gentime.substr(10, 2), 10);
  var ss = parseInt(gentime.substr(12, 2), 10);
  var fff = 0;
  var offset = 0;
  var isUTC = false;

  if(gentime.charAt(gentime.length - 1) === 'Z') {
    isUTC = true;
  }

  var end = gentime.length - 5, c = gentime.charAt(end);
  if(c === '+' || c === '-') {
    // get hours+minutes offset
    var hhoffset = parseInt(gentime.substr(end + 1, 2), 10);
    var mmoffset = parseInt(gentime.substr(end + 4, 2), 10);

    // calculate offset in milliseconds
    offset = hhoffset * 60 + mmoffset;
    offset *= 60000;

    // apply offset
    if(c === '+') {
      offset *= -1;
    }

    isUTC = true;
  }

  // check for second fraction
  if(gentime.charAt(14) === '.') {
    fff = parseFloat(gentime.substr(14), 10) * 1000;
  }

  if(isUTC) {
    date.setUTCFullYear(YYYY, MM, DD);
    date.setUTCHours(hh, mm, ss, fff);

    // apply offset
    date.setTime(+date + offset);
  } else {
    date.setFullYear(YYYY, MM, DD);
    date.setHours(hh, mm, ss, fff);
  }

  return date;
};

/**
 * Converts a date to a UTCTime value.
 *
 * Note: GeneralizedTime has 4 digits for the year and is used for X.509
 * dates past 2049. Converting to a GeneralizedTime hasn't been
 * implemented yet.
 *
 * @param date the date to convert.
 *
 * @return the UTCTime value.
 */
asn1$5.dateToUtcTime = function(date) {
  // TODO: validate; currently assumes proper format
  if(typeof date === 'string') {
    return date;
  }

  var rval = '';

  // create format YYMMDDhhmmssZ
  var format = [];
  format.push(('' + date.getUTCFullYear()).substr(2));
  format.push('' + (date.getUTCMonth() + 1));
  format.push('' + date.getUTCDate());
  format.push('' + date.getUTCHours());
  format.push('' + date.getUTCMinutes());
  format.push('' + date.getUTCSeconds());

  // ensure 2 digits are used for each format entry
  for(var i = 0; i < format.length; ++i) {
    if(format[i].length < 2) {
      rval += '0';
    }
    rval += format[i];
  }
  rval += 'Z';

  return rval;
};

/**
 * Converts a date to a GeneralizedTime value.
 *
 * @param date the date to convert.
 *
 * @return the GeneralizedTime value as a string.
 */
asn1$5.dateToGeneralizedTime = function(date) {
  // TODO: validate; currently assumes proper format
  if(typeof date === 'string') {
    return date;
  }

  var rval = '';

  // create format YYYYMMDDHHMMSSZ
  var format = [];
  format.push('' + date.getUTCFullYear());
  format.push('' + (date.getUTCMonth() + 1));
  format.push('' + date.getUTCDate());
  format.push('' + date.getUTCHours());
  format.push('' + date.getUTCMinutes());
  format.push('' + date.getUTCSeconds());

  // ensure 2 digits are used for each format entry
  for(var i = 0; i < format.length; ++i) {
    if(format[i].length < 2) {
      rval += '0';
    }
    rval += format[i];
  }
  rval += 'Z';

  return rval;
};

/**
 * Converts a javascript integer to a DER-encoded byte buffer to be used
 * as the value for an INTEGER type.
 *
 * @param x the integer.
 *
 * @return the byte buffer.
 */
asn1$5.integerToDer = function(x) {
  var rval = forge$p.util.createBuffer();
  if(x >= -0x80 && x < 0x80) {
    return rval.putSignedInt(x, 8);
  }
  if(x >= -0x8000 && x < 0x8000) {
    return rval.putSignedInt(x, 16);
  }
  if(x >= -0x800000 && x < 0x800000) {
    return rval.putSignedInt(x, 24);
  }
  if(x >= -0x80000000 && x < 0x80000000) {
    return rval.putSignedInt(x, 32);
  }
  var error = new Error('Integer too large; max is 32-bits.');
  error.integer = x;
  throw error;
};

/**
 * Converts a DER-encoded byte buffer to a javascript integer. This is
 * typically used to decode the value of an INTEGER type.
 *
 * @param bytes the byte buffer.
 *
 * @return the integer.
 */
asn1$5.derToInteger = function(bytes) {
  // wrap in buffer if needed
  if(typeof bytes === 'string') {
    bytes = forge$p.util.createBuffer(bytes);
  }

  var n = bytes.length() * 8;
  if(n > 32) {
    throw new Error('Integer too large; max is 32-bits.');
  }
  return bytes.getSignedInt(n);
};

/**
 * Validates that the given ASN.1 object is at least a super set of the
 * given ASN.1 structure. Only tag classes and types are checked. An
 * optional map may also be provided to capture ASN.1 values while the
 * structure is checked.
 *
 * To capture an ASN.1 value, set an object in the validator's 'capture'
 * parameter to the key to use in the capture map. To capture the full
 * ASN.1 object, specify 'captureAsn1'. To capture BIT STRING bytes, including
 * the leading unused bits counter byte, specify 'captureBitStringContents'.
 * To capture BIT STRING bytes, without the leading unused bits counter byte,
 * specify 'captureBitStringValue'.
 *
 * Objects in the validator may set a field 'optional' to true to indicate
 * that it isn't necessary to pass validation.
 *
 * @param obj the ASN.1 object to validate.
 * @param v the ASN.1 structure validator.
 * @param capture an optional map to capture values in.
 * @param errors an optional array for storing validation errors.
 *
 * @return true on success, false on failure.
 */
asn1$5.validate = function(obj, v, capture, errors) {
  var rval = false;

  // ensure tag class and type are the same if specified
  if((obj.tagClass === v.tagClass || typeof(v.tagClass) === 'undefined') &&
    (obj.type === v.type || typeof(v.type) === 'undefined')) {
    // ensure constructed flag is the same if specified
    if(obj.constructed === v.constructed ||
      typeof(v.constructed) === 'undefined') {
      rval = true;

      // handle sub values
      if(v.value && forge$p.util.isArray(v.value)) {
        var j = 0;
        for(var i = 0; rval && i < v.value.length; ++i) {
          rval = v.value[i].optional || false;
          if(obj.value[j]) {
            rval = asn1$5.validate(obj.value[j], v.value[i], capture, errors);
            if(rval) {
              ++j;
            } else if(v.value[i].optional) {
              rval = true;
            }
          }
          if(!rval && errors) {
            errors.push(
              '[' + v.name + '] ' +
              'Tag class "' + v.tagClass + '", type "' +
              v.type + '" expected value length "' +
              v.value.length + '", got "' +
              obj.value.length + '"');
          }
        }
      }

      if(rval && capture) {
        if(v.capture) {
          capture[v.capture] = obj.value;
        }
        if(v.captureAsn1) {
          capture[v.captureAsn1] = obj;
        }
        if(v.captureBitStringContents && 'bitStringContents' in obj) {
          capture[v.captureBitStringContents] = obj.bitStringContents;
        }
        if(v.captureBitStringValue && 'bitStringContents' in obj) {
          if(obj.bitStringContents.length < 2) {
            capture[v.captureBitStringValue] = '';
          } else {
            // FIXME: support unused bits with data shifting
            var unused = obj.bitStringContents.charCodeAt(0);
            if(unused !== 0) {
              throw new Error(
                'captureBitStringValue only supported for zero unused bits');
            }
            capture[v.captureBitStringValue] = obj.bitStringContents.slice(1);
          }
        }
      }
    } else if(errors) {
      errors.push(
        '[' + v.name + '] ' +
        'Expected constructed "' + v.constructed + '", got "' +
        obj.constructed + '"');
    }
  } else if(errors) {
    if(obj.tagClass !== v.tagClass) {
      errors.push(
        '[' + v.name + '] ' +
        'Expected tag class "' + v.tagClass + '", got "' +
        obj.tagClass + '"');
    }
    if(obj.type !== v.type) {
      errors.push(
        '[' + v.name + '] ' +
        'Expected type "' + v.type + '", got "' + obj.type + '"');
    }
  }
  return rval;
};

// regex for testing for non-latin characters
var _nonLatinRegex = /[^\\u0000-\\u00ff]/;

/**
 * Pretty prints an ASN.1 object to a string.
 *
 * @param obj the object to write out.
 * @param level the level in the tree.
 * @param indentation the indentation to use.
 *
 * @return the string.
 */
asn1$5.prettyPrint = function(obj, level, indentation) {
  var rval = '';

  // set default level and indentation
  level = level || 0;
  indentation = indentation || 2;

  // start new line for deep levels
  if(level > 0) {
    rval += '\n';
  }

  // create indent
  var indent = '';
  for(var i = 0; i < level * indentation; ++i) {
    indent += ' ';
  }

  // print class:type
  rval += indent + 'Tag: ';
  switch(obj.tagClass) {
  case asn1$5.Class.UNIVERSAL:
    rval += 'Universal:';
    break;
  case asn1$5.Class.APPLICATION:
    rval += 'Application:';
    break;
  case asn1$5.Class.CONTEXT_SPECIFIC:
    rval += 'Context-Specific:';
    break;
  case asn1$5.Class.PRIVATE:
    rval += 'Private:';
    break;
  }

  if(obj.tagClass === asn1$5.Class.UNIVERSAL) {
    rval += obj.type;

    // known types
    switch(obj.type) {
    case asn1$5.Type.NONE:
      rval += ' (None)';
      break;
    case asn1$5.Type.BOOLEAN:
      rval += ' (Boolean)';
      break;
    case asn1$5.Type.INTEGER:
      rval += ' (Integer)';
      break;
    case asn1$5.Type.BITSTRING:
      rval += ' (Bit string)';
      break;
    case asn1$5.Type.OCTETSTRING:
      rval += ' (Octet string)';
      break;
    case asn1$5.Type.NULL:
      rval += ' (Null)';
      break;
    case asn1$5.Type.OID:
      rval += ' (Object Identifier)';
      break;
    case asn1$5.Type.ODESC:
      rval += ' (Object Descriptor)';
      break;
    case asn1$5.Type.EXTERNAL:
      rval += ' (External or Instance of)';
      break;
    case asn1$5.Type.REAL:
      rval += ' (Real)';
      break;
    case asn1$5.Type.ENUMERATED:
      rval += ' (Enumerated)';
      break;
    case asn1$5.Type.EMBEDDED:
      rval += ' (Embedded PDV)';
      break;
    case asn1$5.Type.UTF8:
      rval += ' (UTF8)';
      break;
    case asn1$5.Type.ROID:
      rval += ' (Relative Object Identifier)';
      break;
    case asn1$5.Type.SEQUENCE:
      rval += ' (Sequence)';
      break;
    case asn1$5.Type.SET:
      rval += ' (Set)';
      break;
    case asn1$5.Type.PRINTABLESTRING:
      rval += ' (Printable String)';
      break;
    case asn1$5.Type.IA5String:
      rval += ' (IA5String (ASCII))';
      break;
    case asn1$5.Type.UTCTIME:
      rval += ' (UTC time)';
      break;
    case asn1$5.Type.GENERALIZEDTIME:
      rval += ' (Generalized time)';
      break;
    case asn1$5.Type.BMPSTRING:
      rval += ' (BMP String)';
      break;
    }
  } else {
    rval += obj.type;
  }

  rval += '\n';
  rval += indent + 'Constructed: ' + obj.constructed + '\n';

  if(obj.composed) {
    var subvalues = 0;
    var sub = '';
    for(var i = 0; i < obj.value.length; ++i) {
      if(obj.value[i] !== undefined) {
        subvalues += 1;
        sub += asn1$5.prettyPrint(obj.value[i], level + 1, indentation);
        if((i + 1) < obj.value.length) {
          sub += ',';
        }
      }
    }
    rval += indent + 'Sub values: ' + subvalues + sub;
  } else {
    rval += indent + 'Value: ';
    if(obj.type === asn1$5.Type.OID) {
      var oid = asn1$5.derToOid(obj.value);
      rval += oid;
      if(forge$p.pki && forge$p.pki.oids) {
        if(oid in forge$p.pki.oids) {
          rval += ' (' + forge$p.pki.oids[oid] + ') ';
        }
      }
    }
    if(obj.type === asn1$5.Type.INTEGER) {
      try {
        rval += asn1$5.derToInteger(obj.value);
      } catch(ex) {
        rval += '0x' + forge$p.util.bytesToHex(obj.value);
      }
    } else if(obj.type === asn1$5.Type.BITSTRING) {
      // TODO: shift bits as needed to display without padding
      if(obj.value.length > 1) {
        // remove unused bits field
        rval += '0x' + forge$p.util.bytesToHex(obj.value.slice(1));
      } else {
        rval += '(none)';
      }
      // show unused bit count
      if(obj.value.length > 0) {
        var unused = obj.value.charCodeAt(0);
        if(unused == 1) {
          rval += ' (1 unused bit shown)';
        } else if(unused > 1) {
          rval += ' (' + unused + ' unused bits shown)';
        }
      }
    } else if(obj.type === asn1$5.Type.OCTETSTRING) {
      if(!_nonLatinRegex.test(obj.value)) {
        rval += '(' + obj.value + ') ';
      }
      rval += '0x' + forge$p.util.bytesToHex(obj.value);
    } else if(obj.type === asn1$5.Type.UTF8) {
      try {
        rval += forge$p.util.decodeUtf8(obj.value);
      } catch(e) {
        if(e.message === 'URI malformed') {
          rval +=
            '0x' + forge$p.util.bytesToHex(obj.value) + ' (malformed UTF8)';
        } else {
          throw e;
        }
      }
    } else if(obj.type === asn1$5.Type.PRINTABLESTRING ||
      obj.type === asn1$5.Type.IA5String) {
      rval += obj.value;
    } else if(_nonLatinRegex.test(obj.value)) {
      rval += '0x' + forge$p.util.bytesToHex(obj.value);
    } else if(obj.value.length === 0) {
      rval += '[null]';
    } else {
      rval += obj.value;
    }
  }

  return rval;
};

/**
 * Cipher base API.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 */

var forge$o = forge$s;


forge$o.cipher = forge$o.cipher || {};

// registered algorithms
forge$o.cipher.algorithms = forge$o.cipher.algorithms || {};

/**
 * Creates a cipher object that can be used to encrypt data using the given
 * algorithm and key. The algorithm may be provided as a string value for a
 * previously registered algorithm or it may be given as a cipher algorithm
 * API object.
 *
 * @param algorithm the algorithm to use, either a string or an algorithm API
 *          object.
 * @param key the key to use, as a binary-encoded string of bytes or a
 *          byte buffer.
 *
 * @return the cipher.
 */
forge$o.cipher.createCipher = function(algorithm, key) {
  var api = algorithm;
  if(typeof api === 'string') {
    api = forge$o.cipher.getAlgorithm(api);
    if(api) {
      api = api();
    }
  }
  if(!api) {
    throw new Error('Unsupported algorithm: ' + algorithm);
  }

  // assume block cipher
  return new forge$o.cipher.BlockCipher({
    algorithm: api,
    key: key,
    decrypt: false
  });
};

/**
 * Creates a decipher object that can be used to decrypt data using the given
 * algorithm and key. The algorithm may be provided as a string value for a
 * previously registered algorithm or it may be given as a cipher algorithm
 * API object.
 *
 * @param algorithm the algorithm to use, either a string or an algorithm API
 *          object.
 * @param key the key to use, as a binary-encoded string of bytes or a
 *          byte buffer.
 *
 * @return the cipher.
 */
forge$o.cipher.createDecipher = function(algorithm, key) {
  var api = algorithm;
  if(typeof api === 'string') {
    api = forge$o.cipher.getAlgorithm(api);
    if(api) {
      api = api();
    }
  }
  if(!api) {
    throw new Error('Unsupported algorithm: ' + algorithm);
  }

  // assume block cipher
  return new forge$o.cipher.BlockCipher({
    algorithm: api,
    key: key,
    decrypt: true
  });
};

/**
 * Registers an algorithm by name. If the name was already registered, the
 * algorithm API object will be overwritten.
 *
 * @param name the name of the algorithm.
 * @param algorithm the algorithm API object.
 */
forge$o.cipher.registerAlgorithm = function(name, algorithm) {
  name = name.toUpperCase();
  forge$o.cipher.algorithms[name] = algorithm;
};

/**
 * Gets a registered algorithm by name.
 *
 * @param name the name of the algorithm.
 *
 * @return the algorithm, if found, null if not.
 */
forge$o.cipher.getAlgorithm = function(name) {
  name = name.toUpperCase();
  if(name in forge$o.cipher.algorithms) {
    return forge$o.cipher.algorithms[name];
  }
  return null;
};

var BlockCipher = forge$o.cipher.BlockCipher = function(options) {
  this.algorithm = options.algorithm;
  this.mode = this.algorithm.mode;
  this.blockSize = this.mode.blockSize;
  this._finish = false;
  this._input = null;
  this.output = null;
  this._op = options.decrypt ? this.mode.decrypt : this.mode.encrypt;
  this._decrypt = options.decrypt;
  this.algorithm.initialize(options);
};

/**
 * Starts or restarts the encryption or decryption process, whichever
 * was previously configured.
 *
 * For non-GCM mode, the IV may be a binary-encoded string of bytes, an array
 * of bytes, a byte buffer, or an array of 32-bit integers. If the IV is in
 * bytes, then it must be Nb (16) bytes in length. If the IV is given in as
 * 32-bit integers, then it must be 4 integers long.
 *
 * Note: an IV is not required or used in ECB mode.
 *
 * For GCM-mode, the IV must be given as a binary-encoded string of bytes or
 * a byte buffer. The number of bytes should be 12 (96 bits) as recommended
 * by NIST SP-800-38D but another length may be given.
 *
 * @param options the options to use:
 *          iv the initialization vector to use as a binary-encoded string of
 *            bytes, null to reuse the last ciphered block from a previous
 *            update() (this "residue" method is for legacy support only).
 *          additionalData additional authentication data as a binary-encoded
 *            string of bytes, for 'GCM' mode, (default: none).
 *          tagLength desired length of authentication tag, in bits, for
 *            'GCM' mode (0-128, default: 128).
 *          tag the authentication tag to check if decrypting, as a
 *             binary-encoded string of bytes.
 *          output the output the buffer to write to, null to create one.
 */
BlockCipher.prototype.start = function(options) {
  options = options || {};
  var opts = {};
  for(var key in options) {
    opts[key] = options[key];
  }
  opts.decrypt = this._decrypt;
  this._finish = false;
  this._input = forge$o.util.createBuffer();
  this.output = options.output || forge$o.util.createBuffer();
  this.mode.start(opts);
};

/**
 * Updates the next block according to the cipher mode.
 *
 * @param input the buffer to read from.
 */
BlockCipher.prototype.update = function(input) {
  if(input) {
    // input given, so empty it into the input buffer
    this._input.putBuffer(input);
  }

  // do cipher operation until it needs more input and not finished
  while(!this._op.call(this.mode, this._input, this.output, this._finish) &&
    !this._finish) {}

  // free consumed memory from input buffer
  this._input.compact();
};

/**
 * Finishes encrypting or decrypting.
 *
 * @param pad a padding function to use in CBC mode, null for default,
 *          signature(blockSize, buffer, decrypt).
 *
 * @return true if successful, false on error.
 */
BlockCipher.prototype.finish = function(pad) {
  // backwards-compatibility w/deprecated padding API
  // Note: will overwrite padding functions even after another start() call
  if(pad && (this.mode.name === 'ECB' || this.mode.name === 'CBC')) {
    this.mode.pad = function(input) {
      return pad(this.blockSize, input, false);
    };
    this.mode.unpad = function(output) {
      return pad(this.blockSize, output, true);
    };
  }

  // build options for padding and afterFinish functions
  var options = {};
  options.decrypt = this._decrypt;

  // get # of bytes that won't fill a block
  options.overflow = this._input.length() % this.blockSize;

  if(!this._decrypt && this.mode.pad) {
    if(!this.mode.pad(this._input, options)) {
      return false;
    }
  }

  // do final update
  this._finish = true;
  this.update();

  if(this._decrypt && this.mode.unpad) {
    if(!this.mode.unpad(this.output, options)) {
      return false;
    }
  }

  if(this.mode.afterFinish) {
    if(!this.mode.afterFinish(this.output, options)) {
      return false;
    }
  }

  return true;
};

/**
 * Supported cipher modes.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 */

var forge$n = forge$s;


forge$n.cipher = forge$n.cipher || {};

// supported cipher modes
var modes = forge$n.cipher.modes = forge$n.cipher.modes || {};

/** Electronic codebook (ECB) (Don't use this; it's not secure) **/

modes.ecb = function(options) {
  options = options || {};
  this.name = 'ECB';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = new Array(this._ints);
  this._outBlock = new Array(this._ints);
};

modes.ecb.prototype.start = function(options) {};

modes.ecb.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {
    return true;
  }

  // get next block
  for(var i = 0; i < this._ints; ++i) {
    this._inBlock[i] = input.getInt32();
  }

  // encrypt block
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // write output
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._outBlock[i]);
  }
};

modes.ecb.prototype.decrypt = function(input, output, finish) {
  // not enough input to decrypt
  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {
    return true;
  }

  // get next block
  for(var i = 0; i < this._ints; ++i) {
    this._inBlock[i] = input.getInt32();
  }

  // decrypt block
  this.cipher.decrypt(this._inBlock, this._outBlock);

  // write output
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._outBlock[i]);
  }
};

modes.ecb.prototype.pad = function(input, options) {
  // add PKCS#7 padding to block (each pad byte is the
  // value of the number of pad bytes)
  var padding = (input.length() === this.blockSize ?
    this.blockSize : (this.blockSize - input.length()));
  input.fillWithByte(padding, padding);
  return true;
};

modes.ecb.prototype.unpad = function(output, options) {
  // check for error: input data not a multiple of blockSize
  if(options.overflow > 0) {
    return false;
  }

  // ensure padding byte count is valid
  var len = output.length();
  var count = output.at(len - 1);
  if(count > (this.blockSize << 2)) {
    return false;
  }

  // trim off padding bytes
  output.truncate(count);
  return true;
};

/** Cipher-block Chaining (CBC) **/

modes.cbc = function(options) {
  options = options || {};
  this.name = 'CBC';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = new Array(this._ints);
  this._outBlock = new Array(this._ints);
};

modes.cbc.prototype.start = function(options) {
  // Note: legacy support for using IV residue (has security flaws)
  // if IV is null, reuse block from previous processing
  if(options.iv === null) {
    // must have a previous block
    if(!this._prev) {
      throw new Error('Invalid IV parameter.');
    }
    this._iv = this._prev.slice(0);
  } else if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  } else {
    // save IV as "previous" block
    this._iv = transformIV(options.iv, this.blockSize);
    this._prev = this._iv.slice(0);
  }
};

modes.cbc.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {
    return true;
  }

  // get next block
  // CBC XOR's IV (or previous block) with plaintext
  for(var i = 0; i < this._ints; ++i) {
    this._inBlock[i] = this._prev[i] ^ input.getInt32();
  }

  // encrypt block
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // write output, save previous block
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._outBlock[i]);
  }
  this._prev = this._outBlock;
};

modes.cbc.prototype.decrypt = function(input, output, finish) {
  // not enough input to decrypt
  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {
    return true;
  }

  // get next block
  for(var i = 0; i < this._ints; ++i) {
    this._inBlock[i] = input.getInt32();
  }

  // decrypt block
  this.cipher.decrypt(this._inBlock, this._outBlock);

  // write output, save previous ciphered block
  // CBC XOR's IV (or previous block) with ciphertext
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._prev[i] ^ this._outBlock[i]);
  }
  this._prev = this._inBlock.slice(0);
};

modes.cbc.prototype.pad = function(input, options) {
  // add PKCS#7 padding to block (each pad byte is the
  // value of the number of pad bytes)
  var padding = (input.length() === this.blockSize ?
    this.blockSize : (this.blockSize - input.length()));
  input.fillWithByte(padding, padding);
  return true;
};

modes.cbc.prototype.unpad = function(output, options) {
  // check for error: input data not a multiple of blockSize
  if(options.overflow > 0) {
    return false;
  }

  // ensure padding byte count is valid
  var len = output.length();
  var count = output.at(len - 1);
  if(count > (this.blockSize << 2)) {
    return false;
  }

  // trim off padding bytes
  output.truncate(count);
  return true;
};

/** Cipher feedback (CFB) **/

modes.cfb = function(options) {
  options = options || {};
  this.name = 'CFB';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = null;
  this._outBlock = new Array(this._ints);
  this._partialBlock = new Array(this._ints);
  this._partialOutput = forge$n.util.createBuffer();
  this._partialBytes = 0;
};

modes.cfb.prototype.start = function(options) {
  if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  }
  // use IV as first input
  this._iv = transformIV(options.iv, this.blockSize);
  this._inBlock = this._iv.slice(0);
  this._partialBytes = 0;
};

modes.cfb.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  var inputLength = input.length();
  if(inputLength === 0) {
    return true;
  }

  // encrypt block
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output, write input as output
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = input.getInt32() ^ this._outBlock[i];
      output.putInt32(this._inBlock[i]);
    }
    return;
  }

  // handle partial block
  var partialBytes = (this.blockSize - inputLength) % this.blockSize;
  if(partialBytes > 0) {
    partialBytes = this.blockSize - partialBytes;
  }

  // XOR input with output, write input as partial output
  this._partialOutput.clear();
  for(var i = 0; i < this._ints; ++i) {
    this._partialBlock[i] = input.getInt32() ^ this._outBlock[i];
    this._partialOutput.putInt32(this._partialBlock[i]);
  }

  if(partialBytes > 0) {
    // block still incomplete, restore input buffer
    input.read -= this.blockSize;
  } else {
    // block complete, update input block
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = this._partialBlock[i];
    }
  }

  // skip any previous partial bytes
  if(this._partialBytes > 0) {
    this._partialOutput.getBytes(this._partialBytes);
  }

  if(partialBytes > 0 && !finish) {
    output.putBytes(this._partialOutput.getBytes(
      partialBytes - this._partialBytes));
    this._partialBytes = partialBytes;
    return true;
  }

  output.putBytes(this._partialOutput.getBytes(
    inputLength - this._partialBytes));
  this._partialBytes = 0;
};

modes.cfb.prototype.decrypt = function(input, output, finish) {
  // not enough input to decrypt
  var inputLength = input.length();
  if(inputLength === 0) {
    return true;
  }

  // encrypt block (CFB always uses encryption mode)
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output, write input as output
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = input.getInt32();
      output.putInt32(this._inBlock[i] ^ this._outBlock[i]);
    }
    return;
  }

  // handle partial block
  var partialBytes = (this.blockSize - inputLength) % this.blockSize;
  if(partialBytes > 0) {
    partialBytes = this.blockSize - partialBytes;
  }

  // XOR input with output, write input as partial output
  this._partialOutput.clear();
  for(var i = 0; i < this._ints; ++i) {
    this._partialBlock[i] = input.getInt32();
    this._partialOutput.putInt32(this._partialBlock[i] ^ this._outBlock[i]);
  }

  if(partialBytes > 0) {
    // block still incomplete, restore input buffer
    input.read -= this.blockSize;
  } else {
    // block complete, update input block
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = this._partialBlock[i];
    }
  }

  // skip any previous partial bytes
  if(this._partialBytes > 0) {
    this._partialOutput.getBytes(this._partialBytes);
  }

  if(partialBytes > 0 && !finish) {
    output.putBytes(this._partialOutput.getBytes(
      partialBytes - this._partialBytes));
    this._partialBytes = partialBytes;
    return true;
  }

  output.putBytes(this._partialOutput.getBytes(
    inputLength - this._partialBytes));
  this._partialBytes = 0;
};

/** Output feedback (OFB) **/

modes.ofb = function(options) {
  options = options || {};
  this.name = 'OFB';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = null;
  this._outBlock = new Array(this._ints);
  this._partialOutput = forge$n.util.createBuffer();
  this._partialBytes = 0;
};

modes.ofb.prototype.start = function(options) {
  if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  }
  // use IV as first input
  this._iv = transformIV(options.iv, this.blockSize);
  this._inBlock = this._iv.slice(0);
  this._partialBytes = 0;
};

modes.ofb.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  var inputLength = input.length();
  if(input.length() === 0) {
    return true;
  }

  // encrypt block (OFB always uses encryption mode)
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output and update next input
    for(var i = 0; i < this._ints; ++i) {
      output.putInt32(input.getInt32() ^ this._outBlock[i]);
      this._inBlock[i] = this._outBlock[i];
    }
    return;
  }

  // handle partial block
  var partialBytes = (this.blockSize - inputLength) % this.blockSize;
  if(partialBytes > 0) {
    partialBytes = this.blockSize - partialBytes;
  }

  // XOR input with output
  this._partialOutput.clear();
  for(var i = 0; i < this._ints; ++i) {
    this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);
  }

  if(partialBytes > 0) {
    // block still incomplete, restore input buffer
    input.read -= this.blockSize;
  } else {
    // block complete, update input block
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = this._outBlock[i];
    }
  }

  // skip any previous partial bytes
  if(this._partialBytes > 0) {
    this._partialOutput.getBytes(this._partialBytes);
  }

  if(partialBytes > 0 && !finish) {
    output.putBytes(this._partialOutput.getBytes(
      partialBytes - this._partialBytes));
    this._partialBytes = partialBytes;
    return true;
  }

  output.putBytes(this._partialOutput.getBytes(
    inputLength - this._partialBytes));
  this._partialBytes = 0;
};

modes.ofb.prototype.decrypt = modes.ofb.prototype.encrypt;

/** Counter (CTR) **/

modes.ctr = function(options) {
  options = options || {};
  this.name = 'CTR';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = null;
  this._outBlock = new Array(this._ints);
  this._partialOutput = forge$n.util.createBuffer();
  this._partialBytes = 0;
};

modes.ctr.prototype.start = function(options) {
  if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  }
  // use IV as first input
  this._iv = transformIV(options.iv, this.blockSize);
  this._inBlock = this._iv.slice(0);
  this._partialBytes = 0;
};

modes.ctr.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  var inputLength = input.length();
  if(inputLength === 0) {
    return true;
  }

  // encrypt block (CTR always uses encryption mode)
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output
    for(var i = 0; i < this._ints; ++i) {
      output.putInt32(input.getInt32() ^ this._outBlock[i]);
    }
  } else {
    // handle partial block
    var partialBytes = (this.blockSize - inputLength) % this.blockSize;
    if(partialBytes > 0) {
      partialBytes = this.blockSize - partialBytes;
    }

    // XOR input with output
    this._partialOutput.clear();
    for(var i = 0; i < this._ints; ++i) {
      this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);
    }

    if(partialBytes > 0) {
      // block still incomplete, restore input buffer
      input.read -= this.blockSize;
    }

    // skip any previous partial bytes
    if(this._partialBytes > 0) {
      this._partialOutput.getBytes(this._partialBytes);
    }

    if(partialBytes > 0 && !finish) {
      output.putBytes(this._partialOutput.getBytes(
        partialBytes - this._partialBytes));
      this._partialBytes = partialBytes;
      return true;
    }

    output.putBytes(this._partialOutput.getBytes(
      inputLength - this._partialBytes));
    this._partialBytes = 0;
  }

  // block complete, increment counter (input block)
  inc32(this._inBlock);
};

modes.ctr.prototype.decrypt = modes.ctr.prototype.encrypt;

/** Galois/Counter Mode (GCM) **/

modes.gcm = function(options) {
  options = options || {};
  this.name = 'GCM';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = new Array(this._ints);
  this._outBlock = new Array(this._ints);
  this._partialOutput = forge$n.util.createBuffer();
  this._partialBytes = 0;

  // R is actually this value concatenated with 120 more zero bits, but
  // we only XOR against R so the other zeros have no effect -- we just
  // apply this value to the first integer in a block
  this._R = 0xE1000000;
};

modes.gcm.prototype.start = function(options) {
  if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  }
  // ensure IV is a byte buffer
  var iv = forge$n.util.createBuffer(options.iv);

  // no ciphered data processed yet
  this._cipherLength = 0;

  // default additional data is none
  var additionalData;
  if('additionalData' in options) {
    additionalData = forge$n.util.createBuffer(options.additionalData);
  } else {
    additionalData = forge$n.util.createBuffer();
  }

  // default tag length is 128 bits
  if('tagLength' in options) {
    this._tagLength = options.tagLength;
  } else {
    this._tagLength = 128;
  }

  // if tag is given, ensure tag matches tag length
  this._tag = null;
  if(options.decrypt) {
    // save tag to check later
    this._tag = forge$n.util.createBuffer(options.tag).getBytes();
    if(this._tag.length !== (this._tagLength / 8)) {
      throw new Error('Authentication tag does not match tag length.');
    }
  }

  // create tmp storage for hash calculation
  this._hashBlock = new Array(this._ints);

  // no tag generated yet
  this.tag = null;

  // generate hash subkey
  // (apply block cipher to "zero" block)
  this._hashSubkey = new Array(this._ints);
  this.cipher.encrypt([0, 0, 0, 0], this._hashSubkey);

  // generate table M
  // use 4-bit tables (32 component decomposition of a 16 byte value)
  // 8-bit tables take more space and are known to have security
  // vulnerabilities (in native implementations)
  this.componentBits = 4;
  this._m = this.generateHashTable(this._hashSubkey, this.componentBits);

  // Note: support IV length different from 96 bits? (only supporting
  // 96 bits is recommended by NIST SP-800-38D)
  // generate J_0
  var ivLength = iv.length();
  if(ivLength === 12) {
    // 96-bit IV
    this._j0 = [iv.getInt32(), iv.getInt32(), iv.getInt32(), 1];
  } else {
    // IV is NOT 96-bits
    this._j0 = [0, 0, 0, 0];
    while(iv.length() > 0) {
      this._j0 = this.ghash(
        this._hashSubkey, this._j0,
        [iv.getInt32(), iv.getInt32(), iv.getInt32(), iv.getInt32()]);
    }
    this._j0 = this.ghash(
      this._hashSubkey, this._j0, [0, 0].concat(from64To32(ivLength * 8)));
  }

  // generate ICB (initial counter block)
  this._inBlock = this._j0.slice(0);
  inc32(this._inBlock);
  this._partialBytes = 0;

  // consume authentication data
  additionalData = forge$n.util.createBuffer(additionalData);
  // save additional data length as a BE 64-bit number
  this._aDataLength = from64To32(additionalData.length() * 8);
  // pad additional data to 128 bit (16 byte) block size
  var overflow = additionalData.length() % this.blockSize;
  if(overflow) {
    additionalData.fillWithByte(0, this.blockSize - overflow);
  }
  this._s = [0, 0, 0, 0];
  while(additionalData.length() > 0) {
    this._s = this.ghash(this._hashSubkey, this._s, [
      additionalData.getInt32(),
      additionalData.getInt32(),
      additionalData.getInt32(),
      additionalData.getInt32()
    ]);
  }
};

modes.gcm.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  var inputLength = input.length();
  if(inputLength === 0) {
    return true;
  }

  // encrypt block
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output
    for(var i = 0; i < this._ints; ++i) {
      output.putInt32(this._outBlock[i] ^= input.getInt32());
    }
    this._cipherLength += this.blockSize;
  } else {
    // handle partial block
    var partialBytes = (this.blockSize - inputLength) % this.blockSize;
    if(partialBytes > 0) {
      partialBytes = this.blockSize - partialBytes;
    }

    // XOR input with output
    this._partialOutput.clear();
    for(var i = 0; i < this._ints; ++i) {
      this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);
    }

    if(partialBytes <= 0 || finish) {
      // handle overflow prior to hashing
      if(finish) {
        // get block overflow
        var overflow = inputLength % this.blockSize;
        this._cipherLength += overflow;
        // truncate for hash function
        this._partialOutput.truncate(this.blockSize - overflow);
      } else {
        this._cipherLength += this.blockSize;
      }

      // get output block for hashing
      for(var i = 0; i < this._ints; ++i) {
        this._outBlock[i] = this._partialOutput.getInt32();
      }
      this._partialOutput.read -= this.blockSize;
    }

    // skip any previous partial bytes
    if(this._partialBytes > 0) {
      this._partialOutput.getBytes(this._partialBytes);
    }

    if(partialBytes > 0 && !finish) {
      // block still incomplete, restore input buffer, get partial output,
      // and return early
      input.read -= this.blockSize;
      output.putBytes(this._partialOutput.getBytes(
        partialBytes - this._partialBytes));
      this._partialBytes = partialBytes;
      return true;
    }

    output.putBytes(this._partialOutput.getBytes(
      inputLength - this._partialBytes));
    this._partialBytes = 0;
  }

  // update hash block S
  this._s = this.ghash(this._hashSubkey, this._s, this._outBlock);

  // increment counter (input block)
  inc32(this._inBlock);
};

modes.gcm.prototype.decrypt = function(input, output, finish) {
  // not enough input to decrypt
  var inputLength = input.length();
  if(inputLength < this.blockSize && !(finish && inputLength > 0)) {
    return true;
  }

  // encrypt block (GCM always uses encryption mode)
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // increment counter (input block)
  inc32(this._inBlock);

  // update hash block S
  this._hashBlock[0] = input.getInt32();
  this._hashBlock[1] = input.getInt32();
  this._hashBlock[2] = input.getInt32();
  this._hashBlock[3] = input.getInt32();
  this._s = this.ghash(this._hashSubkey, this._s, this._hashBlock);

  // XOR hash input with output
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._outBlock[i] ^ this._hashBlock[i]);
  }

  // increment cipher data length
  if(inputLength < this.blockSize) {
    this._cipherLength += inputLength % this.blockSize;
  } else {
    this._cipherLength += this.blockSize;
  }
};

modes.gcm.prototype.afterFinish = function(output, options) {
  var rval = true;

  // handle overflow
  if(options.decrypt && options.overflow) {
    output.truncate(this.blockSize - options.overflow);
  }

  // handle authentication tag
  this.tag = forge$n.util.createBuffer();

  // concatenate additional data length with cipher length
  var lengths = this._aDataLength.concat(from64To32(this._cipherLength * 8));

  // include lengths in hash
  this._s = this.ghash(this._hashSubkey, this._s, lengths);

  // do GCTR(J_0, S)
  var tag = [];
  this.cipher.encrypt(this._j0, tag);
  for(var i = 0; i < this._ints; ++i) {
    this.tag.putInt32(this._s[i] ^ tag[i]);
  }

  // trim tag to length
  this.tag.truncate(this.tag.length() % (this._tagLength / 8));

  // check authentication tag
  if(options.decrypt && this.tag.bytes() !== this._tag) {
    rval = false;
  }

  return rval;
};

/**
 * See NIST SP-800-38D 6.3 (Algorithm 1). This function performs Galois
 * field multiplication. The field, GF(2^128), is defined by the polynomial:
 *
 * x^128 + x^7 + x^2 + x + 1
 *
 * Which is represented in little-endian binary form as: 11100001 (0xe1). When
 * the value of a coefficient is 1, a bit is set. The value R, is the
 * concatenation of this value and 120 zero bits, yielding a 128-bit value
 * which matches the block size.
 *
 * This function will multiply two elements (vectors of bytes), X and Y, in
 * the field GF(2^128). The result is initialized to zero. For each bit of
 * X (out of 128), x_i, if x_i is set, then the result is multiplied (XOR'd)
 * by the current value of Y. For each bit, the value of Y will be raised by
 * a power of x (multiplied by the polynomial x). This can be achieved by
 * shifting Y once to the right. If the current value of Y, prior to being
 * multiplied by x, has 0 as its LSB, then it is a 127th degree polynomial.
 * Otherwise, we must divide by R after shifting to find the remainder.
 *
 * @param x the first block to multiply by the second.
 * @param y the second block to multiply by the first.
 *
 * @return the block result of the multiplication.
 */
modes.gcm.prototype.multiply = function(x, y) {
  var z_i = [0, 0, 0, 0];
  var v_i = y.slice(0);

  // calculate Z_128 (block has 128 bits)
  for(var i = 0; i < 128; ++i) {
    // if x_i is 0, Z_{i+1} = Z_i (unchanged)
    // else Z_{i+1} = Z_i ^ V_i
    // get x_i by finding 32-bit int position, then left shift 1 by remainder
    var x_i = x[(i / 32) | 0] & (1 << (31 - i % 32));
    if(x_i) {
      z_i[0] ^= v_i[0];
      z_i[1] ^= v_i[1];
      z_i[2] ^= v_i[2];
      z_i[3] ^= v_i[3];
    }

    // if LSB(V_i) is 1, V_i = V_i >> 1
    // else V_i = (V_i >> 1) ^ R
    this.pow(v_i, v_i);
  }

  return z_i;
};

modes.gcm.prototype.pow = function(x, out) {
  // if LSB(x) is 1, x = x >>> 1
  // else x = (x >>> 1) ^ R
  var lsb = x[3] & 1;

  // always do x >>> 1:
  // starting with the rightmost integer, shift each integer to the right
  // one bit, pulling in the bit from the integer to the left as its top
  // most bit (do this for the last 3 integers)
  for(var i = 3; i > 0; --i) {
    out[i] = (x[i] >>> 1) | ((x[i - 1] & 1) << 31);
  }
  // shift the first integer normally
  out[0] = x[0] >>> 1;

  // if lsb was not set, then polynomial had a degree of 127 and doesn't
  // need to divided; otherwise, XOR with R to find the remainder; we only
  // need to XOR the first integer since R technically ends w/120 zero bits
  if(lsb) {
    out[0] ^= this._R;
  }
};

modes.gcm.prototype.tableMultiply = function(x) {
  // assumes 4-bit tables are used
  var z = [0, 0, 0, 0];
  for(var i = 0; i < 32; ++i) {
    var idx = (i / 8) | 0;
    var x_i = (x[idx] >>> ((7 - (i % 8)) * 4)) & 0xF;
    var ah = this._m[i][x_i];
    z[0] ^= ah[0];
    z[1] ^= ah[1];
    z[2] ^= ah[2];
    z[3] ^= ah[3];
  }
  return z;
};

/**
 * A continuing version of the GHASH algorithm that operates on a single
 * block. The hash block, last hash value (Ym) and the new block to hash
 * are given.
 *
 * @param h the hash block.
 * @param y the previous value for Ym, use [0, 0, 0, 0] for a new hash.
 * @param x the block to hash.
 *
 * @return the hashed value (Ym).
 */
modes.gcm.prototype.ghash = function(h, y, x) {
  y[0] ^= x[0];
  y[1] ^= x[1];
  y[2] ^= x[2];
  y[3] ^= x[3];
  return this.tableMultiply(y);
  //return this.multiply(y, h);
};

/**
 * Precomputes a table for multiplying against the hash subkey. This
 * mechanism provides a substantial speed increase over multiplication
 * performed without a table. The table-based multiplication this table is
 * for solves X * H by multiplying each component of X by H and then
 * composing the results together using XOR.
 *
 * This function can be used to generate tables with different bit sizes
 * for the components, however, this implementation assumes there are
 * 32 components of X (which is a 16 byte vector), therefore each component
 * takes 4-bits (so the table is constructed with bits=4).
 *
 * @param h the hash subkey.
 * @param bits the bit size for a component.
 */
modes.gcm.prototype.generateHashTable = function(h, bits) {
  // TODO: There are further optimizations that would use only the
  // first table M_0 (or some variant) along with a remainder table;
  // this can be explored in the future
  var multiplier = 8 / bits;
  var perInt = 4 * multiplier;
  var size = 16 * multiplier;
  var m = new Array(size);
  for(var i = 0; i < size; ++i) {
    var tmp = [0, 0, 0, 0];
    var idx = (i / perInt) | 0;
    var shft = ((perInt - 1 - (i % perInt)) * bits);
    tmp[idx] = (1 << (bits - 1)) << shft;
    m[i] = this.generateSubHashTable(this.multiply(tmp, h), bits);
  }
  return m;
};

/**
 * Generates a table for multiplying against the hash subkey for one
 * particular component (out of all possible component values).
 *
 * @param mid the pre-multiplied value for the middle key of the table.
 * @param bits the bit size for a component.
 */
modes.gcm.prototype.generateSubHashTable = function(mid, bits) {
  // compute the table quickly by minimizing the number of
  // POW operations -- they only need to be performed for powers of 2,
  // all other entries can be composed from those powers using XOR
  var size = 1 << bits;
  var half = size >>> 1;
  var m = new Array(size);
  m[half] = mid.slice(0);
  var i = half >>> 1;
  while(i > 0) {
    // raise m0[2 * i] and store in m0[i]
    this.pow(m[2 * i], m[i] = []);
    i >>= 1;
  }
  i = 2;
  while(i < half) {
    for(var j = 1; j < i; ++j) {
      var m_i = m[i];
      var m_j = m[j];
      m[i + j] = [
        m_i[0] ^ m_j[0],
        m_i[1] ^ m_j[1],
        m_i[2] ^ m_j[2],
        m_i[3] ^ m_j[3]
      ];
    }
    i *= 2;
  }
  m[0] = [0, 0, 0, 0];
  /* Note: We could avoid storing these by doing composition during multiply
  calculate top half using composition by speed is preferred. */
  for(i = half + 1; i < size; ++i) {
    var c = m[i ^ half];
    m[i] = [mid[0] ^ c[0], mid[1] ^ c[1], mid[2] ^ c[2], mid[3] ^ c[3]];
  }
  return m;
};

/** Utility functions */

function transformIV(iv, blockSize) {
  if(typeof iv === 'string') {
    // convert iv string into byte buffer
    iv = forge$n.util.createBuffer(iv);
  }

  if(forge$n.util.isArray(iv) && iv.length > 4) {
    // convert iv byte array into byte buffer
    var tmp = iv;
    iv = forge$n.util.createBuffer();
    for(var i = 0; i < tmp.length; ++i) {
      iv.putByte(tmp[i]);
    }
  }

  if(iv.length() < blockSize) {
    throw new Error(
      'Invalid IV length; got ' + iv.length() +
      ' bytes and expected ' + blockSize + ' bytes.');
  }

  if(!forge$n.util.isArray(iv)) {
    // convert iv byte buffer into 32-bit integer array
    var ints = [];
    var blocks = blockSize / 4;
    for(var i = 0; i < blocks; ++i) {
      ints.push(iv.getInt32());
    }
    iv = ints;
  }

  return iv;
}

function inc32(block) {
  // increment last 32 bits of block only
  block[block.length - 1] = (block[block.length - 1] + 1) & 0xFFFFFFFF;
}

function from64To32(num) {
  // convert 64-bit number to two BE Int32s
  return [(num / 0x100000000) | 0, num & 0xFFFFFFFF];
}

/**
 * Advanced Encryption Standard (AES) implementation.
 *
 * This implementation is based on the public domain library 'jscrypto' which
 * was written by:
 *
 * Emily Stark (estark@stanford.edu)
 * Mike Hamburg (mhamburg@stanford.edu)
 * Dan Boneh (dabo@cs.stanford.edu)
 *
 * Parts of this code are based on the OpenSSL implementation of AES:
 * http://www.openssl.org
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 */

var forge$m = forge$s;




/* AES API */
forge$m.aes = forge$m.aes || {};

/**
 * Deprecated. Instead, use:
 *
 * var cipher = forge.cipher.createCipher('AES-<mode>', key);
 * cipher.start({iv: iv});
 *
 * Creates an AES cipher object to encrypt data using the given symmetric key.
 * The output will be stored in the 'output' member of the returned cipher.
 *
 * The key and iv may be given as a string of bytes, an array of bytes,
 * a byte buffer, or an array of 32-bit words.
 *
 * @param key the symmetric key to use.
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$m.aes.startEncrypting = function(key, iv, output, mode) {
  var cipher = _createCipher$1({
    key: key,
    output: output,
    decrypt: false,
    mode: mode
  });
  cipher.start(iv);
  return cipher;
};

/**
 * Deprecated. Instead, use:
 *
 * var cipher = forge.cipher.createCipher('AES-<mode>', key);
 *
 * Creates an AES cipher object to encrypt data using the given symmetric key.
 *
 * The key may be given as a string of bytes, an array of bytes, a
 * byte buffer, or an array of 32-bit words.
 *
 * @param key the symmetric key to use.
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$m.aes.createEncryptionCipher = function(key, mode) {
  return _createCipher$1({
    key: key,
    output: null,
    decrypt: false,
    mode: mode
  });
};

/**
 * Deprecated. Instead, use:
 *
 * var decipher = forge.cipher.createDecipher('AES-<mode>', key);
 * decipher.start({iv: iv});
 *
 * Creates an AES cipher object to decrypt data using the given symmetric key.
 * The output will be stored in the 'output' member of the returned cipher.
 *
 * The key and iv may be given as a string of bytes, an array of bytes,
 * a byte buffer, or an array of 32-bit words.
 *
 * @param key the symmetric key to use.
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$m.aes.startDecrypting = function(key, iv, output, mode) {
  var cipher = _createCipher$1({
    key: key,
    output: output,
    decrypt: true,
    mode: mode
  });
  cipher.start(iv);
  return cipher;
};

/**
 * Deprecated. Instead, use:
 *
 * var decipher = forge.cipher.createDecipher('AES-<mode>', key);
 *
 * Creates an AES cipher object to decrypt data using the given symmetric key.
 *
 * The key may be given as a string of bytes, an array of bytes, a
 * byte buffer, or an array of 32-bit words.
 *
 * @param key the symmetric key to use.
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$m.aes.createDecryptionCipher = function(key, mode) {
  return _createCipher$1({
    key: key,
    output: null,
    decrypt: true,
    mode: mode
  });
};

/**
 * Creates a new AES cipher algorithm object.
 *
 * @param name the name of the algorithm.
 * @param mode the mode factory function.
 *
 * @return the AES algorithm object.
 */
forge$m.aes.Algorithm = function(name, mode) {
  if(!init) {
    initialize();
  }
  var self = this;
  self.name = name;
  self.mode = new mode({
    blockSize: 16,
    cipher: {
      encrypt: function(inBlock, outBlock) {
        return _updateBlock$1(self._w, inBlock, outBlock, false);
      },
      decrypt: function(inBlock, outBlock) {
        return _updateBlock$1(self._w, inBlock, outBlock, true);
      }
    }
  });
  self._init = false;
};

/**
 * Initializes this AES algorithm by expanding its key.
 *
 * @param options the options to use.
 *          key the key to use with this algorithm.
 *          decrypt true if the algorithm should be initialized for decryption,
 *            false for encryption.
 */
forge$m.aes.Algorithm.prototype.initialize = function(options) {
  if(this._init) {
    return;
  }

  var key = options.key;
  var tmp;

  /* Note: The key may be a string of bytes, an array of bytes, a byte
    buffer, or an array of 32-bit integers. If the key is in bytes, then
    it must be 16, 24, or 32 bytes in length. If it is in 32-bit
    integers, it must be 4, 6, or 8 integers long. */

  if(typeof key === 'string' &&
    (key.length === 16 || key.length === 24 || key.length === 32)) {
    // convert key string into byte buffer
    key = forge$m.util.createBuffer(key);
  } else if(forge$m.util.isArray(key) &&
    (key.length === 16 || key.length === 24 || key.length === 32)) {
    // convert key integer array into byte buffer
    tmp = key;
    key = forge$m.util.createBuffer();
    for(var i = 0; i < tmp.length; ++i) {
      key.putByte(tmp[i]);
    }
  }

  // convert key byte buffer into 32-bit integer array
  if(!forge$m.util.isArray(key)) {
    tmp = key;
    key = [];

    // key lengths of 16, 24, 32 bytes allowed
    var len = tmp.length();
    if(len === 16 || len === 24 || len === 32) {
      len = len >>> 2;
      for(var i = 0; i < len; ++i) {
        key.push(tmp.getInt32());
      }
    }
  }

  // key must be an array of 32-bit integers by now
  if(!forge$m.util.isArray(key) ||
    !(key.length === 4 || key.length === 6 || key.length === 8)) {
    throw new Error('Invalid key parameter.');
  }

  // encryption operation is always used for these modes
  var mode = this.mode.name;
  var encryptOp = (['CFB', 'OFB', 'CTR', 'GCM'].indexOf(mode) !== -1);

  // do key expansion
  this._w = _expandKey(key, options.decrypt && !encryptOp);
  this._init = true;
};

/**
 * Expands a key. Typically only used for testing.
 *
 * @param key the symmetric key to expand, as an array of 32-bit words.
 * @param decrypt true to expand for decryption, false for encryption.
 *
 * @return the expanded key.
 */
forge$m.aes._expandKey = function(key, decrypt) {
  if(!init) {
    initialize();
  }
  return _expandKey(key, decrypt);
};

/**
 * Updates a single block. Typically only used for testing.
 *
 * @param w the expanded key to use.
 * @param input an array of block-size 32-bit words.
 * @param output an array of block-size 32-bit words.
 * @param decrypt true to decrypt, false to encrypt.
 */
forge$m.aes._updateBlock = _updateBlock$1;

/** Register AES algorithms **/

registerAlgorithm$1('AES-ECB', forge$m.cipher.modes.ecb);
registerAlgorithm$1('AES-CBC', forge$m.cipher.modes.cbc);
registerAlgorithm$1('AES-CFB', forge$m.cipher.modes.cfb);
registerAlgorithm$1('AES-OFB', forge$m.cipher.modes.ofb);
registerAlgorithm$1('AES-CTR', forge$m.cipher.modes.ctr);
registerAlgorithm$1('AES-GCM', forge$m.cipher.modes.gcm);

function registerAlgorithm$1(name, mode) {
  var factory = function() {
    return new forge$m.aes.Algorithm(name, mode);
  };
  forge$m.cipher.registerAlgorithm(name, factory);
}

/** AES implementation **/

var init = false; // not yet initialized
var Nb = 4;       // number of words comprising the state (AES = 4)
var sbox;         // non-linear substitution table used in key expansion
var isbox;        // inversion of sbox
var rcon;         // round constant word array
var mix;          // mix-columns table
var imix;         // inverse mix-columns table

/**
 * Performs initialization, ie: precomputes tables to optimize for speed.
 *
 * One way to understand how AES works is to imagine that 'addition' and
 * 'multiplication' are interfaces that require certain mathematical
 * properties to hold true (ie: they are associative) but they might have
 * different implementations and produce different kinds of results ...
 * provided that their mathematical properties remain true. AES defines
 * its own methods of addition and multiplication but keeps some important
 * properties the same, ie: associativity and distributivity. The
 * explanation below tries to shed some light on how AES defines addition
 * and multiplication of bytes and 32-bit words in order to perform its
 * encryption and decryption algorithms.
 *
 * The basics:
 *
 * The AES algorithm views bytes as binary representations of polynomials
 * that have either 1 or 0 as the coefficients. It defines the addition
 * or subtraction of two bytes as the XOR operation. It also defines the
 * multiplication of two bytes as a finite field referred to as GF(2^8)
 * (Note: 'GF' means "Galois Field" which is a field that contains a finite
 * number of elements so GF(2^8) has 256 elements).
 *
 * This means that any two bytes can be represented as binary polynomials;
 * when they multiplied together and modularly reduced by an irreducible
 * polynomial of the 8th degree, the results are the field GF(2^8). The
 * specific irreducible polynomial that AES uses in hexadecimal is 0x11b.
 * This multiplication is associative with 0x01 as the identity:
 *
 * (b * 0x01 = GF(b, 0x01) = b).
 *
 * The operation GF(b, 0x02) can be performed at the byte level by left
 * shifting b once and then XOR'ing it (to perform the modular reduction)
 * with 0x11b if b is >= 128. Repeated application of the multiplication
 * of 0x02 can be used to implement the multiplication of any two bytes.
 *
 * For instance, multiplying 0x57 and 0x13, denoted as GF(0x57, 0x13), can
 * be performed by factoring 0x13 into 0x01, 0x02, and 0x10. Then these
 * factors can each be multiplied by 0x57 and then added together. To do
 * the multiplication, values for 0x57 multiplied by each of these 3 factors
 * can be precomputed and stored in a table. To add them, the values from
 * the table are XOR'd together.
 *
 * AES also defines addition and multiplication of words, that is 4-byte
 * numbers represented as polynomials of 3 degrees where the coefficients
 * are the values of the bytes.
 *
 * The word [a0, a1, a2, a3] is a polynomial a3x^3 + a2x^2 + a1x + a0.
 *
 * Addition is performed by XOR'ing like powers of x. Multiplication
 * is performed in two steps, the first is an algebriac expansion as
 * you would do normally (where addition is XOR). But the result is
 * a polynomial larger than 3 degrees and thus it cannot fit in a word. So
 * next the result is modularly reduced by an AES-specific polynomial of
 * degree 4 which will always produce a polynomial of less than 4 degrees
 * such that it will fit in a word. In AES, this polynomial is x^4 + 1.
 *
 * The modular product of two polynomials 'a' and 'b' is thus:
 *
 * d(x) = d3x^3 + d2x^2 + d1x + d0
 * with
 * d0 = GF(a0, b0) ^ GF(a3, b1) ^ GF(a2, b2) ^ GF(a1, b3)
 * d1 = GF(a1, b0) ^ GF(a0, b1) ^ GF(a3, b2) ^ GF(a2, b3)
 * d2 = GF(a2, b0) ^ GF(a1, b1) ^ GF(a0, b2) ^ GF(a3, b3)
 * d3 = GF(a3, b0) ^ GF(a2, b1) ^ GF(a1, b2) ^ GF(a0, b3)
 *
 * As a matrix:
 *
 * [d0] = [a0 a3 a2 a1][b0]
 * [d1]   [a1 a0 a3 a2][b1]
 * [d2]   [a2 a1 a0 a3][b2]
 * [d3]   [a3 a2 a1 a0][b3]
 *
 * Special polynomials defined by AES (0x02 == {02}):
 * a(x)    = {03}x^3 + {01}x^2 + {01}x + {02}
 * a^-1(x) = {0b}x^3 + {0d}x^2 + {09}x + {0e}.
 *
 * These polynomials are used in the MixColumns() and InverseMixColumns()
 * operations, respectively, to cause each element in the state to affect
 * the output (referred to as diffusing).
 *
 * RotWord() uses: a0 = a1 = a2 = {00} and a3 = {01}, which is the
 * polynomial x3.
 *
 * The ShiftRows() method modifies the last 3 rows in the state (where
 * the state is 4 words with 4 bytes per word) by shifting bytes cyclically.
 * The 1st byte in the second row is moved to the end of the row. The 1st
 * and 2nd bytes in the third row are moved to the end of the row. The 1st,
 * 2nd, and 3rd bytes are moved in the fourth row.
 *
 * More details on how AES arithmetic works:
 *
 * In the polynomial representation of binary numbers, XOR performs addition
 * and subtraction and multiplication in GF(2^8) denoted as GF(a, b)
 * corresponds with the multiplication of polynomials modulo an irreducible
 * polynomial of degree 8. In other words, for AES, GF(a, b) will multiply
 * polynomial 'a' with polynomial 'b' and then do a modular reduction by
 * an AES-specific irreducible polynomial of degree 8.
 *
 * A polynomial is irreducible if its only divisors are one and itself. For
 * the AES algorithm, this irreducible polynomial is:
 *
 * m(x) = x^8 + x^4 + x^3 + x + 1,
 *
 * or {01}{1b} in hexadecimal notation, where each coefficient is a bit:
 * 100011011 = 283 = 0x11b.
 *
 * For example, GF(0x57, 0x83) = 0xc1 because
 *
 * 0x57 = 87  = 01010111 = x^6 + x^4 + x^2 + x + 1
 * 0x85 = 131 = 10000101 = x^7 + x + 1
 *
 * (x^6 + x^4 + x^2 + x + 1) * (x^7 + x + 1)
 * =  x^13 + x^11 + x^9 + x^8 + x^7 +
 *    x^7 + x^5 + x^3 + x^2 + x +
 *    x^6 + x^4 + x^2 + x + 1
 * =  x^13 + x^11 + x^9 + x^8 + x^6 + x^5 + x^4 + x^3 + 1 = y
 *    y modulo (x^8 + x^4 + x^3 + x + 1)
 * =  x^7 + x^6 + 1.
 *
 * The modular reduction by m(x) guarantees the result will be a binary
 * polynomial of less than degree 8, so that it can fit in a byte.
 *
 * The operation to multiply a binary polynomial b with x (the polynomial
 * x in binary representation is 00000010) is:
 *
 * b_7x^8 + b_6x^7 + b_5x^6 + b_4x^5 + b_3x^4 + b_2x^3 + b_1x^2 + b_0x^1
 *
 * To get GF(b, x) we must reduce that by m(x). If b_7 is 0 (that is the
 * most significant bit is 0 in b) then the result is already reduced. If
 * it is 1, then we can reduce it by subtracting m(x) via an XOR.
 *
 * It follows that multiplication by x (00000010 or 0x02) can be implemented
 * by performing a left shift followed by a conditional bitwise XOR with
 * 0x1b. This operation on bytes is denoted by xtime(). Multiplication by
 * higher powers of x can be implemented by repeated application of xtime().
 *
 * By adding intermediate results, multiplication by any constant can be
 * implemented. For instance:
 *
 * GF(0x57, 0x13) = 0xfe because:
 *
 * xtime(b) = (b & 128) ? (b << 1 ^ 0x11b) : (b << 1)
 *
 * Note: We XOR with 0x11b instead of 0x1b because in javascript our
 * datatype for b can be larger than 1 byte, so a left shift will not
 * automatically eliminate bits that overflow a byte ... by XOR'ing the
 * overflow bit with 1 (the extra one from 0x11b) we zero it out.
 *
 * GF(0x57, 0x02) = xtime(0x57) = 0xae
 * GF(0x57, 0x04) = xtime(0xae) = 0x47
 * GF(0x57, 0x08) = xtime(0x47) = 0x8e
 * GF(0x57, 0x10) = xtime(0x8e) = 0x07
 *
 * GF(0x57, 0x13) = GF(0x57, (0x01 ^ 0x02 ^ 0x10))
 *
 * And by the distributive property (since XOR is addition and GF() is
 * multiplication):
 *
 * = GF(0x57, 0x01) ^ GF(0x57, 0x02) ^ GF(0x57, 0x10)
 * = 0x57 ^ 0xae ^ 0x07
 * = 0xfe.
 */
function initialize() {
  init = true;

  /* Populate the Rcon table. These are the values given by
    [x^(i-1),{00},{00},{00}] where x^(i-1) are powers of x (and x = 0x02)
    in the field of GF(2^8), where i starts at 1.

    rcon[0] = [0x00, 0x00, 0x00, 0x00]
    rcon[1] = [0x01, 0x00, 0x00, 0x00] 2^(1-1) = 2^0 = 1
    rcon[2] = [0x02, 0x00, 0x00, 0x00] 2^(2-1) = 2^1 = 2
    ...
    rcon[9]  = [0x1B, 0x00, 0x00, 0x00] 2^(9-1)  = 2^8 = 0x1B
    rcon[10] = [0x36, 0x00, 0x00, 0x00] 2^(10-1) = 2^9 = 0x36

    We only store the first byte because it is the only one used.
  */
  rcon = [0x00, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1B, 0x36];

  // compute xtime table which maps i onto GF(i, 0x02)
  var xtime = new Array(256);
  for(var i = 0; i < 128; ++i) {
    xtime[i] = i << 1;
    xtime[i + 128] = (i + 128) << 1 ^ 0x11B;
  }

  // compute all other tables
  sbox = new Array(256);
  isbox = new Array(256);
  mix = new Array(4);
  imix = new Array(4);
  for(var i = 0; i < 4; ++i) {
    mix[i] = new Array(256);
    imix[i] = new Array(256);
  }
  var e = 0, ei = 0, e2, e4, e8, sx, sx2, me, ime;
  for(var i = 0; i < 256; ++i) {
    /* We need to generate the SubBytes() sbox and isbox tables so that
      we can perform byte substitutions. This requires us to traverse
      all of the elements in GF, find their multiplicative inverses,
      and apply to each the following affine transformation:

      bi' = bi ^ b(i + 4) mod 8 ^ b(i + 5) mod 8 ^ b(i + 6) mod 8 ^
            b(i + 7) mod 8 ^ ci
      for 0 <= i < 8, where bi is the ith bit of the byte, and ci is the
      ith bit of a byte c with the value {63} or {01100011}.

      It is possible to traverse every possible value in a Galois field
      using what is referred to as a 'generator'. There are many
      generators (128 out of 256): 3,5,6,9,11,82 to name a few. To fully
      traverse GF we iterate 255 times, multiplying by our generator
      each time.

      On each iteration we can determine the multiplicative inverse for
      the current element.

      Suppose there is an element in GF 'e'. For a given generator 'g',
      e = g^x. The multiplicative inverse of e is g^(255 - x). It turns
      out that if use the inverse of a generator as another generator
      it will produce all of the corresponding multiplicative inverses
      at the same time. For this reason, we choose 5 as our inverse
      generator because it only requires 2 multiplies and 1 add and its
      inverse, 82, requires relatively few operations as well.

      In order to apply the affine transformation, the multiplicative
      inverse 'ei' of 'e' can be repeatedly XOR'd (4 times) with a
      bit-cycling of 'ei'. To do this 'ei' is first stored in 's' and
      'x'. Then 's' is left shifted and the high bit of 's' is made the
      low bit. The resulting value is stored in 's'. Then 'x' is XOR'd
      with 's' and stored in 'x'. On each subsequent iteration the same
      operation is performed. When 4 iterations are complete, 'x' is
      XOR'd with 'c' (0x63) and the transformed value is stored in 'x'.
      For example:

      s = 01000001
      x = 01000001

      iteration 1: s = 10000010, x ^= s
      iteration 2: s = 00000101, x ^= s
      iteration 3: s = 00001010, x ^= s
      iteration 4: s = 00010100, x ^= s
      x ^= 0x63

      This can be done with a loop where s = (s << 1) | (s >> 7). However,
      it can also be done by using a single 16-bit (in this case 32-bit)
      number 'sx'. Since XOR is an associative operation, we can set 'sx'
      to 'ei' and then XOR it with 'sx' left-shifted 1,2,3, and 4 times.
      The most significant bits will flow into the high 8 bit positions
      and be correctly XOR'd with one another. All that remains will be
      to cycle the high 8 bits by XOR'ing them all with the lower 8 bits
      afterwards.

      At the same time we're populating sbox and isbox we can precompute
      the multiplication we'll need to do to do MixColumns() later.
    */

    // apply affine transformation
    sx = ei ^ (ei << 1) ^ (ei << 2) ^ (ei << 3) ^ (ei << 4);
    sx = (sx >> 8) ^ (sx & 255) ^ 0x63;

    // update tables
    sbox[e] = sx;
    isbox[sx] = e;

    /* Mixing columns is done using matrix multiplication. The columns
      that are to be mixed are each a single word in the current state.
      The state has Nb columns (4 columns). Therefore each column is a
      4 byte word. So to mix the columns in a single column 'c' where
      its rows are r0, r1, r2, and r3, we use the following matrix
      multiplication:

      [2 3 1 1]*[r0,c]=[r'0,c]
      [1 2 3 1] [r1,c] [r'1,c]
      [1 1 2 3] [r2,c] [r'2,c]
      [3 1 1 2] [r3,c] [r'3,c]

      r0, r1, r2, and r3 are each 1 byte of one of the words in the
      state (a column). To do matrix multiplication for each mixed
      column c' we multiply the corresponding row from the left matrix
      with the corresponding column from the right matrix. In total, we
      get 4 equations:

      r0,c' = 2*r0,c + 3*r1,c + 1*r2,c + 1*r3,c
      r1,c' = 1*r0,c + 2*r1,c + 3*r2,c + 1*r3,c
      r2,c' = 1*r0,c + 1*r1,c + 2*r2,c + 3*r3,c
      r3,c' = 3*r0,c + 1*r1,c + 1*r2,c + 2*r3,c

      As usual, the multiplication is as previously defined and the
      addition is XOR. In order to optimize mixing columns we can store
      the multiplication results in tables. If you think of the whole
      column as a word (it might help to visualize by mentally rotating
      the equations above by counterclockwise 90 degrees) then you can
      see that it would be useful to map the multiplications performed on
      each byte (r0, r1, r2, r3) onto a word as well. For instance, we
      could map 2*r0,1*r0,1*r0,3*r0 onto a word by storing 2*r0 in the
      highest 8 bits and 3*r0 in the lowest 8 bits (with the other two
      respectively in the middle). This means that a table can be
      constructed that uses r0 as an index to the word. We can do the
      same with r1, r2, and r3, creating a total of 4 tables.

      To construct a full c', we can just look up each byte of c in
      their respective tables and XOR the results together.

      Also, to build each table we only have to calculate the word
      for 2,1,1,3 for every byte ... which we can do on each iteration
      of this loop since we will iterate over every byte. After we have
      calculated 2,1,1,3 we can get the results for the other tables
      by cycling the byte at the end to the beginning. For instance
      we can take the result of table 2,1,1,3 and produce table 3,2,1,1
      by moving the right most byte to the left most position just like
      how you can imagine the 3 moved out of 2,1,1,3 and to the front
      to produce 3,2,1,1.

      There is another optimization in that the same multiples of
      the current element we need in order to advance our generator
      to the next iteration can be reused in performing the 2,1,1,3
      calculation. We also calculate the inverse mix column tables,
      with e,9,d,b being the inverse of 2,1,1,3.

      When we're done, and we need to actually mix columns, the first
      byte of each state word should be put through mix[0] (2,1,1,3),
      the second through mix[1] (3,2,1,1) and so forth. Then they should
      be XOR'd together to produce the fully mixed column.
    */

    // calculate mix and imix table values
    sx2 = xtime[sx];
    e2 = xtime[e];
    e4 = xtime[e2];
    e8 = xtime[e4];
    me =
      (sx2 << 24) ^  // 2
      (sx << 16) ^   // 1
      (sx << 8) ^    // 1
      (sx ^ sx2);    // 3
    ime =
      (e2 ^ e4 ^ e8) << 24 ^  // E (14)
      (e ^ e8) << 16 ^        // 9
      (e ^ e4 ^ e8) << 8 ^    // D (13)
      (e ^ e2 ^ e8);          // B (11)
    // produce each of the mix tables by rotating the 2,1,1,3 value
    for(var n = 0; n < 4; ++n) {
      mix[n][e] = me;
      imix[n][sx] = ime;
      // cycle the right most byte to the left most position
      // ie: 2,1,1,3 becomes 3,2,1,1
      me = me << 24 | me >>> 8;
      ime = ime << 24 | ime >>> 8;
    }

    // get next element and inverse
    if(e === 0) {
      // 1 is the inverse of 1
      e = ei = 1;
    } else {
      // e = 2e + 2*2*2*(10e)) = multiply e by 82 (chosen generator)
      // ei = ei + 2*2*ei = multiply ei by 5 (inverse generator)
      e = e2 ^ xtime[xtime[xtime[e2 ^ e8]]];
      ei ^= xtime[xtime[ei]];
    }
  }
}

/**
 * Generates a key schedule using the AES key expansion algorithm.
 *
 * The AES algorithm takes the Cipher Key, K, and performs a Key Expansion
 * routine to generate a key schedule. The Key Expansion generates a total
 * of Nb*(Nr + 1) words: the algorithm requires an initial set of Nb words,
 * and each of the Nr rounds requires Nb words of key data. The resulting
 * key schedule consists of a linear array of 4-byte words, denoted [wi ],
 * with i in the range 0 <= i < Nb(Nr + 1).
 *
 * KeyExpansion(byte key[4*Nk], word w[Nb*(Nr+1)], Nk)
 * AES-128 (Nb=4, Nk=4, Nr=10)
 * AES-192 (Nb=4, Nk=6, Nr=12)
 * AES-256 (Nb=4, Nk=8, Nr=14)
 * Note: Nr=Nk+6.
 *
 * Nb is the number of columns (32-bit words) comprising the State (or
 * number of bytes in a block). For AES, Nb=4.
 *
 * @param key the key to schedule (as an array of 32-bit words).
 * @param decrypt true to modify the key schedule to decrypt, false not to.
 *
 * @return the generated key schedule.
 */
function _expandKey(key, decrypt) {
  // copy the key's words to initialize the key schedule
  var w = key.slice(0);

  /* RotWord() will rotate a word, moving the first byte to the last
    byte's position (shifting the other bytes left).

    We will be getting the value of Rcon at i / Nk. 'i' will iterate
    from Nk to (Nb * Nr+1). Nk = 4 (4 byte key), Nb = 4 (4 words in
    a block), Nr = Nk + 6 (10). Therefore 'i' will iterate from
    4 to 44 (exclusive). Each time we iterate 4 times, i / Nk will
    increase by 1. We use a counter iNk to keep track of this.
   */

  // go through the rounds expanding the key
  var temp, iNk = 1;
  var Nk = w.length;
  var Nr1 = Nk + 6 + 1;
  var end = Nb * Nr1;
  for(var i = Nk; i < end; ++i) {
    temp = w[i - 1];
    if(i % Nk === 0) {
      // temp = SubWord(RotWord(temp)) ^ Rcon[i / Nk]
      temp =
        sbox[temp >>> 16 & 255] << 24 ^
        sbox[temp >>> 8 & 255] << 16 ^
        sbox[temp & 255] << 8 ^
        sbox[temp >>> 24] ^ (rcon[iNk] << 24);
      iNk++;
    } else if(Nk > 6 && (i % Nk === 4)) {
      // temp = SubWord(temp)
      temp =
        sbox[temp >>> 24] << 24 ^
        sbox[temp >>> 16 & 255] << 16 ^
        sbox[temp >>> 8 & 255] << 8 ^
        sbox[temp & 255];
    }
    w[i] = w[i - Nk] ^ temp;
  }

  /* When we are updating a cipher block we always use the code path for
     encryption whether we are decrypting or not (to shorten code and
     simplify the generation of look up tables). However, because there
     are differences in the decryption algorithm, other than just swapping
     in different look up tables, we must transform our key schedule to
     account for these changes:

     1. The decryption algorithm gets its key rounds in reverse order.
     2. The decryption algorithm adds the round key before mixing columns
       instead of afterwards.

     We don't need to modify our key schedule to handle the first case,
     we can just traverse the key schedule in reverse order when decrypting.

     The second case requires a little work.

     The tables we built for performing rounds will take an input and then
     perform SubBytes() and MixColumns() or, for the decrypt version,
     InvSubBytes() and InvMixColumns(). But the decrypt algorithm requires
     us to AddRoundKey() before InvMixColumns(). This means we'll need to
     apply some transformations to the round key to inverse-mix its columns
     so they'll be correct for moving AddRoundKey() to after the state has
     had its columns inverse-mixed.

     To inverse-mix the columns of the state when we're decrypting we use a
     lookup table that will apply InvSubBytes() and InvMixColumns() at the
     same time. However, the round key's bytes are not inverse-substituted
     in the decryption algorithm. To get around this problem, we can first
     substitute the bytes in the round key so that when we apply the
     transformation via the InvSubBytes()+InvMixColumns() table, it will
     undo our substitution leaving us with the original value that we
     want -- and then inverse-mix that value.

     This change will correctly alter our key schedule so that we can XOR
     each round key with our already transformed decryption state. This
     allows us to use the same code path as the encryption algorithm.

     We make one more change to the decryption key. Since the decryption
     algorithm runs in reverse from the encryption algorithm, we reverse
     the order of the round keys to avoid having to iterate over the key
     schedule backwards when running the encryption algorithm later in
     decryption mode. In addition to reversing the order of the round keys,
     we also swap each round key's 2nd and 4th rows. See the comments
     section where rounds are performed for more details about why this is
     done. These changes are done inline with the other substitution
     described above.
  */
  if(decrypt) {
    var tmp;
    var m0 = imix[0];
    var m1 = imix[1];
    var m2 = imix[2];
    var m3 = imix[3];
    var wnew = w.slice(0);
    end = w.length;
    for(var i = 0, wi = end - Nb; i < end; i += Nb, wi -= Nb) {
      // do not sub the first or last round key (round keys are Nb
      // words) as no column mixing is performed before they are added,
      // but do change the key order
      if(i === 0 || i === (end - Nb)) {
        wnew[i] = w[wi];
        wnew[i + 1] = w[wi + 3];
        wnew[i + 2] = w[wi + 2];
        wnew[i + 3] = w[wi + 1];
      } else {
        // substitute each round key byte because the inverse-mix
        // table will inverse-substitute it (effectively cancel the
        // substitution because round key bytes aren't sub'd in
        // decryption mode) and swap indexes 3 and 1
        for(var n = 0; n < Nb; ++n) {
          tmp = w[wi + n];
          wnew[i + (3&-n)] =
            m0[sbox[tmp >>> 24]] ^
            m1[sbox[tmp >>> 16 & 255]] ^
            m2[sbox[tmp >>> 8 & 255]] ^
            m3[sbox[tmp & 255]];
        }
      }
    }
    w = wnew;
  }

  return w;
}

/**
 * Updates a single block (16 bytes) using AES. The update will either
 * encrypt or decrypt the block.
 *
 * @param w the key schedule.
 * @param input the input block (an array of 32-bit words).
 * @param output the updated output block.
 * @param decrypt true to decrypt the block, false to encrypt it.
 */
function _updateBlock$1(w, input, output, decrypt) {
  /*
  Cipher(byte in[4*Nb], byte out[4*Nb], word w[Nb*(Nr+1)])
  begin
    byte state[4,Nb]
    state = in
    AddRoundKey(state, w[0, Nb-1])
    for round = 1 step 1 to Nr-1
      SubBytes(state)
      ShiftRows(state)
      MixColumns(state)
      AddRoundKey(state, w[round*Nb, (round+1)*Nb-1])
    end for
    SubBytes(state)
    ShiftRows(state)
    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])
    out = state
  end

  InvCipher(byte in[4*Nb], byte out[4*Nb], word w[Nb*(Nr+1)])
  begin
    byte state[4,Nb]
    state = in
    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])
    for round = Nr-1 step -1 downto 1
      InvShiftRows(state)
      InvSubBytes(state)
      AddRoundKey(state, w[round*Nb, (round+1)*Nb-1])
      InvMixColumns(state)
    end for
    InvShiftRows(state)
    InvSubBytes(state)
    AddRoundKey(state, w[0, Nb-1])
    out = state
  end
  */

  // Encrypt: AddRoundKey(state, w[0, Nb-1])
  // Decrypt: AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])
  var Nr = w.length / 4 - 1;
  var m0, m1, m2, m3, sub;
  if(decrypt) {
    m0 = imix[0];
    m1 = imix[1];
    m2 = imix[2];
    m3 = imix[3];
    sub = isbox;
  } else {
    m0 = mix[0];
    m1 = mix[1];
    m2 = mix[2];
    m3 = mix[3];
    sub = sbox;
  }
  var a, b, c, d, a2, b2, c2;
  a = input[0] ^ w[0];
  b = input[decrypt ? 3 : 1] ^ w[1];
  c = input[2] ^ w[2];
  d = input[decrypt ? 1 : 3] ^ w[3];
  var i = 3;

  /* In order to share code we follow the encryption algorithm when both
    encrypting and decrypting. To account for the changes required in the
    decryption algorithm, we use different lookup tables when decrypting
    and use a modified key schedule to account for the difference in the
    order of transformations applied when performing rounds. We also get
    key rounds in reverse order (relative to encryption). */
  for(var round = 1; round < Nr; ++round) {
    /* As described above, we'll be using table lookups to perform the
      column mixing. Each column is stored as a word in the state (the
      array 'input' has one column as a word at each index). In order to
      mix a column, we perform these transformations on each row in c,
      which is 1 byte in each word. The new column for c0 is c'0:

               m0      m1      m2      m3
      r0,c'0 = 2*r0,c0 + 3*r1,c0 + 1*r2,c0 + 1*r3,c0
      r1,c'0 = 1*r0,c0 + 2*r1,c0 + 3*r2,c0 + 1*r3,c0
      r2,c'0 = 1*r0,c0 + 1*r1,c0 + 2*r2,c0 + 3*r3,c0
      r3,c'0 = 3*r0,c0 + 1*r1,c0 + 1*r2,c0 + 2*r3,c0

      So using mix tables where c0 is a word with r0 being its upper
      8 bits and r3 being its lower 8 bits:

      m0[c0 >> 24] will yield this word: [2*r0,1*r0,1*r0,3*r0]
      ...
      m3[c0 & 255] will yield this word: [1*r3,1*r3,3*r3,2*r3]

      Therefore to mix the columns in each word in the state we
      do the following (& 255 omitted for brevity):
      c'0,r0 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]
      c'0,r1 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]
      c'0,r2 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]
      c'0,r3 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]

      However, before mixing, the algorithm requires us to perform
      ShiftRows(). The ShiftRows() transformation cyclically shifts the
      last 3 rows of the state over different offsets. The first row
      (r = 0) is not shifted.

      s'_r,c = s_r,(c + shift(r, Nb) mod Nb
      for 0 < r < 4 and 0 <= c < Nb and
      shift(1, 4) = 1
      shift(2, 4) = 2
      shift(3, 4) = 3.

      This causes the first byte in r = 1 to be moved to the end of
      the row, the first 2 bytes in r = 2 to be moved to the end of
      the row, the first 3 bytes in r = 3 to be moved to the end of
      the row:

      r1: [c0 c1 c2 c3] => [c1 c2 c3 c0]
      r2: [c0 c1 c2 c3]    [c2 c3 c0 c1]
      r3: [c0 c1 c2 c3]    [c3 c0 c1 c2]

      We can make these substitutions inline with our column mixing to
      generate an updated set of equations to produce each word in the
      state (note the columns have changed positions):

      c0 c1 c2 c3 => c0 c1 c2 c3
      c0 c1 c2 c3    c1 c2 c3 c0  (cycled 1 byte)
      c0 c1 c2 c3    c2 c3 c0 c1  (cycled 2 bytes)
      c0 c1 c2 c3    c3 c0 c1 c2  (cycled 3 bytes)

      Therefore:

      c'0 = 2*r0,c0 + 3*r1,c1 + 1*r2,c2 + 1*r3,c3
      c'0 = 1*r0,c0 + 2*r1,c1 + 3*r2,c2 + 1*r3,c3
      c'0 = 1*r0,c0 + 1*r1,c1 + 2*r2,c2 + 3*r3,c3
      c'0 = 3*r0,c0 + 1*r1,c1 + 1*r2,c2 + 2*r3,c3

      c'1 = 2*r0,c1 + 3*r1,c2 + 1*r2,c3 + 1*r3,c0
      c'1 = 1*r0,c1 + 2*r1,c2 + 3*r2,c3 + 1*r3,c0
      c'1 = 1*r0,c1 + 1*r1,c2 + 2*r2,c3 + 3*r3,c0
      c'1 = 3*r0,c1 + 1*r1,c2 + 1*r2,c3 + 2*r3,c0

      ... and so forth for c'2 and c'3. The important distinction is
      that the columns are cycling, with c0 being used with the m0
      map when calculating c0, but c1 being used with the m0 map when
      calculating c1 ... and so forth.

      When performing the inverse we transform the mirror image and
      skip the bottom row, instead of the top one, and move upwards:

      c3 c2 c1 c0 => c0 c3 c2 c1  (cycled 3 bytes) *same as encryption
      c3 c2 c1 c0    c1 c0 c3 c2  (cycled 2 bytes)
      c3 c2 c1 c0    c2 c1 c0 c3  (cycled 1 byte)  *same as encryption
      c3 c2 c1 c0    c3 c2 c1 c0

      If you compare the resulting matrices for ShiftRows()+MixColumns()
      and for InvShiftRows()+InvMixColumns() the 2nd and 4th columns are
      different (in encrypt mode vs. decrypt mode). So in order to use
      the same code to handle both encryption and decryption, we will
      need to do some mapping.

      If in encryption mode we let a=c0, b=c1, c=c2, d=c3, and r<N> be
      a row number in the state, then the resulting matrix in encryption
      mode for applying the above transformations would be:

      r1: a b c d
      r2: b c d a
      r3: c d a b
      r4: d a b c

      If we did the same in decryption mode we would get:

      r1: a d c b
      r2: b a d c
      r3: c b a d
      r4: d c b a

      If instead we swap d and b (set b=c3 and d=c1), then we get:

      r1: a b c d
      r2: d a b c
      r3: c d a b
      r4: b c d a

      Now the 1st and 3rd rows are the same as the encryption matrix. All
      we need to do then to make the mapping exactly the same is to swap
      the 2nd and 4th rows when in decryption mode. To do this without
      having to do it on each iteration, we swapped the 2nd and 4th rows
      in the decryption key schedule. We also have to do the swap above
      when we first pull in the input and when we set the final output. */
    a2 =
      m0[a >>> 24] ^
      m1[b >>> 16 & 255] ^
      m2[c >>> 8 & 255] ^
      m3[d & 255] ^ w[++i];
    b2 =
      m0[b >>> 24] ^
      m1[c >>> 16 & 255] ^
      m2[d >>> 8 & 255] ^
      m3[a & 255] ^ w[++i];
    c2 =
      m0[c >>> 24] ^
      m1[d >>> 16 & 255] ^
      m2[a >>> 8 & 255] ^
      m3[b & 255] ^ w[++i];
    d =
      m0[d >>> 24] ^
      m1[a >>> 16 & 255] ^
      m2[b >>> 8 & 255] ^
      m3[c & 255] ^ w[++i];
    a = a2;
    b = b2;
    c = c2;
  }

  /*
    Encrypt:
    SubBytes(state)
    ShiftRows(state)
    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])

    Decrypt:
    InvShiftRows(state)
    InvSubBytes(state)
    AddRoundKey(state, w[0, Nb-1])
   */
  // Note: rows are shifted inline
  output[0] =
    (sub[a >>> 24] << 24) ^
    (sub[b >>> 16 & 255] << 16) ^
    (sub[c >>> 8 & 255] << 8) ^
    (sub[d & 255]) ^ w[++i];
  output[decrypt ? 3 : 1] =
    (sub[b >>> 24] << 24) ^
    (sub[c >>> 16 & 255] << 16) ^
    (sub[d >>> 8 & 255] << 8) ^
    (sub[a & 255]) ^ w[++i];
  output[2] =
    (sub[c >>> 24] << 24) ^
    (sub[d >>> 16 & 255] << 16) ^
    (sub[a >>> 8 & 255] << 8) ^
    (sub[b & 255]) ^ w[++i];
  output[decrypt ? 1 : 3] =
    (sub[d >>> 24] << 24) ^
    (sub[a >>> 16 & 255] << 16) ^
    (sub[b >>> 8 & 255] << 8) ^
    (sub[c & 255]) ^ w[++i];
}

/**
 * Deprecated. Instead, use:
 *
 * forge.cipher.createCipher('AES-<mode>', key);
 * forge.cipher.createDecipher('AES-<mode>', key);
 *
 * Creates a deprecated AES cipher object. This object's mode will default to
 * CBC (cipher-block-chaining).
 *
 * The key and iv may be given as a string of bytes, an array of bytes, a
 * byte buffer, or an array of 32-bit words.
 *
 * @param options the options to use.
 *          key the symmetric key to use.
 *          output the buffer to write to.
 *          decrypt true for decryption, false for encryption.
 *          mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
function _createCipher$1(options) {
  options = options || {};
  var mode = (options.mode || 'CBC').toUpperCase();
  var algorithm = 'AES-' + mode;

  var cipher;
  if(options.decrypt) {
    cipher = forge$m.cipher.createDecipher(algorithm, options.key);
  } else {
    cipher = forge$m.cipher.createCipher(algorithm, options.key);
  }

  // backwards compatible start API
  var start = cipher.start;
  cipher.start = function(iv, options) {
    // backwards compatibility: support second arg as output buffer
    var output = null;
    if(options instanceof forge$m.util.ByteBuffer) {
      output = options;
      options = {};
    }
    options = options || {};
    options.output = output;
    options.iv = iv;
    start.call(cipher, options);
  };

  return cipher;
}

/**
 * DES (Data Encryption Standard) implementation.
 *
 * This implementation supports DES as well as 3DES-EDE in ECB and CBC mode.
 * It is based on the BSD-licensed implementation by Paul Tero:
 *
 * Paul Tero, July 2001
 * http://www.tero.co.uk/des/
 *
 * Optimised for performance with large blocks by
 * Michael Hayworth, November 2001
 * http://www.netdealing.com
 *
 * THIS SOFTWARE IS PROVIDED "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * @author Stefan Siegl
 * @author Dave Longley
 *
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 * Copyright (c) 2012-2014 Digital Bazaar, Inc.
 */

var forge$l = forge$s;




/* DES API */
forge$l.des = forge$l.des || {};

/**
 * Deprecated. Instead, use:
 *
 * var cipher = forge.cipher.createCipher('DES-<mode>', key);
 * cipher.start({iv: iv});
 *
 * Creates an DES cipher object to encrypt data using the given symmetric key.
 * The output will be stored in the 'output' member of the returned cipher.
 *
 * The key and iv may be given as binary-encoded strings of bytes or
 * byte buffers.
 *
 * @param key the symmetric key to use (64 or 192 bits).
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 * @param mode the cipher mode to use (default: 'CBC' if IV is
 *          given, 'ECB' if null).
 *
 * @return the cipher.
 */
forge$l.des.startEncrypting = function(key, iv, output, mode) {
  var cipher = _createCipher({
    key: key,
    output: output,
    decrypt: false,
    mode: mode || (iv === null ? 'ECB' : 'CBC')
  });
  cipher.start(iv);
  return cipher;
};

/**
 * Deprecated. Instead, use:
 *
 * var cipher = forge.cipher.createCipher('DES-<mode>', key);
 *
 * Creates an DES cipher object to encrypt data using the given symmetric key.
 *
 * The key may be given as a binary-encoded string of bytes or a byte buffer.
 *
 * @param key the symmetric key to use (64 or 192 bits).
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$l.des.createEncryptionCipher = function(key, mode) {
  return _createCipher({
    key: key,
    output: null,
    decrypt: false,
    mode: mode
  });
};

/**
 * Deprecated. Instead, use:
 *
 * var decipher = forge.cipher.createDecipher('DES-<mode>', key);
 * decipher.start({iv: iv});
 *
 * Creates an DES cipher object to decrypt data using the given symmetric key.
 * The output will be stored in the 'output' member of the returned cipher.
 *
 * The key and iv may be given as binary-encoded strings of bytes or
 * byte buffers.
 *
 * @param key the symmetric key to use (64 or 192 bits).
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 * @param mode the cipher mode to use (default: 'CBC' if IV is
 *          given, 'ECB' if null).
 *
 * @return the cipher.
 */
forge$l.des.startDecrypting = function(key, iv, output, mode) {
  var cipher = _createCipher({
    key: key,
    output: output,
    decrypt: true,
    mode: mode || (iv === null ? 'ECB' : 'CBC')
  });
  cipher.start(iv);
  return cipher;
};

/**
 * Deprecated. Instead, use:
 *
 * var decipher = forge.cipher.createDecipher('DES-<mode>', key);
 *
 * Creates an DES cipher object to decrypt data using the given symmetric key.
 *
 * The key may be given as a binary-encoded string of bytes or a byte buffer.
 *
 * @param key the symmetric key to use (64 or 192 bits).
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$l.des.createDecryptionCipher = function(key, mode) {
  return _createCipher({
    key: key,
    output: null,
    decrypt: true,
    mode: mode
  });
};

/**
 * Creates a new DES cipher algorithm object.
 *
 * @param name the name of the algorithm.
 * @param mode the mode factory function.
 *
 * @return the DES algorithm object.
 */
forge$l.des.Algorithm = function(name, mode) {
  var self = this;
  self.name = name;
  self.mode = new mode({
    blockSize: 8,
    cipher: {
      encrypt: function(inBlock, outBlock) {
        return _updateBlock(self._keys, inBlock, outBlock, false);
      },
      decrypt: function(inBlock, outBlock) {
        return _updateBlock(self._keys, inBlock, outBlock, true);
      }
    }
  });
  self._init = false;
};

/**
 * Initializes this DES algorithm by expanding its key.
 *
 * @param options the options to use.
 *          key the key to use with this algorithm.
 *          decrypt true if the algorithm should be initialized for decryption,
 *            false for encryption.
 */
forge$l.des.Algorithm.prototype.initialize = function(options) {
  if(this._init) {
    return;
  }

  var key = forge$l.util.createBuffer(options.key);
  if(this.name.indexOf('3DES') === 0) {
    if(key.length() !== 24) {
      throw new Error('Invalid Triple-DES key size: ' + key.length() * 8);
    }
  }

  // do key expansion to 16 or 48 subkeys (single or triple DES)
  this._keys = _createKeys(key);
  this._init = true;
};

/** Register DES algorithms **/

registerAlgorithm('DES-ECB', forge$l.cipher.modes.ecb);
registerAlgorithm('DES-CBC', forge$l.cipher.modes.cbc);
registerAlgorithm('DES-CFB', forge$l.cipher.modes.cfb);
registerAlgorithm('DES-OFB', forge$l.cipher.modes.ofb);
registerAlgorithm('DES-CTR', forge$l.cipher.modes.ctr);

registerAlgorithm('3DES-ECB', forge$l.cipher.modes.ecb);
registerAlgorithm('3DES-CBC', forge$l.cipher.modes.cbc);
registerAlgorithm('3DES-CFB', forge$l.cipher.modes.cfb);
registerAlgorithm('3DES-OFB', forge$l.cipher.modes.ofb);
registerAlgorithm('3DES-CTR', forge$l.cipher.modes.ctr);

function registerAlgorithm(name, mode) {
  var factory = function() {
    return new forge$l.des.Algorithm(name, mode);
  };
  forge$l.cipher.registerAlgorithm(name, factory);
}

/** DES implementation **/

var spfunction1 = [0x1010400,0,0x10000,0x1010404,0x1010004,0x10404,0x4,0x10000,0x400,0x1010400,0x1010404,0x400,0x1000404,0x1010004,0x1000000,0x4,0x404,0x1000400,0x1000400,0x10400,0x10400,0x1010000,0x1010000,0x1000404,0x10004,0x1000004,0x1000004,0x10004,0,0x404,0x10404,0x1000000,0x10000,0x1010404,0x4,0x1010000,0x1010400,0x1000000,0x1000000,0x400,0x1010004,0x10000,0x10400,0x1000004,0x400,0x4,0x1000404,0x10404,0x1010404,0x10004,0x1010000,0x1000404,0x1000004,0x404,0x10404,0x1010400,0x404,0x1000400,0x1000400,0,0x10004,0x10400,0,0x1010004];
var spfunction2 = [-0x7fef7fe0,-0x7fff8000,0x8000,0x108020,0x100000,0x20,-0x7fefffe0,-0x7fff7fe0,-0x7fffffe0,-0x7fef7fe0,-0x7fef8000,-0x80000000,-0x7fff8000,0x100000,0x20,-0x7fefffe0,0x108000,0x100020,-0x7fff7fe0,0,-0x80000000,0x8000,0x108020,-0x7ff00000,0x100020,-0x7fffffe0,0,0x108000,0x8020,-0x7fef8000,-0x7ff00000,0x8020,0,0x108020,-0x7fefffe0,0x100000,-0x7fff7fe0,-0x7ff00000,-0x7fef8000,0x8000,-0x7ff00000,-0x7fff8000,0x20,-0x7fef7fe0,0x108020,0x20,0x8000,-0x80000000,0x8020,-0x7fef8000,0x100000,-0x7fffffe0,0x100020,-0x7fff7fe0,-0x7fffffe0,0x100020,0x108000,0,-0x7fff8000,0x8020,-0x80000000,-0x7fefffe0,-0x7fef7fe0,0x108000];
var spfunction3 = [0x208,0x8020200,0,0x8020008,0x8000200,0,0x20208,0x8000200,0x20008,0x8000008,0x8000008,0x20000,0x8020208,0x20008,0x8020000,0x208,0x8000000,0x8,0x8020200,0x200,0x20200,0x8020000,0x8020008,0x20208,0x8000208,0x20200,0x20000,0x8000208,0x8,0x8020208,0x200,0x8000000,0x8020200,0x8000000,0x20008,0x208,0x20000,0x8020200,0x8000200,0,0x200,0x20008,0x8020208,0x8000200,0x8000008,0x200,0,0x8020008,0x8000208,0x20000,0x8000000,0x8020208,0x8,0x20208,0x20200,0x8000008,0x8020000,0x8000208,0x208,0x8020000,0x20208,0x8,0x8020008,0x20200];
var spfunction4 = [0x802001,0x2081,0x2081,0x80,0x802080,0x800081,0x800001,0x2001,0,0x802000,0x802000,0x802081,0x81,0,0x800080,0x800001,0x1,0x2000,0x800000,0x802001,0x80,0x800000,0x2001,0x2080,0x800081,0x1,0x2080,0x800080,0x2000,0x802080,0x802081,0x81,0x800080,0x800001,0x802000,0x802081,0x81,0,0,0x802000,0x2080,0x800080,0x800081,0x1,0x802001,0x2081,0x2081,0x80,0x802081,0x81,0x1,0x2000,0x800001,0x2001,0x802080,0x800081,0x2001,0x2080,0x800000,0x802001,0x80,0x800000,0x2000,0x802080];
var spfunction5 = [0x100,0x2080100,0x2080000,0x42000100,0x80000,0x100,0x40000000,0x2080000,0x40080100,0x80000,0x2000100,0x40080100,0x42000100,0x42080000,0x80100,0x40000000,0x2000000,0x40080000,0x40080000,0,0x40000100,0x42080100,0x42080100,0x2000100,0x42080000,0x40000100,0,0x42000000,0x2080100,0x2000000,0x42000000,0x80100,0x80000,0x42000100,0x100,0x2000000,0x40000000,0x2080000,0x42000100,0x40080100,0x2000100,0x40000000,0x42080000,0x2080100,0x40080100,0x100,0x2000000,0x42080000,0x42080100,0x80100,0x42000000,0x42080100,0x2080000,0,0x40080000,0x42000000,0x80100,0x2000100,0x40000100,0x80000,0,0x40080000,0x2080100,0x40000100];
var spfunction6 = [0x20000010,0x20400000,0x4000,0x20404010,0x20400000,0x10,0x20404010,0x400000,0x20004000,0x404010,0x400000,0x20000010,0x400010,0x20004000,0x20000000,0x4010,0,0x400010,0x20004010,0x4000,0x404000,0x20004010,0x10,0x20400010,0x20400010,0,0x404010,0x20404000,0x4010,0x404000,0x20404000,0x20000000,0x20004000,0x10,0x20400010,0x404000,0x20404010,0x400000,0x4010,0x20000010,0x400000,0x20004000,0x20000000,0x4010,0x20000010,0x20404010,0x404000,0x20400000,0x404010,0x20404000,0,0x20400010,0x10,0x4000,0x20400000,0x404010,0x4000,0x400010,0x20004010,0,0x20404000,0x20000000,0x400010,0x20004010];
var spfunction7 = [0x200000,0x4200002,0x4000802,0,0x800,0x4000802,0x200802,0x4200800,0x4200802,0x200000,0,0x4000002,0x2,0x4000000,0x4200002,0x802,0x4000800,0x200802,0x200002,0x4000800,0x4000002,0x4200000,0x4200800,0x200002,0x4200000,0x800,0x802,0x4200802,0x200800,0x2,0x4000000,0x200800,0x4000000,0x200800,0x200000,0x4000802,0x4000802,0x4200002,0x4200002,0x2,0x200002,0x4000000,0x4000800,0x200000,0x4200800,0x802,0x200802,0x4200800,0x802,0x4000002,0x4200802,0x4200000,0x200800,0,0x2,0x4200802,0,0x200802,0x4200000,0x800,0x4000002,0x4000800,0x800,0x200002];
var spfunction8 = [0x10001040,0x1000,0x40000,0x10041040,0x10000000,0x10001040,0x40,0x10000000,0x40040,0x10040000,0x10041040,0x41000,0x10041000,0x41040,0x1000,0x40,0x10040000,0x10000040,0x10001000,0x1040,0x41000,0x40040,0x10040040,0x10041000,0x1040,0,0,0x10040040,0x10000040,0x10001000,0x41040,0x40000,0x41040,0x40000,0x10041000,0x1000,0x40,0x10040040,0x1000,0x41040,0x10001000,0x40,0x10000040,0x10040000,0x10040040,0x10000000,0x40000,0x10001040,0,0x10041040,0x40040,0x10000040,0x10040000,0x10001000,0x10001040,0,0x10041040,0x41000,0x41000,0x1040,0x1040,0x40040,0x10000000,0x10041000];

/**
 * Create necessary sub keys.
 *
 * @param key the 64-bit or 192-bit key.
 *
 * @return the expanded keys.
 */
function _createKeys(key) {
  var pc2bytes0  = [0,0x4,0x20000000,0x20000004,0x10000,0x10004,0x20010000,0x20010004,0x200,0x204,0x20000200,0x20000204,0x10200,0x10204,0x20010200,0x20010204],
      pc2bytes1  = [0,0x1,0x100000,0x100001,0x4000000,0x4000001,0x4100000,0x4100001,0x100,0x101,0x100100,0x100101,0x4000100,0x4000101,0x4100100,0x4100101],
      pc2bytes2  = [0,0x8,0x800,0x808,0x1000000,0x1000008,0x1000800,0x1000808,0,0x8,0x800,0x808,0x1000000,0x1000008,0x1000800,0x1000808],
      pc2bytes3  = [0,0x200000,0x8000000,0x8200000,0x2000,0x202000,0x8002000,0x8202000,0x20000,0x220000,0x8020000,0x8220000,0x22000,0x222000,0x8022000,0x8222000],
      pc2bytes4  = [0,0x40000,0x10,0x40010,0,0x40000,0x10,0x40010,0x1000,0x41000,0x1010,0x41010,0x1000,0x41000,0x1010,0x41010],
      pc2bytes5  = [0,0x400,0x20,0x420,0,0x400,0x20,0x420,0x2000000,0x2000400,0x2000020,0x2000420,0x2000000,0x2000400,0x2000020,0x2000420],
      pc2bytes6  = [0,0x10000000,0x80000,0x10080000,0x2,0x10000002,0x80002,0x10080002,0,0x10000000,0x80000,0x10080000,0x2,0x10000002,0x80002,0x10080002],
      pc2bytes7  = [0,0x10000,0x800,0x10800,0x20000000,0x20010000,0x20000800,0x20010800,0x20000,0x30000,0x20800,0x30800,0x20020000,0x20030000,0x20020800,0x20030800],
      pc2bytes8  = [0,0x40000,0,0x40000,0x2,0x40002,0x2,0x40002,0x2000000,0x2040000,0x2000000,0x2040000,0x2000002,0x2040002,0x2000002,0x2040002],
      pc2bytes9  = [0,0x10000000,0x8,0x10000008,0,0x10000000,0x8,0x10000008,0x400,0x10000400,0x408,0x10000408,0x400,0x10000400,0x408,0x10000408],
      pc2bytes10 = [0,0x20,0,0x20,0x100000,0x100020,0x100000,0x100020,0x2000,0x2020,0x2000,0x2020,0x102000,0x102020,0x102000,0x102020],
      pc2bytes11 = [0,0x1000000,0x200,0x1000200,0x200000,0x1200000,0x200200,0x1200200,0x4000000,0x5000000,0x4000200,0x5000200,0x4200000,0x5200000,0x4200200,0x5200200],
      pc2bytes12 = [0,0x1000,0x8000000,0x8001000,0x80000,0x81000,0x8080000,0x8081000,0x10,0x1010,0x8000010,0x8001010,0x80010,0x81010,0x8080010,0x8081010],
      pc2bytes13 = [0,0x4,0x100,0x104,0,0x4,0x100,0x104,0x1,0x5,0x101,0x105,0x1,0x5,0x101,0x105];

  // how many iterations (1 for des, 3 for triple des)
  // changed by Paul 16/6/2007 to use Triple DES for 9+ byte keys
  var iterations = key.length() > 8 ? 3 : 1;

  // stores the return keys
  var keys = [];

  // now define the left shifts which need to be done
  var shifts = [0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0];

  var n = 0, tmp;
  for(var j = 0; j < iterations; j++) {
    var left = key.getInt32();
    var right = key.getInt32();

    tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;
    right ^= tmp;
    left ^= (tmp << 4);

    tmp = ((right >>> -16) ^ left) & 0x0000ffff;
    left ^= tmp;
    right ^= (tmp << -16);

    tmp = ((left >>> 2) ^ right) & 0x33333333;
    right ^= tmp;
    left ^= (tmp << 2);

    tmp = ((right >>> -16) ^ left) & 0x0000ffff;
    left ^= tmp;
    right ^= (tmp << -16);

    tmp = ((left >>> 1) ^ right) & 0x55555555;
    right ^= tmp;
    left ^= (tmp << 1);

    tmp = ((right >>> 8) ^ left) & 0x00ff00ff;
    left ^= tmp;
    right ^= (tmp << 8);

    tmp = ((left >>> 1) ^ right) & 0x55555555;
    right ^= tmp;
    left ^= (tmp << 1);

    // right needs to be shifted and OR'd with last four bits of left
    tmp = (left << 8) | ((right >>> 20) & 0x000000f0);

    // left needs to be put upside down
    left = ((right << 24) | ((right << 8) & 0xff0000) |
      ((right >>> 8) & 0xff00) | ((right >>> 24) & 0xf0));
    right = tmp;

    // now go through and perform these shifts on the left and right keys
    for(var i = 0; i < shifts.length; ++i) {
      //shift the keys either one or two bits to the left
      if(shifts[i]) {
        left = (left << 2) | (left >>> 26);
        right = (right << 2) | (right >>> 26);
      } else {
        left = (left << 1) | (left >>> 27);
        right = (right << 1) | (right >>> 27);
      }
      left &= -0xf;
      right &= -0xf;

      // now apply PC-2, in such a way that E is easier when encrypting or
      // decrypting this conversion will look like PC-2 except only the last 6
      // bits of each byte are used rather than 48 consecutive bits and the
      // order of lines will be according to how the S selection functions will
      // be applied: S2, S4, S6, S8, S1, S3, S5, S7
      var lefttmp = (
        pc2bytes0[left >>> 28] | pc2bytes1[(left >>> 24) & 0xf] |
        pc2bytes2[(left >>> 20) & 0xf] | pc2bytes3[(left >>> 16) & 0xf] |
        pc2bytes4[(left >>> 12) & 0xf] | pc2bytes5[(left >>> 8) & 0xf] |
        pc2bytes6[(left >>> 4) & 0xf]);
      var righttmp = (
        pc2bytes7[right >>> 28] | pc2bytes8[(right >>> 24) & 0xf] |
        pc2bytes9[(right >>> 20) & 0xf] | pc2bytes10[(right >>> 16) & 0xf] |
        pc2bytes11[(right >>> 12) & 0xf] | pc2bytes12[(right >>> 8) & 0xf] |
        pc2bytes13[(right >>> 4) & 0xf]);
      tmp = ((righttmp >>> 16) ^ lefttmp) & 0x0000ffff;
      keys[n++] = lefttmp ^ tmp;
      keys[n++] = righttmp ^ (tmp << 16);
    }
  }

  return keys;
}

/**
 * Updates a single block (1 byte) using DES. The update will either
 * encrypt or decrypt the block.
 *
 * @param keys the expanded keys.
 * @param input the input block (an array of 32-bit words).
 * @param output the updated output block.
 * @param decrypt true to decrypt the block, false to encrypt it.
 */
function _updateBlock(keys, input, output, decrypt) {
  // set up loops for single or triple DES
  var iterations = keys.length === 32 ? 3 : 9;
  var looping;
  if(iterations === 3) {
    looping = decrypt ? [30, -2, -2] : [0, 32, 2];
  } else {
    looping = (decrypt ?
      [94, 62, -2, 32, 64, 2, 30, -2, -2] :
      [0, 32, 2, 62, 30, -2, 64, 96, 2]);
  }

  var tmp;

  var left = input[0];
  var right = input[1];

  // first each 64 bit chunk of the message must be permuted according to IP
  tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;
  right ^= tmp;
  left ^= (tmp << 4);

  tmp = ((left >>> 16) ^ right) & 0x0000ffff;
  right ^= tmp;
  left ^= (tmp << 16);

  tmp = ((right >>> 2) ^ left) & 0x33333333;
  left ^= tmp;
  right ^= (tmp << 2);

  tmp = ((right >>> 8) ^ left) & 0x00ff00ff;
  left ^= tmp;
  right ^= (tmp << 8);

  tmp = ((left >>> 1) ^ right) & 0x55555555;
  right ^= tmp;
  left ^= (tmp << 1);

  // rotate left 1 bit
  left = ((left << 1) | (left >>> 31));
  right = ((right << 1) | (right >>> 31));

  for(var j = 0; j < iterations; j += 3) {
    var endloop = looping[j + 1];
    var loopinc = looping[j + 2];

    // now go through and perform the encryption or decryption
    for(var i = looping[j]; i != endloop; i += loopinc) {
      var right1 = right ^ keys[i];
      var right2 = ((right >>> 4) | (right << 28)) ^ keys[i + 1];

      // passing these bytes through the S selection functions
      tmp = left;
      left = right;
      right = tmp ^ (
        spfunction2[(right1 >>> 24) & 0x3f] |
        spfunction4[(right1 >>> 16) & 0x3f] |
        spfunction6[(right1 >>>  8) & 0x3f] |
        spfunction8[right1 & 0x3f] |
        spfunction1[(right2 >>> 24) & 0x3f] |
        spfunction3[(right2 >>> 16) & 0x3f] |
        spfunction5[(right2 >>>  8) & 0x3f] |
        spfunction7[right2 & 0x3f]);
    }
    // unreverse left and right
    tmp = left;
    left = right;
    right = tmp;
  }

  // rotate right 1 bit
  left = ((left >>> 1) | (left << 31));
  right = ((right >>> 1) | (right << 31));

  // now perform IP-1, which is IP in the opposite direction
  tmp = ((left >>> 1) ^ right) & 0x55555555;
  right ^= tmp;
  left ^= (tmp << 1);

  tmp = ((right >>> 8) ^ left) & 0x00ff00ff;
  left ^= tmp;
  right ^= (tmp << 8);

  tmp = ((right >>> 2) ^ left) & 0x33333333;
  left ^= tmp;
  right ^= (tmp << 2);

  tmp = ((left >>> 16) ^ right) & 0x0000ffff;
  right ^= tmp;
  left ^= (tmp << 16);

  tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;
  right ^= tmp;
  left ^= (tmp << 4);

  output[0] = left;
  output[1] = right;
}

/**
 * Deprecated. Instead, use:
 *
 * forge.cipher.createCipher('DES-<mode>', key);
 * forge.cipher.createDecipher('DES-<mode>', key);
 *
 * Creates a deprecated DES cipher object. This object's mode will default to
 * CBC (cipher-block-chaining).
 *
 * The key may be given as a binary-encoded string of bytes or a byte buffer.
 *
 * @param options the options to use.
 *          key the symmetric key to use (64 or 192 bits).
 *          output the buffer to write to.
 *          decrypt true for decryption, false for encryption.
 *          mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
function _createCipher(options) {
  options = options || {};
  var mode = (options.mode || 'CBC').toUpperCase();
  var algorithm = 'DES-' + mode;

  var cipher;
  if(options.decrypt) {
    cipher = forge$l.cipher.createDecipher(algorithm, options.key);
  } else {
    cipher = forge$l.cipher.createCipher(algorithm, options.key);
  }

  // backwards compatible start API
  var start = cipher.start;
  cipher.start = function(iv, options) {
    // backwards compatibility: support second arg as output buffer
    var output = null;
    if(options instanceof forge$l.util.ByteBuffer) {
      output = options;
      options = {};
    }
    options = options || {};
    options.output = output;
    options.iv = iv;
    start.call(cipher, options);
  };

  return cipher;
}

/**
 * Node.js module for Forge message digests.
 *
 * @author Dave Longley
 *
 * Copyright 2011-2017 Digital Bazaar, Inc.
 */

var forge$k = forge$s;

forge$k.md = forge$k.md || {};
forge$k.md.algorithms = forge$k.md.algorithms || {};

/**
 * Hash-based Message Authentication Code implementation. Requires a message
 * digest object that can be obtained, for example, from forge.md.sha1 or
 * forge.md.md5.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2012 Digital Bazaar, Inc. All rights reserved.
 */

var forge$j = forge$s;



/* HMAC API */
var hmac = forge$j.hmac = forge$j.hmac || {};

/**
 * Creates an HMAC object that uses the given message digest object.
 *
 * @return an HMAC object.
 */
hmac.create = function() {
  // the hmac key to use
  var _key = null;

  // the message digest to use
  var _md = null;

  // the inner padding
  var _ipadding = null;

  // the outer padding
  var _opadding = null;

  // hmac context
  var ctx = {};

  /**
   * Starts or restarts the HMAC with the given key and message digest.
   *
   * @param md the message digest to use, null to reuse the previous one,
   *           a string to use builtin 'sha1', 'md5', 'sha256'.
   * @param key the key to use as a string, array of bytes, byte buffer,
   *           or null to reuse the previous key.
   */
  ctx.start = function(md, key) {
    if(md !== null) {
      if(typeof md === 'string') {
        // create builtin message digest
        md = md.toLowerCase();
        if(md in forge$j.md.algorithms) {
          _md = forge$j.md.algorithms[md].create();
        } else {
          throw new Error('Unknown hash algorithm "' + md + '"');
        }
      } else {
        // store message digest
        _md = md;
      }
    }

    if(key === null) {
      // reuse previous key
      key = _key;
    } else {
      if(typeof key === 'string') {
        // convert string into byte buffer
        key = forge$j.util.createBuffer(key);
      } else if(forge$j.util.isArray(key)) {
        // convert byte array into byte buffer
        var tmp = key;
        key = forge$j.util.createBuffer();
        for(var i = 0; i < tmp.length; ++i) {
          key.putByte(tmp[i]);
        }
      }

      // if key is longer than blocksize, hash it
      var keylen = key.length();
      if(keylen > _md.blockLength) {
        _md.start();
        _md.update(key.bytes());
        key = _md.digest();
      }

      // mix key into inner and outer padding
      // ipadding = [0x36 * blocksize] ^ key
      // opadding = [0x5C * blocksize] ^ key
      _ipadding = forge$j.util.createBuffer();
      _opadding = forge$j.util.createBuffer();
      keylen = key.length();
      for(var i = 0; i < keylen; ++i) {
        var tmp = key.at(i);
        _ipadding.putByte(0x36 ^ tmp);
        _opadding.putByte(0x5C ^ tmp);
      }

      // if key is shorter than blocksize, add additional padding
      if(keylen < _md.blockLength) {
        var tmp = _md.blockLength - keylen;
        for(var i = 0; i < tmp; ++i) {
          _ipadding.putByte(0x36);
          _opadding.putByte(0x5C);
        }
      }
      _key = key;
      _ipadding = _ipadding.bytes();
      _opadding = _opadding.bytes();
    }

    // digest is done like so: hash(opadding | hash(ipadding | message))

    // prepare to do inner hash
    // hash(ipadding | message)
    _md.start();
    _md.update(_ipadding);
  };

  /**
   * Updates the HMAC with the given message bytes.
   *
   * @param bytes the bytes to update with.
   */
  ctx.update = function(bytes) {
    _md.update(bytes);
  };

  /**
   * Produces the Message Authentication Code (MAC).
   *
   * @return a byte buffer containing the digest value.
   */
  ctx.getMac = function() {
    // digest is done like so: hash(opadding | hash(ipadding | message))
    // here we do the outer hashing
    var inner = _md.digest().bytes();
    _md.start();
    _md.update(_opadding);
    _md.update(inner);
    return _md.digest();
  };
  // alias for getMac
  ctx.digest = ctx.getMac;

  return ctx;
};

/**
 * Password-Based Key-Derivation Function #2 implementation.
 *
 * See RFC 2898 for details.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2013 Digital Bazaar, Inc.
 */

var forge$i = forge$s;




var pkcs5 = forge$i.pkcs5 = forge$i.pkcs5 || {};

var crypto$4;
if(forge$i.util.isNodejs && !forge$i.options.usePureJavaScript) {
  crypto$4 = require$$1;
}

/**
 * Derives a key from a password.
 *
 * @param p the password as a binary-encoded string of bytes.
 * @param s the salt as a binary-encoded string of bytes.
 * @param c the iteration count, a positive integer.
 * @param dkLen the intended length, in bytes, of the derived key,
 *          (max: 2^32 - 1) * hash length of the PRF.
 * @param [md] the message digest (or algorithm identifier as a string) to use
 *          in the PRF, defaults to SHA-1.
 * @param [callback(err, key)] presence triggers asynchronous version, called
 *          once the operation completes.
 *
 * @return the derived key, as a binary-encoded string of bytes, for the
 *           synchronous version (if no callback is specified).
 */
var pbkdf2$1 = forge$i.pbkdf2 = pkcs5.pbkdf2 = function(
  p, s, c, dkLen, md, callback) {
  if(typeof md === 'function') {
    callback = md;
    md = null;
  }

  // use native implementation if possible and not disabled, note that
  // some node versions only support SHA-1, others allow digest to be changed
  if(forge$i.util.isNodejs && !forge$i.options.usePureJavaScript &&
    crypto$4.pbkdf2 && (md === null || typeof md !== 'object') &&
    (crypto$4.pbkdf2Sync.length > 4 || (!md || md === 'sha1'))) {
    if(typeof md !== 'string') {
      // default prf to SHA-1
      md = 'sha1';
    }
    p = Buffer.from(p, 'binary');
    s = Buffer.from(s, 'binary');
    if(!callback) {
      if(crypto$4.pbkdf2Sync.length === 4) {
        return crypto$4.pbkdf2Sync(p, s, c, dkLen).toString('binary');
      }
      return crypto$4.pbkdf2Sync(p, s, c, dkLen, md).toString('binary');
    }
    if(crypto$4.pbkdf2Sync.length === 4) {
      return crypto$4.pbkdf2(p, s, c, dkLen, function(err, key) {
        if(err) {
          return callback(err);
        }
        callback(null, key.toString('binary'));
      });
    }
    return crypto$4.pbkdf2(p, s, c, dkLen, md, function(err, key) {
      if(err) {
        return callback(err);
      }
      callback(null, key.toString('binary'));
    });
  }

  if(typeof md === 'undefined' || md === null) {
    // default prf to SHA-1
    md = 'sha1';
  }
  if(typeof md === 'string') {
    if(!(md in forge$i.md.algorithms)) {
      throw new Error('Unknown hash algorithm: ' + md);
    }
    md = forge$i.md[md].create();
  }

  var hLen = md.digestLength;

  /* 1. If dkLen > (2^32 - 1) * hLen, output "derived key too long" and
    stop. */
  if(dkLen > (0xFFFFFFFF * hLen)) {
    var err = new Error('Derived key is too long.');
    if(callback) {
      return callback(err);
    }
    throw err;
  }

  /* 2. Let len be the number of hLen-octet blocks in the derived key,
    rounding up, and let r be the number of octets in the last
    block:

    len = CEIL(dkLen / hLen),
    r = dkLen - (len - 1) * hLen. */
  var len = Math.ceil(dkLen / hLen);
  var r = dkLen - (len - 1) * hLen;

  /* 3. For each block of the derived key apply the function F defined
    below to the password P, the salt S, the iteration count c, and
    the block index to compute the block:

    T_1 = F(P, S, c, 1),
    T_2 = F(P, S, c, 2),
    ...
    T_len = F(P, S, c, len),

    where the function F is defined as the exclusive-or sum of the
    first c iterates of the underlying pseudorandom function PRF
    applied to the password P and the concatenation of the salt S
    and the block index i:

    F(P, S, c, i) = u_1 XOR u_2 XOR ... XOR u_c

    where

    u_1 = PRF(P, S || INT(i)),
    u_2 = PRF(P, u_1),
    ...
    u_c = PRF(P, u_{c-1}).

    Here, INT(i) is a four-octet encoding of the integer i, most
    significant octet first. */
  var prf = forge$i.hmac.create();
  prf.start(md, p);
  var dk = '';
  var xor, u_c, u_c1;

  // sync version
  if(!callback) {
    for(var i = 1; i <= len; ++i) {
      // PRF(P, S || INT(i)) (first iteration)
      prf.start(null, null);
      prf.update(s);
      prf.update(forge$i.util.int32ToBytes(i));
      xor = u_c1 = prf.digest().getBytes();

      // PRF(P, u_{c-1}) (other iterations)
      for(var j = 2; j <= c; ++j) {
        prf.start(null, null);
        prf.update(u_c1);
        u_c = prf.digest().getBytes();
        // F(p, s, c, i)
        xor = forge$i.util.xorBytes(xor, u_c, hLen);
        u_c1 = u_c;
      }

      /* 4. Concatenate the blocks and extract the first dkLen octets to
        produce a derived key DK:

        DK = T_1 || T_2 ||  ...  || T_len<0..r-1> */
      dk += (i < len) ? xor : xor.substr(0, r);
    }
    /* 5. Output the derived key DK. */
    return dk;
  }

  // async version
  var i = 1, j;
  function outer() {
    if(i > len) {
      // done
      return callback(null, dk);
    }

    // PRF(P, S || INT(i)) (first iteration)
    prf.start(null, null);
    prf.update(s);
    prf.update(forge$i.util.int32ToBytes(i));
    xor = u_c1 = prf.digest().getBytes();

    // PRF(P, u_{c-1}) (other iterations)
    j = 2;
    inner();
  }

  function inner() {
    if(j <= c) {
      prf.start(null, null);
      prf.update(u_c1);
      u_c = prf.digest().getBytes();
      // F(p, s, c, i)
      xor = forge$i.util.xorBytes(xor, u_c, hLen);
      u_c1 = u_c;
      ++j;
      return forge$i.util.setImmediate(inner);
    }

    /* 4. Concatenate the blocks and extract the first dkLen octets to
      produce a derived key DK:

      DK = T_1 || T_2 ||  ...  || T_len<0..r-1> */
    dk += (i < len) ? xor : xor.substr(0, r);

    ++i;
    outer();
  }

  outer();
};

/**
 * Javascript implementation of basic PEM (Privacy Enhanced Mail) algorithms.
 *
 * See: RFC 1421.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2013-2014 Digital Bazaar, Inc.
 *
 * A Forge PEM object has the following fields:
 *
 * type: identifies the type of message (eg: "RSA PRIVATE KEY").
 *
 * procType: identifies the type of processing performed on the message,
 *   it has two subfields: version and type, eg: 4,ENCRYPTED.
 *
 * contentDomain: identifies the type of content in the message, typically
 *   only uses the value: "RFC822".
 *
 * dekInfo: identifies the message encryption algorithm and mode and includes
 *   any parameters for the algorithm, it has two subfields: algorithm and
 *   parameters, eg: DES-CBC,F8143EDE5960C597.
 *
 * headers: contains all other PEM encapsulated headers -- where order is
 *   significant (for pairing data like recipient ID + key info).
 *
 * body: the binary-encoded body.
 */

var forge$h = forge$s;


// shortcut for pem API
var pem = forge$h.pem = forge$h.pem || {};

/**
 * Encodes (serializes) the given PEM object.
 *
 * @param msg the PEM message object to encode.
 * @param options the options to use:
 *          maxline the maximum characters per line for the body, (default: 64).
 *
 * @return the PEM-formatted string.
 */
pem.encode = function(msg, options) {
  options = options || {};
  var rval = '-----BEGIN ' + msg.type + '-----\r\n';

  // encode special headers
  var header;
  if(msg.procType) {
    header = {
      name: 'Proc-Type',
      values: [String(msg.procType.version), msg.procType.type]
    };
    rval += foldHeader(header);
  }
  if(msg.contentDomain) {
    header = {name: 'Content-Domain', values: [msg.contentDomain]};
    rval += foldHeader(header);
  }
  if(msg.dekInfo) {
    header = {name: 'DEK-Info', values: [msg.dekInfo.algorithm]};
    if(msg.dekInfo.parameters) {
      header.values.push(msg.dekInfo.parameters);
    }
    rval += foldHeader(header);
  }

  if(msg.headers) {
    // encode all other headers
    for(var i = 0; i < msg.headers.length; ++i) {
      rval += foldHeader(msg.headers[i]);
    }
  }

  // terminate header
  if(msg.procType) {
    rval += '\r\n';
  }

  // add body
  rval += forge$h.util.encode64(msg.body, options.maxline || 64) + '\r\n';

  rval += '-----END ' + msg.type + '-----\r\n';
  return rval;
};

/**
 * Decodes (deserializes) all PEM messages found in the given string.
 *
 * @param str the PEM-formatted string to decode.
 *
 * @return the PEM message objects in an array.
 */
pem.decode = function(str) {
  var rval = [];

  // split string into PEM messages (be lenient w/EOF on BEGIN line)
  var rMessage = /\s*-----BEGIN ([A-Z0-9- ]+)-----\r?\n?([\x21-\x7e\s]+?(?:\r?\n\r?\n))?([:A-Za-z0-9+\/=\s]+?)-----END \1-----/g;
  var rHeader = /([\x21-\x7e]+):\s*([\x21-\x7e\s^:]+)/;
  var rCRLF = /\r?\n/;
  var match;
  while(true) {
    match = rMessage.exec(str);
    if(!match) {
      break;
    }

    // accept "NEW CERTIFICATE REQUEST" as "CERTIFICATE REQUEST"
    // https://datatracker.ietf.org/doc/html/rfc7468#section-7
    var type = match[1];
    if(type === 'NEW CERTIFICATE REQUEST') {
      type = 'CERTIFICATE REQUEST';
    }

    var msg = {
      type: type,
      procType: null,
      contentDomain: null,
      dekInfo: null,
      headers: [],
      body: forge$h.util.decode64(match[3])
    };
    rval.push(msg);

    // no headers
    if(!match[2]) {
      continue;
    }

    // parse headers
    var lines = match[2].split(rCRLF);
    var li = 0;
    while(match && li < lines.length) {
      // get line, trim any rhs whitespace
      var line = lines[li].replace(/\s+$/, '');

      // RFC2822 unfold any following folded lines
      for(var nl = li + 1; nl < lines.length; ++nl) {
        var next = lines[nl];
        if(!/\s/.test(next[0])) {
          break;
        }
        line += next;
        li = nl;
      }

      // parse header
      match = line.match(rHeader);
      if(match) {
        var header = {name: match[1], values: []};
        var values = match[2].split(',');
        for(var vi = 0; vi < values.length; ++vi) {
          header.values.push(ltrim(values[vi]));
        }

        // Proc-Type must be the first header
        if(!msg.procType) {
          if(header.name !== 'Proc-Type') {
            throw new Error('Invalid PEM formatted message. The first ' +
              'encapsulated header must be "Proc-Type".');
          } else if(header.values.length !== 2) {
            throw new Error('Invalid PEM formatted message. The "Proc-Type" ' +
              'header must have two subfields.');
          }
          msg.procType = {version: values[0], type: values[1]};
        } else if(!msg.contentDomain && header.name === 'Content-Domain') {
          // special-case Content-Domain
          msg.contentDomain = values[0] || '';
        } else if(!msg.dekInfo && header.name === 'DEK-Info') {
          // special-case DEK-Info
          if(header.values.length === 0) {
            throw new Error('Invalid PEM formatted message. The "DEK-Info" ' +
              'header must have at least one subfield.');
          }
          msg.dekInfo = {algorithm: values[0], parameters: values[1] || null};
        } else {
          msg.headers.push(header);
        }
      }

      ++li;
    }

    if(msg.procType === 'ENCRYPTED' && !msg.dekInfo) {
      throw new Error('Invalid PEM formatted message. The "DEK-Info" ' +
        'header must be present if "Proc-Type" is "ENCRYPTED".');
    }
  }

  if(rval.length === 0) {
    throw new Error('Invalid PEM formatted message.');
  }

  return rval;
};

function foldHeader(header) {
  var rval = header.name + ': ';

  // ensure values with CRLF are folded
  var values = [];
  var insertSpace = function(match, $1) {
    return ' ' + $1;
  };
  for(var i = 0; i < header.values.length; ++i) {
    values.push(header.values[i].replace(/^(\S+\r\n)/, insertSpace));
  }
  rval += values.join(',') + '\r\n';

  // do folding
  var length = 0;
  var candidate = -1;
  for(var i = 0; i < rval.length; ++i, ++length) {
    if(length > 65 && candidate !== -1) {
      var insert = rval[candidate];
      if(insert === ',') {
        ++candidate;
        rval = rval.substr(0, candidate) + '\r\n ' + rval.substr(candidate);
      } else {
        rval = rval.substr(0, candidate) +
          '\r\n' + insert + rval.substr(candidate + 1);
      }
      length = (i - candidate - 1);
      candidate = -1;
      ++i;
    } else if(rval[i] === ' ' || rval[i] === '\t' || rval[i] === ',') {
      candidate = i;
    }
  }

  return rval;
}

function ltrim(str) {
  return str.replace(/^\s+/, '');
}

/**
 * Secure Hash Algorithm with 256-bit digest (SHA-256) implementation.
 *
 * See FIPS 180-2 for details.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2015 Digital Bazaar, Inc.
 */

var forge$g = forge$s;



var sha256$1 = forge$g.sha256 = forge$g.sha256 || {};
forge$g.md.sha256 = forge$g.md.algorithms.sha256 = sha256$1;

/**
 * Creates a SHA-256 message digest object.
 *
 * @return a message digest object.
 */
sha256$1.create = function() {
  // do initialization as necessary
  if(!_initialized$2) {
    _init$2();
  }

  // SHA-256 state contains eight 32-bit integers
  var _state = null;

  // input buffer
  var _input = forge$g.util.createBuffer();

  // used for word storage
  var _w = new Array(64);

  // message digest object
  var md = {
    algorithm: 'sha256',
    blockLength: 64,
    digestLength: 32,
    // 56-bit length of message so far (does not including padding)
    messageLength: 0,
    // true message length
    fullMessageLength: null,
    // size of message length in bytes
    messageLengthSize: 8
  };

  /**
   * Starts the digest.
   *
   * @return this digest object.
   */
  md.start = function() {
    // up to 56-bit message length for convenience
    md.messageLength = 0;

    // full message length (set md.messageLength64 for backwards-compatibility)
    md.fullMessageLength = md.messageLength64 = [];
    var int32s = md.messageLengthSize / 4;
    for(var i = 0; i < int32s; ++i) {
      md.fullMessageLength.push(0);
    }
    _input = forge$g.util.createBuffer();
    _state = {
      h0: 0x6A09E667,
      h1: 0xBB67AE85,
      h2: 0x3C6EF372,
      h3: 0xA54FF53A,
      h4: 0x510E527F,
      h5: 0x9B05688C,
      h6: 0x1F83D9AB,
      h7: 0x5BE0CD19
    };
    return md;
  };
  // start digest automatically for first time
  md.start();

  /**
   * Updates the digest with the given message input. The given input can
   * treated as raw input (no encoding will be applied) or an encoding of
   * 'utf8' maybe given to encode the input using UTF-8.
   *
   * @param msg the message input to update with.
   * @param encoding the encoding to use (default: 'raw', other: 'utf8').
   *
   * @return this digest object.
   */
  md.update = function(msg, encoding) {
    if(encoding === 'utf8') {
      msg = forge$g.util.encodeUtf8(msg);
    }

    // update message length
    var len = msg.length;
    md.messageLength += len;
    len = [(len / 0x100000000) >>> 0, len >>> 0];
    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {
      md.fullMessageLength[i] += len[1];
      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);
      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;
      len[0] = ((len[1] / 0x100000000) >>> 0);
    }

    // add bytes to input buffer
    _input.putBytes(msg);

    // process bytes
    _update$2(_state, _w, _input);

    // compact input buffer every 2K or if empty
    if(_input.read > 2048 || _input.length() === 0) {
      _input.compact();
    }

    return md;
  };

  /**
   * Produces the digest.
   *
   * @return a byte buffer containing the digest value.
   */
  md.digest = function() {
    /* Note: Here we copy the remaining bytes in the input buffer and
    add the appropriate SHA-256 padding. Then we do the final update
    on a copy of the state so that if the user wants to get
    intermediate digests they can do so. */

    /* Determine the number of bytes that must be added to the message
    to ensure its length is congruent to 448 mod 512. In other words,
    the data to be digested must be a multiple of 512 bits (or 128 bytes).
    This data includes the message, some padding, and the length of the
    message. Since the length of the message will be encoded as 8 bytes (64
    bits), that means that the last segment of the data must have 56 bytes
    (448 bits) of message and padding. Therefore, the length of the message
    plus the padding must be congruent to 448 mod 512 because
    512 - 128 = 448.

    In order to fill up the message length it must be filled with
    padding that begins with 1 bit followed by all 0 bits. Padding
    must *always* be present, so if the message length is already
    congruent to 448 mod 512, then 512 padding bits must be added. */

    var finalBlock = forge$g.util.createBuffer();
    finalBlock.putBytes(_input.bytes());

    // compute remaining size to be digested (include message length size)
    var remaining = (
      md.fullMessageLength[md.fullMessageLength.length - 1] +
      md.messageLengthSize);

    // add padding for overflow blockSize - overflow
    // _padding starts with 1 byte with first bit is set (byte value 128), then
    // there may be up to (blockSize - 1) other pad bytes
    var overflow = remaining & (md.blockLength - 1);
    finalBlock.putBytes(_padding$2.substr(0, md.blockLength - overflow));

    // serialize message length in bits in big-endian order; since length
    // is stored in bytes we multiply by 8 and add carry from next int
    var next, carry;
    var bits = md.fullMessageLength[0] * 8;
    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {
      next = md.fullMessageLength[i + 1] * 8;
      carry = (next / 0x100000000) >>> 0;
      bits += carry;
      finalBlock.putInt32(bits >>> 0);
      bits = next >>> 0;
    }
    finalBlock.putInt32(bits);

    var s2 = {
      h0: _state.h0,
      h1: _state.h1,
      h2: _state.h2,
      h3: _state.h3,
      h4: _state.h4,
      h5: _state.h5,
      h6: _state.h6,
      h7: _state.h7
    };
    _update$2(s2, _w, finalBlock);
    var rval = forge$g.util.createBuffer();
    rval.putInt32(s2.h0);
    rval.putInt32(s2.h1);
    rval.putInt32(s2.h2);
    rval.putInt32(s2.h3);
    rval.putInt32(s2.h4);
    rval.putInt32(s2.h5);
    rval.putInt32(s2.h6);
    rval.putInt32(s2.h7);
    return rval;
  };

  return md;
};

// sha-256 padding bytes not initialized yet
var _padding$2 = null;
var _initialized$2 = false;

// table of constants
var _k$1 = null;

/**
 * Initializes the constant tables.
 */
function _init$2() {
  // create padding
  _padding$2 = String.fromCharCode(128);
  _padding$2 += forge$g.util.fillString(String.fromCharCode(0x00), 64);

  // create K table for SHA-256
  _k$1 = [
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
    0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,
    0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,
    0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,
    0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,
    0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2];

  // now initialized
  _initialized$2 = true;
}

/**
 * Updates a SHA-256 state with the given byte buffer.
 *
 * @param s the SHA-256 state to update.
 * @param w the array to use to store words.
 * @param bytes the byte buffer to update with.
 */
function _update$2(s, w, bytes) {
  // consume 512 bit (64 byte) chunks
  var t1, t2, s0, s1, ch, maj, i, a, b, c, d, e, f, g, h;
  var len = bytes.length();
  while(len >= 64) {
    // the w array will be populated with sixteen 32-bit big-endian words
    // and then extended into 64 32-bit words according to SHA-256
    for(i = 0; i < 16; ++i) {
      w[i] = bytes.getInt32();
    }
    for(; i < 64; ++i) {
      // XOR word 2 words ago rot right 17, rot right 19, shft right 10
      t1 = w[i - 2];
      t1 =
        ((t1 >>> 17) | (t1 << 15)) ^
        ((t1 >>> 19) | (t1 << 13)) ^
        (t1 >>> 10);
      // XOR word 15 words ago rot right 7, rot right 18, shft right 3
      t2 = w[i - 15];
      t2 =
        ((t2 >>> 7) | (t2 << 25)) ^
        ((t2 >>> 18) | (t2 << 14)) ^
        (t2 >>> 3);
      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^32
      w[i] = (t1 + w[i - 7] + t2 + w[i - 16]) | 0;
    }

    // initialize hash value for this chunk
    a = s.h0;
    b = s.h1;
    c = s.h2;
    d = s.h3;
    e = s.h4;
    f = s.h5;
    g = s.h6;
    h = s.h7;

    // round function
    for(i = 0; i < 64; ++i) {
      // Sum1(e)
      s1 =
        ((e >>> 6) | (e << 26)) ^
        ((e >>> 11) | (e << 21)) ^
        ((e >>> 25) | (e << 7));
      // Ch(e, f, g) (optimized the same way as SHA-1)
      ch = g ^ (e & (f ^ g));
      // Sum0(a)
      s0 =
        ((a >>> 2) | (a << 30)) ^
        ((a >>> 13) | (a << 19)) ^
        ((a >>> 22) | (a << 10));
      // Maj(a, b, c) (optimized the same way as SHA-1)
      maj = (a & b) | (c & (a ^ b));

      // main algorithm
      t1 = h + s1 + ch + _k$1[i] + w[i];
      t2 = s0 + maj;
      h = g;
      g = f;
      f = e;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      // can't truncate with `| 0`
      e = (d + t1) >>> 0;
      d = c;
      c = b;
      b = a;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      // can't truncate with `| 0`
      a = (t1 + t2) >>> 0;
    }

    // update hash state
    s.h0 = (s.h0 + a) | 0;
    s.h1 = (s.h1 + b) | 0;
    s.h2 = (s.h2 + c) | 0;
    s.h3 = (s.h3 + d) | 0;
    s.h4 = (s.h4 + e) | 0;
    s.h5 = (s.h5 + f) | 0;
    s.h6 = (s.h6 + g) | 0;
    s.h7 = (s.h7 + h) | 0;
    len -= 64;
  }
}

/**
 * A javascript implementation of a cryptographically-secure
 * Pseudo Random Number Generator (PRNG). The Fortuna algorithm is followed
 * here though the use of SHA-256 is not enforced; when generating an
 * a PRNG context, the hashing algorithm and block cipher used for
 * the generator are specified via a plugin.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 */

var forge$f = forge$s;


var _crypto$1 = null;
if(forge$f.util.isNodejs && !forge$f.options.usePureJavaScript &&
  !process.versions['node-webkit']) {
  _crypto$1 = require$$1;
}

/* PRNG API */
var prng = forge$f.prng = forge$f.prng || {};

/**
 * Creates a new PRNG context.
 *
 * A PRNG plugin must be passed in that will provide:
 *
 * 1. A function that initializes the key and seed of a PRNG context. It
 *   will be given a 16 byte key and a 16 byte seed. Any key expansion
 *   or transformation of the seed from a byte string into an array of
 *   integers (or similar) should be performed.
 * 2. The cryptographic function used by the generator. It takes a key and
 *   a seed.
 * 3. A seed increment function. It takes the seed and returns seed + 1.
 * 4. An api to create a message digest.
 *
 * For an example, see random.js.
 *
 * @param plugin the PRNG plugin to use.
 */
prng.create = function(plugin) {
  var ctx = {
    plugin: plugin,
    key: null,
    seed: null,
    time: null,
    // number of reseeds so far
    reseeds: 0,
    // amount of data generated so far
    generated: 0,
    // no initial key bytes
    keyBytes: ''
  };

  // create 32 entropy pools (each is a message digest)
  var md = plugin.md;
  var pools = new Array(32);
  for(var i = 0; i < 32; ++i) {
    pools[i] = md.create();
  }
  ctx.pools = pools;

  // entropy pools are written to cyclically, starting at index 0
  ctx.pool = 0;

  /**
   * Generates random bytes. The bytes may be generated synchronously or
   * asynchronously. Web workers must use the asynchronous interface or
   * else the behavior is undefined.
   *
   * @param count the number of random bytes to generate.
   * @param [callback(err, bytes)] called once the operation completes.
   *
   * @return count random bytes as a string.
   */
  ctx.generate = function(count, callback) {
    // do synchronously
    if(!callback) {
      return ctx.generateSync(count);
    }

    // simple generator using counter-based CBC
    var cipher = ctx.plugin.cipher;
    var increment = ctx.plugin.increment;
    var formatKey = ctx.plugin.formatKey;
    var formatSeed = ctx.plugin.formatSeed;
    var b = forge$f.util.createBuffer();

    // paranoid deviation from Fortuna:
    // reset key for every request to protect previously
    // generated random bytes should the key be discovered;
    // there is no 100ms based reseeding because of this
    // forced reseed for every `generate` call
    ctx.key = null;

    generate();

    function generate(err) {
      if(err) {
        return callback(err);
      }

      // sufficient bytes generated
      if(b.length() >= count) {
        return callback(null, b.getBytes(count));
      }

      // if amount of data generated is greater than 1 MiB, trigger reseed
      if(ctx.generated > 0xfffff) {
        ctx.key = null;
      }

      if(ctx.key === null) {
        // prevent stack overflow
        return forge$f.util.nextTick(function() {
          _reseed(generate);
        });
      }

      // generate the random bytes
      var bytes = cipher(ctx.key, ctx.seed);
      ctx.generated += bytes.length;
      b.putBytes(bytes);

      // generate bytes for a new key and seed
      ctx.key = formatKey(cipher(ctx.key, increment(ctx.seed)));
      ctx.seed = formatSeed(cipher(ctx.key, ctx.seed));

      forge$f.util.setImmediate(generate);
    }
  };

  /**
   * Generates random bytes synchronously.
   *
   * @param count the number of random bytes to generate.
   *
   * @return count random bytes as a string.
   */
  ctx.generateSync = function(count) {
    // simple generator using counter-based CBC
    var cipher = ctx.plugin.cipher;
    var increment = ctx.plugin.increment;
    var formatKey = ctx.plugin.formatKey;
    var formatSeed = ctx.plugin.formatSeed;

    // paranoid deviation from Fortuna:
    // reset key for every request to protect previously
    // generated random bytes should the key be discovered;
    // there is no 100ms based reseeding because of this
    // forced reseed for every `generateSync` call
    ctx.key = null;

    var b = forge$f.util.createBuffer();
    while(b.length() < count) {
      // if amount of data generated is greater than 1 MiB, trigger reseed
      if(ctx.generated > 0xfffff) {
        ctx.key = null;
      }

      if(ctx.key === null) {
        _reseedSync();
      }

      // generate the random bytes
      var bytes = cipher(ctx.key, ctx.seed);
      ctx.generated += bytes.length;
      b.putBytes(bytes);

      // generate bytes for a new key and seed
      ctx.key = formatKey(cipher(ctx.key, increment(ctx.seed)));
      ctx.seed = formatSeed(cipher(ctx.key, ctx.seed));
    }

    return b.getBytes(count);
  };

  /**
   * Private function that asynchronously reseeds a generator.
   *
   * @param callback(err) called once the operation completes.
   */
  function _reseed(callback) {
    if(ctx.pools[0].messageLength >= 32) {
      _seed();
      return callback();
    }
    // not enough seed data...
    var needed = (32 - ctx.pools[0].messageLength) << 5;
    ctx.seedFile(needed, function(err, bytes) {
      if(err) {
        return callback(err);
      }
      ctx.collect(bytes);
      _seed();
      callback();
    });
  }

  /**
   * Private function that synchronously reseeds a generator.
   */
  function _reseedSync() {
    if(ctx.pools[0].messageLength >= 32) {
      return _seed();
    }
    // not enough seed data...
    var needed = (32 - ctx.pools[0].messageLength) << 5;
    ctx.collect(ctx.seedFileSync(needed));
    _seed();
  }

  /**
   * Private function that seeds a generator once enough bytes are available.
   */
  function _seed() {
    // update reseed count
    ctx.reseeds = (ctx.reseeds === 0xffffffff) ? 0 : ctx.reseeds + 1;

    // goal is to update `key` via:
    // key = hash(key + s)
    //   where 's' is all collected entropy from selected pools, then...

    // create a plugin-based message digest
    var md = ctx.plugin.md.create();

    // consume current key bytes
    md.update(ctx.keyBytes);

    // digest the entropy of pools whose index k meet the
    // condition 'n mod 2^k == 0' where n is the number of reseeds
    var _2powK = 1;
    for(var k = 0; k < 32; ++k) {
      if(ctx.reseeds % _2powK === 0) {
        md.update(ctx.pools[k].digest().getBytes());
        ctx.pools[k].start();
      }
      _2powK = _2powK << 1;
    }

    // get digest for key bytes
    ctx.keyBytes = md.digest().getBytes();

    // paranoid deviation from Fortuna:
    // update `seed` via `seed = hash(key)`
    // instead of initializing to zero once and only
    // ever incrementing it
    md.start();
    md.update(ctx.keyBytes);
    var seedBytes = md.digest().getBytes();

    // update state
    ctx.key = ctx.plugin.formatKey(ctx.keyBytes);
    ctx.seed = ctx.plugin.formatSeed(seedBytes);
    ctx.generated = 0;
  }

  /**
   * The built-in default seedFile. This seedFile is used when entropy
   * is needed immediately.
   *
   * @param needed the number of bytes that are needed.
   *
   * @return the random bytes.
   */
  function defaultSeedFile(needed) {
    // use window.crypto.getRandomValues strong source of entropy if available
    var getRandomValues = null;
    var globalScope = forge$f.util.globalScope;
    var _crypto = globalScope.crypto || globalScope.msCrypto;
    if(_crypto && _crypto.getRandomValues) {
      getRandomValues = function(arr) {
        return _crypto.getRandomValues(arr);
      };
    }

    var b = forge$f.util.createBuffer();
    if(getRandomValues) {
      while(b.length() < needed) {
        // max byte length is 65536 before QuotaExceededError is thrown
        // http://www.w3.org/TR/WebCryptoAPI/#RandomSource-method-getRandomValues
        var count = Math.max(1, Math.min(needed - b.length(), 65536) / 4);
        var entropy = new Uint32Array(Math.floor(count));
        try {
          getRandomValues(entropy);
          for(var i = 0; i < entropy.length; ++i) {
            b.putInt32(entropy[i]);
          }
        } catch(e) {
          /* only ignore QuotaExceededError */
          if(!(typeof QuotaExceededError !== 'undefined' &&
            e instanceof QuotaExceededError)) {
            throw e;
          }
        }
      }
    }

    // be sad and add some weak random data
    if(b.length() < needed) {
      /* Draws from Park-Miller "minimal standard" 31 bit PRNG,
      implemented with David G. Carta's optimization: with 32 bit math
      and without division (Public Domain). */
      var hi, lo, next;
      var seed = Math.floor(Math.random() * 0x010000);
      while(b.length() < needed) {
        lo = 16807 * (seed & 0xFFFF);
        hi = 16807 * (seed >> 16);
        lo += (hi & 0x7FFF) << 16;
        lo += hi >> 15;
        lo = (lo & 0x7FFFFFFF) + (lo >> 31);
        seed = lo & 0xFFFFFFFF;

        // consume lower 3 bytes of seed
        for(var i = 0; i < 3; ++i) {
          // throw in more pseudo random
          next = seed >>> (i << 3);
          next ^= Math.floor(Math.random() * 0x0100);
          b.putByte(next & 0xFF);
        }
      }
    }

    return b.getBytes(needed);
  }
  // initialize seed file APIs
  if(_crypto$1) {
    // use nodejs async API
    ctx.seedFile = function(needed, callback) {
      _crypto$1.randomBytes(needed, function(err, bytes) {
        if(err) {
          return callback(err);
        }
        callback(null, bytes.toString());
      });
    };
    // use nodejs sync API
    ctx.seedFileSync = function(needed) {
      return _crypto$1.randomBytes(needed).toString();
    };
  } else {
    ctx.seedFile = function(needed, callback) {
      try {
        callback(null, defaultSeedFile(needed));
      } catch(e) {
        callback(e);
      }
    };
    ctx.seedFileSync = defaultSeedFile;
  }

  /**
   * Adds entropy to a prng ctx's accumulator.
   *
   * @param bytes the bytes of entropy as a string.
   */
  ctx.collect = function(bytes) {
    // iterate over pools distributing entropy cyclically
    var count = bytes.length;
    for(var i = 0; i < count; ++i) {
      ctx.pools[ctx.pool].update(bytes.substr(i, 1));
      ctx.pool = (ctx.pool === 31) ? 0 : ctx.pool + 1;
    }
  };

  /**
   * Collects an integer of n bits.
   *
   * @param i the integer entropy.
   * @param n the number of bits in the integer.
   */
  ctx.collectInt = function(i, n) {
    var bytes = '';
    for(var x = 0; x < n; x += 8) {
      bytes += String.fromCharCode((i >> x) & 0xFF);
    }
    ctx.collect(bytes);
  };

  /**
   * Registers a Web Worker to receive immediate entropy from the main thread.
   * This method is required until Web Workers can access the native crypto
   * API. This method should be called twice for each created worker, once in
   * the main thread, and once in the worker itself.
   *
   * @param worker the worker to register.
   */
  ctx.registerWorker = function(worker) {
    // worker receives random bytes
    if(worker === self) {
      ctx.seedFile = function(needed, callback) {
        function listener(e) {
          var data = e.data;
          if(data.forge && data.forge.prng) {
            self.removeEventListener('message', listener);
            callback(data.forge.prng.err, data.forge.prng.bytes);
          }
        }
        self.addEventListener('message', listener);
        self.postMessage({forge: {prng: {needed: needed}}});
      };
    } else {
      // main thread sends random bytes upon request
      var listener = function(e) {
        var data = e.data;
        if(data.forge && data.forge.prng) {
          ctx.seedFile(data.forge.prng.needed, function(err, bytes) {
            worker.postMessage({forge: {prng: {err: err, bytes: bytes}}});
          });
        }
      };
      // TODO: do we need to remove the event listener when the worker dies?
      worker.addEventListener('message', listener);
    }
  };

  return ctx;
};

/**
 * An API for getting cryptographically-secure random bytes. The bytes are
 * generated using the Fortuna algorithm devised by Bruce Schneier and
 * Niels Ferguson.
 *
 * Getting strong random bytes is not yet easy to do in javascript. The only
 * truish random entropy that can be collected is from the mouse, keyboard, or
 * from timing with respect to page loads, etc. This generator makes a poor
 * attempt at providing random bytes when those sources haven't yet provided
 * enough entropy to initially seed or to reseed the PRNG.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2009-2014 Digital Bazaar, Inc.
 */

var forge$e = forge$s;





(function() {

// forge.random already defined
if(forge$e.random && forge$e.random.getBytes) {
  return;
}

(function(jQuery) {

// the default prng plugin, uses AES-128
var prng_aes = {};
var _prng_aes_output = new Array(4);
var _prng_aes_buffer = forge$e.util.createBuffer();
prng_aes.formatKey = function(key) {
  // convert the key into 32-bit integers
  var tmp = forge$e.util.createBuffer(key);
  key = new Array(4);
  key[0] = tmp.getInt32();
  key[1] = tmp.getInt32();
  key[2] = tmp.getInt32();
  key[3] = tmp.getInt32();

  // return the expanded key
  return forge$e.aes._expandKey(key, false);
};
prng_aes.formatSeed = function(seed) {
  // convert seed into 32-bit integers
  var tmp = forge$e.util.createBuffer(seed);
  seed = new Array(4);
  seed[0] = tmp.getInt32();
  seed[1] = tmp.getInt32();
  seed[2] = tmp.getInt32();
  seed[3] = tmp.getInt32();
  return seed;
};
prng_aes.cipher = function(key, seed) {
  forge$e.aes._updateBlock(key, seed, _prng_aes_output, false);
  _prng_aes_buffer.putInt32(_prng_aes_output[0]);
  _prng_aes_buffer.putInt32(_prng_aes_output[1]);
  _prng_aes_buffer.putInt32(_prng_aes_output[2]);
  _prng_aes_buffer.putInt32(_prng_aes_output[3]);
  return _prng_aes_buffer.getBytes();
};
prng_aes.increment = function(seed) {
  // FIXME: do we care about carry or signed issues?
  ++seed[3];
  return seed;
};
prng_aes.md = forge$e.md.sha256;

/**
 * Creates a new PRNG.
 */
function spawnPrng() {
  var ctx = forge$e.prng.create(prng_aes);

  /**
   * Gets random bytes. If a native secure crypto API is unavailable, this
   * method tries to make the bytes more unpredictable by drawing from data that
   * can be collected from the user of the browser, eg: mouse movement.
   *
   * If a callback is given, this method will be called asynchronously.
   *
   * @param count the number of random bytes to get.
   * @param [callback(err, bytes)] called once the operation completes.
   *
   * @return the random bytes in a string.
   */
  ctx.getBytes = function(count, callback) {
    return ctx.generate(count, callback);
  };

  /**
   * Gets random bytes asynchronously. If a native secure crypto API is
   * unavailable, this method tries to make the bytes more unpredictable by
   * drawing from data that can be collected from the user of the browser,
   * eg: mouse movement.
   *
   * @param count the number of random bytes to get.
   *
   * @return the random bytes in a string.
   */
  ctx.getBytesSync = function(count) {
    return ctx.generate(count);
  };

  return ctx;
}

// create default prng context
var _ctx = spawnPrng();

// add other sources of entropy only if window.crypto.getRandomValues is not
// available -- otherwise this source will be automatically used by the prng
var getRandomValues = null;
var globalScope = forge$e.util.globalScope;
var _crypto = globalScope.crypto || globalScope.msCrypto;
if(_crypto && _crypto.getRandomValues) {
  getRandomValues = function(arr) {
    return _crypto.getRandomValues(arr);
  };
}

if((!forge$e.util.isNodejs && !getRandomValues)) {

  // get load time entropy
  _ctx.collectInt(+new Date(), 32);

  // add some entropy from navigator object
  if(typeof(navigator) !== 'undefined') {
    var _navBytes = '';
    for(var key in navigator) {
      try {
        if(typeof(navigator[key]) == 'string') {
          _navBytes += navigator[key];
        }
      } catch(e) {
        /* Some navigator keys might not be accessible, e.g. the geolocation
          attribute throws an exception if touched in Mozilla chrome://
          context.

          Silently ignore this and just don't use this as a source of
          entropy. */
      }
    }
    _ctx.collect(_navBytes);
    _navBytes = null;
  }

  // add mouse and keyboard collectors if jquery is available
  if(jQuery) {
    // set up mouse entropy capture
    jQuery().mousemove(function(e) {
      // add mouse coords
      _ctx.collectInt(e.clientX, 16);
      _ctx.collectInt(e.clientY, 16);
    });

    // set up keyboard entropy capture
    jQuery().keypress(function(e) {
      _ctx.collectInt(e.charCode, 8);
    });
  }
}

/* Random API */
if(!forge$e.random) {
  forge$e.random = _ctx;
} else {
  // extend forge.random with _ctx
  for(var key in _ctx) {
    forge$e.random[key] = _ctx[key];
  }
}

// expose spawn PRNG
forge$e.random.createInstance = spawnPrng;

})(typeof(jQuery) !== 'undefined' ? jQuery : null);

})();

/**
 * RC2 implementation.
 *
 * @author Stefan Siegl
 *
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 *
 * Information on the RC2 cipher is available from RFC #2268,
 * http://www.ietf.org/rfc/rfc2268.txt
 */

var forge$d = forge$s;


var piTable = [
  0xd9, 0x78, 0xf9, 0xc4, 0x19, 0xdd, 0xb5, 0xed, 0x28, 0xe9, 0xfd, 0x79, 0x4a, 0xa0, 0xd8, 0x9d,
  0xc6, 0x7e, 0x37, 0x83, 0x2b, 0x76, 0x53, 0x8e, 0x62, 0x4c, 0x64, 0x88, 0x44, 0x8b, 0xfb, 0xa2,
  0x17, 0x9a, 0x59, 0xf5, 0x87, 0xb3, 0x4f, 0x13, 0x61, 0x45, 0x6d, 0x8d, 0x09, 0x81, 0x7d, 0x32,
  0xbd, 0x8f, 0x40, 0xeb, 0x86, 0xb7, 0x7b, 0x0b, 0xf0, 0x95, 0x21, 0x22, 0x5c, 0x6b, 0x4e, 0x82,
  0x54, 0xd6, 0x65, 0x93, 0xce, 0x60, 0xb2, 0x1c, 0x73, 0x56, 0xc0, 0x14, 0xa7, 0x8c, 0xf1, 0xdc,
  0x12, 0x75, 0xca, 0x1f, 0x3b, 0xbe, 0xe4, 0xd1, 0x42, 0x3d, 0xd4, 0x30, 0xa3, 0x3c, 0xb6, 0x26,
  0x6f, 0xbf, 0x0e, 0xda, 0x46, 0x69, 0x07, 0x57, 0x27, 0xf2, 0x1d, 0x9b, 0xbc, 0x94, 0x43, 0x03,
  0xf8, 0x11, 0xc7, 0xf6, 0x90, 0xef, 0x3e, 0xe7, 0x06, 0xc3, 0xd5, 0x2f, 0xc8, 0x66, 0x1e, 0xd7,
  0x08, 0xe8, 0xea, 0xde, 0x80, 0x52, 0xee, 0xf7, 0x84, 0xaa, 0x72, 0xac, 0x35, 0x4d, 0x6a, 0x2a,
  0x96, 0x1a, 0xd2, 0x71, 0x5a, 0x15, 0x49, 0x74, 0x4b, 0x9f, 0xd0, 0x5e, 0x04, 0x18, 0xa4, 0xec,
  0xc2, 0xe0, 0x41, 0x6e, 0x0f, 0x51, 0xcb, 0xcc, 0x24, 0x91, 0xaf, 0x50, 0xa1, 0xf4, 0x70, 0x39,
  0x99, 0x7c, 0x3a, 0x85, 0x23, 0xb8, 0xb4, 0x7a, 0xfc, 0x02, 0x36, 0x5b, 0x25, 0x55, 0x97, 0x31,
  0x2d, 0x5d, 0xfa, 0x98, 0xe3, 0x8a, 0x92, 0xae, 0x05, 0xdf, 0x29, 0x10, 0x67, 0x6c, 0xba, 0xc9,
  0xd3, 0x00, 0xe6, 0xcf, 0xe1, 0x9e, 0xa8, 0x2c, 0x63, 0x16, 0x01, 0x3f, 0x58, 0xe2, 0x89, 0xa9,
  0x0d, 0x38, 0x34, 0x1b, 0xab, 0x33, 0xff, 0xb0, 0xbb, 0x48, 0x0c, 0x5f, 0xb9, 0xb1, 0xcd, 0x2e,
  0xc5, 0xf3, 0xdb, 0x47, 0xe5, 0xa5, 0x9c, 0x77, 0x0a, 0xa6, 0x20, 0x68, 0xfe, 0x7f, 0xc1, 0xad
];

var s = [1, 2, 3, 5];

/**
 * Rotate a word left by given number of bits.
 *
 * Bits that are shifted out on the left are put back in on the right
 * hand side.
 *
 * @param word The word to shift left.
 * @param bits The number of bits to shift by.
 * @return The rotated word.
 */
var rol = function(word, bits) {
  return ((word << bits) & 0xffff) | ((word & 0xffff) >> (16 - bits));
};

/**
 * Rotate a word right by given number of bits.
 *
 * Bits that are shifted out on the right are put back in on the left
 * hand side.
 *
 * @param word The word to shift right.
 * @param bits The number of bits to shift by.
 * @return The rotated word.
 */
var ror = function(word, bits) {
  return ((word & 0xffff) >> bits) | ((word << (16 - bits)) & 0xffff);
};

/* RC2 API */
forge$d.rc2 = forge$d.rc2 || {};

/**
 * Perform RC2 key expansion as per RFC #2268, section 2.
 *
 * @param key variable-length user key (between 1 and 128 bytes)
 * @param effKeyBits number of effective key bits (default: 128)
 * @return the expanded RC2 key (ByteBuffer of 128 bytes)
 */
forge$d.rc2.expandKey = function(key, effKeyBits) {
  if(typeof key === 'string') {
    key = forge$d.util.createBuffer(key);
  }
  effKeyBits = effKeyBits || 128;

  /* introduce variables that match the names used in RFC #2268 */
  var L = key;
  var T = key.length();
  var T1 = effKeyBits;
  var T8 = Math.ceil(T1 / 8);
  var TM = 0xff >> (T1 & 0x07);
  var i;

  for(i = T; i < 128; i++) {
    L.putByte(piTable[(L.at(i - 1) + L.at(i - T)) & 0xff]);
  }

  L.setAt(128 - T8, piTable[L.at(128 - T8) & TM]);

  for(i = 127 - T8; i >= 0; i--) {
    L.setAt(i, piTable[L.at(i + 1) ^ L.at(i + T8)]);
  }

  return L;
};

/**
 * Creates a RC2 cipher object.
 *
 * @param key the symmetric key to use (as base for key generation).
 * @param bits the number of effective key bits.
 * @param encrypt false for decryption, true for encryption.
 *
 * @return the cipher.
 */
var createCipher = function(key, bits, encrypt) {
  var _finish = false, _input = null, _output = null, _iv = null;
  var mixRound, mashRound;
  var i, j, K = [];

  /* Expand key and fill into K[] Array */
  key = forge$d.rc2.expandKey(key, bits);
  for(i = 0; i < 64; i++) {
    K.push(key.getInt16Le());
  }

  if(encrypt) {
    /**
     * Perform one mixing round "in place".
     *
     * @param R Array of four words to perform mixing on.
     */
    mixRound = function(R) {
      for(i = 0; i < 4; i++) {
        R[i] += K[j] + (R[(i + 3) % 4] & R[(i + 2) % 4]) +
          ((~R[(i + 3) % 4]) & R[(i + 1) % 4]);
        R[i] = rol(R[i], s[i]);
        j++;
      }
    };

    /**
     * Perform one mashing round "in place".
     *
     * @param R Array of four words to perform mashing on.
     */
    mashRound = function(R) {
      for(i = 0; i < 4; i++) {
        R[i] += K[R[(i + 3) % 4] & 63];
      }
    };
  } else {
    /**
     * Perform one r-mixing round "in place".
     *
     * @param R Array of four words to perform mixing on.
     */
    mixRound = function(R) {
      for(i = 3; i >= 0; i--) {
        R[i] = ror(R[i], s[i]);
        R[i] -= K[j] + (R[(i + 3) % 4] & R[(i + 2) % 4]) +
          ((~R[(i + 3) % 4]) & R[(i + 1) % 4]);
        j--;
      }
    };

    /**
     * Perform one r-mashing round "in place".
     *
     * @param R Array of four words to perform mashing on.
     */
    mashRound = function(R) {
      for(i = 3; i >= 0; i--) {
        R[i] -= K[R[(i + 3) % 4] & 63];
      }
    };
  }

  /**
   * Run the specified cipher execution plan.
   *
   * This function takes four words from the input buffer, applies the IV on
   * it (if requested) and runs the provided execution plan.
   *
   * The plan must be put together in form of a array of arrays.  Where the
   * outer one is simply a list of steps to perform and the inner one needs
   * to have two elements: the first one telling how many rounds to perform,
   * the second one telling what to do (i.e. the function to call).
   *
   * @param {Array} plan The plan to execute.
   */
  var runPlan = function(plan) {
    var R = [];

    /* Get data from input buffer and fill the four words into R */
    for(i = 0; i < 4; i++) {
      var val = _input.getInt16Le();

      if(_iv !== null) {
        if(encrypt) {
          /* We're encrypting, apply the IV first. */
          val ^= _iv.getInt16Le();
        } else {
          /* We're decryption, keep cipher text for next block. */
          _iv.putInt16Le(val);
        }
      }

      R.push(val & 0xffff);
    }

    /* Reset global "j" variable as per spec. */
    j = encrypt ? 0 : 63;

    /* Run execution plan. */
    for(var ptr = 0; ptr < plan.length; ptr++) {
      for(var ctr = 0; ctr < plan[ptr][0]; ctr++) {
        plan[ptr][1](R);
      }
    }

    /* Write back result to output buffer. */
    for(i = 0; i < 4; i++) {
      if(_iv !== null) {
        if(encrypt) {
          /* We're encrypting in CBC-mode, feed back encrypted bytes into
             IV buffer to carry it forward to next block. */
          _iv.putInt16Le(R[i]);
        } else {
          R[i] ^= _iv.getInt16Le();
        }
      }

      _output.putInt16Le(R[i]);
    }
  };

  /* Create cipher object */
  var cipher = null;
  cipher = {
    /**
     * Starts or restarts the encryption or decryption process, whichever
     * was previously configured.
     *
     * To use the cipher in CBC mode, iv may be given either as a string
     * of bytes, or as a byte buffer.  For ECB mode, give null as iv.
     *
     * @param iv the initialization vector to use, null for ECB mode.
     * @param output the output the buffer to write to, null to create one.
     */
    start: function(iv, output) {
      if(iv) {
        /* CBC mode */
        if(typeof iv === 'string') {
          iv = forge$d.util.createBuffer(iv);
        }
      }

      _finish = false;
      _input = forge$d.util.createBuffer();
      _output = output || new forge$d.util.createBuffer();
      _iv = iv;

      cipher.output = _output;
    },

    /**
     * Updates the next block.
     *
     * @param input the buffer to read from.
     */
    update: function(input) {
      if(!_finish) {
        // not finishing, so fill the input buffer with more input
        _input.putBuffer(input);
      }

      while(_input.length() >= 8) {
        runPlan([
            [ 5, mixRound ],
            [ 1, mashRound ],
            [ 6, mixRound ],
            [ 1, mashRound ],
            [ 5, mixRound ]
          ]);
      }
    },

    /**
     * Finishes encrypting or decrypting.
     *
     * @param pad a padding function to use, null for PKCS#7 padding,
     *           signature(blockSize, buffer, decrypt).
     *
     * @return true if successful, false on error.
     */
    finish: function(pad) {
      var rval = true;

      if(encrypt) {
        if(pad) {
          rval = pad(8, _input, !encrypt);
        } else {
          // add PKCS#7 padding to block (each pad byte is the
          // value of the number of pad bytes)
          var padding = (_input.length() === 8) ? 8 : (8 - _input.length());
          _input.fillWithByte(padding, padding);
        }
      }

      if(rval) {
        // do final update
        _finish = true;
        cipher.update();
      }

      if(!encrypt) {
        // check for error: input data not a multiple of block size
        rval = (_input.length() === 0);
        if(rval) {
          if(pad) {
            rval = pad(8, _output, !encrypt);
          } else {
            // ensure padding byte count is valid
            var len = _output.length();
            var count = _output.at(len - 1);

            if(count > len) {
              rval = false;
            } else {
              // trim off padding bytes
              _output.truncate(count);
            }
          }
        }
      }

      return rval;
    }
  };

  return cipher;
};

/**
 * Creates an RC2 cipher object to encrypt data in ECB or CBC mode using the
 * given symmetric key. The output will be stored in the 'output' member
 * of the returned cipher.
 *
 * The key and iv may be given as a string of bytes or a byte buffer.
 * The cipher is initialized to use 128 effective key bits.
 *
 * @param key the symmetric key to use.
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 *
 * @return the cipher.
 */
forge$d.rc2.startEncrypting = function(key, iv, output) {
  var cipher = forge$d.rc2.createEncryptionCipher(key, 128);
  cipher.start(iv, output);
  return cipher;
};

/**
 * Creates an RC2 cipher object to encrypt data in ECB or CBC mode using the
 * given symmetric key.
 *
 * The key may be given as a string of bytes or a byte buffer.
 *
 * To start encrypting call start() on the cipher with an iv and optional
 * output buffer.
 *
 * @param key the symmetric key to use.
 *
 * @return the cipher.
 */
forge$d.rc2.createEncryptionCipher = function(key, bits) {
  return createCipher(key, bits, true);
};

/**
 * Creates an RC2 cipher object to decrypt data in ECB or CBC mode using the
 * given symmetric key. The output will be stored in the 'output' member
 * of the returned cipher.
 *
 * The key and iv may be given as a string of bytes or a byte buffer.
 * The cipher is initialized to use 128 effective key bits.
 *
 * @param key the symmetric key to use.
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 *
 * @return the cipher.
 */
forge$d.rc2.startDecrypting = function(key, iv, output) {
  var cipher = forge$d.rc2.createDecryptionCipher(key, 128);
  cipher.start(iv, output);
  return cipher;
};

/**
 * Creates an RC2 cipher object to decrypt data in ECB or CBC mode using the
 * given symmetric key.
 *
 * The key may be given as a string of bytes or a byte buffer.
 *
 * To start decrypting call start() on the cipher with an iv and optional
 * output buffer.
 *
 * @param key the symmetric key to use.
 *
 * @return the cipher.
 */
forge$d.rc2.createDecryptionCipher = function(key, bits) {
  return createCipher(key, bits, false);
};

// Copyright (c) 2005  Tom Wu
// All Rights Reserved.
// See "LICENSE" for details.

// Basic JavaScript BN library - subset useful for RSA encryption.

/*
Licensing (LICENSE)
-------------------

This software is covered under the following copyright:
*/
/*
 * Copyright (c) 2003-2005  Tom Wu
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS-IS" AND WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS, IMPLIED OR OTHERWISE, INCLUDING WITHOUT LIMITATION, ANY
 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.
 *
 * IN NO EVENT SHALL TOM WU BE LIABLE FOR ANY SPECIAL, INCIDENTAL,
 * INDIRECT OR CONSEQUENTIAL DAMAGES OF ANY KIND, OR ANY DAMAGES WHATSOEVER
 * RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER OR NOT ADVISED OF
 * THE POSSIBILITY OF DAMAGE, AND ON ANY THEORY OF LIABILITY, ARISING OUT
 * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *
 * In addition, the following condition applies:
 *
 * All redistributions must retain an intact copy of this copyright notice
 * and disclaimer.
 */
/*
Address all questions regarding this license to:

  Tom Wu
  tjw@cs.Stanford.EDU
*/
var forge$c = forge$s;

forge$c.jsbn = forge$c.jsbn || {};

// Bits per digit
var dbits;

// (public) Constructor
function BigInteger$2(a,b,c) {
  this.data = [];
  if(a != null)
    if("number" == typeof a) this.fromNumber(a,b,c);
    else if(b == null && "string" != typeof a) this.fromString(a,256);
    else this.fromString(a,b);
}
forge$c.jsbn.BigInteger = BigInteger$2;

// return new, unset BigInteger
function nbi() { return new BigInteger$2(null); }

// am: Compute w_j += (x*this_i), propagate carries,
// c is initial carry, returns final carry.
// c < 3*dvalue, x < 2*dvalue, this_i < dvalue
// We need to select the fastest one that works in this environment.

// am1: use a single mult and divide to get the high bits,
// max digit bits should be 26 because
// max internal value = 2*dvalue^2-2*dvalue (< 2^53)
function am1(i,x,w,j,c,n) {
  while(--n >= 0) {
    var v = x*this.data[i++]+w.data[j]+c;
    c = Math.floor(v/0x4000000);
    w.data[j++] = v&0x3ffffff;
  }
  return c;
}
// am2 avoids a big mult-and-extract completely.
// Max digit bits should be <= 30 because we do bitwise ops
// on values up to 2*hdvalue^2-hdvalue-1 (< 2^31)
function am2(i,x,w,j,c,n) {
  var xl = x&0x7fff, xh = x>>15;
  while(--n >= 0) {
    var l = this.data[i]&0x7fff;
    var h = this.data[i++]>>15;
    var m = xh*l+h*xl;
    l = xl*l+((m&0x7fff)<<15)+w.data[j]+(c&0x3fffffff);
    c = (l>>>30)+(m>>>15)+xh*h+(c>>>30);
    w.data[j++] = l&0x3fffffff;
  }
  return c;
}
// Alternately, set max digit bits to 28 since some
// browsers slow down when dealing with 32-bit numbers.
function am3(i,x,w,j,c,n) {
  var xl = x&0x3fff, xh = x>>14;
  while(--n >= 0) {
    var l = this.data[i]&0x3fff;
    var h = this.data[i++]>>14;
    var m = xh*l+h*xl;
    l = xl*l+((m&0x3fff)<<14)+w.data[j]+c;
    c = (l>>28)+(m>>14)+xh*h;
    w.data[j++] = l&0xfffffff;
  }
  return c;
}

// node.js (no browser)
if(typeof(navigator) === 'undefined')
{
   BigInteger$2.prototype.am = am3;
   dbits = 28;
} else if((navigator.appName == "Microsoft Internet Explorer")) {
  BigInteger$2.prototype.am = am2;
  dbits = 30;
} else if((navigator.appName != "Netscape")) {
  BigInteger$2.prototype.am = am1;
  dbits = 26;
} else { // Mozilla/Netscape seems to prefer am3
  BigInteger$2.prototype.am = am3;
  dbits = 28;
}

BigInteger$2.prototype.DB = dbits;
BigInteger$2.prototype.DM = ((1<<dbits)-1);
BigInteger$2.prototype.DV = (1<<dbits);

var BI_FP = 52;
BigInteger$2.prototype.FV = Math.pow(2,BI_FP);
BigInteger$2.prototype.F1 = BI_FP-dbits;
BigInteger$2.prototype.F2 = 2*dbits-BI_FP;

// Digit conversions
var BI_RM = "0123456789abcdefghijklmnopqrstuvwxyz";
var BI_RC = new Array();
var rr,vv;
rr = "0".charCodeAt(0);
for(vv = 0; vv <= 9; ++vv) BI_RC[rr++] = vv;
rr = "a".charCodeAt(0);
for(vv = 10; vv < 36; ++vv) BI_RC[rr++] = vv;
rr = "A".charCodeAt(0);
for(vv = 10; vv < 36; ++vv) BI_RC[rr++] = vv;

function int2char(n) { return BI_RM.charAt(n); }
function intAt(s,i) {
  var c = BI_RC[s.charCodeAt(i)];
  return (c==null)?-1:c;
}

// (protected) copy this to r
function bnpCopyTo(r) {
  for(var i = this.t-1; i >= 0; --i) r.data[i] = this.data[i];
  r.t = this.t;
  r.s = this.s;
}

// (protected) set from integer value x, -DV <= x < DV
function bnpFromInt(x) {
  this.t = 1;
  this.s = (x<0)?-1:0;
  if(x > 0) this.data[0] = x;
  else if(x < -1) this.data[0] = x+this.DV;
  else this.t = 0;
}

// return bigint initialized to value
function nbv(i) { var r = nbi(); r.fromInt(i); return r; }

// (protected) set from string and radix
function bnpFromString(s,b) {
  var k;
  if(b == 16) k = 4;
  else if(b == 8) k = 3;
  else if(b == 256) k = 8; // byte array
  else if(b == 2) k = 1;
  else if(b == 32) k = 5;
  else if(b == 4) k = 2;
  else { this.fromRadix(s,b); return; }
  this.t = 0;
  this.s = 0;
  var i = s.length, mi = false, sh = 0;
  while(--i >= 0) {
    var x = (k==8)?s[i]&0xff:intAt(s,i);
    if(x < 0) {
      if(s.charAt(i) == "-") mi = true;
      continue;
    }
    mi = false;
    if(sh == 0)
      this.data[this.t++] = x;
    else if(sh+k > this.DB) {
      this.data[this.t-1] |= (x&((1<<(this.DB-sh))-1))<<sh;
      this.data[this.t++] = (x>>(this.DB-sh));
    } else
      this.data[this.t-1] |= x<<sh;
    sh += k;
    if(sh >= this.DB) sh -= this.DB;
  }
  if(k == 8 && (s[0]&0x80) != 0) {
    this.s = -1;
    if(sh > 0) this.data[this.t-1] |= ((1<<(this.DB-sh))-1)<<sh;
  }
  this.clamp();
  if(mi) BigInteger$2.ZERO.subTo(this,this);
}

// (protected) clamp off excess high words
function bnpClamp() {
  var c = this.s&this.DM;
  while(this.t > 0 && this.data[this.t-1] == c) --this.t;
}

// (public) return string representation in given radix
function bnToString(b) {
  if(this.s < 0) return "-"+this.negate().toString(b);
  var k;
  if(b == 16) k = 4;
  else if(b == 8) k = 3;
  else if(b == 2) k = 1;
  else if(b == 32) k = 5;
  else if(b == 4) k = 2;
  else return this.toRadix(b);
  var km = (1<<k)-1, d, m = false, r = "", i = this.t;
  var p = this.DB-(i*this.DB)%k;
  if(i-- > 0) {
    if(p < this.DB && (d = this.data[i]>>p) > 0) { m = true; r = int2char(d); }
    while(i >= 0) {
      if(p < k) {
        d = (this.data[i]&((1<<p)-1))<<(k-p);
        d |= this.data[--i]>>(p+=this.DB-k);
      } else {
        d = (this.data[i]>>(p-=k))&km;
        if(p <= 0) { p += this.DB; --i; }
      }
      if(d > 0) m = true;
      if(m) r += int2char(d);
    }
  }
  return m?r:"0";
}

// (public) -this
function bnNegate() { var r = nbi(); BigInteger$2.ZERO.subTo(this,r); return r; }

// (public) |this|
function bnAbs() { return (this.s<0)?this.negate():this; }

// (public) return + if this > a, - if this < a, 0 if equal
function bnCompareTo(a) {
  var r = this.s-a.s;
  if(r != 0) return r;
  var i = this.t;
  r = i-a.t;
  if(r != 0) return (this.s<0)?-r:r;
  while(--i >= 0) if((r=this.data[i]-a.data[i]) != 0) return r;
  return 0;
}

// returns bit length of the integer x
function nbits(x) {
  var r = 1, t;
  if((t=x>>>16) != 0) { x = t; r += 16; }
  if((t=x>>8) != 0) { x = t; r += 8; }
  if((t=x>>4) != 0) { x = t; r += 4; }
  if((t=x>>2) != 0) { x = t; r += 2; }
  if((t=x>>1) != 0) { x = t; r += 1; }
  return r;
}

// (public) return the number of bits in "this"
function bnBitLength() {
  if(this.t <= 0) return 0;
  return this.DB*(this.t-1)+nbits(this.data[this.t-1]^(this.s&this.DM));
}

// (protected) r = this << n*DB
function bnpDLShiftTo(n,r) {
  var i;
  for(i = this.t-1; i >= 0; --i) r.data[i+n] = this.data[i];
  for(i = n-1; i >= 0; --i) r.data[i] = 0;
  r.t = this.t+n;
  r.s = this.s;
}

// (protected) r = this >> n*DB
function bnpDRShiftTo(n,r) {
  for(var i = n; i < this.t; ++i) r.data[i-n] = this.data[i];
  r.t = Math.max(this.t-n,0);
  r.s = this.s;
}

// (protected) r = this << n
function bnpLShiftTo(n,r) {
  var bs = n%this.DB;
  var cbs = this.DB-bs;
  var bm = (1<<cbs)-1;
  var ds = Math.floor(n/this.DB), c = (this.s<<bs)&this.DM, i;
  for(i = this.t-1; i >= 0; --i) {
    r.data[i+ds+1] = (this.data[i]>>cbs)|c;
    c = (this.data[i]&bm)<<bs;
  }
  for(i = ds-1; i >= 0; --i) r.data[i] = 0;
  r.data[ds] = c;
  r.t = this.t+ds+1;
  r.s = this.s;
  r.clamp();
}

// (protected) r = this >> n
function bnpRShiftTo(n,r) {
  r.s = this.s;
  var ds = Math.floor(n/this.DB);
  if(ds >= this.t) { r.t = 0; return; }
  var bs = n%this.DB;
  var cbs = this.DB-bs;
  var bm = (1<<bs)-1;
  r.data[0] = this.data[ds]>>bs;
  for(var i = ds+1; i < this.t; ++i) {
    r.data[i-ds-1] |= (this.data[i]&bm)<<cbs;
    r.data[i-ds] = this.data[i]>>bs;
  }
  if(bs > 0) r.data[this.t-ds-1] |= (this.s&bm)<<cbs;
  r.t = this.t-ds;
  r.clamp();
}

// (protected) r = this - a
function bnpSubTo(a,r) {
  var i = 0, c = 0, m = Math.min(a.t,this.t);
  while(i < m) {
    c += this.data[i]-a.data[i];
    r.data[i++] = c&this.DM;
    c >>= this.DB;
  }
  if(a.t < this.t) {
    c -= a.s;
    while(i < this.t) {
      c += this.data[i];
      r.data[i++] = c&this.DM;
      c >>= this.DB;
    }
    c += this.s;
  } else {
    c += this.s;
    while(i < a.t) {
      c -= a.data[i];
      r.data[i++] = c&this.DM;
      c >>= this.DB;
    }
    c -= a.s;
  }
  r.s = (c<0)?-1:0;
  if(c < -1) r.data[i++] = this.DV+c;
  else if(c > 0) r.data[i++] = c;
  r.t = i;
  r.clamp();
}

// (protected) r = this * a, r != this,a (HAC 14.12)
// "this" should be the larger one if appropriate.
function bnpMultiplyTo(a,r) {
  var x = this.abs(), y = a.abs();
  var i = x.t;
  r.t = i+y.t;
  while(--i >= 0) r.data[i] = 0;
  for(i = 0; i < y.t; ++i) r.data[i+x.t] = x.am(0,y.data[i],r,i,0,x.t);
  r.s = 0;
  r.clamp();
  if(this.s != a.s) BigInteger$2.ZERO.subTo(r,r);
}

// (protected) r = this^2, r != this (HAC 14.16)
function bnpSquareTo(r) {
  var x = this.abs();
  var i = r.t = 2*x.t;
  while(--i >= 0) r.data[i] = 0;
  for(i = 0; i < x.t-1; ++i) {
    var c = x.am(i,x.data[i],r,2*i,0,1);
    if((r.data[i+x.t]+=x.am(i+1,2*x.data[i],r,2*i+1,c,x.t-i-1)) >= x.DV) {
      r.data[i+x.t] -= x.DV;
      r.data[i+x.t+1] = 1;
    }
  }
  if(r.t > 0) r.data[r.t-1] += x.am(i,x.data[i],r,2*i,0,1);
  r.s = 0;
  r.clamp();
}

// (protected) divide this by m, quotient and remainder to q, r (HAC 14.20)
// r != q, this != m.  q or r may be null.
function bnpDivRemTo(m,q,r) {
  var pm = m.abs();
  if(pm.t <= 0) return;
  var pt = this.abs();
  if(pt.t < pm.t) {
    if(q != null) q.fromInt(0);
    if(r != null) this.copyTo(r);
    return;
  }
  if(r == null) r = nbi();
  var y = nbi(), ts = this.s, ms = m.s;
  var nsh = this.DB-nbits(pm.data[pm.t-1]);	// normalize modulus
  if(nsh > 0) { pm.lShiftTo(nsh,y); pt.lShiftTo(nsh,r); } else { pm.copyTo(y); pt.copyTo(r); }
  var ys = y.t;
  var y0 = y.data[ys-1];
  if(y0 == 0) return;
  var yt = y0*(1<<this.F1)+((ys>1)?y.data[ys-2]>>this.F2:0);
  var d1 = this.FV/yt, d2 = (1<<this.F1)/yt, e = 1<<this.F2;
  var i = r.t, j = i-ys, t = (q==null)?nbi():q;
  y.dlShiftTo(j,t);
  if(r.compareTo(t) >= 0) {
    r.data[r.t++] = 1;
    r.subTo(t,r);
  }
  BigInteger$2.ONE.dlShiftTo(ys,t);
  t.subTo(y,y);	// "negative" y so we can replace sub with am later
  while(y.t < ys) y.data[y.t++] = 0;
  while(--j >= 0) {
    // Estimate quotient digit
    var qd = (r.data[--i]==y0)?this.DM:Math.floor(r.data[i]*d1+(r.data[i-1]+e)*d2);
    if((r.data[i]+=y.am(0,qd,r,j,0,ys)) < qd) {	// Try it out
      y.dlShiftTo(j,t);
      r.subTo(t,r);
      while(r.data[i] < --qd) r.subTo(t,r);
    }
  }
  if(q != null) {
    r.drShiftTo(ys,q);
    if(ts != ms) BigInteger$2.ZERO.subTo(q,q);
  }
  r.t = ys;
  r.clamp();
  if(nsh > 0) r.rShiftTo(nsh,r);	// Denormalize remainder
  if(ts < 0) BigInteger$2.ZERO.subTo(r,r);
}

// (public) this mod a
function bnMod(a) {
  var r = nbi();
  this.abs().divRemTo(a,null,r);
  if(this.s < 0 && r.compareTo(BigInteger$2.ZERO) > 0) a.subTo(r,r);
  return r;
}

// Modular reduction using "classic" algorithm
function Classic(m) { this.m = m; }
function cConvert(x) {
  if(x.s < 0 || x.compareTo(this.m) >= 0) return x.mod(this.m);
  else return x;
}
function cRevert(x) { return x; }
function cReduce(x) { x.divRemTo(this.m,null,x); }
function cMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }
function cSqrTo(x,r) { x.squareTo(r); this.reduce(r); }

Classic.prototype.convert = cConvert;
Classic.prototype.revert = cRevert;
Classic.prototype.reduce = cReduce;
Classic.prototype.mulTo = cMulTo;
Classic.prototype.sqrTo = cSqrTo;

// (protected) return "-1/this % 2^DB"; useful for Mont. reduction
// justification:
//         xy == 1 (mod m)
//         xy =  1+km
//   xy(2-xy) = (1+km)(1-km)
// x[y(2-xy)] = 1-k^2m^2
// x[y(2-xy)] == 1 (mod m^2)
// if y is 1/x mod m, then y(2-xy) is 1/x mod m^2
// should reduce x and y(2-xy) by m^2 at each step to keep size bounded.
// JS multiply "overflows" differently from C/C++, so care is needed here.
function bnpInvDigit() {
  if(this.t < 1) return 0;
  var x = this.data[0];
  if((x&1) == 0) return 0;
  var y = x&3;		// y == 1/x mod 2^2
  y = (y*(2-(x&0xf)*y))&0xf;	// y == 1/x mod 2^4
  y = (y*(2-(x&0xff)*y))&0xff;	// y == 1/x mod 2^8
  y = (y*(2-(((x&0xffff)*y)&0xffff)))&0xffff;	// y == 1/x mod 2^16
  // last step - calculate inverse mod DV directly;
  // assumes 16 < DB <= 32 and assumes ability to handle 48-bit ints
  y = (y*(2-x*y%this.DV))%this.DV;		// y == 1/x mod 2^dbits
  // we really want the negative inverse, and -DV < y < DV
  return (y>0)?this.DV-y:-y;
}

// Montgomery reduction
function Montgomery(m) {
  this.m = m;
  this.mp = m.invDigit();
  this.mpl = this.mp&0x7fff;
  this.mph = this.mp>>15;
  this.um = (1<<(m.DB-15))-1;
  this.mt2 = 2*m.t;
}

// xR mod m
function montConvert(x) {
  var r = nbi();
  x.abs().dlShiftTo(this.m.t,r);
  r.divRemTo(this.m,null,r);
  if(x.s < 0 && r.compareTo(BigInteger$2.ZERO) > 0) this.m.subTo(r,r);
  return r;
}

// x/R mod m
function montRevert(x) {
  var r = nbi();
  x.copyTo(r);
  this.reduce(r);
  return r;
}

// x = x/R mod m (HAC 14.32)
function montReduce(x) {
  while(x.t <= this.mt2)	// pad x so am has enough room later
    x.data[x.t++] = 0;
  for(var i = 0; i < this.m.t; ++i) {
    // faster way of calculating u0 = x.data[i]*mp mod DV
    var j = x.data[i]&0x7fff;
    var u0 = (j*this.mpl+(((j*this.mph+(x.data[i]>>15)*this.mpl)&this.um)<<15))&x.DM;
    // use am to combine the multiply-shift-add into one call
    j = i+this.m.t;
    x.data[j] += this.m.am(0,u0,x,i,0,this.m.t);
    // propagate carry
    while(x.data[j] >= x.DV) { x.data[j] -= x.DV; x.data[++j]++; }
  }
  x.clamp();
  x.drShiftTo(this.m.t,x);
  if(x.compareTo(this.m) >= 0) x.subTo(this.m,x);
}

// r = "x^2/R mod m"; x != r
function montSqrTo(x,r) { x.squareTo(r); this.reduce(r); }

// r = "xy/R mod m"; x,y != r
function montMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }

Montgomery.prototype.convert = montConvert;
Montgomery.prototype.revert = montRevert;
Montgomery.prototype.reduce = montReduce;
Montgomery.prototype.mulTo = montMulTo;
Montgomery.prototype.sqrTo = montSqrTo;

// (protected) true iff this is even
function bnpIsEven() { return ((this.t>0)?(this.data[0]&1):this.s) == 0; }

// (protected) this^e, e < 2^32, doing sqr and mul with "r" (HAC 14.79)
function bnpExp(e,z) {
  if(e > 0xffffffff || e < 1) return BigInteger$2.ONE;
  var r = nbi(), r2 = nbi(), g = z.convert(this), i = nbits(e)-1;
  g.copyTo(r);
  while(--i >= 0) {
    z.sqrTo(r,r2);
    if((e&(1<<i)) > 0) z.mulTo(r2,g,r);
    else { var t = r; r = r2; r2 = t; }
  }
  return z.revert(r);
}

// (public) this^e % m, 0 <= e < 2^32
function bnModPowInt(e,m) {
  var z;
  if(e < 256 || m.isEven()) z = new Classic(m); else z = new Montgomery(m);
  return this.exp(e,z);
}

// protected
BigInteger$2.prototype.copyTo = bnpCopyTo;
BigInteger$2.prototype.fromInt = bnpFromInt;
BigInteger$2.prototype.fromString = bnpFromString;
BigInteger$2.prototype.clamp = bnpClamp;
BigInteger$2.prototype.dlShiftTo = bnpDLShiftTo;
BigInteger$2.prototype.drShiftTo = bnpDRShiftTo;
BigInteger$2.prototype.lShiftTo = bnpLShiftTo;
BigInteger$2.prototype.rShiftTo = bnpRShiftTo;
BigInteger$2.prototype.subTo = bnpSubTo;
BigInteger$2.prototype.multiplyTo = bnpMultiplyTo;
BigInteger$2.prototype.squareTo = bnpSquareTo;
BigInteger$2.prototype.divRemTo = bnpDivRemTo;
BigInteger$2.prototype.invDigit = bnpInvDigit;
BigInteger$2.prototype.isEven = bnpIsEven;
BigInteger$2.prototype.exp = bnpExp;

// public
BigInteger$2.prototype.toString = bnToString;
BigInteger$2.prototype.negate = bnNegate;
BigInteger$2.prototype.abs = bnAbs;
BigInteger$2.prototype.compareTo = bnCompareTo;
BigInteger$2.prototype.bitLength = bnBitLength;
BigInteger$2.prototype.mod = bnMod;
BigInteger$2.prototype.modPowInt = bnModPowInt;

// "constants"
BigInteger$2.ZERO = nbv(0);
BigInteger$2.ONE = nbv(1);

// jsbn2 lib

//Copyright (c) 2005-2009  Tom Wu
//All Rights Reserved.
//See "LICENSE" for details (See jsbn.js for LICENSE).

//Extended JavaScript BN functions, required for RSA private ops.

//Version 1.1: new BigInteger("0", 10) returns "proper" zero

//(public)
function bnClone() { var r = nbi(); this.copyTo(r); return r; }

//(public) return value as integer
function bnIntValue() {
if(this.s < 0) {
 if(this.t == 1) return this.data[0]-this.DV;
 else if(this.t == 0) return -1;
} else if(this.t == 1) return this.data[0];
else if(this.t == 0) return 0;
// assumes 16 < DB < 32
return ((this.data[1]&((1<<(32-this.DB))-1))<<this.DB)|this.data[0];
}

//(public) return value as byte
function bnByteValue() { return (this.t==0)?this.s:(this.data[0]<<24)>>24; }

//(public) return value as short (assumes DB>=16)
function bnShortValue() { return (this.t==0)?this.s:(this.data[0]<<16)>>16; }

//(protected) return x s.t. r^x < DV
function bnpChunkSize(r) { return Math.floor(Math.LN2*this.DB/Math.log(r)); }

//(public) 0 if this == 0, 1 if this > 0
function bnSigNum() {
if(this.s < 0) return -1;
else if(this.t <= 0 || (this.t == 1 && this.data[0] <= 0)) return 0;
else return 1;
}

//(protected) convert to radix string
function bnpToRadix(b) {
if(b == null) b = 10;
if(this.signum() == 0 || b < 2 || b > 36) return "0";
var cs = this.chunkSize(b);
var a = Math.pow(b,cs);
var d = nbv(a), y = nbi(), z = nbi(), r = "";
this.divRemTo(d,y,z);
while(y.signum() > 0) {
 r = (a+z.intValue()).toString(b).substr(1) + r;
 y.divRemTo(d,y,z);
}
return z.intValue().toString(b) + r;
}

//(protected) convert from radix string
function bnpFromRadix(s,b) {
this.fromInt(0);
if(b == null) b = 10;
var cs = this.chunkSize(b);
var d = Math.pow(b,cs), mi = false, j = 0, w = 0;
for(var i = 0; i < s.length; ++i) {
 var x = intAt(s,i);
 if(x < 0) {
   if(s.charAt(i) == "-" && this.signum() == 0) mi = true;
   continue;
 }
 w = b*w+x;
 if(++j >= cs) {
   this.dMultiply(d);
   this.dAddOffset(w,0);
   j = 0;
   w = 0;
 }
}
if(j > 0) {
 this.dMultiply(Math.pow(b,j));
 this.dAddOffset(w,0);
}
if(mi) BigInteger$2.ZERO.subTo(this,this);
}

//(protected) alternate constructor
function bnpFromNumber(a,b,c) {
if("number" == typeof b) {
 // new BigInteger(int,int,RNG)
 if(a < 2) this.fromInt(1);
 else {
   this.fromNumber(a,c);
   if(!this.testBit(a-1))  // force MSB set
     this.bitwiseTo(BigInteger$2.ONE.shiftLeft(a-1),op_or,this);
   if(this.isEven()) this.dAddOffset(1,0); // force odd
   while(!this.isProbablePrime(b)) {
     this.dAddOffset(2,0);
     if(this.bitLength() > a) this.subTo(BigInteger$2.ONE.shiftLeft(a-1),this);
   }
 }
} else {
 // new BigInteger(int,RNG)
 var x = new Array(), t = a&7;
 x.length = (a>>3)+1;
 b.nextBytes(x);
 if(t > 0) x[0] &= ((1<<t)-1); else x[0] = 0;
 this.fromString(x,256);
}
}

//(public) convert to bigendian byte array
function bnToByteArray() {
var i = this.t, r = new Array();
r[0] = this.s;
var p = this.DB-(i*this.DB)%8, d, k = 0;
if(i-- > 0) {
 if(p < this.DB && (d = this.data[i]>>p) != (this.s&this.DM)>>p)
   r[k++] = d|(this.s<<(this.DB-p));
 while(i >= 0) {
   if(p < 8) {
     d = (this.data[i]&((1<<p)-1))<<(8-p);
     d |= this.data[--i]>>(p+=this.DB-8);
   } else {
     d = (this.data[i]>>(p-=8))&0xff;
     if(p <= 0) { p += this.DB; --i; }
   }
   if((d&0x80) != 0) d |= -256;
   if(k == 0 && (this.s&0x80) != (d&0x80)) ++k;
   if(k > 0 || d != this.s) r[k++] = d;
 }
}
return r;
}

function bnEquals(a) { return(this.compareTo(a)==0); }
function bnMin(a) { return (this.compareTo(a)<0)?this:a; }
function bnMax(a) { return (this.compareTo(a)>0)?this:a; }

//(protected) r = this op a (bitwise)
function bnpBitwiseTo(a,op,r) {
var i, f, m = Math.min(a.t,this.t);
for(i = 0; i < m; ++i) r.data[i] = op(this.data[i],a.data[i]);
if(a.t < this.t) {
 f = a.s&this.DM;
 for(i = m; i < this.t; ++i) r.data[i] = op(this.data[i],f);
 r.t = this.t;
} else {
 f = this.s&this.DM;
 for(i = m; i < a.t; ++i) r.data[i] = op(f,a.data[i]);
 r.t = a.t;
}
r.s = op(this.s,a.s);
r.clamp();
}

//(public) this & a
function op_and(x,y) { return x&y; }
function bnAnd(a) { var r = nbi(); this.bitwiseTo(a,op_and,r); return r; }

//(public) this | a
function op_or(x,y) { return x|y; }
function bnOr(a) { var r = nbi(); this.bitwiseTo(a,op_or,r); return r; }

//(public) this ^ a
function op_xor(x,y) { return x^y; }
function bnXor(a) { var r = nbi(); this.bitwiseTo(a,op_xor,r); return r; }

//(public) this & ~a
function op_andnot(x,y) { return x&~y; }
function bnAndNot(a) { var r = nbi(); this.bitwiseTo(a,op_andnot,r); return r; }

//(public) ~this
function bnNot() {
var r = nbi();
for(var i = 0; i < this.t; ++i) r.data[i] = this.DM&~this.data[i];
r.t = this.t;
r.s = ~this.s;
return r;
}

//(public) this << n
function bnShiftLeft(n) {
var r = nbi();
if(n < 0) this.rShiftTo(-n,r); else this.lShiftTo(n,r);
return r;
}

//(public) this >> n
function bnShiftRight(n) {
var r = nbi();
if(n < 0) this.lShiftTo(-n,r); else this.rShiftTo(n,r);
return r;
}

//return index of lowest 1-bit in x, x < 2^31
function lbit(x) {
if(x == 0) return -1;
var r = 0;
if((x&0xffff) == 0) { x >>= 16; r += 16; }
if((x&0xff) == 0) { x >>= 8; r += 8; }
if((x&0xf) == 0) { x >>= 4; r += 4; }
if((x&3) == 0) { x >>= 2; r += 2; }
if((x&1) == 0) ++r;
return r;
}

//(public) returns index of lowest 1-bit (or -1 if none)
function bnGetLowestSetBit() {
for(var i = 0; i < this.t; ++i)
 if(this.data[i] != 0) return i*this.DB+lbit(this.data[i]);
if(this.s < 0) return this.t*this.DB;
return -1;
}

//return number of 1 bits in x
function cbit(x) {
var r = 0;
while(x != 0) { x &= x-1; ++r; }
return r;
}

//(public) return number of set bits
function bnBitCount() {
var r = 0, x = this.s&this.DM;
for(var i = 0; i < this.t; ++i) r += cbit(this.data[i]^x);
return r;
}

//(public) true iff nth bit is set
function bnTestBit(n) {
var j = Math.floor(n/this.DB);
if(j >= this.t) return(this.s!=0);
return((this.data[j]&(1<<(n%this.DB)))!=0);
}

//(protected) this op (1<<n)
function bnpChangeBit(n,op) {
var r = BigInteger$2.ONE.shiftLeft(n);
this.bitwiseTo(r,op,r);
return r;
}

//(public) this | (1<<n)
function bnSetBit(n) { return this.changeBit(n,op_or); }

//(public) this & ~(1<<n)
function bnClearBit(n) { return this.changeBit(n,op_andnot); }

//(public) this ^ (1<<n)
function bnFlipBit(n) { return this.changeBit(n,op_xor); }

//(protected) r = this + a
function bnpAddTo(a,r) {
var i = 0, c = 0, m = Math.min(a.t,this.t);
while(i < m) {
 c += this.data[i]+a.data[i];
 r.data[i++] = c&this.DM;
 c >>= this.DB;
}
if(a.t < this.t) {
 c += a.s;
 while(i < this.t) {
   c += this.data[i];
   r.data[i++] = c&this.DM;
   c >>= this.DB;
 }
 c += this.s;
} else {
 c += this.s;
 while(i < a.t) {
   c += a.data[i];
   r.data[i++] = c&this.DM;
   c >>= this.DB;
 }
 c += a.s;
}
r.s = (c<0)?-1:0;
if(c > 0) r.data[i++] = c;
else if(c < -1) r.data[i++] = this.DV+c;
r.t = i;
r.clamp();
}

//(public) this + a
function bnAdd(a) { var r = nbi(); this.addTo(a,r); return r; }

//(public) this - a
function bnSubtract(a) { var r = nbi(); this.subTo(a,r); return r; }

//(public) this * a
function bnMultiply(a) { var r = nbi(); this.multiplyTo(a,r); return r; }

//(public) this / a
function bnDivide(a) { var r = nbi(); this.divRemTo(a,r,null); return r; }

//(public) this % a
function bnRemainder(a) { var r = nbi(); this.divRemTo(a,null,r); return r; }

//(public) [this/a,this%a]
function bnDivideAndRemainder(a) {
var q = nbi(), r = nbi();
this.divRemTo(a,q,r);
return new Array(q,r);
}

//(protected) this *= n, this >= 0, 1 < n < DV
function bnpDMultiply(n) {
this.data[this.t] = this.am(0,n-1,this,0,0,this.t);
++this.t;
this.clamp();
}

//(protected) this += n << w words, this >= 0
function bnpDAddOffset(n,w) {
if(n == 0) return;
while(this.t <= w) this.data[this.t++] = 0;
this.data[w] += n;
while(this.data[w] >= this.DV) {
 this.data[w] -= this.DV;
 if(++w >= this.t) this.data[this.t++] = 0;
 ++this.data[w];
}
}

//A "null" reducer
function NullExp() {}
function nNop(x) { return x; }
function nMulTo(x,y,r) { x.multiplyTo(y,r); }
function nSqrTo(x,r) { x.squareTo(r); }

NullExp.prototype.convert = nNop;
NullExp.prototype.revert = nNop;
NullExp.prototype.mulTo = nMulTo;
NullExp.prototype.sqrTo = nSqrTo;

//(public) this^e
function bnPow(e) { return this.exp(e,new NullExp()); }

//(protected) r = lower n words of "this * a", a.t <= n
//"this" should be the larger one if appropriate.
function bnpMultiplyLowerTo(a,n,r) {
var i = Math.min(this.t+a.t,n);
r.s = 0; // assumes a,this >= 0
r.t = i;
while(i > 0) r.data[--i] = 0;
var j;
for(j = r.t-this.t; i < j; ++i) r.data[i+this.t] = this.am(0,a.data[i],r,i,0,this.t);
for(j = Math.min(a.t,n); i < j; ++i) this.am(0,a.data[i],r,i,0,n-i);
r.clamp();
}

//(protected) r = "this * a" without lower n words, n > 0
//"this" should be the larger one if appropriate.
function bnpMultiplyUpperTo(a,n,r) {
--n;
var i = r.t = this.t+a.t-n;
r.s = 0; // assumes a,this >= 0
while(--i >= 0) r.data[i] = 0;
for(i = Math.max(n-this.t,0); i < a.t; ++i)
 r.data[this.t+i-n] = this.am(n-i,a.data[i],r,0,0,this.t+i-n);
r.clamp();
r.drShiftTo(1,r);
}

//Barrett modular reduction
function Barrett(m) {
// setup Barrett
this.r2 = nbi();
this.q3 = nbi();
BigInteger$2.ONE.dlShiftTo(2*m.t,this.r2);
this.mu = this.r2.divide(m);
this.m = m;
}

function barrettConvert(x) {
if(x.s < 0 || x.t > 2*this.m.t) return x.mod(this.m);
else if(x.compareTo(this.m) < 0) return x;
else { var r = nbi(); x.copyTo(r); this.reduce(r); return r; }
}

function barrettRevert(x) { return x; }

//x = x mod m (HAC 14.42)
function barrettReduce(x) {
x.drShiftTo(this.m.t-1,this.r2);
if(x.t > this.m.t+1) { x.t = this.m.t+1; x.clamp(); }
this.mu.multiplyUpperTo(this.r2,this.m.t+1,this.q3);
this.m.multiplyLowerTo(this.q3,this.m.t+1,this.r2);
while(x.compareTo(this.r2) < 0) x.dAddOffset(1,this.m.t+1);
x.subTo(this.r2,x);
while(x.compareTo(this.m) >= 0) x.subTo(this.m,x);
}

//r = x^2 mod m; x != r
function barrettSqrTo(x,r) { x.squareTo(r); this.reduce(r); }

//r = x*y mod m; x,y != r
function barrettMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }

Barrett.prototype.convert = barrettConvert;
Barrett.prototype.revert = barrettRevert;
Barrett.prototype.reduce = barrettReduce;
Barrett.prototype.mulTo = barrettMulTo;
Barrett.prototype.sqrTo = barrettSqrTo;

//(public) this^e % m (HAC 14.85)
function bnModPow(e,m) {
var i = e.bitLength(), k, r = nbv(1), z;
if(i <= 0) return r;
else if(i < 18) k = 1;
else if(i < 48) k = 3;
else if(i < 144) k = 4;
else if(i < 768) k = 5;
else k = 6;
if(i < 8)
 z = new Classic(m);
else if(m.isEven())
 z = new Barrett(m);
else
 z = new Montgomery(m);

// precomputation
var g = new Array(), n = 3, k1 = k-1, km = (1<<k)-1;
g[1] = z.convert(this);
if(k > 1) {
 var g2 = nbi();
 z.sqrTo(g[1],g2);
 while(n <= km) {
   g[n] = nbi();
   z.mulTo(g2,g[n-2],g[n]);
   n += 2;
 }
}

var j = e.t-1, w, is1 = true, r2 = nbi(), t;
i = nbits(e.data[j])-1;
while(j >= 0) {
 if(i >= k1) w = (e.data[j]>>(i-k1))&km;
 else {
   w = (e.data[j]&((1<<(i+1))-1))<<(k1-i);
   if(j > 0) w |= e.data[j-1]>>(this.DB+i-k1);
 }

 n = k;
 while((w&1) == 0) { w >>= 1; --n; }
 if((i -= n) < 0) { i += this.DB; --j; }
 if(is1) {  // ret == 1, don't bother squaring or multiplying it
   g[w].copyTo(r);
   is1 = false;
 } else {
   while(n > 1) { z.sqrTo(r,r2); z.sqrTo(r2,r); n -= 2; }
   if(n > 0) z.sqrTo(r,r2); else { t = r; r = r2; r2 = t; }
   z.mulTo(r2,g[w],r);
 }

 while(j >= 0 && (e.data[j]&(1<<i)) == 0) {
   z.sqrTo(r,r2); t = r; r = r2; r2 = t;
   if(--i < 0) { i = this.DB-1; --j; }
 }
}
return z.revert(r);
}

//(public) gcd(this,a) (HAC 14.54)
function bnGCD(a) {
var x = (this.s<0)?this.negate():this.clone();
var y = (a.s<0)?a.negate():a.clone();
if(x.compareTo(y) < 0) { var t = x; x = y; y = t; }
var i = x.getLowestSetBit(), g = y.getLowestSetBit();
if(g < 0) return x;
if(i < g) g = i;
if(g > 0) {
 x.rShiftTo(g,x);
 y.rShiftTo(g,y);
}
while(x.signum() > 0) {
 if((i = x.getLowestSetBit()) > 0) x.rShiftTo(i,x);
 if((i = y.getLowestSetBit()) > 0) y.rShiftTo(i,y);
 if(x.compareTo(y) >= 0) {
   x.subTo(y,x);
   x.rShiftTo(1,x);
 } else {
   y.subTo(x,y);
   y.rShiftTo(1,y);
 }
}
if(g > 0) y.lShiftTo(g,y);
return y;
}

//(protected) this % n, n < 2^26
function bnpModInt(n) {
if(n <= 0) return 0;
var d = this.DV%n, r = (this.s<0)?n-1:0;
if(this.t > 0)
 if(d == 0) r = this.data[0]%n;
 else for(var i = this.t-1; i >= 0; --i) r = (d*r+this.data[i])%n;
return r;
}

//(public) 1/this % m (HAC 14.61)
function bnModInverse(m) {
var ac = m.isEven();
if((this.isEven() && ac) || m.signum() == 0) return BigInteger$2.ZERO;
var u = m.clone(), v = this.clone();
var a = nbv(1), b = nbv(0), c = nbv(0), d = nbv(1);
while(u.signum() != 0) {
 while(u.isEven()) {
   u.rShiftTo(1,u);
   if(ac) {
     if(!a.isEven() || !b.isEven()) { a.addTo(this,a); b.subTo(m,b); }
     a.rShiftTo(1,a);
   } else if(!b.isEven()) b.subTo(m,b);
   b.rShiftTo(1,b);
 }
 while(v.isEven()) {
   v.rShiftTo(1,v);
   if(ac) {
     if(!c.isEven() || !d.isEven()) { c.addTo(this,c); d.subTo(m,d); }
     c.rShiftTo(1,c);
   } else if(!d.isEven()) d.subTo(m,d);
   d.rShiftTo(1,d);
 }
 if(u.compareTo(v) >= 0) {
   u.subTo(v,u);
   if(ac) a.subTo(c,a);
   b.subTo(d,b);
 } else {
   v.subTo(u,v);
   if(ac) c.subTo(a,c);
   d.subTo(b,d);
 }
}
if(v.compareTo(BigInteger$2.ONE) != 0) return BigInteger$2.ZERO;
if(d.compareTo(m) >= 0) return d.subtract(m);
if(d.signum() < 0) d.addTo(m,d); else return d;
if(d.signum() < 0) return d.add(m); else return d;
}

var lowprimes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,103,107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211,223,227,229,233,239,241,251,257,263,269,271,277,281,283,293,307,311,313,317,331,337,347,349,353,359,367,373,379,383,389,397,401,409,419,421,431,433,439,443,449,457,461,463,467,479,487,491,499,503,509];
var lplim = (1<<26)/lowprimes[lowprimes.length-1];

//(public) test primality with certainty >= 1-.5^t
function bnIsProbablePrime(t) {
var i, x = this.abs();
if(x.t == 1 && x.data[0] <= lowprimes[lowprimes.length-1]) {
 for(i = 0; i < lowprimes.length; ++i)
   if(x.data[0] == lowprimes[i]) return true;
 return false;
}
if(x.isEven()) return false;
i = 1;
while(i < lowprimes.length) {
 var m = lowprimes[i], j = i+1;
 while(j < lowprimes.length && m < lplim) m *= lowprimes[j++];
 m = x.modInt(m);
 while(i < j) if(m%lowprimes[i++] == 0) return false;
}
return x.millerRabin(t);
}

//(protected) true if probably prime (HAC 4.24, Miller-Rabin)
function bnpMillerRabin(t) {
var n1 = this.subtract(BigInteger$2.ONE);
var k = n1.getLowestSetBit();
if(k <= 0) return false;
var r = n1.shiftRight(k);
var prng = bnGetPrng();
var a;
for(var i = 0; i < t; ++i) {
 // select witness 'a' at random from between 1 and n1
 do {
   a = new BigInteger$2(this.bitLength(), prng);
 }
 while(a.compareTo(BigInteger$2.ONE) <= 0 || a.compareTo(n1) >= 0);
 var y = a.modPow(r,this);
 if(y.compareTo(BigInteger$2.ONE) != 0 && y.compareTo(n1) != 0) {
   var j = 1;
   while(j++ < k && y.compareTo(n1) != 0) {
     y = y.modPowInt(2,this);
     if(y.compareTo(BigInteger$2.ONE) == 0) return false;
   }
   if(y.compareTo(n1) != 0) return false;
 }
}
return true;
}

// get pseudo random number generator
function bnGetPrng() {
  // create prng with api that matches BigInteger secure random
  return {
    // x is an array to fill with bytes
    nextBytes: function(x) {
      for(var i = 0; i < x.length; ++i) {
        x[i] = Math.floor(Math.random() * 0x0100);
      }
    }
  };
}

//protected
BigInteger$2.prototype.chunkSize = bnpChunkSize;
BigInteger$2.prototype.toRadix = bnpToRadix;
BigInteger$2.prototype.fromRadix = bnpFromRadix;
BigInteger$2.prototype.fromNumber = bnpFromNumber;
BigInteger$2.prototype.bitwiseTo = bnpBitwiseTo;
BigInteger$2.prototype.changeBit = bnpChangeBit;
BigInteger$2.prototype.addTo = bnpAddTo;
BigInteger$2.prototype.dMultiply = bnpDMultiply;
BigInteger$2.prototype.dAddOffset = bnpDAddOffset;
BigInteger$2.prototype.multiplyLowerTo = bnpMultiplyLowerTo;
BigInteger$2.prototype.multiplyUpperTo = bnpMultiplyUpperTo;
BigInteger$2.prototype.modInt = bnpModInt;
BigInteger$2.prototype.millerRabin = bnpMillerRabin;

//public
BigInteger$2.prototype.clone = bnClone;
BigInteger$2.prototype.intValue = bnIntValue;
BigInteger$2.prototype.byteValue = bnByteValue;
BigInteger$2.prototype.shortValue = bnShortValue;
BigInteger$2.prototype.signum = bnSigNum;
BigInteger$2.prototype.toByteArray = bnToByteArray;
BigInteger$2.prototype.equals = bnEquals;
BigInteger$2.prototype.min = bnMin;
BigInteger$2.prototype.max = bnMax;
BigInteger$2.prototype.and = bnAnd;
BigInteger$2.prototype.or = bnOr;
BigInteger$2.prototype.xor = bnXor;
BigInteger$2.prototype.andNot = bnAndNot;
BigInteger$2.prototype.not = bnNot;
BigInteger$2.prototype.shiftLeft = bnShiftLeft;
BigInteger$2.prototype.shiftRight = bnShiftRight;
BigInteger$2.prototype.getLowestSetBit = bnGetLowestSetBit;
BigInteger$2.prototype.bitCount = bnBitCount;
BigInteger$2.prototype.testBit = bnTestBit;
BigInteger$2.prototype.setBit = bnSetBit;
BigInteger$2.prototype.clearBit = bnClearBit;
BigInteger$2.prototype.flipBit = bnFlipBit;
BigInteger$2.prototype.add = bnAdd;
BigInteger$2.prototype.subtract = bnSubtract;
BigInteger$2.prototype.multiply = bnMultiply;
BigInteger$2.prototype.divide = bnDivide;
BigInteger$2.prototype.remainder = bnRemainder;
BigInteger$2.prototype.divideAndRemainder = bnDivideAndRemainder;
BigInteger$2.prototype.modPow = bnModPow;
BigInteger$2.prototype.modInverse = bnModInverse;
BigInteger$2.prototype.pow = bnPow;
BigInteger$2.prototype.gcd = bnGCD;
BigInteger$2.prototype.isProbablePrime = bnIsProbablePrime;

/**
 * Secure Hash Algorithm with 160-bit digest (SHA-1) implementation.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2015 Digital Bazaar, Inc.
 */

var forge$b = forge$s;



var sha1 = forge$b.sha1 = forge$b.sha1 || {};
forge$b.md.sha1 = forge$b.md.algorithms.sha1 = sha1;

/**
 * Creates a SHA-1 message digest object.
 *
 * @return a message digest object.
 */
sha1.create = function() {
  // do initialization as necessary
  if(!_initialized$1) {
    _init$1();
  }

  // SHA-1 state contains five 32-bit integers
  var _state = null;

  // input buffer
  var _input = forge$b.util.createBuffer();

  // used for word storage
  var _w = new Array(80);

  // message digest object
  var md = {
    algorithm: 'sha1',
    blockLength: 64,
    digestLength: 20,
    // 56-bit length of message so far (does not including padding)
    messageLength: 0,
    // true message length
    fullMessageLength: null,
    // size of message length in bytes
    messageLengthSize: 8
  };

  /**
   * Starts the digest.
   *
   * @return this digest object.
   */
  md.start = function() {
    // up to 56-bit message length for convenience
    md.messageLength = 0;

    // full message length (set md.messageLength64 for backwards-compatibility)
    md.fullMessageLength = md.messageLength64 = [];
    var int32s = md.messageLengthSize / 4;
    for(var i = 0; i < int32s; ++i) {
      md.fullMessageLength.push(0);
    }
    _input = forge$b.util.createBuffer();
    _state = {
      h0: 0x67452301,
      h1: 0xEFCDAB89,
      h2: 0x98BADCFE,
      h3: 0x10325476,
      h4: 0xC3D2E1F0
    };
    return md;
  };
  // start digest automatically for first time
  md.start();

  /**
   * Updates the digest with the given message input. The given input can
   * treated as raw input (no encoding will be applied) or an encoding of
   * 'utf8' maybe given to encode the input using UTF-8.
   *
   * @param msg the message input to update with.
   * @param encoding the encoding to use (default: 'raw', other: 'utf8').
   *
   * @return this digest object.
   */
  md.update = function(msg, encoding) {
    if(encoding === 'utf8') {
      msg = forge$b.util.encodeUtf8(msg);
    }

    // update message length
    var len = msg.length;
    md.messageLength += len;
    len = [(len / 0x100000000) >>> 0, len >>> 0];
    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {
      md.fullMessageLength[i] += len[1];
      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);
      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;
      len[0] = ((len[1] / 0x100000000) >>> 0);
    }

    // add bytes to input buffer
    _input.putBytes(msg);

    // process bytes
    _update$1(_state, _w, _input);

    // compact input buffer every 2K or if empty
    if(_input.read > 2048 || _input.length() === 0) {
      _input.compact();
    }

    return md;
  };

  /**
   * Produces the digest.
   *
   * @return a byte buffer containing the digest value.
   */
  md.digest = function() {
    /* Note: Here we copy the remaining bytes in the input buffer and
    add the appropriate SHA-1 padding. Then we do the final update
    on a copy of the state so that if the user wants to get
    intermediate digests they can do so. */

    /* Determine the number of bytes that must be added to the message
    to ensure its length is congruent to 448 mod 512. In other words,
    the data to be digested must be a multiple of 512 bits (or 128 bytes).
    This data includes the message, some padding, and the length of the
    message. Since the length of the message will be encoded as 8 bytes (64
    bits), that means that the last segment of the data must have 56 bytes
    (448 bits) of message and padding. Therefore, the length of the message
    plus the padding must be congruent to 448 mod 512 because
    512 - 128 = 448.

    In order to fill up the message length it must be filled with
    padding that begins with 1 bit followed by all 0 bits. Padding
    must *always* be present, so if the message length is already
    congruent to 448 mod 512, then 512 padding bits must be added. */

    var finalBlock = forge$b.util.createBuffer();
    finalBlock.putBytes(_input.bytes());

    // compute remaining size to be digested (include message length size)
    var remaining = (
      md.fullMessageLength[md.fullMessageLength.length - 1] +
      md.messageLengthSize);

    // add padding for overflow blockSize - overflow
    // _padding starts with 1 byte with first bit is set (byte value 128), then
    // there may be up to (blockSize - 1) other pad bytes
    var overflow = remaining & (md.blockLength - 1);
    finalBlock.putBytes(_padding$1.substr(0, md.blockLength - overflow));

    // serialize message length in bits in big-endian order; since length
    // is stored in bytes we multiply by 8 and add carry from next int
    var next, carry;
    var bits = md.fullMessageLength[0] * 8;
    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {
      next = md.fullMessageLength[i + 1] * 8;
      carry = (next / 0x100000000) >>> 0;
      bits += carry;
      finalBlock.putInt32(bits >>> 0);
      bits = next >>> 0;
    }
    finalBlock.putInt32(bits);

    var s2 = {
      h0: _state.h0,
      h1: _state.h1,
      h2: _state.h2,
      h3: _state.h3,
      h4: _state.h4
    };
    _update$1(s2, _w, finalBlock);
    var rval = forge$b.util.createBuffer();
    rval.putInt32(s2.h0);
    rval.putInt32(s2.h1);
    rval.putInt32(s2.h2);
    rval.putInt32(s2.h3);
    rval.putInt32(s2.h4);
    return rval;
  };

  return md;
};

// sha-1 padding bytes not initialized yet
var _padding$1 = null;
var _initialized$1 = false;

/**
 * Initializes the constant tables.
 */
function _init$1() {
  // create padding
  _padding$1 = String.fromCharCode(128);
  _padding$1 += forge$b.util.fillString(String.fromCharCode(0x00), 64);

  // now initialized
  _initialized$1 = true;
}

/**
 * Updates a SHA-1 state with the given byte buffer.
 *
 * @param s the SHA-1 state to update.
 * @param w the array to use to store words.
 * @param bytes the byte buffer to update with.
 */
function _update$1(s, w, bytes) {
  // consume 512 bit (64 byte) chunks
  var t, a, b, c, d, e, f, i;
  var len = bytes.length();
  while(len >= 64) {
    // the w array will be populated with sixteen 32-bit big-endian words
    // and then extended into 80 32-bit words according to SHA-1 algorithm
    // and for 32-79 using Max Locktyukhin's optimization

    // initialize hash value for this chunk
    a = s.h0;
    b = s.h1;
    c = s.h2;
    d = s.h3;
    e = s.h4;

    // round 1
    for(i = 0; i < 16; ++i) {
      t = bytes.getInt32();
      w[i] = t;
      f = d ^ (b & (c ^ d));
      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    for(; i < 20; ++i) {
      t = (w[i - 3] ^ w[i - 8] ^ w[i - 14] ^ w[i - 16]);
      t = (t << 1) | (t >>> 31);
      w[i] = t;
      f = d ^ (b & (c ^ d));
      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    // round 2
    for(; i < 32; ++i) {
      t = (w[i - 3] ^ w[i - 8] ^ w[i - 14] ^ w[i - 16]);
      t = (t << 1) | (t >>> 31);
      w[i] = t;
      f = b ^ c ^ d;
      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    for(; i < 40; ++i) {
      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);
      t = (t << 2) | (t >>> 30);
      w[i] = t;
      f = b ^ c ^ d;
      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    // round 3
    for(; i < 60; ++i) {
      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);
      t = (t << 2) | (t >>> 30);
      w[i] = t;
      f = (b & c) | (d & (b ^ c));
      t = ((a << 5) | (a >>> 27)) + f + e + 0x8F1BBCDC + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    // round 4
    for(; i < 80; ++i) {
      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);
      t = (t << 2) | (t >>> 30);
      w[i] = t;
      f = b ^ c ^ d;
      t = ((a << 5) | (a >>> 27)) + f + e + 0xCA62C1D6 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }

    // update hash state
    s.h0 = (s.h0 + a) | 0;
    s.h1 = (s.h1 + b) | 0;
    s.h2 = (s.h2 + c) | 0;
    s.h3 = (s.h3 + d) | 0;
    s.h4 = (s.h4 + e) | 0;

    len -= 64;
  }
}

/**
 * Partial implementation of PKCS#1 v2.2: RSA-OEAP
 *
 * Modified but based on the following MIT and BSD licensed code:
 *
 * https://github.com/kjur/jsjws/blob/master/rsa.js:
 *
 * The 'jsjws'(JSON Web Signature JavaScript Library) License
 *
 * Copyright (c) 2012 Kenji Urushima
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 *
 * http://webrsa.cvs.sourceforge.net/viewvc/webrsa/Client/RSAES-OAEP.js?content-type=text%2Fplain:
 *
 * RSAES-OAEP.js
 * $Id: RSAES-OAEP.js,v 1.1.1.1 2003/03/19 15:37:20 ellispritchard Exp $
 * JavaScript Implementation of PKCS #1 v2.1 RSA CRYPTOGRAPHY STANDARD (RSA Laboratories, June 14, 2002)
 * Copyright (C) Ellis Pritchard, Guardian Unlimited 2003.
 * Contact: ellis@nukinetics.com
 * Distributed under the BSD License.
 *
 * Official documentation: http://www.rsa.com/rsalabs/node.asp?id=2125
 *
 * @author Evan Jones (http://evanjones.ca/)
 * @author Dave Longley
 *
 * Copyright (c) 2013-2014 Digital Bazaar, Inc.
 */

var forge$a = forge$s;




// shortcut for PKCS#1 API
var pkcs1 = forge$a.pkcs1 = forge$a.pkcs1 || {};

/**
 * Encode the given RSAES-OAEP message (M) using key, with optional label (L)
 * and seed.
 *
 * This method does not perform RSA encryption, it only encodes the message
 * using RSAES-OAEP.
 *
 * @param key the RSA key to use.
 * @param message the message to encode.
 * @param options the options to use:
 *          label an optional label to use.
 *          seed the seed to use.
 *          md the message digest object to use, undefined for SHA-1.
 *          mgf1 optional mgf1 parameters:
 *            md the message digest object to use for MGF1.
 *
 * @return the encoded message bytes.
 */
pkcs1.encode_rsa_oaep = function(key, message, options) {
  // parse arguments
  var label;
  var seed;
  var md;
  var mgf1Md;
  // legacy args (label, seed, md)
  if(typeof options === 'string') {
    label = options;
    seed = arguments[3] || undefined;
    md = arguments[4] || undefined;
  } else if(options) {
    label = options.label || undefined;
    seed = options.seed || undefined;
    md = options.md || undefined;
    if(options.mgf1 && options.mgf1.md) {
      mgf1Md = options.mgf1.md;
    }
  }

  // default OAEP to SHA-1 message digest
  if(!md) {
    md = forge$a.md.sha1.create();
  } else {
    md.start();
  }

  // default MGF-1 to same as OAEP
  if(!mgf1Md) {
    mgf1Md = md;
  }

  // compute length in bytes and check output
  var keyLength = Math.ceil(key.n.bitLength() / 8);
  var maxLength = keyLength - 2 * md.digestLength - 2;
  if(message.length > maxLength) {
    var error = new Error('RSAES-OAEP input message length is too long.');
    error.length = message.length;
    error.maxLength = maxLength;
    throw error;
  }

  if(!label) {
    label = '';
  }
  md.update(label, 'raw');
  var lHash = md.digest();

  var PS = '';
  var PS_length = maxLength - message.length;
  for(var i = 0; i < PS_length; i++) {
    PS += '\x00';
  }

  var DB = lHash.getBytes() + PS + '\x01' + message;

  if(!seed) {
    seed = forge$a.random.getBytes(md.digestLength);
  } else if(seed.length !== md.digestLength) {
    var error = new Error('Invalid RSAES-OAEP seed. The seed length must ' +
      'match the digest length.');
    error.seedLength = seed.length;
    error.digestLength = md.digestLength;
    throw error;
  }

  var dbMask = rsa_mgf1(seed, keyLength - md.digestLength - 1, mgf1Md);
  var maskedDB = forge$a.util.xorBytes(DB, dbMask, DB.length);

  var seedMask = rsa_mgf1(maskedDB, md.digestLength, mgf1Md);
  var maskedSeed = forge$a.util.xorBytes(seed, seedMask, seed.length);

  // return encoded message
  return '\x00' + maskedSeed + maskedDB;
};

/**
 * Decode the given RSAES-OAEP encoded message (EM) using key, with optional
 * label (L).
 *
 * This method does not perform RSA decryption, it only decodes the message
 * using RSAES-OAEP.
 *
 * @param key the RSA key to use.
 * @param em the encoded message to decode.
 * @param options the options to use:
 *          label an optional label to use.
 *          md the message digest object to use for OAEP, undefined for SHA-1.
 *          mgf1 optional mgf1 parameters:
 *            md the message digest object to use for MGF1.
 *
 * @return the decoded message bytes.
 */
pkcs1.decode_rsa_oaep = function(key, em, options) {
  // parse args
  var label;
  var md;
  var mgf1Md;
  // legacy args
  if(typeof options === 'string') {
    label = options;
    md = arguments[3] || undefined;
  } else if(options) {
    label = options.label || undefined;
    md = options.md || undefined;
    if(options.mgf1 && options.mgf1.md) {
      mgf1Md = options.mgf1.md;
    }
  }

  // compute length in bytes
  var keyLength = Math.ceil(key.n.bitLength() / 8);

  if(em.length !== keyLength) {
    var error = new Error('RSAES-OAEP encoded message length is invalid.');
    error.length = em.length;
    error.expectedLength = keyLength;
    throw error;
  }

  // default OAEP to SHA-1 message digest
  if(md === undefined) {
    md = forge$a.md.sha1.create();
  } else {
    md.start();
  }

  // default MGF-1 to same as OAEP
  if(!mgf1Md) {
    mgf1Md = md;
  }

  if(keyLength < 2 * md.digestLength + 2) {
    throw new Error('RSAES-OAEP key is too short for the hash function.');
  }

  if(!label) {
    label = '';
  }
  md.update(label, 'raw');
  var lHash = md.digest().getBytes();

  // split the message into its parts
  var y = em.charAt(0);
  var maskedSeed = em.substring(1, md.digestLength + 1);
  var maskedDB = em.substring(1 + md.digestLength);

  var seedMask = rsa_mgf1(maskedDB, md.digestLength, mgf1Md);
  var seed = forge$a.util.xorBytes(maskedSeed, seedMask, maskedSeed.length);

  var dbMask = rsa_mgf1(seed, keyLength - md.digestLength - 1, mgf1Md);
  var db = forge$a.util.xorBytes(maskedDB, dbMask, maskedDB.length);

  var lHashPrime = db.substring(0, md.digestLength);

  // constant time check that all values match what is expected
  var error = (y !== '\x00');

  // constant time check lHash vs lHashPrime
  for(var i = 0; i < md.digestLength; ++i) {
    error |= (lHash.charAt(i) !== lHashPrime.charAt(i));
  }

  // "constant time" find the 0x1 byte separating the padding (zeros) from the
  // message
  // TODO: It must be possible to do this in a better/smarter way?
  var in_ps = 1;
  var index = md.digestLength;
  for(var j = md.digestLength; j < db.length; j++) {
    var code = db.charCodeAt(j);

    var is_0 = (code & 0x1) ^ 0x1;

    // non-zero if not 0 or 1 in the ps section
    var error_mask = in_ps ? 0xfffe : 0x0000;
    error |= (code & error_mask);

    // latch in_ps to zero after we find 0x1
    in_ps = in_ps & is_0;
    index += in_ps;
  }

  if(error || db.charCodeAt(index) !== 0x1) {
    throw new Error('Invalid RSAES-OAEP padding.');
  }

  return db.substring(index + 1);
};

function rsa_mgf1(seed, maskLength, hash) {
  // default to SHA-1 message digest
  if(!hash) {
    hash = forge$a.md.sha1.create();
  }
  var t = '';
  var count = Math.ceil(maskLength / hash.digestLength);
  for(var i = 0; i < count; ++i) {
    var c = String.fromCharCode(
      (i >> 24) & 0xFF, (i >> 16) & 0xFF, (i >> 8) & 0xFF, i & 0xFF);
    hash.start();
    hash.update(seed + c);
    t += hash.digest().getBytes();
  }
  return t.substring(0, maskLength);
}

/**
 * Prime number generation API.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2014 Digital Bazaar, Inc.
 */

var forge$9 = forge$s;




(function() {

// forge.prime already defined
if(forge$9.prime) {
  return;
}

/* PRIME API */
var prime = forge$9.prime = forge$9.prime || {};

var BigInteger = forge$9.jsbn.BigInteger;

// primes are 30k+i for i = 1, 7, 11, 13, 17, 19, 23, 29
var GCD_30_DELTA = [6, 4, 2, 4, 2, 4, 6, 2];
var THIRTY = new BigInteger(null);
THIRTY.fromInt(30);
var op_or = function(x, y) {return x|y;};

/**
 * Generates a random probable prime with the given number of bits.
 *
 * Alternative algorithms can be specified by name as a string or as an
 * object with custom options like so:
 *
 * {
 *   name: 'PRIMEINC',
 *   options: {
 *     maxBlockTime: <the maximum amount of time to block the main
 *       thread before allowing I/O other JS to run>,
 *     millerRabinTests: <the number of miller-rabin tests to run>,
 *     workerScript: <the worker script URL>,
 *     workers: <the number of web workers (if supported) to use,
 *       -1 to use estimated cores minus one>.
 *     workLoad: the size of the work load, ie: number of possible prime
 *       numbers for each web worker to check per work assignment,
 *       (default: 100).
 *   }
 * }
 *
 * @param bits the number of bits for the prime number.
 * @param options the options to use.
 *          [algorithm] the algorithm to use (default: 'PRIMEINC').
 *          [prng] a custom crypto-secure pseudo-random number generator to use,
 *            that must define "getBytesSync".
 *
 * @return callback(err, num) called once the operation completes.
 */
prime.generateProbablePrime = function(bits, options, callback) {
  if(typeof options === 'function') {
    callback = options;
    options = {};
  }
  options = options || {};

  // default to PRIMEINC algorithm
  var algorithm = options.algorithm || 'PRIMEINC';
  if(typeof algorithm === 'string') {
    algorithm = {name: algorithm};
  }
  algorithm.options = algorithm.options || {};

  // create prng with api that matches BigInteger secure random
  var prng = options.prng || forge$9.random;
  var rng = {
    // x is an array to fill with bytes
    nextBytes: function(x) {
      var b = prng.getBytesSync(x.length);
      for(var i = 0; i < x.length; ++i) {
        x[i] = b.charCodeAt(i);
      }
    }
  };

  if(algorithm.name === 'PRIMEINC') {
    return primeincFindPrime(bits, rng, algorithm.options, callback);
  }

  throw new Error('Invalid prime generation algorithm: ' + algorithm.name);
};

function primeincFindPrime(bits, rng, options, callback) {
  if('workers' in options) {
    return primeincFindPrimeWithWorkers(bits, rng, options, callback);
  }
  return primeincFindPrimeWithoutWorkers(bits, rng, options, callback);
}

function primeincFindPrimeWithoutWorkers(bits, rng, options, callback) {
  // initialize random number
  var num = generateRandom(bits, rng);

  /* Note: All primes are of the form 30k+i for i < 30 and gcd(30, i)=1. The
  number we are given is always aligned at 30k + 1. Each time the number is
  determined not to be prime we add to get to the next 'i', eg: if the number
  was at 30k + 1 we add 6. */
  var deltaIdx = 0;

  // get required number of MR tests
  var mrTests = getMillerRabinTests(num.bitLength());
  if('millerRabinTests' in options) {
    mrTests = options.millerRabinTests;
  }

  // find prime nearest to 'num' for maxBlockTime ms
  // 10 ms gives 5ms of leeway for other calculations before dropping
  // below 60fps (1000/60 == 16.67), but in reality, the number will
  // likely be higher due to an 'atomic' big int modPow
  var maxBlockTime = 10;
  if('maxBlockTime' in options) {
    maxBlockTime = options.maxBlockTime;
  }

  _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback);
}

function _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback) {
  var start = +new Date();
  do {
    // overflow, regenerate random number
    if(num.bitLength() > bits) {
      num = generateRandom(bits, rng);
    }
    // do primality test
    if(num.isProbablePrime(mrTests)) {
      return callback(null, num);
    }
    // get next potential prime
    num.dAddOffset(GCD_30_DELTA[deltaIdx++ % 8], 0);
  } while(maxBlockTime < 0 || (+new Date() - start < maxBlockTime));

  // keep trying later
  forge$9.util.setImmediate(function() {
    _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback);
  });
}

// NOTE: This algorithm is indeterminate in nature because workers
// run in parallel looking at different segments of numbers. Even if this
// algorithm is run twice with the same input from a predictable RNG, it
// may produce different outputs.
function primeincFindPrimeWithWorkers(bits, rng, options, callback) {
  // web workers unavailable
  if(typeof Worker === 'undefined') {
    return primeincFindPrimeWithoutWorkers(bits, rng, options, callback);
  }

  // initialize random number
  var num = generateRandom(bits, rng);

  // use web workers to generate keys
  var numWorkers = options.workers;
  var workLoad = options.workLoad || 100;
  var range = workLoad * 30 / 8;
  var workerScript = options.workerScript || 'forge/prime.worker.js';
  if(numWorkers === -1) {
    return forge$9.util.estimateCores(function(err, cores) {
      if(err) {
        // default to 2
        cores = 2;
      }
      numWorkers = cores - 1;
      generate();
    });
  }
  generate();

  function generate() {
    // require at least 1 worker
    numWorkers = Math.max(1, numWorkers);

    // TODO: consider optimizing by starting workers outside getPrime() ...
    // note that in order to clean up they will have to be made internally
    // asynchronous which may actually be slower

    // start workers immediately
    var workers = [];
    for(var i = 0; i < numWorkers; ++i) {
      // FIXME: fix path or use blob URLs
      workers[i] = new Worker(workerScript);
    }

    // listen for requests from workers and assign ranges to find prime
    for(var i = 0; i < numWorkers; ++i) {
      workers[i].addEventListener('message', workerMessage);
    }

    /* Note: The distribution of random numbers is unknown. Therefore, each
    web worker is continuously allocated a range of numbers to check for a
    random number until one is found.

    Every 30 numbers will be checked just 8 times, because prime numbers
    have the form:

    30k+i, for i < 30 and gcd(30, i)=1 (there are 8 values of i for this)

    Therefore, if we want a web worker to run N checks before asking for
    a new range of numbers, each range must contain N*30/8 numbers.

    For 100 checks (workLoad), this is a range of 375. */

    var found = false;
    function workerMessage(e) {
      // ignore message, prime already found
      if(found) {
        return;
      }
      var data = e.data;
      if(data.found) {
        // terminate all workers
        for(var i = 0; i < workers.length; ++i) {
          workers[i].terminate();
        }
        found = true;
        return callback(null, new BigInteger(data.prime, 16));
      }

      // overflow, regenerate random number
      if(num.bitLength() > bits) {
        num = generateRandom(bits, rng);
      }

      // assign new range to check
      var hex = num.toString(16);

      // start prime search
      e.target.postMessage({
        hex: hex,
        workLoad: workLoad
      });

      num.dAddOffset(range, 0);
    }
  }
}

/**
 * Generates a random number using the given number of bits and RNG.
 *
 * @param bits the number of bits for the number.
 * @param rng the random number generator to use.
 *
 * @return the random number.
 */
function generateRandom(bits, rng) {
  var num = new BigInteger(bits, rng);
  // force MSB set
  var bits1 = bits - 1;
  if(!num.testBit(bits1)) {
    num.bitwiseTo(BigInteger.ONE.shiftLeft(bits1), op_or, num);
  }
  // align number on 30k+1 boundary
  num.dAddOffset(31 - num.mod(THIRTY).byteValue(), 0);
  return num;
}

/**
 * Returns the required number of Miller-Rabin tests to generate a
 * prime with an error probability of (1/2)^80.
 *
 * See Handbook of Applied Cryptography Chapter 4, Table 4.4.
 *
 * @param bits the bit size.
 *
 * @return the required number of iterations.
 */
function getMillerRabinTests(bits) {
  if(bits <= 100) return 27;
  if(bits <= 150) return 18;
  if(bits <= 200) return 15;
  if(bits <= 250) return 12;
  if(bits <= 300) return 9;
  if(bits <= 350) return 8;
  if(bits <= 400) return 7;
  if(bits <= 500) return 6;
  if(bits <= 600) return 5;
  if(bits <= 800) return 4;
  if(bits <= 1250) return 3;
  return 2;
}

})();

/**
 * Javascript implementation of basic RSA algorithms.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 *
 * The only algorithm currently supported for PKI is RSA.
 *
 * An RSA key is often stored in ASN.1 DER format. The SubjectPublicKeyInfo
 * ASN.1 structure is composed of an algorithm of type AlgorithmIdentifier
 * and a subjectPublicKey of type bit string.
 *
 * The AlgorithmIdentifier contains an Object Identifier (OID) and parameters
 * for the algorithm, if any. In the case of RSA, there aren't any.
 *
 * SubjectPublicKeyInfo ::= SEQUENCE {
 *   algorithm AlgorithmIdentifier,
 *   subjectPublicKey BIT STRING
 * }
 *
 * AlgorithmIdentifer ::= SEQUENCE {
 *   algorithm OBJECT IDENTIFIER,
 *   parameters ANY DEFINED BY algorithm OPTIONAL
 * }
 *
 * For an RSA public key, the subjectPublicKey is:
 *
 * RSAPublicKey ::= SEQUENCE {
 *   modulus            INTEGER,    -- n
 *   publicExponent     INTEGER     -- e
 * }
 *
 * PrivateKeyInfo ::= SEQUENCE {
 *   version                   Version,
 *   privateKeyAlgorithm       PrivateKeyAlgorithmIdentifier,
 *   privateKey                PrivateKey,
 *   attributes           [0]  IMPLICIT Attributes OPTIONAL
 * }
 *
 * Version ::= INTEGER
 * PrivateKeyAlgorithmIdentifier ::= AlgorithmIdentifier
 * PrivateKey ::= OCTET STRING
 * Attributes ::= SET OF Attribute
 *
 * An RSA private key as the following structure:
 *
 * RSAPrivateKey ::= SEQUENCE {
 *   version Version,
 *   modulus INTEGER, -- n
 *   publicExponent INTEGER, -- e
 *   privateExponent INTEGER, -- d
 *   prime1 INTEGER, -- p
 *   prime2 INTEGER, -- q
 *   exponent1 INTEGER, -- d mod (p-1)
 *   exponent2 INTEGER, -- d mod (q-1)
 *   coefficient INTEGER -- (inverse of q) mod p
 * }
 *
 * Version ::= INTEGER
 *
 * The OID for the RSA key algorithm is: 1.2.840.113549.1.1.1
 */

var forge$8 = forge$s;








if(typeof BigInteger$1 === 'undefined') {
  var BigInteger$1 = forge$8.jsbn.BigInteger;
}

var _crypto = forge$8.util.isNodejs ? require$$1 : null;

// shortcut for asn.1 API
var asn1$4 = forge$8.asn1;

// shortcut for util API
var util$u = forge$8.util;

/*
 * RSA encryption and decryption, see RFC 2313.
 */
forge$8.pki = forge$8.pki || {};
forge$8.pki.rsa = forge$8.rsa = forge$8.rsa || {};
var pki$3 = forge$8.pki;

// for finding primes, which are 30k+i for i = 1, 7, 11, 13, 17, 19, 23, 29
var GCD_30_DELTA = [6, 4, 2, 4, 2, 4, 6, 2];

// validator for a PrivateKeyInfo structure
var privateKeyValidator = {
  // PrivateKeyInfo
  name: 'PrivateKeyInfo',
  tagClass: asn1$4.Class.UNIVERSAL,
  type: asn1$4.Type.SEQUENCE,
  constructed: true,
  value: [{
    // Version (INTEGER)
    name: 'PrivateKeyInfo.version',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyVersion'
  }, {
    // privateKeyAlgorithm
    name: 'PrivateKeyInfo.privateKeyAlgorithm',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'AlgorithmIdentifier.algorithm',
      tagClass: asn1$4.Class.UNIVERSAL,
      type: asn1$4.Type.OID,
      constructed: false,
      capture: 'privateKeyOid'
    }]
  }, {
    // PrivateKey
    name: 'PrivateKeyInfo',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.OCTETSTRING,
    constructed: false,
    capture: 'privateKey'
  }]
};

// validator for an RSA private key
var rsaPrivateKeyValidator = {
  // RSAPrivateKey
  name: 'RSAPrivateKey',
  tagClass: asn1$4.Class.UNIVERSAL,
  type: asn1$4.Type.SEQUENCE,
  constructed: true,
  value: [{
    // Version (INTEGER)
    name: 'RSAPrivateKey.version',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyVersion'
  }, {
    // modulus (n)
    name: 'RSAPrivateKey.modulus',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyModulus'
  }, {
    // publicExponent (e)
    name: 'RSAPrivateKey.publicExponent',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyPublicExponent'
  }, {
    // privateExponent (d)
    name: 'RSAPrivateKey.privateExponent',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyPrivateExponent'
  }, {
    // prime1 (p)
    name: 'RSAPrivateKey.prime1',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyPrime1'
  }, {
    // prime2 (q)
    name: 'RSAPrivateKey.prime2',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyPrime2'
  }, {
    // exponent1 (d mod (p-1))
    name: 'RSAPrivateKey.exponent1',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyExponent1'
  }, {
    // exponent2 (d mod (q-1))
    name: 'RSAPrivateKey.exponent2',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyExponent2'
  }, {
    // coefficient ((inverse of q) mod p)
    name: 'RSAPrivateKey.coefficient',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyCoefficient'
  }]
};

// validator for an RSA public key
var rsaPublicKeyValidator = {
  // RSAPublicKey
  name: 'RSAPublicKey',
  tagClass: asn1$4.Class.UNIVERSAL,
  type: asn1$4.Type.SEQUENCE,
  constructed: true,
  value: [{
    // modulus (n)
    name: 'RSAPublicKey.modulus',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'publicKeyModulus'
  }, {
    // publicExponent (e)
    name: 'RSAPublicKey.exponent',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.INTEGER,
    constructed: false,
    capture: 'publicKeyExponent'
  }]
};

// validator for an SubjectPublicKeyInfo structure
// Note: Currently only works with an RSA public key
var publicKeyValidator$1 = forge$8.pki.rsa.publicKeyValidator = {
  name: 'SubjectPublicKeyInfo',
  tagClass: asn1$4.Class.UNIVERSAL,
  type: asn1$4.Type.SEQUENCE,
  constructed: true,
  captureAsn1: 'subjectPublicKeyInfo',
  value: [{
    name: 'SubjectPublicKeyInfo.AlgorithmIdentifier',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'AlgorithmIdentifier.algorithm',
      tagClass: asn1$4.Class.UNIVERSAL,
      type: asn1$4.Type.OID,
      constructed: false,
      capture: 'publicKeyOid'
    }]
  }, {
    // subjectPublicKey
    name: 'SubjectPublicKeyInfo.subjectPublicKey',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.BITSTRING,
    constructed: false,
    value: [{
      // RSAPublicKey
      name: 'SubjectPublicKeyInfo.subjectPublicKey.RSAPublicKey',
      tagClass: asn1$4.Class.UNIVERSAL,
      type: asn1$4.Type.SEQUENCE,
      constructed: true,
      optional: true,
      captureAsn1: 'rsaPublicKey'
    }]
  }]
};

// validator for a DigestInfo structure
var digestInfoValidator = {
  name: 'DigestInfo',
  tagClass: asn1$4.Class.UNIVERSAL,
  type: asn1$4.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'DigestInfo.DigestAlgorithm',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'DigestInfo.DigestAlgorithm.algorithmIdentifier',
      tagClass: asn1$4.Class.UNIVERSAL,
      type: asn1$4.Type.OID,
      constructed: false,
      capture: 'algorithmIdentifier'
    }, {
      // NULL paramters
      name: 'DigestInfo.DigestAlgorithm.parameters',
      tagClass: asn1$4.Class.UNIVERSAL,
      type: asn1$4.Type.NULL,
      // captured only to check existence for md2 and md5
      capture: 'parameters',
      optional: true,
      constructed: false
    }]
  }, {
    // digest
    name: 'DigestInfo.digest',
    tagClass: asn1$4.Class.UNIVERSAL,
    type: asn1$4.Type.OCTETSTRING,
    constructed: false,
    capture: 'digest'
  }]
};

/**
 * Wrap digest in DigestInfo object.
 *
 * This function implements EMSA-PKCS1-v1_5-ENCODE as per RFC 3447.
 *
 * DigestInfo ::= SEQUENCE {
 *   digestAlgorithm DigestAlgorithmIdentifier,
 *   digest Digest
 * }
 *
 * DigestAlgorithmIdentifier ::= AlgorithmIdentifier
 * Digest ::= OCTET STRING
 *
 * @param md the message digest object with the hash to sign.
 *
 * @return the encoded message (ready for RSA encrytion)
 */
var emsaPkcs1v15encode = function(md) {
  // get the oid for the algorithm
  var oid;
  if(md.algorithm in pki$3.oids) {
    oid = pki$3.oids[md.algorithm];
  } else {
    var error = new Error('Unknown message digest algorithm.');
    error.algorithm = md.algorithm;
    throw error;
  }
  var oidBytes = asn1$4.oidToDer(oid).getBytes();

  // create the digest info
  var digestInfo = asn1$4.create(
    asn1$4.Class.UNIVERSAL, asn1$4.Type.SEQUENCE, true, []);
  var digestAlgorithm = asn1$4.create(
    asn1$4.Class.UNIVERSAL, asn1$4.Type.SEQUENCE, true, []);
  digestAlgorithm.value.push(asn1$4.create(
    asn1$4.Class.UNIVERSAL, asn1$4.Type.OID, false, oidBytes));
  digestAlgorithm.value.push(asn1$4.create(
    asn1$4.Class.UNIVERSAL, asn1$4.Type.NULL, false, ''));
  var digest = asn1$4.create(
    asn1$4.Class.UNIVERSAL, asn1$4.Type.OCTETSTRING,
    false, md.digest().getBytes());
  digestInfo.value.push(digestAlgorithm);
  digestInfo.value.push(digest);

  // encode digest info
  return asn1$4.toDer(digestInfo).getBytes();
};

/**
 * Performs x^c mod n (RSA encryption or decryption operation).
 *
 * @param x the number to raise and mod.
 * @param key the key to use.
 * @param pub true if the key is public, false if private.
 *
 * @return the result of x^c mod n.
 */
var _modPow = function(x, key, pub) {
  if(pub) {
    return x.modPow(key.e, key.n);
  }

  if(!key.p || !key.q) {
    // allow calculation without CRT params (slow)
    return x.modPow(key.d, key.n);
  }

  // pre-compute dP, dQ, and qInv if necessary
  if(!key.dP) {
    key.dP = key.d.mod(key.p.subtract(BigInteger$1.ONE));
  }
  if(!key.dQ) {
    key.dQ = key.d.mod(key.q.subtract(BigInteger$1.ONE));
  }
  if(!key.qInv) {
    key.qInv = key.q.modInverse(key.p);
  }

  /* Chinese remainder theorem (CRT) states:

    Suppose n1, n2, ..., nk are positive integers which are pairwise
    coprime (n1 and n2 have no common factors other than 1). For any
    integers x1, x2, ..., xk there exists an integer x solving the
    system of simultaneous congruences (where ~= means modularly
    congruent so a ~= b mod n means a mod n = b mod n):

    x ~= x1 mod n1
    x ~= x2 mod n2
    ...
    x ~= xk mod nk

    This system of congruences has a single simultaneous solution x
    between 0 and n - 1. Furthermore, each xk solution and x itself
    is congruent modulo the product n = n1*n2*...*nk.
    So x1 mod n = x2 mod n = xk mod n = x mod n.

    The single simultaneous solution x can be solved with the following
    equation:

    x = sum(xi*ri*si) mod n where ri = n/ni and si = ri^-1 mod ni.

    Where x is less than n, xi = x mod ni.

    For RSA we are only concerned with k = 2. The modulus n = pq, where
    p and q are coprime. The RSA decryption algorithm is:

    y = x^d mod n

    Given the above:

    x1 = x^d mod p
    r1 = n/p = q
    s1 = q^-1 mod p
    x2 = x^d mod q
    r2 = n/q = p
    s2 = p^-1 mod q

    So y = (x1r1s1 + x2r2s2) mod n
         = ((x^d mod p)q(q^-1 mod p) + (x^d mod q)p(p^-1 mod q)) mod n

    According to Fermat's Little Theorem, if the modulus P is prime,
    for any integer A not evenly divisible by P, A^(P-1) ~= 1 mod P.
    Since A is not divisible by P it follows that if:
    N ~= M mod (P - 1), then A^N mod P = A^M mod P. Therefore:

    A^N mod P = A^(M mod (P - 1)) mod P. (The latter takes less effort
    to calculate). In order to calculate x^d mod p more quickly the
    exponent d mod (p - 1) is stored in the RSA private key (the same
    is done for x^d mod q). These values are referred to as dP and dQ
    respectively. Therefore we now have:

    y = ((x^dP mod p)q(q^-1 mod p) + (x^dQ mod q)p(p^-1 mod q)) mod n

    Since we'll be reducing x^dP by modulo p (same for q) we can also
    reduce x by p (and q respectively) before hand. Therefore, let

    xp = ((x mod p)^dP mod p), and
    xq = ((x mod q)^dQ mod q), yielding:

    y = (xp*q*(q^-1 mod p) + xq*p*(p^-1 mod q)) mod n

    This can be further reduced to a simple algorithm that only
    requires 1 inverse (the q inverse is used) to be used and stored.
    The algorithm is called Garner's algorithm. If qInv is the
    inverse of q, we simply calculate:

    y = (qInv*(xp - xq) mod p) * q + xq

    However, there are two further complications. First, we need to
    ensure that xp > xq to prevent signed BigIntegers from being used
    so we add p until this is true (since we will be mod'ing with
    p anyway). Then, there is a known timing attack on algorithms
    using the CRT. To mitigate this risk, "cryptographic blinding"
    should be used. This requires simply generating a random number r
    between 0 and n-1 and its inverse and multiplying x by r^e before
    calculating y and then multiplying y by r^-1 afterwards. Note that
    r must be coprime with n (gcd(r, n) === 1) in order to have an
    inverse.
  */

  // cryptographic blinding
  var r;
  do {
    r = new BigInteger$1(
      forge$8.util.bytesToHex(forge$8.random.getBytes(key.n.bitLength() / 8)),
      16);
  } while(r.compareTo(key.n) >= 0 || !r.gcd(key.n).equals(BigInteger$1.ONE));
  x = x.multiply(r.modPow(key.e, key.n)).mod(key.n);

  // calculate xp and xq
  var xp = x.mod(key.p).modPow(key.dP, key.p);
  var xq = x.mod(key.q).modPow(key.dQ, key.q);

  // xp must be larger than xq to avoid signed bit usage
  while(xp.compareTo(xq) < 0) {
    xp = xp.add(key.p);
  }

  // do last step
  var y = xp.subtract(xq)
    .multiply(key.qInv).mod(key.p)
    .multiply(key.q).add(xq);

  // remove effect of random for cryptographic blinding
  y = y.multiply(r.modInverse(key.n)).mod(key.n);

  return y;
};

/**
 * NOTE: THIS METHOD IS DEPRECATED, use 'sign' on a private key object or
 * 'encrypt' on a public key object instead.
 *
 * Performs RSA encryption.
 *
 * The parameter bt controls whether to put padding bytes before the
 * message passed in. Set bt to either true or false to disable padding
 * completely (in order to handle e.g. EMSA-PSS encoding seperately before),
 * signaling whether the encryption operation is a public key operation
 * (i.e. encrypting data) or not, i.e. private key operation (data signing).
 *
 * For PKCS#1 v1.5 padding pass in the block type to use, i.e. either 0x01
 * (for signing) or 0x02 (for encryption). The key operation mode (private
 * or public) is derived from this flag in that case).
 *
 * @param m the message to encrypt as a byte string.
 * @param key the RSA key to use.
 * @param bt for PKCS#1 v1.5 padding, the block type to use
 *   (0x01 for private key, 0x02 for public),
 *   to disable padding: true = public key, false = private key.
 *
 * @return the encrypted bytes as a string.
 */
pki$3.rsa.encrypt = function(m, key, bt) {
  var pub = bt;
  var eb;

  // get the length of the modulus in bytes
  var k = Math.ceil(key.n.bitLength() / 8);

  if(bt !== false && bt !== true) {
    // legacy, default to PKCS#1 v1.5 padding
    pub = (bt === 0x02);
    eb = _encodePkcs1_v1_5(m, key, bt);
  } else {
    eb = forge$8.util.createBuffer();
    eb.putBytes(m);
  }

  // load encryption block as big integer 'x'
  // FIXME: hex conversion inefficient, get BigInteger w/byte strings
  var x = new BigInteger$1(eb.toHex(), 16);

  // do RSA encryption
  var y = _modPow(x, key, pub);

  // convert y into the encrypted data byte string, if y is shorter in
  // bytes than k, then prepend zero bytes to fill up ed
  // FIXME: hex conversion inefficient, get BigInteger w/byte strings
  var yhex = y.toString(16);
  var ed = forge$8.util.createBuffer();
  var zeros = k - Math.ceil(yhex.length / 2);
  while(zeros > 0) {
    ed.putByte(0x00);
    --zeros;
  }
  ed.putBytes(forge$8.util.hexToBytes(yhex));
  return ed.getBytes();
};

/**
 * NOTE: THIS METHOD IS DEPRECATED, use 'decrypt' on a private key object or
 * 'verify' on a public key object instead.
 *
 * Performs RSA decryption.
 *
 * The parameter ml controls whether to apply PKCS#1 v1.5 padding
 * or not.  Set ml = false to disable padding removal completely
 * (in order to handle e.g. EMSA-PSS later on) and simply pass back
 * the RSA encryption block.
 *
 * @param ed the encrypted data to decrypt in as a byte string.
 * @param key the RSA key to use.
 * @param pub true for a public key operation, false for private.
 * @param ml the message length, if known, false to disable padding.
 *
 * @return the decrypted message as a byte string.
 */
pki$3.rsa.decrypt = function(ed, key, pub, ml) {
  // get the length of the modulus in bytes
  var k = Math.ceil(key.n.bitLength() / 8);

  // error if the length of the encrypted data ED is not k
  if(ed.length !== k) {
    var error = new Error('Encrypted message length is invalid.');
    error.length = ed.length;
    error.expected = k;
    throw error;
  }

  // convert encrypted data into a big integer
  // FIXME: hex conversion inefficient, get BigInteger w/byte strings
  var y = new BigInteger$1(forge$8.util.createBuffer(ed).toHex(), 16);

  // y must be less than the modulus or it wasn't the result of
  // a previous mod operation (encryption) using that modulus
  if(y.compareTo(key.n) >= 0) {
    throw new Error('Encrypted message is invalid.');
  }

  // do RSA decryption
  var x = _modPow(y, key, pub);

  // create the encryption block, if x is shorter in bytes than k, then
  // prepend zero bytes to fill up eb
  // FIXME: hex conversion inefficient, get BigInteger w/byte strings
  var xhex = x.toString(16);
  var eb = forge$8.util.createBuffer();
  var zeros = k - Math.ceil(xhex.length / 2);
  while(zeros > 0) {
    eb.putByte(0x00);
    --zeros;
  }
  eb.putBytes(forge$8.util.hexToBytes(xhex));

  if(ml !== false) {
    // legacy, default to PKCS#1 v1.5 padding
    return _decodePkcs1_v1_5(eb.getBytes(), key, pub);
  }

  // return message
  return eb.getBytes();
};

/**
 * Creates an RSA key-pair generation state object. It is used to allow
 * key-generation to be performed in steps. It also allows for a UI to
 * display progress updates.
 *
 * @param bits the size for the private key in bits, defaults to 2048.
 * @param e the public exponent to use, defaults to 65537 (0x10001).
 * @param [options] the options to use.
 *          prng a custom crypto-secure pseudo-random number generator to use,
 *            that must define "getBytesSync".
 *          algorithm the algorithm to use (default: 'PRIMEINC').
 *
 * @return the state object to use to generate the key-pair.
 */
pki$3.rsa.createKeyPairGenerationState = function(bits, e, options) {
  // TODO: migrate step-based prime generation code to forge.prime

  // set default bits
  if(typeof(bits) === 'string') {
    bits = parseInt(bits, 10);
  }
  bits = bits || 2048;

  // create prng with api that matches BigInteger secure random
  options = options || {};
  var prng = options.prng || forge$8.random;
  var rng = {
    // x is an array to fill with bytes
    nextBytes: function(x) {
      var b = prng.getBytesSync(x.length);
      for(var i = 0; i < x.length; ++i) {
        x[i] = b.charCodeAt(i);
      }
    }
  };

  var algorithm = options.algorithm || 'PRIMEINC';

  // create PRIMEINC algorithm state
  var rval;
  if(algorithm === 'PRIMEINC') {
    rval = {
      algorithm: algorithm,
      state: 0,
      bits: bits,
      rng: rng,
      eInt: e || 65537,
      e: new BigInteger$1(null),
      p: null,
      q: null,
      qBits: bits >> 1,
      pBits: bits - (bits >> 1),
      pqState: 0,
      num: null,
      keys: null
    };
    rval.e.fromInt(rval.eInt);
  } else {
    throw new Error('Invalid key generation algorithm: ' + algorithm);
  }

  return rval;
};

/**
 * Attempts to runs the key-generation algorithm for at most n seconds
 * (approximately) using the given state. When key-generation has completed,
 * the keys will be stored in state.keys.
 *
 * To use this function to update a UI while generating a key or to prevent
 * causing browser lockups/warnings, set "n" to a value other than 0. A
 * simple pattern for generating a key and showing a progress indicator is:
 *
 * var state = pki.rsa.createKeyPairGenerationState(2048);
 * var step = function() {
 *   // step key-generation, run algorithm for 100 ms, repeat
 *   if(!forge.pki.rsa.stepKeyPairGenerationState(state, 100)) {
 *     setTimeout(step, 1);
 *   } else {
 *     // key-generation complete
 *     // TODO: turn off progress indicator here
 *     // TODO: use the generated key-pair in "state.keys"
 *   }
 * };
 * // TODO: turn on progress indicator here
 * setTimeout(step, 0);
 *
 * @param state the state to use.
 * @param n the maximum number of milliseconds to run the algorithm for, 0
 *          to run the algorithm to completion.
 *
 * @return true if the key-generation completed, false if not.
 */
pki$3.rsa.stepKeyPairGenerationState = function(state, n) {
  // set default algorithm if not set
  if(!('algorithm' in state)) {
    state.algorithm = 'PRIMEINC';
  }

  // TODO: migrate step-based prime generation code to forge.prime
  // TODO: abstract as PRIMEINC algorithm

  // do key generation (based on Tom Wu's rsa.js, see jsbn.js license)
  // with some minor optimizations and designed to run in steps

  // local state vars
  var THIRTY = new BigInteger$1(null);
  THIRTY.fromInt(30);
  var deltaIdx = 0;
  var op_or = function(x, y) {return x | y;};

  // keep stepping until time limit is reached or done
  var t1 = +new Date();
  var t2;
  var total = 0;
  while(state.keys === null && (n <= 0 || total < n)) {
    // generate p or q
    if(state.state === 0) {
      /* Note: All primes are of the form:

        30k+i, for i < 30 and gcd(30, i)=1, where there are 8 values for i

        When we generate a random number, we always align it at 30k + 1. Each
        time the number is determined not to be prime we add to get to the
        next 'i', eg: if the number was at 30k + 1 we add 6. */
      var bits = (state.p === null) ? state.pBits : state.qBits;
      var bits1 = bits - 1;

      // get a random number
      if(state.pqState === 0) {
        state.num = new BigInteger$1(bits, state.rng);
        // force MSB set
        if(!state.num.testBit(bits1)) {
          state.num.bitwiseTo(
            BigInteger$1.ONE.shiftLeft(bits1), op_or, state.num);
        }
        // align number on 30k+1 boundary
        state.num.dAddOffset(31 - state.num.mod(THIRTY).byteValue(), 0);
        deltaIdx = 0;

        ++state.pqState;
      } else if(state.pqState === 1) {
        // try to make the number a prime
        if(state.num.bitLength() > bits) {
          // overflow, try again
          state.pqState = 0;
          // do primality test
        } else if(state.num.isProbablePrime(
          _getMillerRabinTests(state.num.bitLength()))) {
          ++state.pqState;
        } else {
          // get next potential prime
          state.num.dAddOffset(GCD_30_DELTA[deltaIdx++ % 8], 0);
        }
      } else if(state.pqState === 2) {
        // ensure number is coprime with e
        state.pqState =
          (state.num.subtract(BigInteger$1.ONE).gcd(state.e)
            .compareTo(BigInteger$1.ONE) === 0) ? 3 : 0;
      } else if(state.pqState === 3) {
        // store p or q
        state.pqState = 0;
        if(state.p === null) {
          state.p = state.num;
        } else {
          state.q = state.num;
        }

        // advance state if both p and q are ready
        if(state.p !== null && state.q !== null) {
          ++state.state;
        }
        state.num = null;
      }
    } else if(state.state === 1) {
      // ensure p is larger than q (swap them if not)
      if(state.p.compareTo(state.q) < 0) {
        state.num = state.p;
        state.p = state.q;
        state.q = state.num;
      }
      ++state.state;
    } else if(state.state === 2) {
      // compute phi: (p - 1)(q - 1) (Euler's totient function)
      state.p1 = state.p.subtract(BigInteger$1.ONE);
      state.q1 = state.q.subtract(BigInteger$1.ONE);
      state.phi = state.p1.multiply(state.q1);
      ++state.state;
    } else if(state.state === 3) {
      // ensure e and phi are coprime
      if(state.phi.gcd(state.e).compareTo(BigInteger$1.ONE) === 0) {
        // phi and e are coprime, advance
        ++state.state;
      } else {
        // phi and e aren't coprime, so generate a new p and q
        state.p = null;
        state.q = null;
        state.state = 0;
      }
    } else if(state.state === 4) {
      // create n, ensure n is has the right number of bits
      state.n = state.p.multiply(state.q);

      // ensure n is right number of bits
      if(state.n.bitLength() === state.bits) {
        // success, advance
        ++state.state;
      } else {
        // failed, get new q
        state.q = null;
        state.state = 0;
      }
    } else if(state.state === 5) {
      // set keys
      var d = state.e.modInverse(state.phi);
      state.keys = {
        privateKey: pki$3.rsa.setPrivateKey(
          state.n, state.e, d, state.p, state.q,
          d.mod(state.p1), d.mod(state.q1),
          state.q.modInverse(state.p)),
        publicKey: pki$3.rsa.setPublicKey(state.n, state.e)
      };
    }

    // update timing
    t2 = +new Date();
    total += t2 - t1;
    t1 = t2;
  }

  return state.keys !== null;
};

/**
 * Generates an RSA public-private key pair in a single call.
 *
 * To generate a key-pair in steps (to allow for progress updates and to
 * prevent blocking or warnings in slow browsers) then use the key-pair
 * generation state functions.
 *
 * To generate a key-pair asynchronously (either through web-workers, if
 * available, or by breaking up the work on the main thread), pass a
 * callback function.
 *
 * @param [bits] the size for the private key in bits, defaults to 2048.
 * @param [e] the public exponent to use, defaults to 65537.
 * @param [options] options for key-pair generation, if given then 'bits'
 *            and 'e' must *not* be given:
 *          bits the size for the private key in bits, (default: 2048).
 *          e the public exponent to use, (default: 65537 (0x10001)).
 *          workerScript the worker script URL.
 *          workers the number of web workers (if supported) to use,
 *            (default: 2).
 *          workLoad the size of the work load, ie: number of possible prime
 *            numbers for each web worker to check per work assignment,
 *            (default: 100).
 *          prng a custom crypto-secure pseudo-random number generator to use,
 *            that must define "getBytesSync". Disables use of native APIs.
 *          algorithm the algorithm to use (default: 'PRIMEINC').
 * @param [callback(err, keypair)] called once the operation completes.
 *
 * @return an object with privateKey and publicKey properties.
 */
pki$3.rsa.generateKeyPair = function(bits, e, options, callback) {
  // (bits), (options), (callback)
  if(arguments.length === 1) {
    if(typeof bits === 'object') {
      options = bits;
      bits = undefined;
    } else if(typeof bits === 'function') {
      callback = bits;
      bits = undefined;
    }
  } else if(arguments.length === 2) {
    // (bits, e), (bits, options), (bits, callback), (options, callback)
    if(typeof bits === 'number') {
      if(typeof e === 'function') {
        callback = e;
        e = undefined;
      } else if(typeof e !== 'number') {
        options = e;
        e = undefined;
      }
    } else {
      options = bits;
      callback = e;
      bits = undefined;
      e = undefined;
    }
  } else if(arguments.length === 3) {
    // (bits, e, options), (bits, e, callback), (bits, options, callback)
    if(typeof e === 'number') {
      if(typeof options === 'function') {
        callback = options;
        options = undefined;
      }
    } else {
      callback = options;
      options = e;
      e = undefined;
    }
  }
  options = options || {};
  if(bits === undefined) {
    bits = options.bits || 2048;
  }
  if(e === undefined) {
    e = options.e || 0x10001;
  }

  // use native code if permitted, available, and parameters are acceptable
  if(!options.prng &&
    bits >= 256 && bits <= 16384 && (e === 0x10001 || e === 3)) {
    if(callback) {
      // try native async
      if(_detectNodeCrypto('generateKeyPair')) {
        return _crypto.generateKeyPair('rsa', {
          modulusLength: bits,
          publicExponent: e,
          publicKeyEncoding: {
            type: 'spki',
            format: 'pem'
          },
          privateKeyEncoding: {
            type: 'pkcs8',
            format: 'pem'
          }
        }, function(err, pub, priv) {
          if(err) {
            return callback(err);
          }
          callback(null, {
            privateKey: pki$3.privateKeyFromPem(priv),
            publicKey: pki$3.publicKeyFromPem(pub)
          });
        });
      }
      if(_detectSubtleCrypto('generateKey') &&
        _detectSubtleCrypto('exportKey')) {
        // use standard native generateKey
        return util$u.globalScope.crypto.subtle.generateKey({
          name: 'RSASSA-PKCS1-v1_5',
          modulusLength: bits,
          publicExponent: _intToUint8Array(e),
          hash: {name: 'SHA-256'}
        }, true /* key can be exported*/, ['sign', 'verify'])
        .then(function(pair) {
          return util$u.globalScope.crypto.subtle.exportKey(
            'pkcs8', pair.privateKey);
        // avoiding catch(function(err) {...}) to support IE <= 8
        }).then(undefined, function(err) {
          callback(err);
        }).then(function(pkcs8) {
          if(pkcs8) {
            var privateKey = pki$3.privateKeyFromAsn1(
              asn1$4.fromDer(forge$8.util.createBuffer(pkcs8)));
            callback(null, {
              privateKey: privateKey,
              publicKey: pki$3.setRsaPublicKey(privateKey.n, privateKey.e)
            });
          }
        });
      }
      if(_detectSubtleMsCrypto('generateKey') &&
        _detectSubtleMsCrypto('exportKey')) {
        var genOp = util$u.globalScope.msCrypto.subtle.generateKey({
          name: 'RSASSA-PKCS1-v1_5',
          modulusLength: bits,
          publicExponent: _intToUint8Array(e),
          hash: {name: 'SHA-256'}
        }, true /* key can be exported*/, ['sign', 'verify']);
        genOp.oncomplete = function(e) {
          var pair = e.target.result;
          var exportOp = util$u.globalScope.msCrypto.subtle.exportKey(
            'pkcs8', pair.privateKey);
          exportOp.oncomplete = function(e) {
            var pkcs8 = e.target.result;
            var privateKey = pki$3.privateKeyFromAsn1(
              asn1$4.fromDer(forge$8.util.createBuffer(pkcs8)));
            callback(null, {
              privateKey: privateKey,
              publicKey: pki$3.setRsaPublicKey(privateKey.n, privateKey.e)
            });
          };
          exportOp.onerror = function(err) {
            callback(err);
          };
        };
        genOp.onerror = function(err) {
          callback(err);
        };
        return;
      }
    } else {
      // try native sync
      if(_detectNodeCrypto('generateKeyPairSync')) {
        var keypair = _crypto.generateKeyPairSync('rsa', {
          modulusLength: bits,
          publicExponent: e,
          publicKeyEncoding: {
            type: 'spki',
            format: 'pem'
          },
          privateKeyEncoding: {
            type: 'pkcs8',
            format: 'pem'
          }
        });
        return {
          privateKey: pki$3.privateKeyFromPem(keypair.privateKey),
          publicKey: pki$3.publicKeyFromPem(keypair.publicKey)
        };
      }
    }
  }

  // use JavaScript implementation
  var state = pki$3.rsa.createKeyPairGenerationState(bits, e, options);
  if(!callback) {
    pki$3.rsa.stepKeyPairGenerationState(state, 0);
    return state.keys;
  }
  _generateKeyPair(state, options, callback);
};

/**
 * Sets an RSA public key from BigIntegers modulus and exponent.
 *
 * @param n the modulus.
 * @param e the exponent.
 *
 * @return the public key.
 */
pki$3.setRsaPublicKey = pki$3.rsa.setPublicKey = function(n, e) {
  var key = {
    n: n,
    e: e
  };

  /**
   * Encrypts the given data with this public key. Newer applications
   * should use the 'RSA-OAEP' decryption scheme, 'RSAES-PKCS1-V1_5' is for
   * legacy applications.
   *
   * @param data the byte string to encrypt.
   * @param scheme the encryption scheme to use:
   *          'RSAES-PKCS1-V1_5' (default),
   *          'RSA-OAEP',
   *          'RAW', 'NONE', or null to perform raw RSA encryption,
   *          an object with an 'encode' property set to a function
   *          with the signature 'function(data, key)' that returns
   *          a binary-encoded string representing the encoded data.
   * @param schemeOptions any scheme-specific options.
   *
   * @return the encrypted byte string.
   */
  key.encrypt = function(data, scheme, schemeOptions) {
    if(typeof scheme === 'string') {
      scheme = scheme.toUpperCase();
    } else if(scheme === undefined) {
      scheme = 'RSAES-PKCS1-V1_5';
    }

    if(scheme === 'RSAES-PKCS1-V1_5') {
      scheme = {
        encode: function(m, key, pub) {
          return _encodePkcs1_v1_5(m, key, 0x02).getBytes();
        }
      };
    } else if(scheme === 'RSA-OAEP' || scheme === 'RSAES-OAEP') {
      scheme = {
        encode: function(m, key) {
          return forge$8.pkcs1.encode_rsa_oaep(key, m, schemeOptions);
        }
      };
    } else if(['RAW', 'NONE', 'NULL', null].indexOf(scheme) !== -1) {
      scheme = {encode: function(e) {return e;}};
    } else if(typeof scheme === 'string') {
      throw new Error('Unsupported encryption scheme: "' + scheme + '".');
    }

    // do scheme-based encoding then rsa encryption
    var e = scheme.encode(data, key, true);
    return pki$3.rsa.encrypt(e, key, true);
  };

  /**
   * Verifies the given signature against the given digest.
   *
   * PKCS#1 supports multiple (currently two) signature schemes:
   * RSASSA-PKCS1-V1_5 and RSASSA-PSS.
   *
   * By default this implementation uses the "old scheme", i.e.
   * RSASSA-PKCS1-V1_5, in which case once RSA-decrypted, the
   * signature is an OCTET STRING that holds a DigestInfo.
   *
   * DigestInfo ::= SEQUENCE {
   *   digestAlgorithm DigestAlgorithmIdentifier,
   *   digest Digest
   * }
   * DigestAlgorithmIdentifier ::= AlgorithmIdentifier
   * Digest ::= OCTET STRING
   *
   * To perform PSS signature verification, provide an instance
   * of Forge PSS object as the scheme parameter.
   *
   * @param digest the message digest hash to compare against the signature,
   *          as a binary-encoded string.
   * @param signature the signature to verify, as a binary-encoded string.
   * @param scheme signature verification scheme to use:
   *          'RSASSA-PKCS1-V1_5' or undefined for RSASSA PKCS#1 v1.5,
   *          a Forge PSS object for RSASSA-PSS,
   *          'NONE' or null for none, DigestInfo will not be expected, but
   *            PKCS#1 v1.5 padding will still be used.
   * @param options optional verify options
   *          _parseAllDigestBytes testing flag to control parsing of all
   *            digest bytes. Unsupported and not for general usage.
   *            (default: true)
   *
   * @return true if the signature was verified, false if not.
   */
  key.verify = function(digest, signature, scheme, options) {
    if(typeof scheme === 'string') {
      scheme = scheme.toUpperCase();
    } else if(scheme === undefined) {
      scheme = 'RSASSA-PKCS1-V1_5';
    }
    if(options === undefined) {
      options = {
        _parseAllDigestBytes: true
      };
    }
    if(!('_parseAllDigestBytes' in options)) {
      options._parseAllDigestBytes = true;
    }

    if(scheme === 'RSASSA-PKCS1-V1_5') {
      scheme = {
        verify: function(digest, d) {
          // remove padding
          d = _decodePkcs1_v1_5(d, key, true);
          // d is ASN.1 BER-encoded DigestInfo
          var obj = asn1$4.fromDer(d, {
            parseAllBytes: options._parseAllDigestBytes
          });

          // validate DigestInfo
          var capture = {};
          var errors = [];
          if(!asn1$4.validate(obj, digestInfoValidator, capture, errors)) {
            var error = new Error(
              'ASN.1 object does not contain a valid RSASSA-PKCS1-v1_5 ' +
              'DigestInfo value.');
            error.errors = errors;
            throw error;
          }
          // check hash algorithm identifier
          // see PKCS1-v1-5DigestAlgorithms in RFC 8017
          // FIXME: add support to vaidator for strict value choices
          var oid = asn1$4.derToOid(capture.algorithmIdentifier);
          if(!(oid === forge$8.oids.md2 ||
            oid === forge$8.oids.md5 ||
            oid === forge$8.oids.sha1 ||
            oid === forge$8.oids.sha224 ||
            oid === forge$8.oids.sha256 ||
            oid === forge$8.oids.sha384 ||
            oid === forge$8.oids.sha512 ||
            oid === forge$8.oids['sha512-224'] ||
            oid === forge$8.oids['sha512-256'])) {
            var error = new Error(
              'Unknown RSASSA-PKCS1-v1_5 DigestAlgorithm identifier.');
            error.oid = oid;
            throw error;
          }

          // special check for md2 and md5 that NULL parameters exist
          if(oid === forge$8.oids.md2 || oid === forge$8.oids.md5) {
            if(!('parameters' in capture)) {
              throw new Error(
                'ASN.1 object does not contain a valid RSASSA-PKCS1-v1_5 ' +
                'DigestInfo value. ' +
                'Missing algorithm identifer NULL parameters.');
            }
          }

          // compare the given digest to the decrypted one
          return digest === capture.digest;
        }
      };
    } else if(scheme === 'NONE' || scheme === 'NULL' || scheme === null) {
      scheme = {
        verify: function(digest, d) {
          // remove padding
          d = _decodePkcs1_v1_5(d, key, true);
          return digest === d;
        }
      };
    }

    // do rsa decryption w/o any decoding, then verify -- which does decoding
    var d = pki$3.rsa.decrypt(signature, key, true, false);
    return scheme.verify(digest, d, key.n.bitLength());
  };

  return key;
};

/**
 * Sets an RSA private key from BigIntegers modulus, exponent, primes,
 * prime exponents, and modular multiplicative inverse.
 *
 * @param n the modulus.
 * @param e the public exponent.
 * @param d the private exponent ((inverse of e) mod n).
 * @param p the first prime.
 * @param q the second prime.
 * @param dP exponent1 (d mod (p-1)).
 * @param dQ exponent2 (d mod (q-1)).
 * @param qInv ((inverse of q) mod p)
 *
 * @return the private key.
 */
pki$3.setRsaPrivateKey = pki$3.rsa.setPrivateKey = function(
  n, e, d, p, q, dP, dQ, qInv) {
  var key = {
    n: n,
    e: e,
    d: d,
    p: p,
    q: q,
    dP: dP,
    dQ: dQ,
    qInv: qInv
  };

  /**
   * Decrypts the given data with this private key. The decryption scheme
   * must match the one used to encrypt the data.
   *
   * @param data the byte string to decrypt.
   * @param scheme the decryption scheme to use:
   *          'RSAES-PKCS1-V1_5' (default),
   *          'RSA-OAEP',
   *          'RAW', 'NONE', or null to perform raw RSA decryption.
   * @param schemeOptions any scheme-specific options.
   *
   * @return the decrypted byte string.
   */
  key.decrypt = function(data, scheme, schemeOptions) {
    if(typeof scheme === 'string') {
      scheme = scheme.toUpperCase();
    } else if(scheme === undefined) {
      scheme = 'RSAES-PKCS1-V1_5';
    }

    // do rsa decryption w/o any decoding
    var d = pki$3.rsa.decrypt(data, key, false, false);

    if(scheme === 'RSAES-PKCS1-V1_5') {
      scheme = {decode: _decodePkcs1_v1_5};
    } else if(scheme === 'RSA-OAEP' || scheme === 'RSAES-OAEP') {
      scheme = {
        decode: function(d, key) {
          return forge$8.pkcs1.decode_rsa_oaep(key, d, schemeOptions);
        }
      };
    } else if(['RAW', 'NONE', 'NULL', null].indexOf(scheme) !== -1) {
      scheme = {decode: function(d) {return d;}};
    } else {
      throw new Error('Unsupported encryption scheme: "' + scheme + '".');
    }

    // decode according to scheme
    return scheme.decode(d, key, false);
  };

  /**
   * Signs the given digest, producing a signature.
   *
   * PKCS#1 supports multiple (currently two) signature schemes:
   * RSASSA-PKCS1-V1_5 and RSASSA-PSS.
   *
   * By default this implementation uses the "old scheme", i.e.
   * RSASSA-PKCS1-V1_5. In order to generate a PSS signature, provide
   * an instance of Forge PSS object as the scheme parameter.
   *
   * @param md the message digest object with the hash to sign.
   * @param scheme the signature scheme to use:
   *          'RSASSA-PKCS1-V1_5' or undefined for RSASSA PKCS#1 v1.5,
   *          a Forge PSS object for RSASSA-PSS,
   *          'NONE' or null for none, DigestInfo will not be used but
   *            PKCS#1 v1.5 padding will still be used.
   *
   * @return the signature as a byte string.
   */
  key.sign = function(md, scheme) {
    /* Note: The internal implementation of RSA operations is being
      transitioned away from a PKCS#1 v1.5 hard-coded scheme. Some legacy
      code like the use of an encoding block identifier 'bt' will eventually
      be removed. */

    // private key operation
    var bt = false;

    if(typeof scheme === 'string') {
      scheme = scheme.toUpperCase();
    }

    if(scheme === undefined || scheme === 'RSASSA-PKCS1-V1_5') {
      scheme = {encode: emsaPkcs1v15encode};
      bt = 0x01;
    } else if(scheme === 'NONE' || scheme === 'NULL' || scheme === null) {
      scheme = {encode: function() {return md;}};
      bt = 0x01;
    }

    // encode and then encrypt
    var d = scheme.encode(md, key.n.bitLength());
    return pki$3.rsa.encrypt(d, key, bt);
  };

  return key;
};

/**
 * Wraps an RSAPrivateKey ASN.1 object in an ASN.1 PrivateKeyInfo object.
 *
 * @param rsaKey the ASN.1 RSAPrivateKey.
 *
 * @return the ASN.1 PrivateKeyInfo.
 */
pki$3.wrapRsaPrivateKey = function(rsaKey) {
  // PrivateKeyInfo
  return asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.SEQUENCE, true, [
    // version (0)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      asn1$4.integerToDer(0).getBytes()),
    // privateKeyAlgorithm
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.SEQUENCE, true, [
      asn1$4.create(
        asn1$4.Class.UNIVERSAL, asn1$4.Type.OID, false,
        asn1$4.oidToDer(pki$3.oids.rsaEncryption).getBytes()),
      asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.NULL, false, '')
    ]),
    // PrivateKey
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.OCTETSTRING, false,
      asn1$4.toDer(rsaKey).getBytes())
  ]);
};

/**
 * Converts a private key from an ASN.1 object.
 *
 * @param obj the ASN.1 representation of a PrivateKeyInfo containing an
 *          RSAPrivateKey or an RSAPrivateKey.
 *
 * @return the private key.
 */
pki$3.privateKeyFromAsn1 = function(obj) {
  // get PrivateKeyInfo
  var capture = {};
  var errors = [];
  if(asn1$4.validate(obj, privateKeyValidator, capture, errors)) {
    obj = asn1$4.fromDer(forge$8.util.createBuffer(capture.privateKey));
  }

  // get RSAPrivateKey
  capture = {};
  errors = [];
  if(!asn1$4.validate(obj, rsaPrivateKeyValidator, capture, errors)) {
    var error = new Error('Cannot read private key. ' +
      'ASN.1 object does not contain an RSAPrivateKey.');
    error.errors = errors;
    throw error;
  }

  // Note: Version is currently ignored.
  // capture.privateKeyVersion
  // FIXME: inefficient, get a BigInteger that uses byte strings
  var n, e, d, p, q, dP, dQ, qInv;
  n = forge$8.util.createBuffer(capture.privateKeyModulus).toHex();
  e = forge$8.util.createBuffer(capture.privateKeyPublicExponent).toHex();
  d = forge$8.util.createBuffer(capture.privateKeyPrivateExponent).toHex();
  p = forge$8.util.createBuffer(capture.privateKeyPrime1).toHex();
  q = forge$8.util.createBuffer(capture.privateKeyPrime2).toHex();
  dP = forge$8.util.createBuffer(capture.privateKeyExponent1).toHex();
  dQ = forge$8.util.createBuffer(capture.privateKeyExponent2).toHex();
  qInv = forge$8.util.createBuffer(capture.privateKeyCoefficient).toHex();

  // set private key
  return pki$3.setRsaPrivateKey(
    new BigInteger$1(n, 16),
    new BigInteger$1(e, 16),
    new BigInteger$1(d, 16),
    new BigInteger$1(p, 16),
    new BigInteger$1(q, 16),
    new BigInteger$1(dP, 16),
    new BigInteger$1(dQ, 16),
    new BigInteger$1(qInv, 16));
};

/**
 * Converts a private key to an ASN.1 RSAPrivateKey.
 *
 * @param key the private key.
 *
 * @return the ASN.1 representation of an RSAPrivateKey.
 */
pki$3.privateKeyToAsn1 = pki$3.privateKeyToRSAPrivateKey = function(key) {
  // RSAPrivateKey
  return asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.SEQUENCE, true, [
    // version (0 = only 2 primes, 1 multiple primes)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      asn1$4.integerToDer(0).getBytes()),
    // modulus (n)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.n)),
    // publicExponent (e)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.e)),
    // privateExponent (d)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.d)),
    // privateKeyPrime1 (p)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.p)),
    // privateKeyPrime2 (q)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.q)),
    // privateKeyExponent1 (dP)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.dP)),
    // privateKeyExponent2 (dQ)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.dQ)),
    // coefficient (qInv)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.qInv))
  ]);
};

/**
 * Converts a public key from an ASN.1 SubjectPublicKeyInfo or RSAPublicKey.
 *
 * @param obj the asn1 representation of a SubjectPublicKeyInfo or RSAPublicKey.
 *
 * @return the public key.
 */
pki$3.publicKeyFromAsn1 = function(obj) {
  // get SubjectPublicKeyInfo
  var capture = {};
  var errors = [];
  if(asn1$4.validate(obj, publicKeyValidator$1, capture, errors)) {
    // get oid
    var oid = asn1$4.derToOid(capture.publicKeyOid);
    if(oid !== pki$3.oids.rsaEncryption) {
      var error = new Error('Cannot read public key. Unknown OID.');
      error.oid = oid;
      throw error;
    }
    obj = capture.rsaPublicKey;
  }

  // get RSA params
  errors = [];
  if(!asn1$4.validate(obj, rsaPublicKeyValidator, capture, errors)) {
    var error = new Error('Cannot read public key. ' +
      'ASN.1 object does not contain an RSAPublicKey.');
    error.errors = errors;
    throw error;
  }

  // FIXME: inefficient, get a BigInteger that uses byte strings
  var n = forge$8.util.createBuffer(capture.publicKeyModulus).toHex();
  var e = forge$8.util.createBuffer(capture.publicKeyExponent).toHex();

  // set public key
  return pki$3.setRsaPublicKey(
    new BigInteger$1(n, 16),
    new BigInteger$1(e, 16));
};

/**
 * Converts a public key to an ASN.1 SubjectPublicKeyInfo.
 *
 * @param key the public key.
 *
 * @return the asn1 representation of a SubjectPublicKeyInfo.
 */
pki$3.publicKeyToAsn1 = pki$3.publicKeyToSubjectPublicKeyInfo = function(key) {
  // SubjectPublicKeyInfo
  return asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.SEQUENCE, true, [
    // AlgorithmIdentifier
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.SEQUENCE, true, [
      // algorithm
      asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.OID, false,
        asn1$4.oidToDer(pki$3.oids.rsaEncryption).getBytes()),
      // parameters (null)
      asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.NULL, false, '')
    ]),
    // subjectPublicKey
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.BITSTRING, false, [
      pki$3.publicKeyToRSAPublicKey(key)
    ])
  ]);
};

/**
 * Converts a public key to an ASN.1 RSAPublicKey.
 *
 * @param key the public key.
 *
 * @return the asn1 representation of a RSAPublicKey.
 */
pki$3.publicKeyToRSAPublicKey = function(key) {
  // RSAPublicKey
  return asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.SEQUENCE, true, [
    // modulus (n)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.n)),
    // publicExponent (e)
    asn1$4.create(asn1$4.Class.UNIVERSAL, asn1$4.Type.INTEGER, false,
      _bnToBytes(key.e))
  ]);
};

/**
 * Encodes a message using PKCS#1 v1.5 padding.
 *
 * @param m the message to encode.
 * @param key the RSA key to use.
 * @param bt the block type to use, i.e. either 0x01 (for signing) or 0x02
 *          (for encryption).
 *
 * @return the padded byte buffer.
 */
function _encodePkcs1_v1_5(m, key, bt) {
  var eb = forge$8.util.createBuffer();

  // get the length of the modulus in bytes
  var k = Math.ceil(key.n.bitLength() / 8);

  /* use PKCS#1 v1.5 padding */
  if(m.length > (k - 11)) {
    var error = new Error('Message is too long for PKCS#1 v1.5 padding.');
    error.length = m.length;
    error.max = k - 11;
    throw error;
  }

  /* A block type BT, a padding string PS, and the data D shall be
    formatted into an octet string EB, the encryption block:

    EB = 00 || BT || PS || 00 || D

    The block type BT shall be a single octet indicating the structure of
    the encryption block. For this version of the document it shall have
    value 00, 01, or 02. For a private-key operation, the block type
    shall be 00 or 01. For a public-key operation, it shall be 02.

    The padding string PS shall consist of k-3-||D|| octets. For block
    type 00, the octets shall have value 00; for block type 01, they
    shall have value FF; and for block type 02, they shall be
    pseudorandomly generated and nonzero. This makes the length of the
    encryption block EB equal to k. */

  // build the encryption block
  eb.putByte(0x00);
  eb.putByte(bt);

  // create the padding
  var padNum = k - 3 - m.length;
  var padByte;
  // private key op
  if(bt === 0x00 || bt === 0x01) {
    padByte = (bt === 0x00) ? 0x00 : 0xFF;
    for(var i = 0; i < padNum; ++i) {
      eb.putByte(padByte);
    }
  } else {
    // public key op
    // pad with random non-zero values
    while(padNum > 0) {
      var numZeros = 0;
      var padBytes = forge$8.random.getBytes(padNum);
      for(var i = 0; i < padNum; ++i) {
        padByte = padBytes.charCodeAt(i);
        if(padByte === 0) {
          ++numZeros;
        } else {
          eb.putByte(padByte);
        }
      }
      padNum = numZeros;
    }
  }

  // zero followed by message
  eb.putByte(0x00);
  eb.putBytes(m);

  return eb;
}

/**
 * Decodes a message using PKCS#1 v1.5 padding.
 *
 * @param em the message to decode.
 * @param key the RSA key to use.
 * @param pub true if the key is a public key, false if it is private.
 * @param ml the message length, if specified.
 *
 * @return the decoded bytes.
 */
function _decodePkcs1_v1_5(em, key, pub, ml) {
  // get the length of the modulus in bytes
  var k = Math.ceil(key.n.bitLength() / 8);

  /* It is an error if any of the following conditions occurs:

    1. The encryption block EB cannot be parsed unambiguously.
    2. The padding string PS consists of fewer than eight octets
      or is inconsisent with the block type BT.
    3. The decryption process is a public-key operation and the block
      type BT is not 00 or 01, or the decryption process is a
      private-key operation and the block type is not 02.
   */

  // parse the encryption block
  var eb = forge$8.util.createBuffer(em);
  var first = eb.getByte();
  var bt = eb.getByte();
  if(first !== 0x00 ||
    (pub && bt !== 0x00 && bt !== 0x01) ||
    (!pub && bt != 0x02) ||
    (pub && bt === 0x00 && typeof(ml) === 'undefined')) {
    throw new Error('Encryption block is invalid.');
  }

  var padNum = 0;
  if(bt === 0x00) {
    // check all padding bytes for 0x00
    padNum = k - 3 - ml;
    for(var i = 0; i < padNum; ++i) {
      if(eb.getByte() !== 0x00) {
        throw new Error('Encryption block is invalid.');
      }
    }
  } else if(bt === 0x01) {
    // find the first byte that isn't 0xFF, should be after all padding
    padNum = 0;
    while(eb.length() > 1) {
      if(eb.getByte() !== 0xFF) {
        --eb.read;
        break;
      }
      ++padNum;
    }
  } else if(bt === 0x02) {
    // look for 0x00 byte
    padNum = 0;
    while(eb.length() > 1) {
      if(eb.getByte() === 0x00) {
        --eb.read;
        break;
      }
      ++padNum;
    }
  }

  // zero must be 0x00 and padNum must be (k - 3 - message length)
  var zero = eb.getByte();
  if(zero !== 0x00 || padNum !== (k - 3 - eb.length())) {
    throw new Error('Encryption block is invalid.');
  }

  return eb.getBytes();
}

/**
 * Runs the key-generation algorithm asynchronously, either in the background
 * via Web Workers, or using the main thread and setImmediate.
 *
 * @param state the key-pair generation state.
 * @param [options] options for key-pair generation:
 *          workerScript the worker script URL.
 *          workers the number of web workers (if supported) to use,
 *            (default: 2, -1 to use estimated cores minus one).
 *          workLoad the size of the work load, ie: number of possible prime
 *            numbers for each web worker to check per work assignment,
 *            (default: 100).
 * @param callback(err, keypair) called once the operation completes.
 */
function _generateKeyPair(state, options, callback) {
  if(typeof options === 'function') {
    callback = options;
    options = {};
  }
  options = options || {};

  var opts = {
    algorithm: {
      name: options.algorithm || 'PRIMEINC',
      options: {
        workers: options.workers || 2,
        workLoad: options.workLoad || 100,
        workerScript: options.workerScript
      }
    }
  };
  if('prng' in options) {
    opts.prng = options.prng;
  }

  generate();

  function generate() {
    // find p and then q (done in series to simplify)
    getPrime(state.pBits, function(err, num) {
      if(err) {
        return callback(err);
      }
      state.p = num;
      if(state.q !== null) {
        return finish(err, state.q);
      }
      getPrime(state.qBits, finish);
    });
  }

  function getPrime(bits, callback) {
    forge$8.prime.generateProbablePrime(bits, opts, callback);
  }

  function finish(err, num) {
    if(err) {
      return callback(err);
    }

    // set q
    state.q = num;

    // ensure p is larger than q (swap them if not)
    if(state.p.compareTo(state.q) < 0) {
      var tmp = state.p;
      state.p = state.q;
      state.q = tmp;
    }

    // ensure p is coprime with e
    if(state.p.subtract(BigInteger$1.ONE).gcd(state.e)
      .compareTo(BigInteger$1.ONE) !== 0) {
      state.p = null;
      generate();
      return;
    }

    // ensure q is coprime with e
    if(state.q.subtract(BigInteger$1.ONE).gcd(state.e)
      .compareTo(BigInteger$1.ONE) !== 0) {
      state.q = null;
      getPrime(state.qBits, finish);
      return;
    }

    // compute phi: (p - 1)(q - 1) (Euler's totient function)
    state.p1 = state.p.subtract(BigInteger$1.ONE);
    state.q1 = state.q.subtract(BigInteger$1.ONE);
    state.phi = state.p1.multiply(state.q1);

    // ensure e and phi are coprime
    if(state.phi.gcd(state.e).compareTo(BigInteger$1.ONE) !== 0) {
      // phi and e aren't coprime, so generate a new p and q
      state.p = state.q = null;
      generate();
      return;
    }

    // create n, ensure n is has the right number of bits
    state.n = state.p.multiply(state.q);
    if(state.n.bitLength() !== state.bits) {
      // failed, get new q
      state.q = null;
      getPrime(state.qBits, finish);
      return;
    }

    // set keys
    var d = state.e.modInverse(state.phi);
    state.keys = {
      privateKey: pki$3.rsa.setPrivateKey(
        state.n, state.e, d, state.p, state.q,
        d.mod(state.p1), d.mod(state.q1),
        state.q.modInverse(state.p)),
      publicKey: pki$3.rsa.setPublicKey(state.n, state.e)
    };

    callback(null, state.keys);
  }
}

/**
 * Converts a positive BigInteger into 2's-complement big-endian bytes.
 *
 * @param b the big integer to convert.
 *
 * @return the bytes.
 */
function _bnToBytes(b) {
  // prepend 0x00 if first byte >= 0x80
  var hex = b.toString(16);
  if(hex[0] >= '8') {
    hex = '00' + hex;
  }
  var bytes = forge$8.util.hexToBytes(hex);

  // ensure integer is minimally-encoded
  if(bytes.length > 1 &&
    // leading 0x00 for positive integer
    ((bytes.charCodeAt(0) === 0 &&
    (bytes.charCodeAt(1) & 0x80) === 0) ||
    // leading 0xFF for negative integer
    (bytes.charCodeAt(0) === 0xFF &&
    (bytes.charCodeAt(1) & 0x80) === 0x80))) {
    return bytes.substr(1);
  }
  return bytes;
}

/**
 * Returns the required number of Miller-Rabin tests to generate a
 * prime with an error probability of (1/2)^80.
 *
 * See Handbook of Applied Cryptography Chapter 4, Table 4.4.
 *
 * @param bits the bit size.
 *
 * @return the required number of iterations.
 */
function _getMillerRabinTests(bits) {
  if(bits <= 100) return 27;
  if(bits <= 150) return 18;
  if(bits <= 200) return 15;
  if(bits <= 250) return 12;
  if(bits <= 300) return 9;
  if(bits <= 350) return 8;
  if(bits <= 400) return 7;
  if(bits <= 500) return 6;
  if(bits <= 600) return 5;
  if(bits <= 800) return 4;
  if(bits <= 1250) return 3;
  return 2;
}

/**
 * Performs feature detection on the Node crypto interface.
 *
 * @param fn the feature (function) to detect.
 *
 * @return true if detected, false if not.
 */
function _detectNodeCrypto(fn) {
  return forge$8.util.isNodejs && typeof _crypto[fn] === 'function';
}

/**
 * Performs feature detection on the SubtleCrypto interface.
 *
 * @param fn the feature (function) to detect.
 *
 * @return true if detected, false if not.
 */
function _detectSubtleCrypto(fn) {
  return (typeof util$u.globalScope !== 'undefined' &&
    typeof util$u.globalScope.crypto === 'object' &&
    typeof util$u.globalScope.crypto.subtle === 'object' &&
    typeof util$u.globalScope.crypto.subtle[fn] === 'function');
}

/**
 * Performs feature detection on the deprecated Microsoft Internet Explorer
 * outdated SubtleCrypto interface. This function should only be used after
 * checking for the modern, standard SubtleCrypto interface.
 *
 * @param fn the feature (function) to detect.
 *
 * @return true if detected, false if not.
 */
function _detectSubtleMsCrypto(fn) {
  return (typeof util$u.globalScope !== 'undefined' &&
    typeof util$u.globalScope.msCrypto === 'object' &&
    typeof util$u.globalScope.msCrypto.subtle === 'object' &&
    typeof util$u.globalScope.msCrypto.subtle[fn] === 'function');
}

function _intToUint8Array(x) {
  var bytes = forge$8.util.hexToBytes(x.toString(16));
  var buffer = new Uint8Array(bytes.length);
  for(var i = 0; i < bytes.length; ++i) {
    buffer[i] = bytes.charCodeAt(i);
  }
  return buffer;
}

/**
 * Password-based encryption functions.
 *
 * @author Dave Longley
 * @author Stefan Siegl <stesie@brokenpipe.de>
 *
 * Copyright (c) 2010-2013 Digital Bazaar, Inc.
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 *
 * An EncryptedPrivateKeyInfo:
 *
 * EncryptedPrivateKeyInfo ::= SEQUENCE {
 *   encryptionAlgorithm  EncryptionAlgorithmIdentifier,
 *   encryptedData        EncryptedData }
 *
 * EncryptionAlgorithmIdentifier ::= AlgorithmIdentifier
 *
 * EncryptedData ::= OCTET STRING
 */

var forge$7 = forge$s;












if(typeof BigInteger === 'undefined') {
  var BigInteger = forge$7.jsbn.BigInteger;
}

// shortcut for asn.1 API
var asn1$3 = forge$7.asn1;

/* Password-based encryption implementation. */
var pki$2 = forge$7.pki = forge$7.pki || {};
pki$2.pbe = forge$7.pbe = forge$7.pbe || {};
var oids$1 = pki$2.oids;

// validator for an EncryptedPrivateKeyInfo structure
// Note: Currently only works w/algorithm params
var encryptedPrivateKeyValidator = {
  name: 'EncryptedPrivateKeyInfo',
  tagClass: asn1$3.Class.UNIVERSAL,
  type: asn1$3.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'EncryptedPrivateKeyInfo.encryptionAlgorithm',
    tagClass: asn1$3.Class.UNIVERSAL,
    type: asn1$3.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'AlgorithmIdentifier.algorithm',
      tagClass: asn1$3.Class.UNIVERSAL,
      type: asn1$3.Type.OID,
      constructed: false,
      capture: 'encryptionOid'
    }, {
      name: 'AlgorithmIdentifier.parameters',
      tagClass: asn1$3.Class.UNIVERSAL,
      type: asn1$3.Type.SEQUENCE,
      constructed: true,
      captureAsn1: 'encryptionParams'
    }]
  }, {
    // encryptedData
    name: 'EncryptedPrivateKeyInfo.encryptedData',
    tagClass: asn1$3.Class.UNIVERSAL,
    type: asn1$3.Type.OCTETSTRING,
    constructed: false,
    capture: 'encryptedData'
  }]
};

// validator for a PBES2Algorithms structure
// Note: Currently only works w/PBKDF2 + AES encryption schemes
var PBES2AlgorithmsValidator = {
  name: 'PBES2Algorithms',
  tagClass: asn1$3.Class.UNIVERSAL,
  type: asn1$3.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'PBES2Algorithms.keyDerivationFunc',
    tagClass: asn1$3.Class.UNIVERSAL,
    type: asn1$3.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'PBES2Algorithms.keyDerivationFunc.oid',
      tagClass: asn1$3.Class.UNIVERSAL,
      type: asn1$3.Type.OID,
      constructed: false,
      capture: 'kdfOid'
    }, {
      name: 'PBES2Algorithms.params',
      tagClass: asn1$3.Class.UNIVERSAL,
      type: asn1$3.Type.SEQUENCE,
      constructed: true,
      value: [{
        name: 'PBES2Algorithms.params.salt',
        tagClass: asn1$3.Class.UNIVERSAL,
        type: asn1$3.Type.OCTETSTRING,
        constructed: false,
        capture: 'kdfSalt'
      }, {
        name: 'PBES2Algorithms.params.iterationCount',
        tagClass: asn1$3.Class.UNIVERSAL,
        type: asn1$3.Type.INTEGER,
        constructed: false,
        capture: 'kdfIterationCount'
      }, {
        name: 'PBES2Algorithms.params.keyLength',
        tagClass: asn1$3.Class.UNIVERSAL,
        type: asn1$3.Type.INTEGER,
        constructed: false,
        optional: true,
        capture: 'keyLength'
      }, {
        // prf
        name: 'PBES2Algorithms.params.prf',
        tagClass: asn1$3.Class.UNIVERSAL,
        type: asn1$3.Type.SEQUENCE,
        constructed: true,
        optional: true,
        value: [{
          name: 'PBES2Algorithms.params.prf.algorithm',
          tagClass: asn1$3.Class.UNIVERSAL,
          type: asn1$3.Type.OID,
          constructed: false,
          capture: 'prfOid'
        }]
      }]
    }]
  }, {
    name: 'PBES2Algorithms.encryptionScheme',
    tagClass: asn1$3.Class.UNIVERSAL,
    type: asn1$3.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'PBES2Algorithms.encryptionScheme.oid',
      tagClass: asn1$3.Class.UNIVERSAL,
      type: asn1$3.Type.OID,
      constructed: false,
      capture: 'encOid'
    }, {
      name: 'PBES2Algorithms.encryptionScheme.iv',
      tagClass: asn1$3.Class.UNIVERSAL,
      type: asn1$3.Type.OCTETSTRING,
      constructed: false,
      capture: 'encIv'
    }]
  }]
};

var pkcs12PbeParamsValidator = {
  name: 'pkcs-12PbeParams',
  tagClass: asn1$3.Class.UNIVERSAL,
  type: asn1$3.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'pkcs-12PbeParams.salt',
    tagClass: asn1$3.Class.UNIVERSAL,
    type: asn1$3.Type.OCTETSTRING,
    constructed: false,
    capture: 'salt'
  }, {
    name: 'pkcs-12PbeParams.iterations',
    tagClass: asn1$3.Class.UNIVERSAL,
    type: asn1$3.Type.INTEGER,
    constructed: false,
    capture: 'iterations'
  }]
};

/**
 * Encrypts a ASN.1 PrivateKeyInfo object, producing an EncryptedPrivateKeyInfo.
 *
 * PBES2Algorithms ALGORITHM-IDENTIFIER ::=
 *   { {PBES2-params IDENTIFIED BY id-PBES2}, ...}
 *
 * id-PBES2 OBJECT IDENTIFIER ::= {pkcs-5 13}
 *
 * PBES2-params ::= SEQUENCE {
 *   keyDerivationFunc AlgorithmIdentifier {{PBES2-KDFs}},
 *   encryptionScheme AlgorithmIdentifier {{PBES2-Encs}}
 * }
 *
 * PBES2-KDFs ALGORITHM-IDENTIFIER ::=
 *   { {PBKDF2-params IDENTIFIED BY id-PBKDF2}, ... }
 *
 * PBES2-Encs ALGORITHM-IDENTIFIER ::= { ... }
 *
 * PBKDF2-params ::= SEQUENCE {
 *   salt CHOICE {
 *     specified OCTET STRING,
 *     otherSource AlgorithmIdentifier {{PBKDF2-SaltSources}}
 *   },
 *   iterationCount INTEGER (1..MAX),
 *   keyLength INTEGER (1..MAX) OPTIONAL,
 *   prf AlgorithmIdentifier {{PBKDF2-PRFs}} DEFAULT algid-hmacWithSHA1
 * }
 *
 * @param obj the ASN.1 PrivateKeyInfo object.
 * @param password the password to encrypt with.
 * @param options:
 *          algorithm the encryption algorithm to use
 *            ('aes128', 'aes192', 'aes256', '3des'), defaults to 'aes128'.
 *          count the iteration count to use.
 *          saltSize the salt size to use.
 *          prfAlgorithm the PRF message digest algorithm to use
 *            ('sha1', 'sha224', 'sha256', 'sha384', 'sha512')
 *
 * @return the ASN.1 EncryptedPrivateKeyInfo.
 */
pki$2.encryptPrivateKeyInfo = function(obj, password, options) {
  // set default options
  options = options || {};
  options.saltSize = options.saltSize || 8;
  options.count = options.count || 2048;
  options.algorithm = options.algorithm || 'aes128';
  options.prfAlgorithm = options.prfAlgorithm || 'sha1';

  // generate PBE params
  var salt = forge$7.random.getBytesSync(options.saltSize);
  var count = options.count;
  var countBytes = asn1$3.integerToDer(count);
  var dkLen;
  var encryptionAlgorithm;
  var encryptedData;
  if(options.algorithm.indexOf('aes') === 0 || options.algorithm === 'des') {
    // do PBES2
    var ivLen, encOid, cipherFn;
    switch(options.algorithm) {
    case 'aes128':
      dkLen = 16;
      ivLen = 16;
      encOid = oids$1['aes128-CBC'];
      cipherFn = forge$7.aes.createEncryptionCipher;
      break;
    case 'aes192':
      dkLen = 24;
      ivLen = 16;
      encOid = oids$1['aes192-CBC'];
      cipherFn = forge$7.aes.createEncryptionCipher;
      break;
    case 'aes256':
      dkLen = 32;
      ivLen = 16;
      encOid = oids$1['aes256-CBC'];
      cipherFn = forge$7.aes.createEncryptionCipher;
      break;
    case 'des':
      dkLen = 8;
      ivLen = 8;
      encOid = oids$1['desCBC'];
      cipherFn = forge$7.des.createEncryptionCipher;
      break;
    default:
      var error = new Error('Cannot encrypt private key. Unknown encryption algorithm.');
      error.algorithm = options.algorithm;
      throw error;
    }

    // get PRF message digest
    var prfAlgorithm = 'hmacWith' + options.prfAlgorithm.toUpperCase();
    var md = prfAlgorithmToMessageDigest(prfAlgorithm);

    // encrypt private key using pbe SHA-1 and AES/DES
    var dk = forge$7.pkcs5.pbkdf2(password, salt, count, dkLen, md);
    var iv = forge$7.random.getBytesSync(ivLen);
    var cipher = cipherFn(dk);
    cipher.start(iv);
    cipher.update(asn1$3.toDer(obj));
    cipher.finish();
    encryptedData = cipher.output.getBytes();

    // get PBKDF2-params
    var params = createPbkdf2Params(salt, countBytes, dkLen, prfAlgorithm);

    encryptionAlgorithm = asn1$3.create(
      asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
      asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.OID, false,
        asn1$3.oidToDer(oids$1['pkcs5PBES2']).getBytes()),
      asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
        // keyDerivationFunc
        asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
          asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.OID, false,
            asn1$3.oidToDer(oids$1['pkcs5PBKDF2']).getBytes()),
          // PBKDF2-params
          params
        ]),
        // encryptionScheme
        asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
          asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.OID, false,
            asn1$3.oidToDer(encOid).getBytes()),
          // iv
          asn1$3.create(
            asn1$3.Class.UNIVERSAL, asn1$3.Type.OCTETSTRING, false, iv)
        ])
      ])
    ]);
  } else if(options.algorithm === '3des') {
    // Do PKCS12 PBE
    dkLen = 24;

    var saltBytes = new forge$7.util.ByteBuffer(salt);
    var dk = pki$2.pbe.generatePkcs12Key(password, saltBytes, 1, count, dkLen);
    var iv = pki$2.pbe.generatePkcs12Key(password, saltBytes, 2, count, dkLen);
    var cipher = forge$7.des.createEncryptionCipher(dk);
    cipher.start(iv);
    cipher.update(asn1$3.toDer(obj));
    cipher.finish();
    encryptedData = cipher.output.getBytes();

    encryptionAlgorithm = asn1$3.create(
      asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
      asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.OID, false,
        asn1$3.oidToDer(oids$1['pbeWithSHAAnd3-KeyTripleDES-CBC']).getBytes()),
      // pkcs-12PbeParams
      asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
        // salt
        asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.OCTETSTRING, false, salt),
        // iteration count
        asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.INTEGER, false,
          countBytes.getBytes())
      ])
    ]);
  } else {
    var error = new Error('Cannot encrypt private key. Unknown encryption algorithm.');
    error.algorithm = options.algorithm;
    throw error;
  }

  // EncryptedPrivateKeyInfo
  var rval = asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
    // encryptionAlgorithm
    encryptionAlgorithm,
    // encryptedData
    asn1$3.create(
      asn1$3.Class.UNIVERSAL, asn1$3.Type.OCTETSTRING, false, encryptedData)
  ]);
  return rval;
};

/**
 * Decrypts a ASN.1 PrivateKeyInfo object.
 *
 * @param obj the ASN.1 EncryptedPrivateKeyInfo object.
 * @param password the password to decrypt with.
 *
 * @return the ASN.1 PrivateKeyInfo on success, null on failure.
 */
pki$2.decryptPrivateKeyInfo = function(obj, password) {
  var rval = null;

  // get PBE params
  var capture = {};
  var errors = [];
  if(!asn1$3.validate(obj, encryptedPrivateKeyValidator, capture, errors)) {
    var error = new Error('Cannot read encrypted private key. ' +
      'ASN.1 object is not a supported EncryptedPrivateKeyInfo.');
    error.errors = errors;
    throw error;
  }

  // get cipher
  var oid = asn1$3.derToOid(capture.encryptionOid);
  var cipher = pki$2.pbe.getCipher(oid, capture.encryptionParams, password);

  // get encrypted data
  var encrypted = forge$7.util.createBuffer(capture.encryptedData);

  cipher.update(encrypted);
  if(cipher.finish()) {
    rval = asn1$3.fromDer(cipher.output);
  }

  return rval;
};

/**
 * Converts a EncryptedPrivateKeyInfo to PEM format.
 *
 * @param epki the EncryptedPrivateKeyInfo.
 * @param maxline the maximum characters per line, defaults to 64.
 *
 * @return the PEM-formatted encrypted private key.
 */
pki$2.encryptedPrivateKeyToPem = function(epki, maxline) {
  // convert to DER, then PEM-encode
  var msg = {
    type: 'ENCRYPTED PRIVATE KEY',
    body: asn1$3.toDer(epki).getBytes()
  };
  return forge$7.pem.encode(msg, {maxline: maxline});
};

/**
 * Converts a PEM-encoded EncryptedPrivateKeyInfo to ASN.1 format. Decryption
 * is not performed.
 *
 * @param pem the EncryptedPrivateKeyInfo in PEM-format.
 *
 * @return the ASN.1 EncryptedPrivateKeyInfo.
 */
pki$2.encryptedPrivateKeyFromPem = function(pem) {
  var msg = forge$7.pem.decode(pem)[0];

  if(msg.type !== 'ENCRYPTED PRIVATE KEY') {
    var error = new Error('Could not convert encrypted private key from PEM; ' +
      'PEM header type is "ENCRYPTED PRIVATE KEY".');
    error.headerType = msg.type;
    throw error;
  }
  if(msg.procType && msg.procType.type === 'ENCRYPTED') {
    throw new Error('Could not convert encrypted private key from PEM; ' +
      'PEM is encrypted.');
  }

  // convert DER to ASN.1 object
  return asn1$3.fromDer(msg.body);
};

/**
 * Encrypts an RSA private key. By default, the key will be wrapped in
 * a PrivateKeyInfo and encrypted to produce a PKCS#8 EncryptedPrivateKeyInfo.
 * This is the standard, preferred way to encrypt a private key.
 *
 * To produce a non-standard PEM-encrypted private key that uses encapsulated
 * headers to indicate the encryption algorithm (old-style non-PKCS#8 OpenSSL
 * private key encryption), set the 'legacy' option to true. Note: Using this
 * option will cause the iteration count to be forced to 1.
 *
 * Note: The 'des' algorithm is supported, but it is not considered to be
 * secure because it only uses a single 56-bit key. If possible, it is highly
 * recommended that a different algorithm be used.
 *
 * @param rsaKey the RSA key to encrypt.
 * @param password the password to use.
 * @param options:
 *          algorithm: the encryption algorithm to use
 *            ('aes128', 'aes192', 'aes256', '3des', 'des').
 *          count: the iteration count to use.
 *          saltSize: the salt size to use.
 *          legacy: output an old non-PKCS#8 PEM-encrypted+encapsulated
 *            headers (DEK-Info) private key.
 *
 * @return the PEM-encoded ASN.1 EncryptedPrivateKeyInfo.
 */
pki$2.encryptRsaPrivateKey = function(rsaKey, password, options) {
  // standard PKCS#8
  options = options || {};
  if(!options.legacy) {
    // encrypt PrivateKeyInfo
    var rval = pki$2.wrapRsaPrivateKey(pki$2.privateKeyToAsn1(rsaKey));
    rval = pki$2.encryptPrivateKeyInfo(rval, password, options);
    return pki$2.encryptedPrivateKeyToPem(rval);
  }

  // legacy non-PKCS#8
  var algorithm;
  var iv;
  var dkLen;
  var cipherFn;
  switch(options.algorithm) {
  case 'aes128':
    algorithm = 'AES-128-CBC';
    dkLen = 16;
    iv = forge$7.random.getBytesSync(16);
    cipherFn = forge$7.aes.createEncryptionCipher;
    break;
  case 'aes192':
    algorithm = 'AES-192-CBC';
    dkLen = 24;
    iv = forge$7.random.getBytesSync(16);
    cipherFn = forge$7.aes.createEncryptionCipher;
    break;
  case 'aes256':
    algorithm = 'AES-256-CBC';
    dkLen = 32;
    iv = forge$7.random.getBytesSync(16);
    cipherFn = forge$7.aes.createEncryptionCipher;
    break;
  case '3des':
    algorithm = 'DES-EDE3-CBC';
    dkLen = 24;
    iv = forge$7.random.getBytesSync(8);
    cipherFn = forge$7.des.createEncryptionCipher;
    break;
  case 'des':
    algorithm = 'DES-CBC';
    dkLen = 8;
    iv = forge$7.random.getBytesSync(8);
    cipherFn = forge$7.des.createEncryptionCipher;
    break;
  default:
    var error = new Error('Could not encrypt RSA private key; unsupported ' +
      'encryption algorithm "' + options.algorithm + '".');
    error.algorithm = options.algorithm;
    throw error;
  }

  // encrypt private key using OpenSSL legacy key derivation
  var dk = forge$7.pbe.opensslDeriveBytes(password, iv.substr(0, 8), dkLen);
  var cipher = cipherFn(dk);
  cipher.start(iv);
  cipher.update(asn1$3.toDer(pki$2.privateKeyToAsn1(rsaKey)));
  cipher.finish();

  var msg = {
    type: 'RSA PRIVATE KEY',
    procType: {
      version: '4',
      type: 'ENCRYPTED'
    },
    dekInfo: {
      algorithm: algorithm,
      parameters: forge$7.util.bytesToHex(iv).toUpperCase()
    },
    body: cipher.output.getBytes()
  };
  return forge$7.pem.encode(msg);
};

/**
 * Decrypts an RSA private key.
 *
 * @param pem the PEM-formatted EncryptedPrivateKeyInfo to decrypt.
 * @param password the password to use.
 *
 * @return the RSA key on success, null on failure.
 */
pki$2.decryptRsaPrivateKey = function(pem, password) {
  var rval = null;

  var msg = forge$7.pem.decode(pem)[0];

  if(msg.type !== 'ENCRYPTED PRIVATE KEY' &&
    msg.type !== 'PRIVATE KEY' &&
    msg.type !== 'RSA PRIVATE KEY') {
    var error = new Error('Could not convert private key from PEM; PEM header type ' +
      'is not "ENCRYPTED PRIVATE KEY", "PRIVATE KEY", or "RSA PRIVATE KEY".');
    error.headerType = error;
    throw error;
  }

  if(msg.procType && msg.procType.type === 'ENCRYPTED') {
    var dkLen;
    var cipherFn;
    switch(msg.dekInfo.algorithm) {
    case 'DES-CBC':
      dkLen = 8;
      cipherFn = forge$7.des.createDecryptionCipher;
      break;
    case 'DES-EDE3-CBC':
      dkLen = 24;
      cipherFn = forge$7.des.createDecryptionCipher;
      break;
    case 'AES-128-CBC':
      dkLen = 16;
      cipherFn = forge$7.aes.createDecryptionCipher;
      break;
    case 'AES-192-CBC':
      dkLen = 24;
      cipherFn = forge$7.aes.createDecryptionCipher;
      break;
    case 'AES-256-CBC':
      dkLen = 32;
      cipherFn = forge$7.aes.createDecryptionCipher;
      break;
    case 'RC2-40-CBC':
      dkLen = 5;
      cipherFn = function(key) {
        return forge$7.rc2.createDecryptionCipher(key, 40);
      };
      break;
    case 'RC2-64-CBC':
      dkLen = 8;
      cipherFn = function(key) {
        return forge$7.rc2.createDecryptionCipher(key, 64);
      };
      break;
    case 'RC2-128-CBC':
      dkLen = 16;
      cipherFn = function(key) {
        return forge$7.rc2.createDecryptionCipher(key, 128);
      };
      break;
    default:
      var error = new Error('Could not decrypt private key; unsupported ' +
        'encryption algorithm "' + msg.dekInfo.algorithm + '".');
      error.algorithm = msg.dekInfo.algorithm;
      throw error;
    }

    // use OpenSSL legacy key derivation
    var iv = forge$7.util.hexToBytes(msg.dekInfo.parameters);
    var dk = forge$7.pbe.opensslDeriveBytes(password, iv.substr(0, 8), dkLen);
    var cipher = cipherFn(dk);
    cipher.start(iv);
    cipher.update(forge$7.util.createBuffer(msg.body));
    if(cipher.finish()) {
      rval = cipher.output.getBytes();
    } else {
      return rval;
    }
  } else {
    rval = msg.body;
  }

  if(msg.type === 'ENCRYPTED PRIVATE KEY') {
    rval = pki$2.decryptPrivateKeyInfo(asn1$3.fromDer(rval), password);
  } else {
    // decryption already performed above
    rval = asn1$3.fromDer(rval);
  }

  if(rval !== null) {
    rval = pki$2.privateKeyFromAsn1(rval);
  }

  return rval;
};

/**
 * Derives a PKCS#12 key.
 *
 * @param password the password to derive the key material from, null or
 *          undefined for none.
 * @param salt the salt, as a ByteBuffer, to use.
 * @param id the PKCS#12 ID byte (1 = key material, 2 = IV, 3 = MAC).
 * @param iter the iteration count.
 * @param n the number of bytes to derive from the password.
 * @param md the message digest to use, defaults to SHA-1.
 *
 * @return a ByteBuffer with the bytes derived from the password.
 */
pki$2.pbe.generatePkcs12Key = function(password, salt, id, iter, n, md) {
  var j, l;

  if(typeof md === 'undefined' || md === null) {
    if(!('sha1' in forge$7.md)) {
      throw new Error('"sha1" hash algorithm unavailable.');
    }
    md = forge$7.md.sha1.create();
  }

  var u = md.digestLength;
  var v = md.blockLength;
  var result = new forge$7.util.ByteBuffer();

  /* Convert password to Unicode byte buffer + trailing 0-byte. */
  var passBuf = new forge$7.util.ByteBuffer();
  if(password !== null && password !== undefined) {
    for(l = 0; l < password.length; l++) {
      passBuf.putInt16(password.charCodeAt(l));
    }
    passBuf.putInt16(0);
  }

  /* Length of salt and password in BYTES. */
  var p = passBuf.length();
  var s = salt.length();

  /* 1. Construct a string, D (the "diversifier"), by concatenating
        v copies of ID. */
  var D = new forge$7.util.ByteBuffer();
  D.fillWithByte(id, v);

  /* 2. Concatenate copies of the salt together to create a string S of length
        v * ceil(s / v) bytes (the final copy of the salt may be trunacted
        to create S).
        Note that if the salt is the empty string, then so is S. */
  var Slen = v * Math.ceil(s / v);
  var S = new forge$7.util.ByteBuffer();
  for(l = 0; l < Slen; l++) {
    S.putByte(salt.at(l % s));
  }

  /* 3. Concatenate copies of the password together to create a string P of
        length v * ceil(p / v) bytes (the final copy of the password may be
        truncated to create P).
        Note that if the password is the empty string, then so is P. */
  var Plen = v * Math.ceil(p / v);
  var P = new forge$7.util.ByteBuffer();
  for(l = 0; l < Plen; l++) {
    P.putByte(passBuf.at(l % p));
  }

  /* 4. Set I=S||P to be the concatenation of S and P. */
  var I = S;
  I.putBuffer(P);

  /* 5. Set c=ceil(n / u). */
  var c = Math.ceil(n / u);

  /* 6. For i=1, 2, ..., c, do the following: */
  for(var i = 1; i <= c; i++) {
    /* a) Set Ai=H^r(D||I). (l.e. the rth hash of D||I, H(H(H(...H(D||I)))) */
    var buf = new forge$7.util.ByteBuffer();
    buf.putBytes(D.bytes());
    buf.putBytes(I.bytes());
    for(var round = 0; round < iter; round++) {
      md.start();
      md.update(buf.getBytes());
      buf = md.digest();
    }

    /* b) Concatenate copies of Ai to create a string B of length v bytes (the
          final copy of Ai may be truncated to create B). */
    var B = new forge$7.util.ByteBuffer();
    for(l = 0; l < v; l++) {
      B.putByte(buf.at(l % u));
    }

    /* c) Treating I as a concatenation I0, I1, ..., Ik-1 of v-byte blocks,
          where k=ceil(s / v) + ceil(p / v), modify I by setting
          Ij=(Ij+B+1) mod 2v for each j.  */
    var k = Math.ceil(s / v) + Math.ceil(p / v);
    var Inew = new forge$7.util.ByteBuffer();
    for(j = 0; j < k; j++) {
      var chunk = new forge$7.util.ByteBuffer(I.getBytes(v));
      var x = 0x1ff;
      for(l = B.length() - 1; l >= 0; l--) {
        x = x >> 8;
        x += B.at(l) + chunk.at(l);
        chunk.setAt(l, x & 0xff);
      }
      Inew.putBuffer(chunk);
    }
    I = Inew;

    /* Add Ai to A. */
    result.putBuffer(buf);
  }

  result.truncate(result.length() - n);
  return result;
};

/**
 * Get new Forge cipher object instance.
 *
 * @param oid the OID (in string notation).
 * @param params the ASN.1 params object.
 * @param password the password to decrypt with.
 *
 * @return new cipher object instance.
 */
pki$2.pbe.getCipher = function(oid, params, password) {
  switch(oid) {
  case pki$2.oids['pkcs5PBES2']:
    return pki$2.pbe.getCipherForPBES2(oid, params, password);

  case pki$2.oids['pbeWithSHAAnd3-KeyTripleDES-CBC']:
  case pki$2.oids['pbewithSHAAnd40BitRC2-CBC']:
    return pki$2.pbe.getCipherForPKCS12PBE(oid, params, password);

  default:
    var error = new Error('Cannot read encrypted PBE data block. Unsupported OID.');
    error.oid = oid;
    error.supportedOids = [
      'pkcs5PBES2',
      'pbeWithSHAAnd3-KeyTripleDES-CBC',
      'pbewithSHAAnd40BitRC2-CBC'
    ];
    throw error;
  }
};

/**
 * Get new Forge cipher object instance according to PBES2 params block.
 *
 * The returned cipher instance is already started using the IV
 * from PBES2 parameter block.
 *
 * @param oid the PKCS#5 PBKDF2 OID (in string notation).
 * @param params the ASN.1 PBES2-params object.
 * @param password the password to decrypt with.
 *
 * @return new cipher object instance.
 */
pki$2.pbe.getCipherForPBES2 = function(oid, params, password) {
  // get PBE params
  var capture = {};
  var errors = [];
  if(!asn1$3.validate(params, PBES2AlgorithmsValidator, capture, errors)) {
    var error = new Error('Cannot read password-based-encryption algorithm ' +
      'parameters. ASN.1 object is not a supported EncryptedPrivateKeyInfo.');
    error.errors = errors;
    throw error;
  }

  // check oids
  oid = asn1$3.derToOid(capture.kdfOid);
  if(oid !== pki$2.oids['pkcs5PBKDF2']) {
    var error = new Error('Cannot read encrypted private key. ' +
      'Unsupported key derivation function OID.');
    error.oid = oid;
    error.supportedOids = ['pkcs5PBKDF2'];
    throw error;
  }
  oid = asn1$3.derToOid(capture.encOid);
  if(oid !== pki$2.oids['aes128-CBC'] &&
    oid !== pki$2.oids['aes192-CBC'] &&
    oid !== pki$2.oids['aes256-CBC'] &&
    oid !== pki$2.oids['des-EDE3-CBC'] &&
    oid !== pki$2.oids['desCBC']) {
    var error = new Error('Cannot read encrypted private key. ' +
      'Unsupported encryption scheme OID.');
    error.oid = oid;
    error.supportedOids = [
      'aes128-CBC', 'aes192-CBC', 'aes256-CBC', 'des-EDE3-CBC', 'desCBC'];
    throw error;
  }

  // set PBE params
  var salt = capture.kdfSalt;
  var count = forge$7.util.createBuffer(capture.kdfIterationCount);
  count = count.getInt(count.length() << 3);
  var dkLen;
  var cipherFn;
  switch(pki$2.oids[oid]) {
  case 'aes128-CBC':
    dkLen = 16;
    cipherFn = forge$7.aes.createDecryptionCipher;
    break;
  case 'aes192-CBC':
    dkLen = 24;
    cipherFn = forge$7.aes.createDecryptionCipher;
    break;
  case 'aes256-CBC':
    dkLen = 32;
    cipherFn = forge$7.aes.createDecryptionCipher;
    break;
  case 'des-EDE3-CBC':
    dkLen = 24;
    cipherFn = forge$7.des.createDecryptionCipher;
    break;
  case 'desCBC':
    dkLen = 8;
    cipherFn = forge$7.des.createDecryptionCipher;
    break;
  }

  // get PRF message digest
  var md = prfOidToMessageDigest(capture.prfOid);

  // decrypt private key using pbe with chosen PRF and AES/DES
  var dk = forge$7.pkcs5.pbkdf2(password, salt, count, dkLen, md);
  var iv = capture.encIv;
  var cipher = cipherFn(dk);
  cipher.start(iv);

  return cipher;
};

/**
 * Get new Forge cipher object instance for PKCS#12 PBE.
 *
 * The returned cipher instance is already started using the key & IV
 * derived from the provided password and PKCS#12 PBE salt.
 *
 * @param oid The PKCS#12 PBE OID (in string notation).
 * @param params The ASN.1 PKCS#12 PBE-params object.
 * @param password The password to decrypt with.
 *
 * @return the new cipher object instance.
 */
pki$2.pbe.getCipherForPKCS12PBE = function(oid, params, password) {
  // get PBE params
  var capture = {};
  var errors = [];
  if(!asn1$3.validate(params, pkcs12PbeParamsValidator, capture, errors)) {
    var error = new Error('Cannot read password-based-encryption algorithm ' +
      'parameters. ASN.1 object is not a supported EncryptedPrivateKeyInfo.');
    error.errors = errors;
    throw error;
  }

  var salt = forge$7.util.createBuffer(capture.salt);
  var count = forge$7.util.createBuffer(capture.iterations);
  count = count.getInt(count.length() << 3);

  var dkLen, dIvLen, cipherFn;
  switch(oid) {
    case pki$2.oids['pbeWithSHAAnd3-KeyTripleDES-CBC']:
      dkLen = 24;
      dIvLen = 8;
      cipherFn = forge$7.des.startDecrypting;
      break;

    case pki$2.oids['pbewithSHAAnd40BitRC2-CBC']:
      dkLen = 5;
      dIvLen = 8;
      cipherFn = function(key, iv) {
        var cipher = forge$7.rc2.createDecryptionCipher(key, 40);
        cipher.start(iv, null);
        return cipher;
      };
      break;

    default:
      var error = new Error('Cannot read PKCS #12 PBE data block. Unsupported OID.');
      error.oid = oid;
      throw error;
  }

  // get PRF message digest
  var md = prfOidToMessageDigest(capture.prfOid);
  var key = pki$2.pbe.generatePkcs12Key(password, salt, 1, count, dkLen, md);
  md.start();
  var iv = pki$2.pbe.generatePkcs12Key(password, salt, 2, count, dIvLen, md);

  return cipherFn(key, iv);
};

/**
 * OpenSSL's legacy key derivation function.
 *
 * See: http://www.openssl.org/docs/crypto/EVP_BytesToKey.html
 *
 * @param password the password to derive the key from.
 * @param salt the salt to use, null for none.
 * @param dkLen the number of bytes needed for the derived key.
 * @param [options] the options to use:
 *          [md] an optional message digest object to use.
 */
pki$2.pbe.opensslDeriveBytes = function(password, salt, dkLen, md) {
  if(typeof md === 'undefined' || md === null) {
    if(!('md5' in forge$7.md)) {
      throw new Error('"md5" hash algorithm unavailable.');
    }
    md = forge$7.md.md5.create();
  }
  if(salt === null) {
    salt = '';
  }
  var digests = [hash$1(md, password + salt)];
  for(var length = 16, i = 1; length < dkLen; ++i, length += 16) {
    digests.push(hash$1(md, digests[i - 1] + password + salt));
  }
  return digests.join('').substr(0, dkLen);
};

function hash$1(md, bytes) {
  return md.start().update(bytes).digest().getBytes();
}

function prfOidToMessageDigest(prfOid) {
  // get PRF algorithm, default to SHA-1
  var prfAlgorithm;
  if(!prfOid) {
    prfAlgorithm = 'hmacWithSHA1';
  } else {
    prfAlgorithm = pki$2.oids[asn1$3.derToOid(prfOid)];
    if(!prfAlgorithm) {
      var error = new Error('Unsupported PRF OID.');
      error.oid = prfOid;
      error.supported = [
        'hmacWithSHA1', 'hmacWithSHA224', 'hmacWithSHA256', 'hmacWithSHA384',
        'hmacWithSHA512'];
      throw error;
    }
  }
  return prfAlgorithmToMessageDigest(prfAlgorithm);
}

function prfAlgorithmToMessageDigest(prfAlgorithm) {
  var factory = forge$7.md;
  switch(prfAlgorithm) {
  case 'hmacWithSHA224':
    factory = forge$7.md.sha512;
  case 'hmacWithSHA1':
  case 'hmacWithSHA256':
  case 'hmacWithSHA384':
  case 'hmacWithSHA512':
    prfAlgorithm = prfAlgorithm.substr(8).toLowerCase();
    break;
  default:
    var error = new Error('Unsupported PRF algorithm.');
    error.algorithm = prfAlgorithm;
    error.supported = [
      'hmacWithSHA1', 'hmacWithSHA224', 'hmacWithSHA256', 'hmacWithSHA384',
      'hmacWithSHA512'];
    throw error;
  }
  if(!factory || !(prfAlgorithm in factory)) {
    throw new Error('Unknown hash algorithm: ' + prfAlgorithm);
  }
  return factory[prfAlgorithm].create();
}

function createPbkdf2Params(salt, countBytes, dkLen, prfAlgorithm) {
  var params = asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
    // salt
    asn1$3.create(
      asn1$3.Class.UNIVERSAL, asn1$3.Type.OCTETSTRING, false, salt),
    // iteration count
    asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.INTEGER, false,
      countBytes.getBytes())
  ]);
  // when PRF algorithm is not SHA-1 default, add key length and PRF algorithm
  if(prfAlgorithm !== 'hmacWithSHA1') {
    params.value.push(
      // key length
      asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.INTEGER, false,
        forge$7.util.hexToBytes(dkLen.toString(16))),
      // AlgorithmIdentifier
      asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.SEQUENCE, true, [
        // algorithm
        asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.OID, false,
          asn1$3.oidToDer(pki$2.oids[prfAlgorithm]).getBytes()),
        // parameters (null)
        asn1$3.create(asn1$3.Class.UNIVERSAL, asn1$3.Type.NULL, false, '')
      ]));
  }
  return params;
}

/**
 * When this error is thrown it means an operation was aborted,
 * usually in response to the `abort` event being emitted by an
 * AbortSignal.
 */
let AbortError$5 = class AbortError extends Error {
    constructor(message = 'The operation was aborted') {
        super(message);
        this.code = AbortError.code;
        this.type = AbortError.type;
    }
    static get code() {
        return 'ABORT_ERR';
    }
    static get type() {
        return 'aborted';
    }
};
class CodeError extends Error {
    constructor(message, code, props) {
        super(message);
        this.code = code;
        this.name = props?.name ?? 'CodeError';
        this.props = props ?? {}; // eslint-disable-line @typescript-eslint/consistent-type-assertions
    }
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$1 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$1 = base$1;

var _brrp__multiformats_scope_baseX = src$1;

/**
 * @param {Uint8Array} aa
 * @param {Uint8Array} bb
 */
const equals$1 = (aa, bb) => {
  if (aa === bb) return true
  if (aa.byteLength !== bb.byteLength) {
    return false
  }

  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false
    }
  }

  return true
};

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
const fromString$3 = str => (new TextEncoder()).encode(str);

/**
 * @param {Uint8Array} b
 * @returns {string}
 */
const toString$8 = b => (new TextDecoder()).decode(b);

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$2 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$1 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$1(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$1(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
}

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$1 = (left, right) => new ComposedDecoder(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$2(name, prefix, baseEncode);
    this.decoder = new Decoder$1(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
}

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$2 = ({ name, prefix, encode, decode }) =>
  new Codec(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX(alphabet, name);
  return from$2({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$9 = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$a = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$2({
    prefix,
    name,
    encode (input) {
      return encode$a(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$9(input, alphabet, bitsPerChar, name)
    }
  })
};

// @ts-check

const identity$1 = from$2({
  prefix: '\x00',
  name: 'identity',
  encode: (buf) => toString$8(buf),
  decode: (str) => fromString$3(str)
});

var identityBase = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identity: identity$1
});

// @ts-check

const base2 = rfc4648({
  prefix: '0',
  name: 'base2',
  alphabet: '01',
  bitsPerChar: 1
});

var base2$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base2: base2
});

// @ts-check

const base8 = rfc4648({
  prefix: '7',
  name: 'base8',
  alphabet: '01234567',
  bitsPerChar: 3
});

var base8$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base8: base8
});

const base10 = baseX({
  prefix: '9',
  name: 'base10',
  alphabet: '0123456789'
});

var base10$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base10: base10
});

// @ts-check

const base16 = rfc4648({
  prefix: 'f',
  name: 'base16',
  alphabet: '0123456789abcdef',
  bitsPerChar: 4
});

const base16upper = rfc4648({
  prefix: 'F',
  name: 'base16upper',
  alphabet: '0123456789ABCDEF',
  bitsPerChar: 4
});

var base16$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base16: base16,
    base16upper: base16upper
});

const base32$1 = rfc4648({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

const base32upper = rfc4648({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

const base32pad = rfc4648({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

const base32padupper = rfc4648({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

const base32hex = rfc4648({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

const base32hexupper = rfc4648({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

const base32hexpad = rfc4648({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

const base32hexpadupper = rfc4648({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

const base32z = rfc4648({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

var base32$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base32: base32$1,
    base32hex: base32hex,
    base32hexpad: base32hexpad,
    base32hexpadupper: base32hexpadupper,
    base32hexupper: base32hexupper,
    base32pad: base32pad,
    base32padupper: base32padupper,
    base32upper: base32upper,
    base32z: base32z
});

const base36 = baseX({
  prefix: 'k',
  name: 'base36',
  alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'
});

const base36upper = baseX({
  prefix: 'K',
  name: 'base36upper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
});

var base36$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base36: base36,
    base36upper: base36upper
});

const base58btc = baseX({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

const base58flickr = baseX({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var base58 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base58btc: base58btc,
    base58flickr: base58flickr
});

// @ts-check

const base64$6 = rfc4648({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

const base64pad = rfc4648({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

const base64url = rfc4648({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

const base64urlpad = rfc4648({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

var base64$7 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base64: base64$6,
    base64pad: base64pad,
    base64url: base64url,
    base64urlpad: base64urlpad
});

const alphabet = Array.from('');
const alphabetBytesToChars = /** @type {string[]} */ (alphabet.reduce((p, c, i) => { p[i] = c; return p }, /** @type {string[]} */([])));
const alphabetCharsToBytes = /** @type {number[]} */ (alphabet.reduce((p, c, i) => { p[/** @type {number} */ (c.codePointAt(0))] = i; return p }, /** @type {number[]} */([])));

/**
 * @param {Uint8Array} data
 * @returns {string}
 */
function encode$9 (data) {
  return data.reduce((p, c) => {
    p += alphabetBytesToChars[c];
    return p
  }, '')
}

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
function decode$8 (str) {
  const byts = [];
  for (const char of str) {
    const byt = alphabetCharsToBytes[/** @type {number} */ (char.codePointAt(0))];
    if (byt === undefined) {
      throw new Error(`Non-base256emoji character: ${char}`)
    }
    byts.push(byt);
  }
  return new Uint8Array(byts)
}

const base256emoji = from$2({
  prefix: '',
  name: 'base256emoji',
  encode: encode$9,
  decode: decode$8
});

var base256emoji$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base256emoji: base256emoji
});

var encode_1$1 = encode$8;

var MSB$3 = 0x80
  , REST$3 = 0x7F
  , MSBALL$1 = ~REST$3
  , INT$1 = Math.pow(2, 31);

function encode$8(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$1) {
    out[offset++] = (num & 0xFF) | MSB$3;
    num /= 128;
  }
  while(num & MSBALL$1) {
    out[offset++] = (num & 0xFF) | MSB$3;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$8.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$7 = read$2;

var MSB$1$1 = 0x80
  , REST$1$1 = 0x7F;

function read$2(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$2.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$1) << shift
      : (b & REST$1$1) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$1)

  read$2.bytes = counter - offset;

  return res
}

var N1$1 = Math.pow(2,  7);
var N2$1 = Math.pow(2, 14);
var N3$1 = Math.pow(2, 21);
var N4$1 = Math.pow(2, 28);
var N5$1 = Math.pow(2, 35);
var N6$1 = Math.pow(2, 42);
var N7$1 = Math.pow(2, 49);
var N8$1 = Math.pow(2, 56);
var N9$1 = Math.pow(2, 63);

var length$1 = function (value) {
  return (
    value < N1$1 ? 1
  : value < N2$1 ? 2
  : value < N3$1 ? 3
  : value < N4$1 ? 4
  : value < N5$1 ? 5
  : value < N6$1 ? 6
  : value < N7$1 ? 7
  : value < N8$1 ? 8
  : value < N9$1 ? 9
  :              10
  )
};

var varint$1 = {
    encode: encode_1$1
  , decode: decode$7
  , encodingLength: length$1
};

var _brrp_varint = varint$1;

/**
 * @param {Uint8Array} data
 * @param {number} [offset=0]
 * @returns {[number, number]}
 */
const decode$6 = (data, offset = 0) => {
  const code = _brrp_varint.decode(data, offset);
  return [code, _brrp_varint.decode.bytes]
};

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo = (int, target, offset = 0) => {
  _brrp_varint.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$2 = (int) => {
  return _brrp_varint.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$d = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$2(code);
  const digestOffset = sizeOffset + encodingLength$2(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo(code, bytes, 0);
  encodeTo(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest(code, size, digest, bytes)
};

/**
 * Turns bytes representation of multihash digest into an instance.
 *
 * @param {Uint8Array} multihash
 * @returns {MultihashDigest}
 */
const decode$5 = (multihash) => {
  const bytes = coerce(multihash);
  const [code, sizeOffset] = decode$6(bytes);
  const [size, digestOffset] = decode$6(bytes.subarray(sizeOffset));
  const digest = bytes.subarray(sizeOffset + digestOffset);

  if (digest.byteLength !== size) {
    throw new Error('Incorrect length')
  }

  return new Digest(code, size, digest, bytes)
};

/**
 * @param {MultihashDigest} a
 * @param {unknown} b
 * @returns {b is MultihashDigest}
 */
const equals = (a, b) => {
  if (a === b) {
    return true
  } else {
    const data = /** @type {{code?:unknown, size?:unknown, bytes?:unknown}} */(b);

    return (
      a.code === data.code &&
      a.size === data.size &&
      data.bytes instanceof Uint8Array &&
      equals$1(a.bytes, data.bytes)
    )
  }
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
}

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$1 = ({ name, code, encode }) => new Hasher(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$d(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$d(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
}

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */

/**
 * @param {AlgorithmIdentifier} name
 */
const sha = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256 = from$1({
  name: 'sha2-256',
  code: 0x12,
  encode: sha('SHA-256')
});

const code = 0x0;
const name$2 = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$7 = coerce;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest = (input) => create$d(code, encode$7(input));

const identity = { code, name: name$2, encode: encode$7, digest };

// @ts-check

/**
 * @template T
 * @typedef {import('./interface.js').ByteView<T>} ByteView
 */

new TextEncoder();
new TextDecoder();

/**
 * @template {API.Link<unknown, number, number, API.Version>} T
 * @template {string} Prefix
 * @param {T} link
 * @param {API.MultibaseEncoder<Prefix>} [base]
 * @returns {API.ToString<T, Prefix>}
 */
const format$3 = (link, base) => {
  const { bytes, version } = link;
  switch (version) {
    case 0:
      return toStringV0(
        bytes,
        baseCache(link),
        /** @type {API.MultibaseEncoder<"z">} */ (base) || base58btc.encoder
      )
    default:
      return toStringV1(
        bytes,
        baseCache(link),
        /** @type {API.MultibaseEncoder<Prefix>} */ (base || base32$1.encoder)
      )
  }
};

/** @type {WeakMap<API.UnknownLink, Map<string, string>>} */
const cache$1 = new WeakMap();

/**
 * @param {API.UnknownLink} cid
 * @returns {Map<string, string>}
 */
const baseCache = cid => {
  const baseCache = cache$1.get(cid);
  if (baseCache == null) {
    const baseCache = new Map();
    cache$1.set(cid, baseCache);
    return baseCache
  }
  return baseCache
};

/**
 * @template {unknown} [Data=unknown]
 * @template {number} [Format=number]
 * @template {number} [Alg=number]
 * @template {API.Version} [Version=API.Version]
 * @implements {API.Link<Data, Format, Alg, Version>}
 */

class CID {
  /**
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} multihash - (Multi)hash of the of the content.
   * @param {Uint8Array} bytes
   *
   */
  constructor (version, code, multihash, bytes) {
    /** @readonly */
    this.code = code;
    /** @readonly */
    this.version = version;
    /** @readonly */
    this.multihash = multihash;
    /** @readonly */
    this.bytes = bytes;

    // flag to serializers that this is a CID and
    // should be treated specially
    /** @readonly */
    this['/'] = bytes;
  }

  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID () {
    return this
  }

  // ArrayBufferView
  get byteOffset () {
    return this.bytes.byteOffset
  }

  // ArrayBufferView
  get byteLength () {
    return this.bytes.byteLength
  }

  /**
   * @returns {CID<Data, API.DAG_PB, API.SHA_256, 0>}
   */
  toV0 () {
    switch (this.version) {
      case 0: {
        return /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */ (this)
      }
      case 1: {
        const { code, multihash } = this;

        if (code !== DAG_PB_CODE) {
          throw new Error('Cannot convert a non dag-pb CID to CIDv0')
        }

        // sha2-256
        if (multihash.code !== SHA_256_CODE) {
          throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0')
        }

        return /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */ (
          CID.createV0(
            /** @type {API.MultihashDigest<API.SHA_256>} */ (multihash)
          )
        )
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 0. This is a bug please report`
        )
      }
    }
  }

  /**
   * @returns {CID<Data, Format, Alg, 1>}
   */
  toV1 () {
    switch (this.version) {
      case 0: {
        const { code, digest } = this.multihash;
        const multihash = create$d(code, digest);
        return /** @type {CID<Data, Format, Alg, 1>} */ (
          CID.createV1(this.code, multihash)
        )
      }
      case 1: {
        return /** @type {CID<Data, Format, Alg, 1>} */ (this)
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 1. This is a bug please report`
        )
      }
    }
  }

  /**
   * @param {unknown} other
   * @returns {other is CID<Data, Format, Alg, Version>}
   */
  equals (other) {
    return CID.equals(this, other)
  }

  /**
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {API.Link<Data, Format, Alg, Version>} self
   * @param {unknown} other
   * @returns {other is CID}
   */
  static equals (self, other) {
    const unknown =
      /** @type {{code?:unknown, version?:unknown, multihash?:unknown}} */ (
        other
      );
    return (
      unknown &&
      self.code === unknown.code &&
      self.version === unknown.version &&
      equals(self.multihash, unknown.multihash)
    )
  }

  /**
   * @param {API.MultibaseEncoder<string>} [base]
   * @returns {string}
   */
  toString (base) {
    return format$3(this, base)
  }

  toJSON () {
    return { '/': format$3(this) }
  }

  link () {
    return this
  }

  get [Symbol.toStringTag] () {
    return 'CID'
  }

  // Legacy

  [Symbol.for('nodejs.util.inspect.custom')] () {
    return `CID(${this.toString()})`
  }

  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @template {unknown} U
   * @param {API.Link<Data, Format, Alg, Version>|U} input
   * @returns {CID<Data, Format, Alg, Version>|null}
   */
  static asCID (input) {
    if (input == null) {
      return null
    }

    const value = /** @type {any} */ (input);
    if (value instanceof CID) {
      // If value is instance of CID then we're all set.
      return value
    } else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {
      // If value isn't instance of this CID class but `this.asCID === this` or
      // `value['/'] === value.bytes` is true it is CID instance coming from a
      // different implementation (diff version or duplicate). In that case we
      // rebase it to this `CID` implementation so caller is guaranteed to get
      // instance with expected API.
      const { version, code, multihash, bytes } = value;
      return new CID(
        version,
        code,
        /** @type {API.MultihashDigest<Alg>} */ (multihash),
        bytes || encodeCID(version, code, multihash.bytes)
      )
    } else if (value[cidSymbol] === true) {
      // If value is a CID from older implementation that used to be tagged via
      // symbol we still rebase it to the this `CID` implementation by
      // delegating that to a constructor.
      const { version, multihash, code } = value;
      const digest =
        /** @type {API.MultihashDigest<Alg>} */
        (decode$5(multihash));
      return CID.create(version, code, digest)
    } else {
      // Otherwise value is not a CID (or an incompatible version of it) in
      // which case we return `null`.
      return null
    }
  }

  /**
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} digest - (Multi)hash of the of the content.
   * @returns {CID<Data, Format, Alg, Version>}
   */
  static create (version, code, digest) {
    if (typeof code !== 'number') {
      throw new Error('String codecs are no longer supported')
    }

    if (!(digest.bytes instanceof Uint8Array)) {
      throw new Error('Invalid digest')
    }

    switch (version) {
      case 0: {
        if (code !== DAG_PB_CODE) {
          throw new Error(
            `Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`
          )
        } else {
          return new CID(version, code, digest, digest.bytes)
        }
      }
      case 1: {
        const bytes = encodeCID(version, code, digest.bytes);
        return new CID(version, code, digest, bytes)
      }
      default: {
        throw new Error('Invalid version')
      }
    }
  }

  /**
   * Simplified version of `create` for CIDv0.
   *
   * @template {unknown} [T=unknown]
   * @param {API.MultihashDigest<typeof SHA_256_CODE>} digest - Multihash.
   * @returns {CID<T, typeof DAG_PB_CODE, typeof SHA_256_CODE, 0>}
   */
  static createV0 (digest) {
    return CID.create(0, DAG_PB_CODE, digest)
  }

  /**
   * Simplified version of `create` for CIDv1.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @param {Code} code - Content encoding format code.
   * @param {API.MultihashDigest<Alg>} digest - Miltihash of the content.
   * @returns {CID<Data, Code, Alg, 1>}
   */
  static createV1 (code, digest) {
    return CID.create(1, code, digest)
  }

  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ByteView<API.Link<Data, Code, Alg, Ver>>} bytes
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static decode (bytes) {
    const [cid, remainder] = CID.decodeFirst(bytes);
    if (remainder.length) {
      throw new Error('Incorrect length')
    }
    return cid
  }

  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} bytes
   * @returns {[CID<T, C, A, V>, Uint8Array]}
   */
  static decodeFirst (bytes) {
    const specs = CID.inspectBytes(bytes);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce(
      bytes.subarray(prefixSize, prefixSize + specs.multihashSize)
    );
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error('Incorrect length')
    }
    const digestBytes = multihashBytes.subarray(
      specs.multihashSize - specs.digestSize
    );
    const digest = new Digest(
      specs.multihashCode,
      specs.digestSize,
      digestBytes,
      multihashBytes
    );
    const cid =
      specs.version === 0
        ? CID.createV0(/** @type {API.MultihashDigest<API.SHA_256>} */ (digest))
        : CID.createV1(specs.codec, digest);
    return [/** @type {CID<T, C, A, V>} */(cid), bytes.subarray(specs.size)]
  }

  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} initialBytes
   * @returns {{ version:V, codec:C, multihashCode:A, digestSize:number, multihashSize:number, size:number }}
   */
  static inspectBytes (initialBytes) {
    let offset = 0;
    const next = () => {
      const [i, length] = decode$6(initialBytes.subarray(offset));
      offset += length;
      return i
    };

    let version = /** @type {V} */ (next());
    let codec = /** @type {C} */ (DAG_PB_CODE);
    if (/** @type {number} */(version) === 18) {
      // CIDv0
      version = /** @type {V} */ (0);
      offset = 0;
    } else {
      codec = /** @type {C} */ (next());
    }

    if (version !== 0 && version !== 1) {
      throw new RangeError(`Invalid CID version ${version}`)
    }

    const prefixSize = offset;
    const multihashCode = /** @type {A} */ (next()); // multihash code
    const digestSize = next(); // multihash length
    const size = offset + digestSize;
    const multihashSize = size - prefixSize;

    return { version, codec, multihashCode, digestSize, multihashSize, size }
  }

  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   *
   * @template {string} Prefix
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
   * @param {API.MultibaseDecoder<Prefix>} [base]
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static parse (source, base) {
    const [prefix, bytes] = parseCIDtoBytes(source, base);

    const cid = CID.decode(bytes);

    if (cid.version === 0 && source[0] !== 'Q') {
      throw Error('Version 0 CID string must not include multibase prefix')
    }

    // Cache string representation to avoid computing it on `this.toString()`
    baseCache(cid).set(prefix, source);

    return cid
  }
}

/**
 * @template {string} Prefix
 * @template {unknown} Data
 * @template {number} Code
 * @template {number} Alg
 * @template {API.Version} Ver
 * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
 * @param {API.MultibaseDecoder<Prefix>} [base]
 * @returns {[Prefix, API.ByteView<API.Link<Data, Code, Alg, Ver>>]}
 */
const parseCIDtoBytes = (source, base) => {
  switch (source[0]) {
    // CIDv0 is parsed differently
    case 'Q': {
      const decoder = base || base58btc;
      return [
        /** @type {Prefix} */ (base58btc.prefix),
        decoder.decode(`${base58btc.prefix}${source}`)
      ]
    }
    case base58btc.prefix: {
      const decoder = base || base58btc;
      return [/** @type {Prefix} */(base58btc.prefix), decoder.decode(source)]
    }
    case base32$1.prefix: {
      const decoder = base || base32$1;
      return [/** @type {Prefix} */(base32$1.prefix), decoder.decode(source)]
    }
    default: {
      if (base == null) {
        throw Error(
          'To parse non base32 or base58btc encoded CID multibase decoder must be provided'
        )
      }
      return [/** @type {Prefix} */(source[0]), base.decode(source)]
    }
  }
};

/**
 *
 * @param {Uint8Array} bytes
 * @param {Map<string, string>} cache
 * @param {API.MultibaseEncoder<'z'>} base
 */
const toStringV0 = (bytes, cache, base) => {
  const { prefix } = base;
  if (prefix !== base58btc.prefix) {
    throw Error(`Cannot string encode V0 in ${base.name} encoding`)
  }

  const cid = cache.get(prefix);
  if (cid == null) {
    const cid = base.encode(bytes).slice(1);
    cache.set(prefix, cid);
    return cid
  } else {
    return cid
  }
};

/**
 * @template {string} Prefix
 * @param {Uint8Array} bytes
 * @param {Map<string, string>} cache
 * @param {API.MultibaseEncoder<Prefix>} base
 */
const toStringV1 = (bytes, cache, base) => {
  const { prefix } = base;
  const cid = cache.get(prefix);
  if (cid == null) {
    const cid = base.encode(bytes);
    cache.set(prefix, cid);
    return cid
  } else {
    return cid
  }
};

const DAG_PB_CODE = 0x70;
const SHA_256_CODE = 0x12;

/**
 * @param {API.Version} version
 * @param {number} code
 * @param {Uint8Array} multihash
 * @returns {Uint8Array}
 */
const encodeCID = (version, code, multihash) => {
  const codeOffset = encodingLength$2(version);
  const hashOffset = codeOffset + encodingLength$2(code);
  const bytes = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo(version, bytes, 0);
  encodeTo(code, bytes, codeOffset);
  bytes.set(multihash, hashOffset);
  return bytes
};

const cidSymbol = Symbol.for('@ipld/js-cid/CID');

// @ts-check

const bases = { ...identityBase, ...base2$1, ...base8$1, ...base10$1, ...base16$1, ...base32$2, ...base36$1, ...base58, ...base64$7, ...base256emoji$1 };

function createCodec$5(name, prefix, encode, decode) {
    return {
        name,
        prefix,
        encoder: {
            name,
            prefix,
            encode
        },
        decoder: {
            decode
        }
    };
}
const string$1 = createCodec$5('utf8', 'u', (buf) => {
    const decoder = new TextDecoder('utf8');
    return 'u' + decoder.decode(buf);
}, (str) => {
    const encoder = new TextEncoder();
    return encoder.encode(str.substring(1));
});
const ascii = createCodec$5('ascii', 'a', (buf) => {
    let string = 'a';
    for (let i = 0; i < buf.length; i++) {
        string += String.fromCharCode(buf[i]);
    }
    return string;
}, (str) => {
    str = str.substring(1);
    const buf = allocUnsafe$3(str.length);
    for (let i = 0; i < str.length; i++) {
        buf[i] = str.charCodeAt(i);
    }
    return buf;
});
const BASES = {
    utf8: string$1,
    'utf-8': string$1,
    hex: bases.base16,
    latin1: ascii,
    ascii: ascii,
    binary: ascii,
    ...bases
};

/**
 * Create a `Uint8Array` from the passed string
 *
 * Supports `utf8`, `utf-8`, `hex`, and any encoding supported by the multiformats module.
 *
 * Also `ascii` which is similar to node's 'binary' encoding.
 */
function fromString$2(string, encoding = 'utf8') {
    const base = BASES[encoding];
    if (base == null) {
        throw new Error(`Unsupported encoding "${encoding}"`);
    }
    if ((encoding === 'utf8' || encoding === 'utf-8') && globalThis.Buffer != null && globalThis.Buffer.from != null) {
        return asUint8Array(globalThis.Buffer.from(string, 'utf-8'));
    }
    // add multibase prefix
    return base.decoder.decode(`${base.prefix}${string}`); // eslint-disable-line @typescript-eslint/restrict-template-expressions
}

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto == null || nativeCrypto.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p-crypto/blob/master/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

/**
 * Turns a `Uint8Array` into a string.
 *
 * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.
 *
 * Also `ascii` which is similar to node's 'binary' encoding.
 */
function toString$7(array, encoding = 'utf8') {
    const base = BASES[encoding];
    if (base == null) {
        throw new Error(`Unsupported encoding "${encoding}"`);
    }
    if ((encoding === 'utf8' || encoding === 'utf-8') && globalThis.Buffer != null && globalThis.Buffer.from != null) {
        return globalThis.Buffer.from(array.buffer, array.byteOffset, array.byteLength).toString('utf8');
    }
    // strip multibase prefix
    return base.encoder.encode(array).substring(1);
}

function bigIntegerToUintBase64url(num, len) {
    // Call `.abs()` to convert to unsigned
    let buf = Uint8Array.from(num.abs().toByteArray()); // toByteArray converts to big endian
    // toByteArray() gives us back a signed array, which will include a leading 0
    // byte if the most significant bit of the number is 1:
    // https://docs.microsoft.com/en-us/windows/win32/seccertenroll/about-integer
    // Our number will always be positive so we should remove the leading padding.
    buf = buf[0] === 0 ? buf.subarray(1) : buf;
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat([new Uint8Array(len - buf.length), buf]);
    }
    return toString$7(buf, 'base64url');
}
// Convert a base64url encoded string to a BigInteger
function base64urlToBigInteger(str) {
    const buf = base64urlToBuffer(str);
    return new forge$s.jsbn.BigInteger(toString$7(buf, 'base16'), 16);
}
function base64urlToBuffer(str, len) {
    let buf = fromString$2(str, 'base64urlpad');
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat([new Uint8Array(len - buf.length), buf]);
    }
    return buf;
}

const bits = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes = Object.keys(bits);
curveTypes.join(' / ');

// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create$c(opts) {
    const algorithm = opts?.algorithm ?? 'AES-GCM';
    let keyLength = opts?.keyLength ?? 16;
    const nonceLength = opts?.nonceLength ?? 12;
    const digest = opts?.digest ?? 'SHA-256';
    const saltLength = opts?.saltLength ?? 16;
    const iterations = opts?.iterations ?? 32767;
    const crypto = webcrypto.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$2(password);
        }
        // Derive a key using PBKDF2.
        const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
        const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey', 'deriveBits']);
        const cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$2(password);
        }
        // Derive the key using PBKDF2.
        const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
        const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey', 'deriveBits']);
        const cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Attempts to decrypt a base64 encoded PrivateKey string
 * with the given password. The privateKey must have been exported
 * using the same password and underlying cipher (aes-gcm)
 */
async function importer(privateKey, password) {
    const encryptedKey = base64$6.decode(privateKey);
    const cipher = create$c();
    return await cipher.decrypt(encryptedKey, password);
}

/**
 * Secure Hash Algorithm with a 1024-bit block size implementation.
 *
 * This includes: SHA-512, SHA-384, SHA-512/224, and SHA-512/256. For
 * SHA-256 (block size 512 bits), see sha256.js.
 *
 * See FIPS 180-4 for details.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2014-2015 Digital Bazaar, Inc.
 */

var forge$6 = forge$s;



var sha512 = forge$6.sha512 = forge$6.sha512 || {};

// SHA-512
forge$6.md.sha512 = forge$6.md.algorithms.sha512 = sha512;

// SHA-384
var sha384 = forge$6.sha384 = forge$6.sha512.sha384 = forge$6.sha512.sha384 || {};
sha384.create = function() {
  return sha512.create('SHA-384');
};
forge$6.md.sha384 = forge$6.md.algorithms.sha384 = sha384;

// SHA-512/256
forge$6.sha512.sha256 = forge$6.sha512.sha256 || {
  create: function() {
    return sha512.create('SHA-512/256');
  }
};
forge$6.md['sha512/256'] = forge$6.md.algorithms['sha512/256'] =
  forge$6.sha512.sha256;

// SHA-512/224
forge$6.sha512.sha224 = forge$6.sha512.sha224 || {
  create: function() {
    return sha512.create('SHA-512/224');
  }
};
forge$6.md['sha512/224'] = forge$6.md.algorithms['sha512/224'] =
  forge$6.sha512.sha224;

/**
 * Creates a SHA-2 message digest object.
 *
 * @param algorithm the algorithm to use (SHA-512, SHA-384, SHA-512/224,
 *          SHA-512/256).
 *
 * @return a message digest object.
 */
sha512.create = function(algorithm) {
  // do initialization as necessary
  if(!_initialized) {
    _init();
  }

  if(typeof algorithm === 'undefined') {
    algorithm = 'SHA-512';
  }

  if(!(algorithm in _states)) {
    throw new Error('Invalid SHA-512 algorithm: ' + algorithm);
  }

  // SHA-512 state contains eight 64-bit integers (each as two 32-bit ints)
  var _state = _states[algorithm];
  var _h = null;

  // input buffer
  var _input = forge$6.util.createBuffer();

  // used for 64-bit word storage
  var _w = new Array(80);
  for(var wi = 0; wi < 80; ++wi) {
    _w[wi] = new Array(2);
  }

  // determine digest length by algorithm name (default)
  var digestLength = 64;
  switch(algorithm) {
    case 'SHA-384':
      digestLength = 48;
      break;
    case 'SHA-512/256':
      digestLength = 32;
      break;
    case 'SHA-512/224':
      digestLength = 28;
      break;
  }

  // message digest object
  var md = {
    // SHA-512 => sha512
    algorithm: algorithm.replace('-', '').toLowerCase(),
    blockLength: 128,
    digestLength: digestLength,
    // 56-bit length of message so far (does not including padding)
    messageLength: 0,
    // true message length
    fullMessageLength: null,
    // size of message length in bytes
    messageLengthSize: 16
  };

  /**
   * Starts the digest.
   *
   * @return this digest object.
   */
  md.start = function() {
    // up to 56-bit message length for convenience
    md.messageLength = 0;

    // full message length (set md.messageLength128 for backwards-compatibility)
    md.fullMessageLength = md.messageLength128 = [];
    var int32s = md.messageLengthSize / 4;
    for(var i = 0; i < int32s; ++i) {
      md.fullMessageLength.push(0);
    }
    _input = forge$6.util.createBuffer();
    _h = new Array(_state.length);
    for(var i = 0; i < _state.length; ++i) {
      _h[i] = _state[i].slice(0);
    }
    return md;
  };
  // start digest automatically for first time
  md.start();

  /**
   * Updates the digest with the given message input. The given input can
   * treated as raw input (no encoding will be applied) or an encoding of
   * 'utf8' maybe given to encode the input using UTF-8.
   *
   * @param msg the message input to update with.
   * @param encoding the encoding to use (default: 'raw', other: 'utf8').
   *
   * @return this digest object.
   */
  md.update = function(msg, encoding) {
    if(encoding === 'utf8') {
      msg = forge$6.util.encodeUtf8(msg);
    }

    // update message length
    var len = msg.length;
    md.messageLength += len;
    len = [(len / 0x100000000) >>> 0, len >>> 0];
    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {
      md.fullMessageLength[i] += len[1];
      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);
      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;
      len[0] = ((len[1] / 0x100000000) >>> 0);
    }

    // add bytes to input buffer
    _input.putBytes(msg);

    // process bytes
    _update(_h, _w, _input);

    // compact input buffer every 2K or if empty
    if(_input.read > 2048 || _input.length() === 0) {
      _input.compact();
    }

    return md;
  };

  /**
   * Produces the digest.
   *
   * @return a byte buffer containing the digest value.
   */
  md.digest = function() {
    /* Note: Here we copy the remaining bytes in the input buffer and
    add the appropriate SHA-512 padding. Then we do the final update
    on a copy of the state so that if the user wants to get
    intermediate digests they can do so. */

    /* Determine the number of bytes that must be added to the message
    to ensure its length is congruent to 896 mod 1024. In other words,
    the data to be digested must be a multiple of 1024 bits (or 128 bytes).
    This data includes the message, some padding, and the length of the
    message. Since the length of the message will be encoded as 16 bytes (128
    bits), that means that the last segment of the data must have 112 bytes
    (896 bits) of message and padding. Therefore, the length of the message
    plus the padding must be congruent to 896 mod 1024 because
    1024 - 128 = 896.

    In order to fill up the message length it must be filled with
    padding that begins with 1 bit followed by all 0 bits. Padding
    must *always* be present, so if the message length is already
    congruent to 896 mod 1024, then 1024 padding bits must be added. */

    var finalBlock = forge$6.util.createBuffer();
    finalBlock.putBytes(_input.bytes());

    // compute remaining size to be digested (include message length size)
    var remaining = (
      md.fullMessageLength[md.fullMessageLength.length - 1] +
      md.messageLengthSize);

    // add padding for overflow blockSize - overflow
    // _padding starts with 1 byte with first bit is set (byte value 128), then
    // there may be up to (blockSize - 1) other pad bytes
    var overflow = remaining & (md.blockLength - 1);
    finalBlock.putBytes(_padding.substr(0, md.blockLength - overflow));

    // serialize message length in bits in big-endian order; since length
    // is stored in bytes we multiply by 8 and add carry from next int
    var next, carry;
    var bits = md.fullMessageLength[0] * 8;
    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {
      next = md.fullMessageLength[i + 1] * 8;
      carry = (next / 0x100000000) >>> 0;
      bits += carry;
      finalBlock.putInt32(bits >>> 0);
      bits = next >>> 0;
    }
    finalBlock.putInt32(bits);

    var h = new Array(_h.length);
    for(var i = 0; i < _h.length; ++i) {
      h[i] = _h[i].slice(0);
    }
    _update(h, _w, finalBlock);
    var rval = forge$6.util.createBuffer();
    var hlen;
    if(algorithm === 'SHA-512') {
      hlen = h.length;
    } else if(algorithm === 'SHA-384') {
      hlen = h.length - 2;
    } else {
      hlen = h.length - 4;
    }
    for(var i = 0; i < hlen; ++i) {
      rval.putInt32(h[i][0]);
      if(i !== hlen - 1 || algorithm !== 'SHA-512/224') {
        rval.putInt32(h[i][1]);
      }
    }
    return rval;
  };

  return md;
};

// sha-512 padding bytes not initialized yet
var _padding = null;
var _initialized = false;

// table of constants
var _k = null;

// initial hash states
var _states = null;

/**
 * Initializes the constant tables.
 */
function _init() {
  // create padding
  _padding = String.fromCharCode(128);
  _padding += forge$6.util.fillString(String.fromCharCode(0x00), 128);

  // create K table for SHA-512
  _k = [
    [0x428a2f98, 0xd728ae22], [0x71374491, 0x23ef65cd],
    [0xb5c0fbcf, 0xec4d3b2f], [0xe9b5dba5, 0x8189dbbc],
    [0x3956c25b, 0xf348b538], [0x59f111f1, 0xb605d019],
    [0x923f82a4, 0xaf194f9b], [0xab1c5ed5, 0xda6d8118],
    [0xd807aa98, 0xa3030242], [0x12835b01, 0x45706fbe],
    [0x243185be, 0x4ee4b28c], [0x550c7dc3, 0xd5ffb4e2],
    [0x72be5d74, 0xf27b896f], [0x80deb1fe, 0x3b1696b1],
    [0x9bdc06a7, 0x25c71235], [0xc19bf174, 0xcf692694],
    [0xe49b69c1, 0x9ef14ad2], [0xefbe4786, 0x384f25e3],
    [0x0fc19dc6, 0x8b8cd5b5], [0x240ca1cc, 0x77ac9c65],
    [0x2de92c6f, 0x592b0275], [0x4a7484aa, 0x6ea6e483],
    [0x5cb0a9dc, 0xbd41fbd4], [0x76f988da, 0x831153b5],
    [0x983e5152, 0xee66dfab], [0xa831c66d, 0x2db43210],
    [0xb00327c8, 0x98fb213f], [0xbf597fc7, 0xbeef0ee4],
    [0xc6e00bf3, 0x3da88fc2], [0xd5a79147, 0x930aa725],
    [0x06ca6351, 0xe003826f], [0x14292967, 0x0a0e6e70],
    [0x27b70a85, 0x46d22ffc], [0x2e1b2138, 0x5c26c926],
    [0x4d2c6dfc, 0x5ac42aed], [0x53380d13, 0x9d95b3df],
    [0x650a7354, 0x8baf63de], [0x766a0abb, 0x3c77b2a8],
    [0x81c2c92e, 0x47edaee6], [0x92722c85, 0x1482353b],
    [0xa2bfe8a1, 0x4cf10364], [0xa81a664b, 0xbc423001],
    [0xc24b8b70, 0xd0f89791], [0xc76c51a3, 0x0654be30],
    [0xd192e819, 0xd6ef5218], [0xd6990624, 0x5565a910],
    [0xf40e3585, 0x5771202a], [0x106aa070, 0x32bbd1b8],
    [0x19a4c116, 0xb8d2d0c8], [0x1e376c08, 0x5141ab53],
    [0x2748774c, 0xdf8eeb99], [0x34b0bcb5, 0xe19b48a8],
    [0x391c0cb3, 0xc5c95a63], [0x4ed8aa4a, 0xe3418acb],
    [0x5b9cca4f, 0x7763e373], [0x682e6ff3, 0xd6b2b8a3],
    [0x748f82ee, 0x5defb2fc], [0x78a5636f, 0x43172f60],
    [0x84c87814, 0xa1f0ab72], [0x8cc70208, 0x1a6439ec],
    [0x90befffa, 0x23631e28], [0xa4506ceb, 0xde82bde9],
    [0xbef9a3f7, 0xb2c67915], [0xc67178f2, 0xe372532b],
    [0xca273ece, 0xea26619c], [0xd186b8c7, 0x21c0c207],
    [0xeada7dd6, 0xcde0eb1e], [0xf57d4f7f, 0xee6ed178],
    [0x06f067aa, 0x72176fba], [0x0a637dc5, 0xa2c898a6],
    [0x113f9804, 0xbef90dae], [0x1b710b35, 0x131c471b],
    [0x28db77f5, 0x23047d84], [0x32caab7b, 0x40c72493],
    [0x3c9ebe0a, 0x15c9bebc], [0x431d67c4, 0x9c100d4c],
    [0x4cc5d4be, 0xcb3e42b6], [0x597f299c, 0xfc657e2a],
    [0x5fcb6fab, 0x3ad6faec], [0x6c44198c, 0x4a475817]
  ];

  // initial hash states
  _states = {};
  _states['SHA-512'] = [
    [0x6a09e667, 0xf3bcc908],
    [0xbb67ae85, 0x84caa73b],
    [0x3c6ef372, 0xfe94f82b],
    [0xa54ff53a, 0x5f1d36f1],
    [0x510e527f, 0xade682d1],
    [0x9b05688c, 0x2b3e6c1f],
    [0x1f83d9ab, 0xfb41bd6b],
    [0x5be0cd19, 0x137e2179]
  ];
  _states['SHA-384'] = [
    [0xcbbb9d5d, 0xc1059ed8],
    [0x629a292a, 0x367cd507],
    [0x9159015a, 0x3070dd17],
    [0x152fecd8, 0xf70e5939],
    [0x67332667, 0xffc00b31],
    [0x8eb44a87, 0x68581511],
    [0xdb0c2e0d, 0x64f98fa7],
    [0x47b5481d, 0xbefa4fa4]
  ];
  _states['SHA-512/256'] = [
    [0x22312194, 0xFC2BF72C],
    [0x9F555FA3, 0xC84C64C2],
    [0x2393B86B, 0x6F53B151],
    [0x96387719, 0x5940EABD],
    [0x96283EE2, 0xA88EFFE3],
    [0xBE5E1E25, 0x53863992],
    [0x2B0199FC, 0x2C85B8AA],
    [0x0EB72DDC, 0x81C52CA2]
  ];
  _states['SHA-512/224'] = [
    [0x8C3D37C8, 0x19544DA2],
    [0x73E19966, 0x89DCD4D6],
    [0x1DFAB7AE, 0x32FF9C82],
    [0x679DD514, 0x582F9FCF],
    [0x0F6D2B69, 0x7BD44DA8],
    [0x77E36F73, 0x04C48942],
    [0x3F9D85A8, 0x6A1D36C8],
    [0x1112E6AD, 0x91D692A1]
  ];

  // now initialized
  _initialized = true;
}

/**
 * Updates a SHA-512 state with the given byte buffer.
 *
 * @param s the SHA-512 state to update.
 * @param w the array to use to store words.
 * @param bytes the byte buffer to update with.
 */
function _update(s, w, bytes) {
  // consume 512 bit (128 byte) chunks
  var t1_hi, t1_lo;
  var t2_hi, t2_lo;
  var s0_hi, s0_lo;
  var s1_hi, s1_lo;
  var ch_hi, ch_lo;
  var maj_hi, maj_lo;
  var a_hi, a_lo;
  var b_hi, b_lo;
  var c_hi, c_lo;
  var d_hi, d_lo;
  var e_hi, e_lo;
  var f_hi, f_lo;
  var g_hi, g_lo;
  var h_hi, h_lo;
  var i, hi, lo, w2, w7, w15, w16;
  var len = bytes.length();
  while(len >= 128) {
    // the w array will be populated with sixteen 64-bit big-endian words
    // and then extended into 64 64-bit words according to SHA-512
    for(i = 0; i < 16; ++i) {
      w[i][0] = bytes.getInt32() >>> 0;
      w[i][1] = bytes.getInt32() >>> 0;
    }
    for(; i < 80; ++i) {
      // for word 2 words ago: ROTR 19(x) ^ ROTR 61(x) ^ SHR 6(x)
      w2 = w[i - 2];
      hi = w2[0];
      lo = w2[1];

      // high bits
      t1_hi = (
        ((hi >>> 19) | (lo << 13)) ^ // ROTR 19
        ((lo >>> 29) | (hi << 3)) ^ // ROTR 61/(swap + ROTR 29)
        (hi >>> 6)) >>> 0; // SHR 6
      // low bits
      t1_lo = (
        ((hi << 13) | (lo >>> 19)) ^ // ROTR 19
        ((lo << 3) | (hi >>> 29)) ^ // ROTR 61/(swap + ROTR 29)
        ((hi << 26) | (lo >>> 6))) >>> 0; // SHR 6

      // for word 15 words ago: ROTR 1(x) ^ ROTR 8(x) ^ SHR 7(x)
      w15 = w[i - 15];
      hi = w15[0];
      lo = w15[1];

      // high bits
      t2_hi = (
        ((hi >>> 1) | (lo << 31)) ^ // ROTR 1
        ((hi >>> 8) | (lo << 24)) ^ // ROTR 8
        (hi >>> 7)) >>> 0; // SHR 7
      // low bits
      t2_lo = (
        ((hi << 31) | (lo >>> 1)) ^ // ROTR 1
        ((hi << 24) | (lo >>> 8)) ^ // ROTR 8
        ((hi << 25) | (lo >>> 7))) >>> 0; // SHR 7

      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^64 (carry lo overflow)
      w7 = w[i - 7];
      w16 = w[i - 16];
      lo = (t1_lo + w7[1] + t2_lo + w16[1]);
      w[i][0] = (t1_hi + w7[0] + t2_hi + w16[0] +
        ((lo / 0x100000000) >>> 0)) >>> 0;
      w[i][1] = lo >>> 0;
    }

    // initialize hash value for this chunk
    a_hi = s[0][0];
    a_lo = s[0][1];
    b_hi = s[1][0];
    b_lo = s[1][1];
    c_hi = s[2][0];
    c_lo = s[2][1];
    d_hi = s[3][0];
    d_lo = s[3][1];
    e_hi = s[4][0];
    e_lo = s[4][1];
    f_hi = s[5][0];
    f_lo = s[5][1];
    g_hi = s[6][0];
    g_lo = s[6][1];
    h_hi = s[7][0];
    h_lo = s[7][1];

    // round function
    for(i = 0; i < 80; ++i) {
      // Sum1(e) = ROTR 14(e) ^ ROTR 18(e) ^ ROTR 41(e)
      s1_hi = (
        ((e_hi >>> 14) | (e_lo << 18)) ^ // ROTR 14
        ((e_hi >>> 18) | (e_lo << 14)) ^ // ROTR 18
        ((e_lo >>> 9) | (e_hi << 23))) >>> 0; // ROTR 41/(swap + ROTR 9)
      s1_lo = (
        ((e_hi << 18) | (e_lo >>> 14)) ^ // ROTR 14
        ((e_hi << 14) | (e_lo >>> 18)) ^ // ROTR 18
        ((e_lo << 23) | (e_hi >>> 9))) >>> 0; // ROTR 41/(swap + ROTR 9)

      // Ch(e, f, g) (optimized the same way as SHA-1)
      ch_hi = (g_hi ^ (e_hi & (f_hi ^ g_hi))) >>> 0;
      ch_lo = (g_lo ^ (e_lo & (f_lo ^ g_lo))) >>> 0;

      // Sum0(a) = ROTR 28(a) ^ ROTR 34(a) ^ ROTR 39(a)
      s0_hi = (
        ((a_hi >>> 28) | (a_lo << 4)) ^ // ROTR 28
        ((a_lo >>> 2) | (a_hi << 30)) ^ // ROTR 34/(swap + ROTR 2)
        ((a_lo >>> 7) | (a_hi << 25))) >>> 0; // ROTR 39/(swap + ROTR 7)
      s0_lo = (
        ((a_hi << 4) | (a_lo >>> 28)) ^ // ROTR 28
        ((a_lo << 30) | (a_hi >>> 2)) ^ // ROTR 34/(swap + ROTR 2)
        ((a_lo << 25) | (a_hi >>> 7))) >>> 0; // ROTR 39/(swap + ROTR 7)

      // Maj(a, b, c) (optimized the same way as SHA-1)
      maj_hi = ((a_hi & b_hi) | (c_hi & (a_hi ^ b_hi))) >>> 0;
      maj_lo = ((a_lo & b_lo) | (c_lo & (a_lo ^ b_lo))) >>> 0;

      // main algorithm
      // t1 = (h + s1 + ch + _k[i] + _w[i]) modulo 2^64 (carry lo overflow)
      lo = (h_lo + s1_lo + ch_lo + _k[i][1] + w[i][1]);
      t1_hi = (h_hi + s1_hi + ch_hi + _k[i][0] + w[i][0] +
        ((lo / 0x100000000) >>> 0)) >>> 0;
      t1_lo = lo >>> 0;

      // t2 = s0 + maj modulo 2^64 (carry lo overflow)
      lo = s0_lo + maj_lo;
      t2_hi = (s0_hi + maj_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
      t2_lo = lo >>> 0;

      h_hi = g_hi;
      h_lo = g_lo;

      g_hi = f_hi;
      g_lo = f_lo;

      f_hi = e_hi;
      f_lo = e_lo;

      // e = (d + t1) modulo 2^64 (carry lo overflow)
      lo = d_lo + t1_lo;
      e_hi = (d_hi + t1_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
      e_lo = lo >>> 0;

      d_hi = c_hi;
      d_lo = c_lo;

      c_hi = b_hi;
      c_lo = b_lo;

      b_hi = a_hi;
      b_lo = a_lo;

      // a = (t1 + t2) modulo 2^64 (carry lo overflow)
      lo = t1_lo + t2_lo;
      a_hi = (t1_hi + t2_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
      a_lo = lo >>> 0;
    }

    // update hash state (additional modulo 2^64)
    lo = s[0][1] + a_lo;
    s[0][0] = (s[0][0] + a_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[0][1] = lo >>> 0;

    lo = s[1][1] + b_lo;
    s[1][0] = (s[1][0] + b_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[1][1] = lo >>> 0;

    lo = s[2][1] + c_lo;
    s[2][0] = (s[2][0] + c_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[2][1] = lo >>> 0;

    lo = s[3][1] + d_lo;
    s[3][0] = (s[3][0] + d_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[3][1] = lo >>> 0;

    lo = s[4][1] + e_lo;
    s[4][0] = (s[4][0] + e_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[4][1] = lo >>> 0;

    lo = s[5][1] + f_lo;
    s[5][0] = (s[5][0] + f_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[5][1] = lo >>> 0;

    lo = s[6][1] + g_lo;
    s[6][0] = (s[6][0] + g_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[6][1] = lo >>> 0;

    lo = s[7][1] + h_lo;
    s[7][0] = (s[7][0] + h_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[7][1] = lo >>> 0;

    len -= 128;
  }
}

/*! noble-secp256k1 - MIT License (c) 2019 Paul Miller (paulmillr.com) */
const _0n$1 = BigInt(0);
const _1n$1 = BigInt(1);
const _2n$1 = BigInt(2);
const _3n = BigInt(3);
const _8n$1 = BigInt(8);
const CURVE$1 = Object.freeze({
    a: _0n$1,
    b: BigInt(7),
    P: BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f'),
    n: BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141'),
    h: _1n$1,
    Gx: BigInt('55066263022277343669578718895168534326250603453777594175500187360389116729240'),
    Gy: BigInt('32670510020758816978083085130507043184471273380659243275938904335757337482424'),
    beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
});
const divNearest = (a, b) => (a + b / _2n$1) / b;
const endo = {
    beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
    splitScalar(k) {
        const { n } = CURVE$1;
        const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');
        const b1 = -_1n$1 * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');
        const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');
        const b2 = a1;
        const POW_2_128 = BigInt('0x100000000000000000000000000000000');
        const c1 = divNearest(b2 * k, n);
        const c2 = divNearest(-b1 * k, n);
        let k1 = mod$1(k - c1 * a1 - c2 * a2, n);
        let k2 = mod$1(-c1 * b1 - c2 * b2, n);
        const k1neg = k1 > POW_2_128;
        const k2neg = k2 > POW_2_128;
        if (k1neg)
            k1 = n - k1;
        if (k2neg)
            k2 = n - k2;
        if (k1 > POW_2_128 || k2 > POW_2_128) {
            throw new Error('splitScalarEndo: Endomorphism failed, k=' + k);
        }
        return { k1neg, k1, k2neg, k2 };
    },
};
const fieldLen = 32;
const groupLen = 32;
const hashLen = 32;
const compressedLen = fieldLen + 1;
const uncompressedLen = 2 * fieldLen + 1;
function weierstrass(x) {
    const { a, b } = CURVE$1;
    const x2 = mod$1(x * x);
    const x3 = mod$1(x2 * x);
    return mod$1(x3 + a * x + b);
}
const USE_ENDOMORPHISM = CURVE$1.a === _0n$1;
class ShaError extends Error {
    constructor(message) {
        super(message);
    }
}
function assertJacPoint(other) {
    if (!(other instanceof JacobianPoint))
        throw new TypeError('JacobianPoint expected');
}
class JacobianPoint {
    constructor(x, y, z) {
        this.x = x;
        this.y = y;
        this.z = z;
    }
    static fromAffine(p) {
        if (!(p instanceof Point$1)) {
            throw new TypeError('JacobianPoint#fromAffine: expected Point');
        }
        if (p.equals(Point$1.ZERO))
            return JacobianPoint.ZERO;
        return new JacobianPoint(p.x, p.y, _1n$1);
    }
    static toAffineBatch(points) {
        const toInv = invertBatch$1(points.map((p) => p.z));
        return points.map((p, i) => p.toAffine(toInv[i]));
    }
    static normalizeZ(points) {
        return JacobianPoint.toAffineBatch(points).map(JacobianPoint.fromAffine);
    }
    equals(other) {
        assertJacPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        const Z1Z1 = mod$1(Z1 * Z1);
        const Z2Z2 = mod$1(Z2 * Z2);
        const U1 = mod$1(X1 * Z2Z2);
        const U2 = mod$1(X2 * Z1Z1);
        const S1 = mod$1(mod$1(Y1 * Z2) * Z2Z2);
        const S2 = mod$1(mod$1(Y2 * Z1) * Z1Z1);
        return U1 === U2 && S1 === S2;
    }
    negate() {
        return new JacobianPoint(this.x, mod$1(-this.y), this.z);
    }
    double() {
        const { x: X1, y: Y1, z: Z1 } = this;
        const A = mod$1(X1 * X1);
        const B = mod$1(Y1 * Y1);
        const C = mod$1(B * B);
        const x1b = X1 + B;
        const D = mod$1(_2n$1 * (mod$1(x1b * x1b) - A - C));
        const E = mod$1(_3n * A);
        const F = mod$1(E * E);
        const X3 = mod$1(F - _2n$1 * D);
        const Y3 = mod$1(E * (D - X3) - _8n$1 * C);
        const Z3 = mod$1(_2n$1 * Y1 * Z1);
        return new JacobianPoint(X3, Y3, Z3);
    }
    add(other) {
        assertJacPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        if (X2 === _0n$1 || Y2 === _0n$1)
            return this;
        if (X1 === _0n$1 || Y1 === _0n$1)
            return other;
        const Z1Z1 = mod$1(Z1 * Z1);
        const Z2Z2 = mod$1(Z2 * Z2);
        const U1 = mod$1(X1 * Z2Z2);
        const U2 = mod$1(X2 * Z1Z1);
        const S1 = mod$1(mod$1(Y1 * Z2) * Z2Z2);
        const S2 = mod$1(mod$1(Y2 * Z1) * Z1Z1);
        const H = mod$1(U2 - U1);
        const r = mod$1(S2 - S1);
        if (H === _0n$1) {
            if (r === _0n$1) {
                return this.double();
            }
            else {
                return JacobianPoint.ZERO;
            }
        }
        const HH = mod$1(H * H);
        const HHH = mod$1(H * HH);
        const V = mod$1(U1 * HH);
        const X3 = mod$1(r * r - HHH - _2n$1 * V);
        const Y3 = mod$1(r * (V - X3) - S1 * HHH);
        const Z3 = mod$1(Z1 * Z2 * H);
        return new JacobianPoint(X3, Y3, Z3);
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiplyUnsafe(scalar) {
        const P0 = JacobianPoint.ZERO;
        if (typeof scalar === 'bigint' && scalar === _0n$1)
            return P0;
        let n = normalizeScalar$1(scalar);
        if (n === _1n$1)
            return this;
        if (!USE_ENDOMORPHISM) {
            let p = P0;
            let d = this;
            while (n > _0n$1) {
                if (n & _1n$1)
                    p = p.add(d);
                d = d.double();
                n >>= _1n$1;
            }
            return p;
        }
        let { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
        let k1p = P0;
        let k2p = P0;
        let d = this;
        while (k1 > _0n$1 || k2 > _0n$1) {
            if (k1 & _1n$1)
                k1p = k1p.add(d);
            if (k2 & _1n$1)
                k2p = k2p.add(d);
            d = d.double();
            k1 >>= _1n$1;
            k2 >>= _1n$1;
        }
        if (k1neg)
            k1p = k1p.negate();
        if (k2neg)
            k2p = k2p.negate();
        k2p = new JacobianPoint(mod$1(k2p.x * endo.beta), k2p.y, k2p.z);
        return k1p.add(k2p);
    }
    precomputeWindow(W) {
        const windows = USE_ENDOMORPHISM ? 128 / W + 1 : 256 / W + 1;
        const points = [];
        let p = this;
        let base = p;
        for (let window = 0; window < windows; window++) {
            base = p;
            points.push(base);
            for (let i = 1; i < 2 ** (W - 1); i++) {
                base = base.add(p);
                points.push(base);
            }
            p = base.double();
        }
        return points;
    }
    wNAF(n, affinePoint) {
        if (!affinePoint && this.equals(JacobianPoint.BASE))
            affinePoint = Point$1.BASE;
        const W = (affinePoint && affinePoint._WINDOW_SIZE) || 1;
        if (256 % W) {
            throw new Error('Point#wNAF: Invalid precomputation window, must be power of 2');
        }
        let precomputes = affinePoint && pointPrecomputes$1.get(affinePoint);
        if (!precomputes) {
            precomputes = this.precomputeWindow(W);
            if (affinePoint && W !== 1) {
                precomputes = JacobianPoint.normalizeZ(precomputes);
                pointPrecomputes$1.set(affinePoint, precomputes);
            }
        }
        let p = JacobianPoint.ZERO;
        let f = JacobianPoint.BASE;
        const windows = 1 + (USE_ENDOMORPHISM ? 128 / W : 256 / W);
        const windowSize = 2 ** (W - 1);
        const mask = BigInt(2 ** W - 1);
        const maxNumber = 2 ** W;
        const shiftBy = BigInt(W);
        for (let window = 0; window < windows; window++) {
            const offset = window * windowSize;
            let wbits = Number(n & mask);
            n >>= shiftBy;
            if (wbits > windowSize) {
                wbits -= maxNumber;
                n += _1n$1;
            }
            const offset1 = offset;
            const offset2 = offset + Math.abs(wbits) - 1;
            const cond1 = window % 2 !== 0;
            const cond2 = wbits < 0;
            if (wbits === 0) {
                f = f.add(constTimeNegate$1(cond1, precomputes[offset1]));
            }
            else {
                p = p.add(constTimeNegate$1(cond2, precomputes[offset2]));
            }
        }
        return { p, f };
    }
    multiply(scalar, affinePoint) {
        let n = normalizeScalar$1(scalar);
        let point;
        let fake;
        if (USE_ENDOMORPHISM) {
            const { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
            let { p: k1p, f: f1p } = this.wNAF(k1, affinePoint);
            let { p: k2p, f: f2p } = this.wNAF(k2, affinePoint);
            k1p = constTimeNegate$1(k1neg, k1p);
            k2p = constTimeNegate$1(k2neg, k2p);
            k2p = new JacobianPoint(mod$1(k2p.x * endo.beta), k2p.y, k2p.z);
            point = k1p.add(k2p);
            fake = f1p.add(f2p);
        }
        else {
            const { p, f } = this.wNAF(n, affinePoint);
            point = p;
            fake = f;
        }
        return JacobianPoint.normalizeZ([point, fake])[0];
    }
    toAffine(invZ) {
        const { x, y, z } = this;
        const is0 = this.equals(JacobianPoint.ZERO);
        if (invZ == null)
            invZ = is0 ? _8n$1 : invert$1(z);
        const iz1 = invZ;
        const iz2 = mod$1(iz1 * iz1);
        const iz3 = mod$1(iz2 * iz1);
        const ax = mod$1(x * iz2);
        const ay = mod$1(y * iz3);
        const zz = mod$1(z * iz1);
        if (is0)
            return Point$1.ZERO;
        if (zz !== _1n$1)
            throw new Error('invZ was invalid');
        return new Point$1(ax, ay);
    }
}
JacobianPoint.BASE = new JacobianPoint(CURVE$1.Gx, CURVE$1.Gy, _1n$1);
JacobianPoint.ZERO = new JacobianPoint(_0n$1, _1n$1, _0n$1);
function constTimeNegate$1(condition, item) {
    const neg = item.negate();
    return condition ? neg : item;
}
const pointPrecomputes$1 = new WeakMap();
let Point$1 = class Point {
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }
    _setWindowSize(windowSize) {
        this._WINDOW_SIZE = windowSize;
        pointPrecomputes$1.delete(this);
    }
    hasEvenY() {
        return this.y % _2n$1 === _0n$1;
    }
    static fromCompressedHex(bytes) {
        const isShort = bytes.length === 32;
        const x = bytesToNumber(isShort ? bytes : bytes.subarray(1));
        if (!isValidFieldElement(x))
            throw new Error('Point is not on curve');
        const y2 = weierstrass(x);
        let y = sqrtMod(y2);
        const isYOdd = (y & _1n$1) === _1n$1;
        if (isShort) {
            if (isYOdd)
                y = mod$1(-y);
        }
        else {
            const isFirstByteOdd = (bytes[0] & 1) === 1;
            if (isFirstByteOdd !== isYOdd)
                y = mod$1(-y);
        }
        const point = new Point(x, y);
        point.assertValidity();
        return point;
    }
    static fromUncompressedHex(bytes) {
        const x = bytesToNumber(bytes.subarray(1, fieldLen + 1));
        const y = bytesToNumber(bytes.subarray(fieldLen + 1, fieldLen * 2 + 1));
        const point = new Point(x, y);
        point.assertValidity();
        return point;
    }
    static fromHex(hex) {
        const bytes = ensureBytes$1(hex);
        const len = bytes.length;
        const header = bytes[0];
        if (len === fieldLen)
            return this.fromCompressedHex(bytes);
        if (len === compressedLen && (header === 0x02 || header === 0x03)) {
            return this.fromCompressedHex(bytes);
        }
        if (len === uncompressedLen && header === 0x04)
            return this.fromUncompressedHex(bytes);
        throw new Error(`Point.fromHex: received invalid point. Expected 32-${compressedLen} compressed bytes or ${uncompressedLen} uncompressed bytes, not ${len}`);
    }
    static fromPrivateKey(privateKey) {
        return Point.BASE.multiply(normalizePrivateKey(privateKey));
    }
    static fromSignature(msgHash, signature, recovery) {
        const { r, s } = normalizeSignature(signature);
        if (![0, 1, 2, 3].includes(recovery))
            throw new Error('Cannot recover: invalid recovery bit');
        const h = truncateHash(ensureBytes$1(msgHash));
        const { n } = CURVE$1;
        const radj = recovery === 2 || recovery === 3 ? r + n : r;
        const rinv = invert$1(radj, n);
        const u1 = mod$1(-h * rinv, n);
        const u2 = mod$1(s * rinv, n);
        const prefix = recovery & 1 ? '03' : '02';
        const R = Point.fromHex(prefix + numTo32bStr(radj));
        const Q = Point.BASE.multiplyAndAddUnsafe(R, u1, u2);
        if (!Q)
            throw new Error('Cannot recover signature: point at infinify');
        Q.assertValidity();
        return Q;
    }
    toRawBytes(isCompressed = false) {
        return hexToBytes$2(this.toHex(isCompressed));
    }
    toHex(isCompressed = false) {
        const x = numTo32bStr(this.x);
        if (isCompressed) {
            const prefix = this.hasEvenY() ? '02' : '03';
            return `${prefix}${x}`;
        }
        else {
            return `04${x}${numTo32bStr(this.y)}`;
        }
    }
    toHexX() {
        return this.toHex(true).slice(2);
    }
    toRawX() {
        return this.toRawBytes(true).slice(1);
    }
    assertValidity() {
        const msg = 'Point is not on elliptic curve';
        const { x, y } = this;
        if (!isValidFieldElement(x) || !isValidFieldElement(y))
            throw new Error(msg);
        const left = mod$1(y * y);
        const right = weierstrass(x);
        if (mod$1(left - right) !== _0n$1)
            throw new Error(msg);
    }
    equals(other) {
        return this.x === other.x && this.y === other.y;
    }
    negate() {
        return new Point(this.x, mod$1(-this.y));
    }
    double() {
        return JacobianPoint.fromAffine(this).double().toAffine();
    }
    add(other) {
        return JacobianPoint.fromAffine(this).add(JacobianPoint.fromAffine(other)).toAffine();
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiply(scalar) {
        return JacobianPoint.fromAffine(this).multiply(scalar, this).toAffine();
    }
    multiplyAndAddUnsafe(Q, a, b) {
        const P = JacobianPoint.fromAffine(this);
        const aP = a === _0n$1 || a === _1n$1 || this !== Point.BASE ? P.multiplyUnsafe(a) : P.multiply(a);
        const bQ = JacobianPoint.fromAffine(Q).multiplyUnsafe(b);
        const sum = aP.add(bQ);
        return sum.equals(JacobianPoint.ZERO) ? undefined : sum.toAffine();
    }
};
Point$1.BASE = new Point$1(CURVE$1.Gx, CURVE$1.Gy);
Point$1.ZERO = new Point$1(_0n$1, _0n$1);
function sliceDER(s) {
    return Number.parseInt(s[0], 16) >= 8 ? '00' + s : s;
}
function parseDERInt(data) {
    if (data.length < 2 || data[0] !== 0x02) {
        throw new Error(`Invalid signature integer tag: ${bytesToHex$2(data)}`);
    }
    const len = data[1];
    const res = data.subarray(2, len + 2);
    if (!len || res.length !== len) {
        throw new Error(`Invalid signature integer: wrong length`);
    }
    if (res[0] === 0x00 && res[1] <= 0x7f) {
        throw new Error('Invalid signature integer: trailing length');
    }
    return { data: bytesToNumber(res), left: data.subarray(len + 2) };
}
function parseDERSignature(data) {
    if (data.length < 2 || data[0] != 0x30) {
        throw new Error(`Invalid signature tag: ${bytesToHex$2(data)}`);
    }
    if (data[1] !== data.length - 2) {
        throw new Error('Invalid signature: incorrect length');
    }
    const { data: r, left: sBytes } = parseDERInt(data.subarray(2));
    const { data: s, left: rBytesLeft } = parseDERInt(sBytes);
    if (rBytesLeft.length) {
        throw new Error(`Invalid signature: left bytes after parsing: ${bytesToHex$2(rBytesLeft)}`);
    }
    return { r, s };
}
let Signature$1 = class Signature {
    constructor(r, s) {
        this.r = r;
        this.s = s;
        this.assertValidity();
    }
    static fromCompact(hex) {
        const arr = hex instanceof Uint8Array;
        const name = 'Signature.fromCompact';
        if (typeof hex !== 'string' && !arr)
            throw new TypeError(`${name}: Expected string or Uint8Array`);
        const str = arr ? bytesToHex$2(hex) : hex;
        if (str.length !== 128)
            throw new Error(`${name}: Expected 64-byte hex`);
        return new Signature(hexToNumber(str.slice(0, 64)), hexToNumber(str.slice(64, 128)));
    }
    static fromDER(hex) {
        const arr = hex instanceof Uint8Array;
        if (typeof hex !== 'string' && !arr)
            throw new TypeError(`Signature.fromDER: Expected string or Uint8Array`);
        const { r, s } = parseDERSignature(arr ? hex : hexToBytes$2(hex));
        return new Signature(r, s);
    }
    static fromHex(hex) {
        return this.fromDER(hex);
    }
    assertValidity() {
        const { r, s } = this;
        if (!isWithinCurveOrder(r))
            throw new Error('Invalid Signature: r must be 0 < r < n');
        if (!isWithinCurveOrder(s))
            throw new Error('Invalid Signature: s must be 0 < s < n');
    }
    hasHighS() {
        const HALF = CURVE$1.n >> _1n$1;
        return this.s > HALF;
    }
    normalizeS() {
        return this.hasHighS() ? new Signature(this.r, mod$1(-this.s, CURVE$1.n)) : this;
    }
    toDERRawBytes() {
        return hexToBytes$2(this.toDERHex());
    }
    toDERHex() {
        const sHex = sliceDER(numberToHexUnpadded(this.s));
        const rHex = sliceDER(numberToHexUnpadded(this.r));
        const sHexL = sHex.length / 2;
        const rHexL = rHex.length / 2;
        const sLen = numberToHexUnpadded(sHexL);
        const rLen = numberToHexUnpadded(rHexL);
        const length = numberToHexUnpadded(rHexL + sHexL + 4);
        return `30${length}02${rLen}${rHex}02${sLen}${sHex}`;
    }
    toRawBytes() {
        return this.toDERRawBytes();
    }
    toHex() {
        return this.toDERHex();
    }
    toCompactRawBytes() {
        return hexToBytes$2(this.toCompactHex());
    }
    toCompactHex() {
        return numTo32bStr(this.r) + numTo32bStr(this.s);
    }
};
function concatBytes$1(...arrays) {
    if (!arrays.every((b) => b instanceof Uint8Array))
        throw new Error('Uint8Array list expected');
    if (arrays.length === 1)
        return arrays[0];
    const length = arrays.reduce((a, arr) => a + arr.length, 0);
    const result = new Uint8Array(length);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const arr = arrays[i];
        result.set(arr, pad);
        pad += arr.length;
    }
    return result;
}
const hexes$1 = Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, '0'));
function bytesToHex$2(uint8a) {
    if (!(uint8a instanceof Uint8Array))
        throw new Error('Expected Uint8Array');
    let hex = '';
    for (let i = 0; i < uint8a.length; i++) {
        hex += hexes$1[uint8a[i]];
    }
    return hex;
}
const POW_2_256$1 = BigInt('0x10000000000000000000000000000000000000000000000000000000000000000');
function numTo32bStr(num) {
    if (typeof num !== 'bigint')
        throw new Error('Expected bigint');
    if (!(_0n$1 <= num && num < POW_2_256$1))
        throw new Error('Expected number 0 <= n < 2^256');
    return num.toString(16).padStart(64, '0');
}
function numTo32b(num) {
    const b = hexToBytes$2(numTo32bStr(num));
    if (b.length !== 32)
        throw new Error('Error: expected 32 bytes');
    return b;
}
function numberToHexUnpadded(num) {
    const hex = num.toString(16);
    return hex.length & 1 ? `0${hex}` : hex;
}
function hexToNumber(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToNumber: expected string, got ' + typeof hex);
    }
    return BigInt(`0x${hex}`);
}
function hexToBytes$2(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToBytes: expected string, got ' + typeof hex);
    }
    if (hex.length % 2)
        throw new Error('hexToBytes: received invalid unpadded hex' + hex.length);
    const array = new Uint8Array(hex.length / 2);
    for (let i = 0; i < array.length; i++) {
        const j = i * 2;
        const hexByte = hex.slice(j, j + 2);
        const byte = Number.parseInt(hexByte, 16);
        if (Number.isNaN(byte) || byte < 0)
            throw new Error('Invalid byte sequence');
        array[i] = byte;
    }
    return array;
}
function bytesToNumber(bytes) {
    return hexToNumber(bytesToHex$2(bytes));
}
function ensureBytes$1(hex) {
    return hex instanceof Uint8Array ? Uint8Array.from(hex) : hexToBytes$2(hex);
}
function normalizeScalar$1(num) {
    if (typeof num === 'number' && Number.isSafeInteger(num) && num > 0)
        return BigInt(num);
    if (typeof num === 'bigint' && isWithinCurveOrder(num))
        return num;
    throw new TypeError('Expected valid private scalar: 0 < scalar < curve.n');
}
function mod$1(a, b = CURVE$1.P) {
    const result = a % b;
    return result >= _0n$1 ? result : b + result;
}
function pow2$1(x, power) {
    const { P } = CURVE$1;
    let res = x;
    while (power-- > _0n$1) {
        res *= res;
        res %= P;
    }
    return res;
}
function sqrtMod(x) {
    const { P } = CURVE$1;
    const _6n = BigInt(6);
    const _11n = BigInt(11);
    const _22n = BigInt(22);
    const _23n = BigInt(23);
    const _44n = BigInt(44);
    const _88n = BigInt(88);
    const b2 = (x * x * x) % P;
    const b3 = (b2 * b2 * x) % P;
    const b6 = (pow2$1(b3, _3n) * b3) % P;
    const b9 = (pow2$1(b6, _3n) * b3) % P;
    const b11 = (pow2$1(b9, _2n$1) * b2) % P;
    const b22 = (pow2$1(b11, _11n) * b11) % P;
    const b44 = (pow2$1(b22, _22n) * b22) % P;
    const b88 = (pow2$1(b44, _44n) * b44) % P;
    const b176 = (pow2$1(b88, _88n) * b88) % P;
    const b220 = (pow2$1(b176, _44n) * b44) % P;
    const b223 = (pow2$1(b220, _3n) * b3) % P;
    const t1 = (pow2$1(b223, _23n) * b22) % P;
    const t2 = (pow2$1(t1, _6n) * b2) % P;
    const rt = pow2$1(t2, _2n$1);
    const xc = (rt * rt) % P;
    if (xc !== x)
        throw new Error('Cannot find square root');
    return rt;
}
function invert$1(number, modulo = CURVE$1.P) {
    if (number === _0n$1 || modulo <= _0n$1) {
        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);
    }
    let a = mod$1(number, modulo);
    let b = modulo;
    let x = _0n$1, u = _1n$1;
    while (a !== _0n$1) {
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n$1)
        throw new Error('invert: does not exist');
    return mod$1(x, modulo);
}
function invertBatch$1(nums, p = CURVE$1.P) {
    const scratch = new Array(nums.length);
    const lastMultiplied = nums.reduce((acc, num, i) => {
        if (num === _0n$1)
            return acc;
        scratch[i] = acc;
        return mod$1(acc * num, p);
    }, _1n$1);
    const inverted = invert$1(lastMultiplied, p);
    nums.reduceRight((acc, num, i) => {
        if (num === _0n$1)
            return acc;
        scratch[i] = mod$1(acc * scratch[i], p);
        return mod$1(acc * num, p);
    }, inverted);
    return scratch;
}
function bits2int_2(bytes) {
    const delta = bytes.length * 8 - groupLen * 8;
    const num = bytesToNumber(bytes);
    return delta > 0 ? num >> BigInt(delta) : num;
}
function truncateHash(hash, truncateOnly = false) {
    const h = bits2int_2(hash);
    if (truncateOnly)
        return h;
    const { n } = CURVE$1;
    return h >= n ? h - n : h;
}
let _sha256Sync;
let _hmacSha256Sync;
class HmacDrbg {
    constructor(hashLen, qByteLen) {
        this.hashLen = hashLen;
        this.qByteLen = qByteLen;
        if (typeof hashLen !== 'number' || hashLen < 2)
            throw new Error('hashLen must be a number');
        if (typeof qByteLen !== 'number' || qByteLen < 2)
            throw new Error('qByteLen must be a number');
        this.v = new Uint8Array(hashLen).fill(1);
        this.k = new Uint8Array(hashLen).fill(0);
        this.counter = 0;
    }
    hmac(...values) {
        return utils$1.hmacSha256(this.k, ...values);
    }
    hmacSync(...values) {
        return _hmacSha256Sync(this.k, ...values);
    }
    checkSync() {
        if (typeof _hmacSha256Sync !== 'function')
            throw new ShaError('hmacSha256Sync needs to be set');
    }
    incr() {
        if (this.counter >= 1000)
            throw new Error('Tried 1,000 k values for sign(), all were invalid');
        this.counter += 1;
    }
    async reseed(seed = new Uint8Array()) {
        this.k = await this.hmac(this.v, Uint8Array.from([0x00]), seed);
        this.v = await this.hmac(this.v);
        if (seed.length === 0)
            return;
        this.k = await this.hmac(this.v, Uint8Array.from([0x01]), seed);
        this.v = await this.hmac(this.v);
    }
    reseedSync(seed = new Uint8Array()) {
        this.checkSync();
        this.k = this.hmacSync(this.v, Uint8Array.from([0x00]), seed);
        this.v = this.hmacSync(this.v);
        if (seed.length === 0)
            return;
        this.k = this.hmacSync(this.v, Uint8Array.from([0x01]), seed);
        this.v = this.hmacSync(this.v);
    }
    async generate() {
        this.incr();
        let len = 0;
        const out = [];
        while (len < this.qByteLen) {
            this.v = await this.hmac(this.v);
            const sl = this.v.slice();
            out.push(sl);
            len += this.v.length;
        }
        return concatBytes$1(...out);
    }
    generateSync() {
        this.checkSync();
        this.incr();
        let len = 0;
        const out = [];
        while (len < this.qByteLen) {
            this.v = this.hmacSync(this.v);
            const sl = this.v.slice();
            out.push(sl);
            len += this.v.length;
        }
        return concatBytes$1(...out);
    }
}
function isWithinCurveOrder(num) {
    return _0n$1 < num && num < CURVE$1.n;
}
function isValidFieldElement(num) {
    return _0n$1 < num && num < CURVE$1.P;
}
function kmdToSig(kBytes, m, d, lowS = true) {
    const { n } = CURVE$1;
    const k = truncateHash(kBytes, true);
    if (!isWithinCurveOrder(k))
        return;
    const kinv = invert$1(k, n);
    const q = Point$1.BASE.multiply(k);
    const r = mod$1(q.x, n);
    if (r === _0n$1)
        return;
    const s = mod$1(kinv * mod$1(m + d * r, n), n);
    if (s === _0n$1)
        return;
    let sig = new Signature$1(r, s);
    let recovery = (q.x === sig.r ? 0 : 2) | Number(q.y & _1n$1);
    if (lowS && sig.hasHighS()) {
        sig = sig.normalizeS();
        recovery ^= 1;
    }
    return { sig, recovery };
}
function normalizePrivateKey(key) {
    let num;
    if (typeof key === 'bigint') {
        num = key;
    }
    else if (typeof key === 'number' && Number.isSafeInteger(key) && key > 0) {
        num = BigInt(key);
    }
    else if (typeof key === 'string') {
        if (key.length !== 2 * groupLen)
            throw new Error('Expected 32 bytes of private key');
        num = hexToNumber(key);
    }
    else if (key instanceof Uint8Array) {
        if (key.length !== groupLen)
            throw new Error('Expected 32 bytes of private key');
        num = bytesToNumber(key);
    }
    else {
        throw new TypeError('Expected valid private key');
    }
    if (!isWithinCurveOrder(num))
        throw new Error('Expected private key: 0 < key < n');
    return num;
}
function normalizePublicKey(publicKey) {
    if (publicKey instanceof Point$1) {
        publicKey.assertValidity();
        return publicKey;
    }
    else {
        return Point$1.fromHex(publicKey);
    }
}
function normalizeSignature(signature) {
    if (signature instanceof Signature$1) {
        signature.assertValidity();
        return signature;
    }
    try {
        return Signature$1.fromDER(signature);
    }
    catch (error) {
        return Signature$1.fromCompact(signature);
    }
}
function getPublicKey$1(privateKey, isCompressed = false) {
    return Point$1.fromPrivateKey(privateKey).toRawBytes(isCompressed);
}
function bits2int(bytes) {
    const slice = bytes.length > fieldLen ? bytes.slice(0, fieldLen) : bytes;
    return bytesToNumber(slice);
}
function bits2octets(bytes) {
    const z1 = bits2int(bytes);
    const z2 = mod$1(z1, CURVE$1.n);
    return int2octets(z2 < _0n$1 ? z1 : z2);
}
function int2octets(num) {
    return numTo32b(num);
}
function initSigArgs(msgHash, privateKey, extraEntropy) {
    if (msgHash == null)
        throw new Error(`sign: expected valid message hash, not "${msgHash}"`);
    const h1 = ensureBytes$1(msgHash);
    const d = normalizePrivateKey(privateKey);
    const seedArgs = [int2octets(d), bits2octets(h1)];
    if (extraEntropy != null) {
        if (extraEntropy === true)
            extraEntropy = utils$1.randomBytes(fieldLen);
        const e = ensureBytes$1(extraEntropy);
        if (e.length !== fieldLen)
            throw new Error(`sign: Expected ${fieldLen} bytes of extra data`);
        seedArgs.push(e);
    }
    const seed = concatBytes$1(...seedArgs);
    const m = bits2int(h1);
    return { seed, m, d };
}
function finalizeSig(recSig, opts) {
    const { sig, recovery } = recSig;
    const { der, recovered } = Object.assign({ canonical: true, der: true }, opts);
    const hashed = der ? sig.toDERRawBytes() : sig.toCompactRawBytes();
    return recovered ? [hashed, recovery] : hashed;
}
async function sign$2(msgHash, privKey, opts = {}) {
    const { seed, m, d } = initSigArgs(msgHash, privKey, opts.extraEntropy);
    const drbg = new HmacDrbg(hashLen, groupLen);
    await drbg.reseed(seed);
    let sig;
    while (!(sig = kmdToSig(await drbg.generate(), m, d, opts.canonical)))
        await drbg.reseed();
    return finalizeSig(sig, opts);
}
const vopts = { strict: true };
function verify$1(signature, msgHash, publicKey, opts = vopts) {
    let sig;
    try {
        sig = normalizeSignature(signature);
        msgHash = ensureBytes$1(msgHash);
    }
    catch (error) {
        return false;
    }
    const { r, s } = sig;
    if (opts.strict && sig.hasHighS())
        return false;
    const h = truncateHash(msgHash);
    let P;
    try {
        P = normalizePublicKey(publicKey);
    }
    catch (error) {
        return false;
    }
    const { n } = CURVE$1;
    const sinv = invert$1(s, n);
    const u1 = mod$1(h * sinv, n);
    const u2 = mod$1(r * sinv, n);
    const R = Point$1.BASE.multiplyAndAddUnsafe(P, u1, u2);
    if (!R)
        return false;
    const v = mod$1(R.x, n);
    return v === r;
}
Point$1.BASE._setWindowSize(8);
const crypto$3 = {
    node: nodeCrypto,
    web: typeof self === 'object' && 'crypto' in self ? self.crypto : undefined,
};
const TAGGED_HASH_PREFIXES = {};
const utils$1 = {
    bytesToHex: bytesToHex$2,
    hexToBytes: hexToBytes$2,
    concatBytes: concatBytes$1,
    mod: mod$1,
    invert: invert$1,
    isValidPrivateKey(privateKey) {
        try {
            normalizePrivateKey(privateKey);
            return true;
        }
        catch (error) {
            return false;
        }
    },
    _bigintTo32Bytes: numTo32b,
    _normalizePrivateKey: normalizePrivateKey,
    hashToPrivateKey: (hash) => {
        hash = ensureBytes$1(hash);
        const minLen = groupLen + 8;
        if (hash.length < minLen || hash.length > 1024) {
            throw new Error(`Expected valid bytes of private key as per FIPS 186`);
        }
        const num = mod$1(bytesToNumber(hash), CURVE$1.n - _1n$1) + _1n$1;
        return numTo32b(num);
    },
    randomBytes: (bytesLength = 32) => {
        if (crypto$3.web) {
            return crypto$3.web.getRandomValues(new Uint8Array(bytesLength));
        }
        else if (crypto$3.node) {
            const { randomBytes } = crypto$3.node;
            return Uint8Array.from(randomBytes(bytesLength));
        }
        else {
            throw new Error("The environment doesn't have randomBytes function");
        }
    },
    randomPrivateKey: () => utils$1.hashToPrivateKey(utils$1.randomBytes(groupLen + 8)),
    precompute(windowSize = 8, point = Point$1.BASE) {
        const cached = point === Point$1.BASE ? point : new Point$1(point.x, point.y);
        cached._setWindowSize(windowSize);
        cached.multiply(_3n);
        return cached;
    },
    sha256: async (...messages) => {
        if (crypto$3.web) {
            const buffer = await crypto$3.web.subtle.digest('SHA-256', concatBytes$1(...messages));
            return new Uint8Array(buffer);
        }
        else if (crypto$3.node) {
            const { createHash } = crypto$3.node;
            const hash = createHash('sha256');
            messages.forEach((m) => hash.update(m));
            return Uint8Array.from(hash.digest());
        }
        else {
            throw new Error("The environment doesn't have sha256 function");
        }
    },
    hmacSha256: async (key, ...messages) => {
        if (crypto$3.web) {
            const ckey = await crypto$3.web.subtle.importKey('raw', key, { name: 'HMAC', hash: { name: 'SHA-256' } }, false, ['sign']);
            const message = concatBytes$1(...messages);
            const buffer = await crypto$3.web.subtle.sign('HMAC', ckey, message);
            return new Uint8Array(buffer);
        }
        else if (crypto$3.node) {
            const { createHmac } = crypto$3.node;
            const hash = createHmac('sha256', key);
            messages.forEach((m) => hash.update(m));
            return Uint8Array.from(hash.digest());
        }
        else {
            throw new Error("The environment doesn't have hmac-sha256 function");
        }
    },
    sha256Sync: undefined,
    hmacSha256Sync: undefined,
    taggedHash: async (tag, ...messages) => {
        let tagP = TAGGED_HASH_PREFIXES[tag];
        if (tagP === undefined) {
            const tagH = await utils$1.sha256(Uint8Array.from(tag, (c) => c.charCodeAt(0)));
            tagP = concatBytes$1(tagH, tagH);
            TAGGED_HASH_PREFIXES[tag] = tagP;
        }
        return utils$1.sha256(tagP, ...messages);
    },
    taggedHashSync: (tag, ...messages) => {
        if (typeof _sha256Sync !== 'function')
            throw new ShaError('sha256Sync is undefined, you need to set it');
        let tagP = TAGGED_HASH_PREFIXES[tag];
        if (tagP === undefined) {
            const tagH = _sha256Sync(Uint8Array.from(tag, (c) => c.charCodeAt(0)));
            tagP = concatBytes$1(tagH, tagH);
            TAGGED_HASH_PREFIXES[tag] = tagP;
        }
        return _sha256Sync(tagP, ...messages);
    },
    _JacobianPoint: JacobianPoint,
};
Object.defineProperties(utils$1, {
    sha256Sync: {
        configurable: false,
        get() {
            return _sha256Sync;
        },
        set(val) {
            if (!_sha256Sync)
                _sha256Sync = val;
        },
    },
    hmacSha256Sync: {
        configurable: false,
        get() {
            return _hmacSha256Sync;
        },
        set(val) {
            if (!_hmacSha256Sync)
                _hmacSha256Sync = val;
        },
    },
});

function randomBytes(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return utils$1.randomBytes(length);
}

// Convert a PKCS#1 in ASN1 DER format to a JWK key
function pkcs1ToJwk(bytes) {
    const asn1 = forge$s.asn1.fromDer(toString$7(bytes, 'ascii'));
    const privateKey = forge$s.pki.privateKeyFromAsn1(asn1);
    // https://tools.ietf.org/html/rfc7518#section-6.3.1
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url(privateKey.n),
        e: bigIntegerToUintBase64url(privateKey.e),
        d: bigIntegerToUintBase64url(privateKey.d),
        p: bigIntegerToUintBase64url(privateKey.p),
        q: bigIntegerToUintBase64url(privateKey.q),
        dp: bigIntegerToUintBase64url(privateKey.dP),
        dq: bigIntegerToUintBase64url(privateKey.dQ),
        qi: bigIntegerToUintBase64url(privateKey.qInv),
        alg: 'RS256'
    };
}
// Convert a JWK key into PKCS#1 in ASN1 DER format
function jwkToPkcs1(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$s.pki.privateKeyToAsn1({
        n: base64urlToBigInteger(jwk.n),
        e: base64urlToBigInteger(jwk.e),
        d: base64urlToBigInteger(jwk.d),
        p: base64urlToBigInteger(jwk.p),
        q: base64urlToBigInteger(jwk.q),
        dP: base64urlToBigInteger(jwk.dp),
        dQ: base64urlToBigInteger(jwk.dq),
        qInv: base64urlToBigInteger(jwk.qi)
    });
    return fromString$2(forge$s.asn1.toDer(asn1).getBytes(), 'ascii');
}
// Convert a PKCIX in ASN1 DER format to a JWK key
function pkixToJwk(bytes) {
    const asn1 = forge$s.asn1.fromDer(toString$7(bytes, 'ascii'));
    const publicKey = forge$s.pki.publicKeyFromAsn1(asn1);
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url(publicKey.n),
        e: bigIntegerToUintBase64url(publicKey.e)
    };
}
// Convert a JWK key to PKCIX in ASN1 DER format
function jwkToPkix(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$s.pki.publicKeyToAsn1({
        n: base64urlToBigInteger(jwk.n),
        e: base64urlToBigInteger(jwk.e)
    });
    return fromString$2(forge$s.asn1.toDer(asn1).getBytes(), 'ascii');
}

function convert(key, types) {
    return types.map(t => base64urlToBigInteger(key[t]));
}
function jwk2priv(key) {
    return forge$s.pki.setRsaPrivateKey(...convert(key, ['n', 'e', 'd', 'p', 'q', 'dp', 'dq', 'qi']));
}
function jwk2pub(key) {
    return forge$s.pki.setRsaPublicKey(...convert(key, ['n', 'e']));
}

async function generateKey$2(bits) {
    const pair = await webcrypto.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$1(key) {
    const privateKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate(key)
    ];
    const keys = await exportKey({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$2(key, msg) {
    const privateKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, Uint8Array.from(msg));
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$2(key, sig, msg) {
    const publicKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return await webcrypto.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg);
}
async function exportKey(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return await Promise.all([
        webcrypto.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate(jwKey) {
    return await webcrypto.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
/*

RSA encryption/decryption for the browser with webcrypto workaround
"bloody dark magic. webcrypto's why."

Explanation:
  - Convert JWK to nodeForge
  - Convert msg Uint8Array to nodeForge buffer: ByteBuffer is a "binary-string backed buffer", so let's make our Uint8Array a binary string
  - Convert resulting nodeForge buffer to Uint8Array: it returns a binary string, turn that into a Uint8Array

*/
function convertKey(key, pub, msg, handle) {
    const fkey = pub ? jwk2pub(key) : jwk2priv(key);
    const fmsg = toString$7(Uint8Array.from(msg), 'ascii');
    const fomsg = handle(fmsg, fkey);
    return fromString$2(fomsg, 'ascii');
}
function encrypt(key, msg) {
    return convertKey(key, true, msg, (msg, key) => key.encrypt(msg));
}
function decrypt(key, msg) {
    return convertKey(key, false, msg, (msg, key) => key.decrypt(msg));
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter(privateKey, password) {
    const cipher = create$c();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64$6.encode(encryptedKey);
}

class RsaPublicKey {
    constructor(key) {
        this._key = key;
    }
    async verify(data, sig) {
        return await hashAndVerify$2(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix(this._key);
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.RSA,
            Data: this.marshal()
        }).subarray();
    }
    encrypt(bytes) {
        return encrypt(this._key, bytes);
    }
    equals(key) {
        return equals$2(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
}
class RsaPrivateKey {
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes(16);
    }
    async sign(message) {
        return await hashAndSign$2(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey(this._publicKey);
    }
    decrypt(bytes) {
        return decrypt(this._key, bytes);
    }
    marshal() {
        return jwkToPkcs1(this._key);
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$2(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$7(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected PEM format
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            const buffer = new forge$s.util.ByteBuffer(this.marshal());
            const asn1 = forge$s.asn1.fromDer(buffer);
            const privateKey = forge$s.pki.privateKeyFromAsn1(asn1);
            const options = {
                algorithm: 'aes256',
                count: 10000,
                saltSize: 128 / 8,
                prfAlgorithm: 'sha512'
            };
            return forge$s.pki.encryptRsaPrivateKey(privateKey, password, options);
        }
        else if (format === 'libp2p-key') {
            return await exporter(this.bytes, password);
        }
        else {
            throw new CodeError(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
async function unmarshalRsaPrivateKey(bytes) {
    const jwk = pkcs1ToJwk(bytes);
    const keys = await unmarshalPrivateKey$1(jwk);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey(bytes) {
    const jwk = pkixToJwk(bytes);
    return new RsaPublicKey(jwk);
}
async function fromJwk(jwk) {
    const keys = await unmarshalPrivateKey$1(jwk);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$3(bits) {
    const keys = await generateKey$2(bits);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}

var RSA = /*#__PURE__*/Object.freeze({
    __proto__: null,
    RsaPrivateKey: RsaPrivateKey,
    RsaPublicKey: RsaPublicKey,
    fromJwk: fromJwk,
    generateKeyPair: generateKeyPair$3,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey
});

/*! noble-ed25519 - MIT License (c) 2019 Paul Miller (paulmillr.com) */
const _0n = BigInt(0);
const _1n = BigInt(1);
const _2n = BigInt(2);
const _8n = BigInt(8);
const CU_O = BigInt('7237005577332262213973186563042994240857116359379907606001950938285454250989');
const CURVE = Object.freeze({
    a: BigInt(-1),
    d: BigInt('37095705934669439343138083508754565189542113879843219016388785533085940283555'),
    P: BigInt('57896044618658097711785492504343953926634992332820282019728792003956564819949'),
    l: CU_O,
    n: CU_O,
    h: BigInt(8),
    Gx: BigInt('15112221349535400772501151409588531511454012693041857206046113283949847762202'),
    Gy: BigInt('46316835694926478169428394003475163141307993866256225615783033603165251855960'),
});
const POW_2_256 = BigInt('0x10000000000000000000000000000000000000000000000000000000000000000');
const SQRT_M1 = BigInt('19681161376707505956807079304988542015446066515923890162744021073123829784752');
BigInt('6853475219497561581579357271197624642482790079785650197046958215289687604742');
const SQRT_AD_MINUS_ONE = BigInt('25063068953384623474111414158702152701244531502492656460079210482610430750235');
const INVSQRT_A_MINUS_D = BigInt('54469307008909316920995813868745141605393597292927456921205312896311721017578');
const ONE_MINUS_D_SQ = BigInt('1159843021668779879193775521855586647937357759715417654439879720876111806838');
const D_MINUS_ONE_SQ = BigInt('40440834346308536858101042469323190826248399146238708352240133220865137265952');
class ExtendedPoint {
    constructor(x, y, z, t) {
        this.x = x;
        this.y = y;
        this.z = z;
        this.t = t;
    }
    static fromAffine(p) {
        if (!(p instanceof Point)) {
            throw new TypeError('ExtendedPoint#fromAffine: expected Point');
        }
        if (p.equals(Point.ZERO))
            return ExtendedPoint.ZERO;
        return new ExtendedPoint(p.x, p.y, _1n, mod(p.x * p.y));
    }
    static toAffineBatch(points) {
        const toInv = invertBatch(points.map((p) => p.z));
        return points.map((p, i) => p.toAffine(toInv[i]));
    }
    static normalizeZ(points) {
        return this.toAffineBatch(points).map(this.fromAffine);
    }
    equals(other) {
        assertExtPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        const X1Z2 = mod(X1 * Z2);
        const X2Z1 = mod(X2 * Z1);
        const Y1Z2 = mod(Y1 * Z2);
        const Y2Z1 = mod(Y2 * Z1);
        return X1Z2 === X2Z1 && Y1Z2 === Y2Z1;
    }
    negate() {
        return new ExtendedPoint(mod(-this.x), this.y, this.z, mod(-this.t));
    }
    double() {
        const { x: X1, y: Y1, z: Z1 } = this;
        const { a } = CURVE;
        const A = mod(X1 * X1);
        const B = mod(Y1 * Y1);
        const C = mod(_2n * mod(Z1 * Z1));
        const D = mod(a * A);
        const x1y1 = X1 + Y1;
        const E = mod(mod(x1y1 * x1y1) - A - B);
        const G = D + B;
        const F = G - C;
        const H = D - B;
        const X3 = mod(E * F);
        const Y3 = mod(G * H);
        const T3 = mod(E * H);
        const Z3 = mod(F * G);
        return new ExtendedPoint(X3, Y3, Z3, T3);
    }
    add(other) {
        assertExtPoint(other);
        const { x: X1, y: Y1, z: Z1, t: T1 } = this;
        const { x: X2, y: Y2, z: Z2, t: T2 } = other;
        const A = mod((Y1 - X1) * (Y2 + X2));
        const B = mod((Y1 + X1) * (Y2 - X2));
        const F = mod(B - A);
        if (F === _0n)
            return this.double();
        const C = mod(Z1 * _2n * T2);
        const D = mod(T1 * _2n * Z2);
        const E = D + C;
        const G = B + A;
        const H = D - C;
        const X3 = mod(E * F);
        const Y3 = mod(G * H);
        const T3 = mod(E * H);
        const Z3 = mod(F * G);
        return new ExtendedPoint(X3, Y3, Z3, T3);
    }
    subtract(other) {
        return this.add(other.negate());
    }
    precomputeWindow(W) {
        const windows = 1 + 256 / W;
        const points = [];
        let p = this;
        let base = p;
        for (let window = 0; window < windows; window++) {
            base = p;
            points.push(base);
            for (let i = 1; i < 2 ** (W - 1); i++) {
                base = base.add(p);
                points.push(base);
            }
            p = base.double();
        }
        return points;
    }
    wNAF(n, affinePoint) {
        if (!affinePoint && this.equals(ExtendedPoint.BASE))
            affinePoint = Point.BASE;
        const W = (affinePoint && affinePoint._WINDOW_SIZE) || 1;
        if (256 % W) {
            throw new Error('Point#wNAF: Invalid precomputation window, must be power of 2');
        }
        let precomputes = affinePoint && pointPrecomputes.get(affinePoint);
        if (!precomputes) {
            precomputes = this.precomputeWindow(W);
            if (affinePoint && W !== 1) {
                precomputes = ExtendedPoint.normalizeZ(precomputes);
                pointPrecomputes.set(affinePoint, precomputes);
            }
        }
        let p = ExtendedPoint.ZERO;
        let f = ExtendedPoint.BASE;
        const windows = 1 + 256 / W;
        const windowSize = 2 ** (W - 1);
        const mask = BigInt(2 ** W - 1);
        const maxNumber = 2 ** W;
        const shiftBy = BigInt(W);
        for (let window = 0; window < windows; window++) {
            const offset = window * windowSize;
            let wbits = Number(n & mask);
            n >>= shiftBy;
            if (wbits > windowSize) {
                wbits -= maxNumber;
                n += _1n;
            }
            const offset1 = offset;
            const offset2 = offset + Math.abs(wbits) - 1;
            const cond1 = window % 2 !== 0;
            const cond2 = wbits < 0;
            if (wbits === 0) {
                f = f.add(constTimeNegate(cond1, precomputes[offset1]));
            }
            else {
                p = p.add(constTimeNegate(cond2, precomputes[offset2]));
            }
        }
        return ExtendedPoint.normalizeZ([p, f])[0];
    }
    multiply(scalar, affinePoint) {
        return this.wNAF(normalizeScalar(scalar, CURVE.l), affinePoint);
    }
    multiplyUnsafe(scalar) {
        let n = normalizeScalar(scalar, CURVE.l, false);
        const G = ExtendedPoint.BASE;
        const P0 = ExtendedPoint.ZERO;
        if (n === _0n)
            return P0;
        if (this.equals(P0) || n === _1n)
            return this;
        if (this.equals(G))
            return this.wNAF(n);
        let p = P0;
        let d = this;
        while (n > _0n) {
            if (n & _1n)
                p = p.add(d);
            d = d.double();
            n >>= _1n;
        }
        return p;
    }
    isSmallOrder() {
        return this.multiplyUnsafe(CURVE.h).equals(ExtendedPoint.ZERO);
    }
    isTorsionFree() {
        let p = this.multiplyUnsafe(CURVE.l / _2n).double();
        if (CURVE.l % _2n)
            p = p.add(this);
        return p.equals(ExtendedPoint.ZERO);
    }
    toAffine(invZ) {
        const { x, y, z } = this;
        const is0 = this.equals(ExtendedPoint.ZERO);
        if (invZ == null)
            invZ = is0 ? _8n : invert(z);
        const ax = mod(x * invZ);
        const ay = mod(y * invZ);
        const zz = mod(z * invZ);
        if (is0)
            return Point.ZERO;
        if (zz !== _1n)
            throw new Error('invZ was invalid');
        return new Point(ax, ay);
    }
    fromRistrettoBytes() {
        legacyRist();
    }
    toRistrettoBytes() {
        legacyRist();
    }
    fromRistrettoHash() {
        legacyRist();
    }
}
ExtendedPoint.BASE = new ExtendedPoint(CURVE.Gx, CURVE.Gy, _1n, mod(CURVE.Gx * CURVE.Gy));
ExtendedPoint.ZERO = new ExtendedPoint(_0n, _1n, _1n, _0n);
function constTimeNegate(condition, item) {
    const neg = item.negate();
    return condition ? neg : item;
}
function assertExtPoint(other) {
    if (!(other instanceof ExtendedPoint))
        throw new TypeError('ExtendedPoint expected');
}
function assertRstPoint(other) {
    if (!(other instanceof RistrettoPoint))
        throw new TypeError('RistrettoPoint expected');
}
function legacyRist() {
    throw new Error('Legacy method: switch to RistrettoPoint');
}
class RistrettoPoint {
    constructor(ep) {
        this.ep = ep;
    }
    static calcElligatorRistrettoMap(r0) {
        const { d } = CURVE;
        const r = mod(SQRT_M1 * r0 * r0);
        const Ns = mod((r + _1n) * ONE_MINUS_D_SQ);
        let c = BigInt(-1);
        const D = mod((c - d * r) * mod(r + d));
        let { isValid: Ns_D_is_sq, value: s } = uvRatio(Ns, D);
        let s_ = mod(s * r0);
        if (!edIsNegative(s_))
            s_ = mod(-s_);
        if (!Ns_D_is_sq)
            s = s_;
        if (!Ns_D_is_sq)
            c = r;
        const Nt = mod(c * (r - _1n) * D_MINUS_ONE_SQ - D);
        const s2 = s * s;
        const W0 = mod((s + s) * D);
        const W1 = mod(Nt * SQRT_AD_MINUS_ONE);
        const W2 = mod(_1n - s2);
        const W3 = mod(_1n + s2);
        return new ExtendedPoint(mod(W0 * W3), mod(W2 * W1), mod(W1 * W3), mod(W0 * W2));
    }
    static hashToCurve(hex) {
        hex = ensureBytes(hex, 64);
        const r1 = bytes255ToNumberLE(hex.slice(0, 32));
        const R1 = this.calcElligatorRistrettoMap(r1);
        const r2 = bytes255ToNumberLE(hex.slice(32, 64));
        const R2 = this.calcElligatorRistrettoMap(r2);
        return new RistrettoPoint(R1.add(R2));
    }
    static fromHex(hex) {
        hex = ensureBytes(hex, 32);
        const { a, d } = CURVE;
        const emsg = 'RistrettoPoint.fromHex: the hex is not valid encoding of RistrettoPoint';
        const s = bytes255ToNumberLE(hex);
        if (!equalBytes(numberTo32BytesLE(s), hex) || edIsNegative(s))
            throw new Error(emsg);
        const s2 = mod(s * s);
        const u1 = mod(_1n + a * s2);
        const u2 = mod(_1n - a * s2);
        const u1_2 = mod(u1 * u1);
        const u2_2 = mod(u2 * u2);
        const v = mod(a * d * u1_2 - u2_2);
        const { isValid, value: I } = invertSqrt(mod(v * u2_2));
        const Dx = mod(I * u2);
        const Dy = mod(I * Dx * v);
        let x = mod((s + s) * Dx);
        if (edIsNegative(x))
            x = mod(-x);
        const y = mod(u1 * Dy);
        const t = mod(x * y);
        if (!isValid || edIsNegative(t) || y === _0n)
            throw new Error(emsg);
        return new RistrettoPoint(new ExtendedPoint(x, y, _1n, t));
    }
    toRawBytes() {
        let { x, y, z, t } = this.ep;
        const u1 = mod(mod(z + y) * mod(z - y));
        const u2 = mod(x * y);
        const u2sq = mod(u2 * u2);
        const { value: invsqrt } = invertSqrt(mod(u1 * u2sq));
        const D1 = mod(invsqrt * u1);
        const D2 = mod(invsqrt * u2);
        const zInv = mod(D1 * D2 * t);
        let D;
        if (edIsNegative(t * zInv)) {
            let _x = mod(y * SQRT_M1);
            let _y = mod(x * SQRT_M1);
            x = _x;
            y = _y;
            D = mod(D1 * INVSQRT_A_MINUS_D);
        }
        else {
            D = D2;
        }
        if (edIsNegative(x * zInv))
            y = mod(-y);
        let s = mod((z - y) * D);
        if (edIsNegative(s))
            s = mod(-s);
        return numberTo32BytesLE(s);
    }
    toHex() {
        return bytesToHex$1(this.toRawBytes());
    }
    toString() {
        return this.toHex();
    }
    equals(other) {
        assertRstPoint(other);
        const a = this.ep;
        const b = other.ep;
        const one = mod(a.x * b.y) === mod(a.y * b.x);
        const two = mod(a.y * b.y) === mod(a.x * b.x);
        return one || two;
    }
    add(other) {
        assertRstPoint(other);
        return new RistrettoPoint(this.ep.add(other.ep));
    }
    subtract(other) {
        assertRstPoint(other);
        return new RistrettoPoint(this.ep.subtract(other.ep));
    }
    multiply(scalar) {
        return new RistrettoPoint(this.ep.multiply(scalar));
    }
    multiplyUnsafe(scalar) {
        return new RistrettoPoint(this.ep.multiplyUnsafe(scalar));
    }
}
RistrettoPoint.BASE = new RistrettoPoint(ExtendedPoint.BASE);
RistrettoPoint.ZERO = new RistrettoPoint(ExtendedPoint.ZERO);
const pointPrecomputes = new WeakMap();
class Point {
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }
    _setWindowSize(windowSize) {
        this._WINDOW_SIZE = windowSize;
        pointPrecomputes.delete(this);
    }
    static fromHex(hex, strict = true) {
        const { d, P } = CURVE;
        hex = ensureBytes(hex, 32);
        const normed = hex.slice();
        normed[31] = hex[31] & ~0x80;
        const y = bytesToNumberLE(normed);
        if (strict && y >= P)
            throw new Error('Expected 0 < hex < P');
        if (!strict && y >= POW_2_256)
            throw new Error('Expected 0 < hex < 2**256');
        const y2 = mod(y * y);
        const u = mod(y2 - _1n);
        const v = mod(d * y2 + _1n);
        let { isValid, value: x } = uvRatio(u, v);
        if (!isValid)
            throw new Error('Point.fromHex: invalid y coordinate');
        const isXOdd = (x & _1n) === _1n;
        const isLastByteOdd = (hex[31] & 0x80) !== 0;
        if (isLastByteOdd !== isXOdd) {
            x = mod(-x);
        }
        return new Point(x, y);
    }
    static async fromPrivateKey(privateKey) {
        return (await getExtendedPublicKey(privateKey)).point;
    }
    toRawBytes() {
        const bytes = numberTo32BytesLE(this.y);
        bytes[31] |= this.x & _1n ? 0x80 : 0;
        return bytes;
    }
    toHex() {
        return bytesToHex$1(this.toRawBytes());
    }
    toX25519() {
        const { y } = this;
        const u = mod((_1n + y) * invert(_1n - y));
        return numberTo32BytesLE(u);
    }
    isTorsionFree() {
        return ExtendedPoint.fromAffine(this).isTorsionFree();
    }
    equals(other) {
        return this.x === other.x && this.y === other.y;
    }
    negate() {
        return new Point(mod(-this.x), this.y);
    }
    add(other) {
        return ExtendedPoint.fromAffine(this).add(ExtendedPoint.fromAffine(other)).toAffine();
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiply(scalar) {
        return ExtendedPoint.fromAffine(this).multiply(scalar, this).toAffine();
    }
}
Point.BASE = new Point(CURVE.Gx, CURVE.Gy);
Point.ZERO = new Point(_0n, _1n);
class Signature {
    constructor(r, s) {
        this.r = r;
        this.s = s;
        this.assertValidity();
    }
    static fromHex(hex) {
        const bytes = ensureBytes(hex, 64);
        const r = Point.fromHex(bytes.slice(0, 32), false);
        const s = bytesToNumberLE(bytes.slice(32, 64));
        return new Signature(r, s);
    }
    assertValidity() {
        const { r, s } = this;
        if (!(r instanceof Point))
            throw new Error('Expected Point instance');
        normalizeScalar(s, CURVE.l, false);
        return this;
    }
    toRawBytes() {
        const u8 = new Uint8Array(64);
        u8.set(this.r.toRawBytes());
        u8.set(numberTo32BytesLE(this.s), 32);
        return u8;
    }
    toHex() {
        return bytesToHex$1(this.toRawBytes());
    }
}
function concatBytes(...arrays) {
    if (!arrays.every((a) => a instanceof Uint8Array))
        throw new Error('Expected Uint8Array list');
    if (arrays.length === 1)
        return arrays[0];
    const length = arrays.reduce((a, arr) => a + arr.length, 0);
    const result = new Uint8Array(length);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const arr = arrays[i];
        result.set(arr, pad);
        pad += arr.length;
    }
    return result;
}
const hexes = Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, '0'));
function bytesToHex$1(uint8a) {
    if (!(uint8a instanceof Uint8Array))
        throw new Error('Uint8Array expected');
    let hex = '';
    for (let i = 0; i < uint8a.length; i++) {
        hex += hexes[uint8a[i]];
    }
    return hex;
}
function hexToBytes$1(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToBytes: expected string, got ' + typeof hex);
    }
    if (hex.length % 2)
        throw new Error('hexToBytes: received invalid unpadded hex');
    const array = new Uint8Array(hex.length / 2);
    for (let i = 0; i < array.length; i++) {
        const j = i * 2;
        const hexByte = hex.slice(j, j + 2);
        const byte = Number.parseInt(hexByte, 16);
        if (Number.isNaN(byte) || byte < 0)
            throw new Error('Invalid byte sequence');
        array[i] = byte;
    }
    return array;
}
function numberTo32BytesBE(num) {
    const length = 32;
    const hex = num.toString(16).padStart(length * 2, '0');
    return hexToBytes$1(hex);
}
function numberTo32BytesLE(num) {
    return numberTo32BytesBE(num).reverse();
}
function edIsNegative(num) {
    return (mod(num) & _1n) === _1n;
}
function bytesToNumberLE(uint8a) {
    if (!(uint8a instanceof Uint8Array))
        throw new Error('Expected Uint8Array');
    return BigInt('0x' + bytesToHex$1(Uint8Array.from(uint8a).reverse()));
}
const MAX_255B = BigInt('0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff');
function bytes255ToNumberLE(bytes) {
    return mod(bytesToNumberLE(bytes) & MAX_255B);
}
function mod(a, b = CURVE.P) {
    const res = a % b;
    return res >= _0n ? res : b + res;
}
function invert(number, modulo = CURVE.P) {
    if (number === _0n || modulo <= _0n) {
        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);
    }
    let a = mod(number, modulo);
    let b = modulo;
    let x = _0n, u = _1n;
    while (a !== _0n) {
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n)
        throw new Error('invert: does not exist');
    return mod(x, modulo);
}
function invertBatch(nums, p = CURVE.P) {
    const tmp = new Array(nums.length);
    const lastMultiplied = nums.reduce((acc, num, i) => {
        if (num === _0n)
            return acc;
        tmp[i] = acc;
        return mod(acc * num, p);
    }, _1n);
    const inverted = invert(lastMultiplied, p);
    nums.reduceRight((acc, num, i) => {
        if (num === _0n)
            return acc;
        tmp[i] = mod(acc * tmp[i], p);
        return mod(acc * num, p);
    }, inverted);
    return tmp;
}
function pow2(x, power) {
    const { P } = CURVE;
    let res = x;
    while (power-- > _0n) {
        res *= res;
        res %= P;
    }
    return res;
}
function pow_2_252_3(x) {
    const { P } = CURVE;
    const _5n = BigInt(5);
    const _10n = BigInt(10);
    const _20n = BigInt(20);
    const _40n = BigInt(40);
    const _80n = BigInt(80);
    const x2 = (x * x) % P;
    const b2 = (x2 * x) % P;
    const b4 = (pow2(b2, _2n) * b2) % P;
    const b5 = (pow2(b4, _1n) * x) % P;
    const b10 = (pow2(b5, _5n) * b5) % P;
    const b20 = (pow2(b10, _10n) * b10) % P;
    const b40 = (pow2(b20, _20n) * b20) % P;
    const b80 = (pow2(b40, _40n) * b40) % P;
    const b160 = (pow2(b80, _80n) * b80) % P;
    const b240 = (pow2(b160, _80n) * b80) % P;
    const b250 = (pow2(b240, _10n) * b10) % P;
    const pow_p_5_8 = (pow2(b250, _2n) * x) % P;
    return { pow_p_5_8, b2 };
}
function uvRatio(u, v) {
    const v3 = mod(v * v * v);
    const v7 = mod(v3 * v3 * v);
    const pow = pow_2_252_3(u * v7).pow_p_5_8;
    let x = mod(u * v3 * pow);
    const vx2 = mod(v * x * x);
    const root1 = x;
    const root2 = mod(x * SQRT_M1);
    const useRoot1 = vx2 === u;
    const useRoot2 = vx2 === mod(-u);
    const noRoot = vx2 === mod(-u * SQRT_M1);
    if (useRoot1)
        x = root1;
    if (useRoot2 || noRoot)
        x = root2;
    if (edIsNegative(x))
        x = mod(-x);
    return { isValid: useRoot1 || useRoot2, value: x };
}
function invertSqrt(number) {
    return uvRatio(_1n, number);
}
function modlLE(hash) {
    return mod(bytesToNumberLE(hash), CURVE.l);
}
function equalBytes(b1, b2) {
    if (b1.length !== b2.length) {
        return false;
    }
    for (let i = 0; i < b1.length; i++) {
        if (b1[i] !== b2[i]) {
            return false;
        }
    }
    return true;
}
function ensureBytes(hex, expectedLength) {
    const bytes = hex instanceof Uint8Array ? Uint8Array.from(hex) : hexToBytes$1(hex);
    if (typeof expectedLength === 'number' && bytes.length !== expectedLength)
        throw new Error(`Expected ${expectedLength} bytes`);
    return bytes;
}
function normalizeScalar(num, max, strict = true) {
    if (!max)
        throw new TypeError('Specify max value');
    if (typeof num === 'number' && Number.isSafeInteger(num))
        num = BigInt(num);
    if (typeof num === 'bigint' && num < max) {
        if (strict) {
            if (_0n < num)
                return num;
        }
        else {
            if (_0n <= num)
                return num;
        }
    }
    throw new TypeError('Expected valid scalar: 0 < scalar < max');
}
function adjustBytes25519(bytes) {
    bytes[0] &= 248;
    bytes[31] &= 127;
    bytes[31] |= 64;
    return bytes;
}
function checkPrivateKey(key) {
    key =
        typeof key === 'bigint' || typeof key === 'number'
            ? numberTo32BytesBE(normalizeScalar(key, POW_2_256))
            : ensureBytes(key);
    if (key.length !== 32)
        throw new Error(`Expected 32 bytes`);
    return key;
}
function getKeyFromHash(hashed) {
    const head = adjustBytes25519(hashed.slice(0, 32));
    const prefix = hashed.slice(32, 64);
    const scalar = modlLE(head);
    const point = Point.BASE.multiply(scalar);
    const pointBytes = point.toRawBytes();
    return { head, prefix, scalar, point, pointBytes };
}
let _sha512Sync;
async function getExtendedPublicKey(key) {
    return getKeyFromHash(await utils.sha512(checkPrivateKey(key)));
}
async function getPublicKey(privateKey) {
    return (await getExtendedPublicKey(privateKey)).pointBytes;
}
async function sign$1(message, privateKey) {
    message = ensureBytes(message);
    const { prefix, scalar, pointBytes } = await getExtendedPublicKey(privateKey);
    const r = modlLE(await utils.sha512(prefix, message));
    const R = Point.BASE.multiply(r);
    const k = modlLE(await utils.sha512(R.toRawBytes(), pointBytes, message));
    const s = mod(r + k * scalar, CURVE.l);
    return new Signature(R, s).toRawBytes();
}
function prepareVerification(sig, message, publicKey) {
    message = ensureBytes(message);
    if (!(publicKey instanceof Point))
        publicKey = Point.fromHex(publicKey, false);
    const { r, s } = sig instanceof Signature ? sig.assertValidity() : Signature.fromHex(sig);
    const SB = ExtendedPoint.BASE.multiplyUnsafe(s);
    return { r, s, SB, pub: publicKey, msg: message };
}
function finishVerification(publicKey, r, SB, hashed) {
    const k = modlLE(hashed);
    const kA = ExtendedPoint.fromAffine(publicKey).multiplyUnsafe(k);
    const RkA = ExtendedPoint.fromAffine(r).add(kA);
    return RkA.subtract(SB).multiplyUnsafe(CURVE.h).equals(ExtendedPoint.ZERO);
}
async function verify(sig, message, publicKey) {
    const { r, SB, msg, pub } = prepareVerification(sig, message, publicKey);
    const hashed = await utils.sha512(r.toRawBytes(), pub.toRawBytes(), msg);
    return finishVerification(pub, r, SB, hashed);
}
Point.BASE._setWindowSize(8);
const crypto$2 = {
    node: nodeCrypto,
    web: typeof self === 'object' && 'crypto' in self ? self.crypto : undefined,
};
const utils = {
    bytesToHex: bytesToHex$1,
    hexToBytes: hexToBytes$1,
    concatBytes,
    getExtendedPublicKey,
    mod,
    invert,
    TORSION_SUBGROUP: [
        '0100000000000000000000000000000000000000000000000000000000000000',
        'c7176a703d4dd84fba3c0b760d10670f2a2053fa2c39ccc64ec7fd7792ac037a',
        '0000000000000000000000000000000000000000000000000000000000000080',
        '26e8958fc2b227b045c3f489f2ef98f0d5dfac05d3c63339b13802886d53fc05',
        'ecffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff7f',
        '26e8958fc2b227b045c3f489f2ef98f0d5dfac05d3c63339b13802886d53fc85',
        '0000000000000000000000000000000000000000000000000000000000000000',
        'c7176a703d4dd84fba3c0b760d10670f2a2053fa2c39ccc64ec7fd7792ac03fa',
    ],
    hashToPrivateScalar: (hash) => {
        hash = ensureBytes(hash);
        if (hash.length < 40 || hash.length > 1024)
            throw new Error('Expected 40-1024 bytes of private key as per FIPS 186');
        return mod(bytesToNumberLE(hash), CURVE.l - _1n) + _1n;
    },
    randomBytes: (bytesLength = 32) => {
        if (crypto$2.web) {
            return crypto$2.web.getRandomValues(new Uint8Array(bytesLength));
        }
        else if (crypto$2.node) {
            const { randomBytes } = crypto$2.node;
            return new Uint8Array(randomBytes(bytesLength).buffer);
        }
        else {
            throw new Error("The environment doesn't have randomBytes function");
        }
    },
    randomPrivateKey: () => {
        return utils.randomBytes(32);
    },
    sha512: async (...messages) => {
        const message = concatBytes(...messages);
        if (crypto$2.web) {
            const buffer = await crypto$2.web.subtle.digest('SHA-512', message.buffer);
            return new Uint8Array(buffer);
        }
        else if (crypto$2.node) {
            return Uint8Array.from(crypto$2.node.createHash('sha512').update(message).digest());
        }
        else {
            throw new Error("The environment doesn't have sha512 function");
        }
    },
    precompute(windowSize = 8, point = Point.BASE) {
        const cached = point.equals(Point.BASE) ? point : new Point(point.x, point.y);
        cached._setWindowSize(windowSize);
        cached.multiply(_2n);
        return cached;
    },
    sha512Sync: undefined,
};
Object.defineProperties(utils, {
    sha512Sync: {
        configurable: false,
        get() {
            return _sha512Sync;
        },
        set(val) {
            if (!_sha512Sync)
                _sha512Sync = val;
        },
    },
});

const PUBLIC_KEY_BYTE_LENGTH = 32;
const PRIVATE_KEY_BYTE_LENGTH = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH = 32;
async function generateKey$1() {
    // the actual private key (32 bytes)
    const privateKeyRaw = utils.randomPrivateKey();
    const publicKey = await getPublicKey(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
async function generateKeyFromSeed(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = await getPublicKey(privateKeyRaw);
    const privateKey = concatKeys(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSign$1(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH);
    return await sign$1(msg, privateKeyRaw);
}
async function hashAndVerify$1(publicKey, sig, msg) {
    return await verify(sig, msg, publicKey);
}
function concatKeys(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH);
    for (let i = 0; i < KEYS_BYTE_LENGTH; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH + i] = publicKey[i];
    }
    return privateKey;
}

class Ed25519PublicKey {
    constructor(key) {
        this._key = ensureKey(key, PUBLIC_KEY_BYTE_LENGTH);
    }
    async verify(data, sig) {
        return await hashAndVerify$1(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$2(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
}
class Ed25519PrivateKey {
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey(key, PRIVATE_KEY_BYTE_LENGTH);
        this._publicKey = ensureKey(publicKey, PUBLIC_KEY_BYTE_LENGTH);
    }
    async sign(message) {
        return await hashAndSign$1(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$2(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity.digest(this.public.bytes);
        return base58btc.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return await exporter(this.bytes, password);
        }
        else {
            throw new CodeError(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
function unmarshalEd25519PrivateKey(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH) {
        bytes = ensureKey(bytes, PRIVATE_KEY_BYTE_LENGTH + PUBLIC_KEY_BYTE_LENGTH);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH, bytes.length);
        return new Ed25519PrivateKey(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey(bytes, PRIVATE_KEY_BYTE_LENGTH);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH);
    return new Ed25519PrivateKey(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey(bytes) {
    bytes = ensureKey(bytes, PUBLIC_KEY_BYTE_LENGTH);
    return new Ed25519PublicKey(bytes);
}
async function generateKeyPair$2() {
    const { privateKey, publicKey } = await generateKey$1();
    return new Ed25519PrivateKey(privateKey, publicKey);
}
async function generateKeyPairFromSeed(seed) {
    const { privateKey, publicKey } = await generateKeyFromSeed(seed);
    return new Ed25519PrivateKey(privateKey, publicKey);
}
function ensureKey(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey,
    Ed25519PublicKey: Ed25519PublicKey,
    generateKeyPair: generateKeyPair$2,
    generateKeyPairFromSeed: generateKeyPairFromSeed,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey
});

function generateKey() {
    return utils$1.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
async function hashAndSign(key, msg) {
    const { digest } = await sha256.digest(msg);
    try {
        return await sign$2(digest, key);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
async function hashAndVerify(key, sig, msg) {
    try {
        const { digest } = await sha256.digest(msg);
        return verify$1(sig, digest, key);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey(key) {
    const point = Point$1.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey(key) {
    try {
        getPublicKey$1(key, true);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey(key) {
    try {
        Point$1.fromHex(key);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey(privateKey) {
    try {
        return getPublicKey$1(privateKey, true);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

class Secp256k1PublicKey {
    constructor(key) {
        validatePublicKey(key);
        this._key = key;
    }
    async verify(data, sig) {
        return await hashAndVerify(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey(this._key);
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$2(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
}
class Secp256k1PrivateKey {
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey(key);
        validatePrivateKey(this._key);
        validatePublicKey(this._publicKey);
    }
    async sign(message) {
        return await hashAndSign(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$2(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$7(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return await exporter(this.bytes, password);
        }
        else {
            throw new CodeError(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
function unmarshalSecp256k1PrivateKey(bytes) {
    return new Secp256k1PrivateKey(bytes);
}
function unmarshalSecp256k1PublicKey(bytes) {
    return new Secp256k1PublicKey(bytes);
}
async function generateKeyPair$1() {
    const privateKeyBytes = generateKey();
    return new Secp256k1PrivateKey(privateKeyBytes);
}

var Secp256k1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey,
    Secp256k1PublicKey: Secp256k1PublicKey,
    generateKeyPair: generateKeyPair$1,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey
});

const supportedKeys = {
    rsa: RSA,
    ed25519: Ed25519,
    secp256k1: Secp256k1
};
function unsupportedKey(type) {
    const supported = Object.keys(supportedKeys).join(' / ');
    return new CodeError(`invalid or unsupported key type ${type}. Must be ${supported}`, 'ERR_UNSUPPORTED_KEY_TYPE');
}
function typeToKey(type) {
    type = type.toLowerCase();
    if (type === 'rsa' || type === 'ed25519' || type === 'secp256k1') {
        return supportedKeys[type];
    }
    throw unsupportedKey(type);
}
// Generates a keypair of the given type and bitsize
async function generateKeyPair(type, bits) {
    return await typeToKey(type).generateKeyPair(bits ?? 2048);
}
// Converts a protobuf serialized public key into its
// representative object
function unmarshalPublicKey(buf) {
    const decoded = PublicKey.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType.RSA:
            return supportedKeys.rsa.unmarshalRsaPublicKey(data);
        case KeyType.Ed25519:
            return supportedKeys.ed25519.unmarshalEd25519PublicKey(data);
        case KeyType.Secp256k1:
            return supportedKeys.secp256k1.unmarshalSecp256k1PublicKey(data);
        default:
            throw unsupportedKey(decoded.Type ?? 'RSA');
    }
}
// Converts a public key object into a protobuf serialized public key
function marshalPublicKey(key, type) {
    type = (type ?? 'rsa').toLowerCase();
    typeToKey(type); // check type
    return key.bytes;
}
// Converts a protobuf serialized private key into its
// representative object
async function unmarshalPrivateKey(buf) {
    const decoded = PrivateKey.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType.RSA:
            return await supportedKeys.rsa.unmarshalRsaPrivateKey(data);
        case KeyType.Ed25519:
            return supportedKeys.ed25519.unmarshalEd25519PrivateKey(data);
        case KeyType.Secp256k1:
            return supportedKeys.secp256k1.unmarshalSecp256k1PrivateKey(data);
        default:
            throw unsupportedKey(decoded.Type ?? 'RSA');
    }
}
// Converts a private key object into a protobuf serialized private key
function marshalPrivateKey(key, type) {
    type = (type ?? 'rsa').toLowerCase();
    typeToKey(type); // check type
    return key.bytes;
}
/**
 *
 * @param {string} encryptedKey
 * @param {string} password
 */
async function importKey(encryptedKey, password) {
    try {
        const key = await importer(encryptedKey, password);
        return await unmarshalPrivateKey(key);
    }
    catch (_) {
        // Ignore and try the old pem decrypt
    }
    // Only rsa supports pem right now
    const key = forge$s.pki.decryptRsaPrivateKey(encryptedKey, password);
    if (key === null) {
        throw new CodeError('Cannot read the key, most likely the password is wrong or not a RSA key', 'ERR_CANNOT_DECRYPT_PEM');
    }
    let der = forge$s.asn1.toDer(forge$s.pki.privateKeyToAsn1(key));
    der = fromString$2(der.getBytes(), 'ascii');
    return await supportedKeys.rsa.unmarshalRsaPrivateKey(der);
}

const symbol$5 = Symbol.for('@libp2p/peer-id');
function isPeerId(other) {
    return other != null && Boolean(other[symbol$5]);
}

const inspect$2 = Symbol.for('nodejs.util.inspect.custom');
const baseDecoder = Object
    .values(bases)
    .map(codec => codec.decoder)
    // @ts-expect-error https://github.com/multiformats/js-multiformats/issues/141
    .reduce((acc, curr) => acc.or(curr), bases.identity.decoder);
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const LIBP2P_KEY_CODE = 0x72;
const MARSHALLED_ED225519_PUBLIC_KEY_LENGTH = 36;
const MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH = 37;
class PeerIdImpl {
    constructor(init) {
        this.type = init.type;
        this.multihash = init.multihash;
        this.privateKey = init.privateKey;
        // mark string cache as non-enumerable
        Object.defineProperty(this, 'string', {
            enumerable: false,
            writable: true
        });
    }
    get [Symbol.toStringTag]() {
        return `PeerId(${this.toString()})`;
    }
    get [symbol$5]() {
        return true;
    }
    toString() {
        if (this.string == null) {
            this.string = base58btc.encode(this.multihash.bytes).slice(1);
        }
        return this.string;
    }
    // return self-describing String representation
    // in default format from RFC 0001: https://github.com/libp2p/specs/pull/209
    toCID() {
        return CID.createV1(LIBP2P_KEY_CODE, this.multihash);
    }
    toBytes() {
        return this.multihash.bytes;
    }
    /**
     * Returns Multiaddr as a JSON string
     */
    toJSON() {
        return this.toString();
    }
    /**
     * Checks the equality of `this` peer against a given PeerId
     */
    equals(id) {
        if (id instanceof Uint8Array) {
            return equals$2(this.multihash.bytes, id);
        }
        else if (typeof id === 'string') {
            return peerIdFromString(id).equals(this);
        }
        else if (id?.multihash?.bytes != null) {
            return equals$2(this.multihash.bytes, id.multihash.bytes);
        }
        else {
            throw new Error('not valid Id');
        }
    }
    /**
     * Returns PeerId as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { peerIdFromString } from '@libp2p/peer-id'
     *
     * console.info(peerIdFromString('QmFoo'))
     * // 'PeerId(QmFoo)'
     * ```
     */
    [inspect$2]() {
        return `PeerId(${this.toString()})`;
    }
}
class RSAPeerIdImpl extends PeerIdImpl {
    constructor(init) {
        super({ ...init, type: 'RSA' });
        this.type = 'RSA';
        this.publicKey = init.publicKey;
    }
}
class Ed25519PeerIdImpl extends PeerIdImpl {
    constructor(init) {
        super({ ...init, type: 'Ed25519' });
        this.type = 'Ed25519';
        this.publicKey = init.multihash.digest;
    }
}
class Secp256k1PeerIdImpl extends PeerIdImpl {
    constructor(init) {
        super({ ...init, type: 'secp256k1' });
        this.type = 'secp256k1';
        this.publicKey = init.multihash.digest;
    }
}
function peerIdFromPeerId(other) {
    if (other.type === 'RSA') {
        return new RSAPeerIdImpl(other);
    }
    if (other.type === 'Ed25519') {
        return new Ed25519PeerIdImpl(other);
    }
    if (other.type === 'secp256k1') {
        return new Secp256k1PeerIdImpl(other);
    }
    throw new CodeError('Not a PeerId', 'ERR_INVALID_PARAMETERS');
}
function peerIdFromString(str, decoder) {
    if (str.charAt(0) === '1' || str.charAt(0) === 'Q') {
        // identity hash ed25519/secp256k1 key or sha2-256 hash of
        // rsa public key - base58btc encoded either way
        const multihash = decode$5(base58btc.decode(`z${str}`));
        if (str.startsWith('12D')) {
            return new Ed25519PeerIdImpl({ multihash });
        }
        else if (str.startsWith('16U')) {
            return new Secp256k1PeerIdImpl({ multihash });
        }
        else {
            return new RSAPeerIdImpl({ multihash });
        }
    }
    return peerIdFromBytes(baseDecoder.decode(str));
}
function peerIdFromBytes(buf) {
    try {
        const multihash = decode$5(buf);
        if (multihash.code === identity.code) {
            if (multihash.digest.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
                return new Ed25519PeerIdImpl({ multihash });
            }
            else if (multihash.digest.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
                return new Secp256k1PeerIdImpl({ multihash });
            }
        }
        if (multihash.code === sha256.code) {
            return new RSAPeerIdImpl({ multihash });
        }
    }
    catch {
        return peerIdFromCID(CID.decode(buf));
    }
    throw new Error('Supplied PeerID CID is invalid');
}
function peerIdFromCID(cid) {
    if (cid == null || cid.multihash == null || cid.version == null || (cid.version === 1 && cid.code !== LIBP2P_KEY_CODE)) {
        throw new Error('Supplied PeerID CID is invalid');
    }
    const multihash = cid.multihash;
    if (multihash.code === sha256.code) {
        return new RSAPeerIdImpl({ multihash: cid.multihash });
    }
    else if (multihash.code === identity.code) {
        if (multihash.digest.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
            return new Ed25519PeerIdImpl({ multihash: cid.multihash });
        }
        else if (multihash.digest.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
            return new Secp256k1PeerIdImpl({ multihash: cid.multihash });
        }
    }
    throw new Error('Supplied PeerID CID is invalid');
}
/**
 * @param publicKey - A marshalled public key
 * @param privateKey - A marshalled private key
 */
async function peerIdFromKeys(publicKey, privateKey) {
    if (publicKey.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
        return new Ed25519PeerIdImpl({ multihash: create$d(identity.code, publicKey), privateKey });
    }
    if (publicKey.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
        return new Secp256k1PeerIdImpl({ multihash: create$d(identity.code, publicKey), privateKey });
    }
    return new RSAPeerIdImpl({ multihash: await sha256.digest(publicKey), publicKey, privateKey });
}

var minimal$6 = {};

var longbits$5;
var hasRequiredLongbits$5;

function requireLongbits$5 () {
	if (hasRequiredLongbits$5) return longbits$5;
	hasRequiredLongbits$5 = 1;
	longbits$5 = LongBits;

	var util = requireMinimal$5();

	/**
	 * Constructs new long bits.
	 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
	 * @memberof util
	 * @constructor
	 * @param {number} lo Low 32 bits, unsigned
	 * @param {number} hi High 32 bits, unsigned
	 */
	function LongBits(lo, hi) {

	    // note that the casts below are theoretically unnecessary as of today, but older statically
	    // generated converter code might still call the ctor with signed 32bits. kept for compat.

	    /**
	     * Low bits.
	     * @type {number}
	     */
	    this.lo = lo >>> 0;

	    /**
	     * High bits.
	     * @type {number}
	     */
	    this.hi = hi >>> 0;
	}

	/**
	 * Zero bits.
	 * @memberof util.LongBits
	 * @type {util.LongBits}
	 */
	var zero = LongBits.zero = new LongBits(0, 0);

	zero.toNumber = function() { return 0; };
	zero.zzEncode = zero.zzDecode = function() { return this; };
	zero.length = function() { return 1; };

	/**
	 * Zero hash.
	 * @memberof util.LongBits
	 * @type {string}
	 */
	var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

	/**
	 * Constructs new long bits from the specified number.
	 * @param {number} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.fromNumber = function fromNumber(value) {
	    if (value === 0)
	        return zero;
	    var sign = value < 0;
	    if (sign)
	        value = -value;
	    var lo = value >>> 0,
	        hi = (value - lo) / 4294967296 >>> 0;
	    if (sign) {
	        hi = ~hi >>> 0;
	        lo = ~lo >>> 0;
	        if (++lo > 4294967295) {
	            lo = 0;
	            if (++hi > 4294967295)
	                hi = 0;
	        }
	    }
	    return new LongBits(lo, hi);
	};

	/**
	 * Constructs new long bits from a number, long or string.
	 * @param {Long|number|string} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.from = function from(value) {
	    if (typeof value === "number")
	        return LongBits.fromNumber(value);
	    if (util.isString(value)) {
	        /* istanbul ignore else */
	        if (util.Long)
	            value = util.Long.fromString(value);
	        else
	            return LongBits.fromNumber(parseInt(value, 10));
	    }
	    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
	};

	/**
	 * Converts this long bits to a possibly unsafe JavaScript number.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {number} Possibly unsafe number
	 */
	LongBits.prototype.toNumber = function toNumber(unsigned) {
	    if (!unsigned && this.hi >>> 31) {
	        var lo = ~this.lo + 1 >>> 0,
	            hi = ~this.hi     >>> 0;
	        if (!lo)
	            hi = hi + 1 >>> 0;
	        return -(lo + hi * 4294967296);
	    }
	    return this.lo + this.hi * 4294967296;
	};

	/**
	 * Converts this long bits to a long.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {Long} Long
	 */
	LongBits.prototype.toLong = function toLong(unsigned) {
	    return util.Long
	        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
	        /* istanbul ignore next */
	        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
	};

	var charCodeAt = String.prototype.charCodeAt;

	/**
	 * Constructs new long bits from the specified 8 characters long hash.
	 * @param {string} hash Hash
	 * @returns {util.LongBits} Bits
	 */
	LongBits.fromHash = function fromHash(hash) {
	    if (hash === zeroHash)
	        return zero;
	    return new LongBits(
	        ( charCodeAt.call(hash, 0)
	        | charCodeAt.call(hash, 1) << 8
	        | charCodeAt.call(hash, 2) << 16
	        | charCodeAt.call(hash, 3) << 24) >>> 0
	    ,
	        ( charCodeAt.call(hash, 4)
	        | charCodeAt.call(hash, 5) << 8
	        | charCodeAt.call(hash, 6) << 16
	        | charCodeAt.call(hash, 7) << 24) >>> 0
	    );
	};

	/**
	 * Converts this long bits to a 8 characters long hash.
	 * @returns {string} Hash
	 */
	LongBits.prototype.toHash = function toHash() {
	    return String.fromCharCode(
	        this.lo        & 255,
	        this.lo >>> 8  & 255,
	        this.lo >>> 16 & 255,
	        this.lo >>> 24      ,
	        this.hi        & 255,
	        this.hi >>> 8  & 255,
	        this.hi >>> 16 & 255,
	        this.hi >>> 24
	    );
	};

	/**
	 * Zig-zag encodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzEncode = function zzEncode() {
	    var mask =   this.hi >> 31;
	    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
	    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Zig-zag decodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzDecode = function zzDecode() {
	    var mask = -(this.lo & 1);
	    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
	    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Calculates the length of this longbits when encoded as a varint.
	 * @returns {number} Length
	 */
	LongBits.prototype.length = function length() {
	    var part0 =  this.lo,
	        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
	        part2 =  this.hi >>> 24;
	    return part2 === 0
	         ? part1 === 0
	           ? part0 < 16384
	             ? part0 < 128 ? 1 : 2
	             : part0 < 2097152 ? 3 : 4
	           : part1 < 16384
	             ? part1 < 128 ? 5 : 6
	             : part1 < 2097152 ? 7 : 8
	         : part2 < 128 ? 9 : 10;
	};
	return longbits$5;
}

var hasRequiredMinimal$5;

function requireMinimal$5 () {
	if (hasRequiredMinimal$5) return minimal$6;
	hasRequiredMinimal$5 = 1;
	(function (exports) {
		var util = exports;

		// used to return a Promise where callback is omitted
		util.asPromise = aspromise;

		// converts to / from base64 encoded strings
		util.base64 = base64$9;

		// base class of rpc.Service
		util.EventEmitter = eventemitter;

		// float handling accross browsers
		util.float = float;

		// requires modules optionally and hides the call from bundlers
		util.inquire = inquire_1;

		// converts to / from utf8 encoded strings
		util.utf8 = utf8$e;

		// provides a node-like buffer pool in the browser
		util.pool = pool_1;

		// utility to work with the low and high bits of a 64 bit value
		util.LongBits = requireLongbits$5();

		/**
		 * Whether running within node or not.
		 * @memberof util
		 * @type {boolean}
		 */
		util.isNode = Boolean(typeof commonjsGlobal !== "undefined"
		                   && commonjsGlobal
		                   && commonjsGlobal.process
		                   && commonjsGlobal.process.versions
		                   && commonjsGlobal.process.versions.node);

		/**
		 * Global object reference.
		 * @memberof util
		 * @type {Object}
		 */
		util.global = util.isNode && commonjsGlobal
		           || typeof window !== "undefined" && window
		           || typeof self   !== "undefined" && self
		           || commonjsGlobal; // eslint-disable-line no-invalid-this

		/**
		 * An immuable empty array.
		 * @memberof util
		 * @type {Array.<*>}
		 * @const
		 */
		util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

		/**
		 * An immutable empty object.
		 * @type {Object}
		 * @const
		 */
		util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

		/**
		 * Tests if the specified value is an integer.
		 * @function
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is an integer
		 */
		util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
		    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
		};

		/**
		 * Tests if the specified value is a string.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a string
		 */
		util.isString = function isString(value) {
		    return typeof value === "string" || value instanceof String;
		};

		/**
		 * Tests if the specified value is a non-null object.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a non-null object
		 */
		util.isObject = function isObject(value) {
		    return value && typeof value === "object";
		};

		/**
		 * Checks if a property on a message is considered to be present.
		 * This is an alias of {@link util.isSet}.
		 * @function
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isset =

		/**
		 * Checks if a property on a message is considered to be present.
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isSet = function isSet(obj, prop) {
		    var value = obj[prop];
		    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
		        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
		    return false;
		};

		/**
		 * Any compatible Buffer instance.
		 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
		 * @interface Buffer
		 * @extends Uint8Array
		 */

		/**
		 * Node's Buffer class if available.
		 * @type {Constructor<Buffer>}
		 */
		util.Buffer = (function() {
		    try {
		        var Buffer = util.inquire("buffer").Buffer;
		        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
		        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
		    } catch (e) {
		        /* istanbul ignore next */
		        return null;
		    }
		})();

		// Internal alias of or polyfull for Buffer.from.
		util._Buffer_from = null;

		// Internal alias of or polyfill for Buffer.allocUnsafe.
		util._Buffer_allocUnsafe = null;

		/**
		 * Creates a new buffer of whatever type supported by the environment.
		 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
		 * @returns {Uint8Array|Buffer} Buffer
		 */
		util.newBuffer = function newBuffer(sizeOrArray) {
		    /* istanbul ignore next */
		    return typeof sizeOrArray === "number"
		        ? util.Buffer
		            ? util._Buffer_allocUnsafe(sizeOrArray)
		            : new util.Array(sizeOrArray)
		        : util.Buffer
		            ? util._Buffer_from(sizeOrArray)
		            : typeof Uint8Array === "undefined"
		                ? sizeOrArray
		                : new Uint8Array(sizeOrArray);
		};

		/**
		 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
		 * @type {Constructor<Uint8Array>}
		 */
		util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

		/**
		 * Any compatible Long instance.
		 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
		 * @interface Long
		 * @property {number} low Low bits
		 * @property {number} high High bits
		 * @property {boolean} unsigned Whether unsigned or not
		 */

		/**
		 * Long.js's Long class if available.
		 * @type {Constructor<Long>}
		 */
		util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
		         || /* istanbul ignore next */ util.global.Long
		         || util.inquire("long");

		/**
		 * Regular expression used to verify 2 bit (`bool`) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key2Re = /^true|false|0|1$/;

		/**
		 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

		/**
		 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

		/**
		 * Converts a number or long to an 8 characters long hash string.
		 * @param {Long|number} value Value to convert
		 * @returns {string} Hash
		 */
		util.longToHash = function longToHash(value) {
		    return value
		        ? util.LongBits.from(value).toHash()
		        : util.LongBits.zeroHash;
		};

		/**
		 * Converts an 8 characters long hash string to a long or number.
		 * @param {string} hash Hash
		 * @param {boolean} [unsigned=false] Whether unsigned or not
		 * @returns {Long|number} Original value
		 */
		util.longFromHash = function longFromHash(hash, unsigned) {
		    var bits = util.LongBits.fromHash(hash);
		    if (util.Long)
		        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
		    return bits.toNumber(Boolean(unsigned));
		};

		/**
		 * Merges the properties of the source object into the destination object.
		 * @memberof util
		 * @param {Object.<string,*>} dst Destination object
		 * @param {Object.<string,*>} src Source object
		 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
		 * @returns {Object.<string,*>} Destination object
		 */
		function merge(dst, src, ifNotSet) { // used by converters
		    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
		        if (dst[keys[i]] === undefined || !ifNotSet)
		            dst[keys[i]] = src[keys[i]];
		    return dst;
		}

		util.merge = merge;

		/**
		 * Converts the first character of a string to lower case.
		 * @param {string} str String to convert
		 * @returns {string} Converted string
		 */
		util.lcFirst = function lcFirst(str) {
		    return str.charAt(0).toLowerCase() + str.substring(1);
		};

		/**
		 * Creates a custom error constructor.
		 * @memberof util
		 * @param {string} name Error name
		 * @returns {Constructor<Error>} Custom error constructor
		 */
		function newError(name) {

		    function CustomError(message, properties) {

		        if (!(this instanceof CustomError))
		            return new CustomError(message, properties);

		        // Error.call(this, message);
		        // ^ just returns a new error instance because the ctor can be called as a function

		        Object.defineProperty(this, "message", { get: function() { return message; } });

		        /* istanbul ignore next */
		        if (Error.captureStackTrace) // node
		            Error.captureStackTrace(this, CustomError);
		        else
		            Object.defineProperty(this, "stack", { value: new Error().stack || "" });

		        if (properties)
		            merge(this, properties);
		    }

		    CustomError.prototype = Object.create(Error.prototype, {
		        constructor: {
		            value: CustomError,
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		        name: {
		            get: function get() { return name; },
		            set: undefined,
		            enumerable: false,
		            // configurable: false would accurately preserve the behavior of
		            // the original, but I'm guessing that was not intentional.
		            // For an actual error subclass, this property would
		            // be configurable.
		            configurable: true,
		        },
		        toString: {
		            value: function value() { return this.name + ": " + this.message; },
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		    });

		    return CustomError;
		}

		util.newError = newError;

		/**
		 * Constructs a new protocol error.
		 * @classdesc Error subclass indicating a protocol specifc error.
		 * @memberof util
		 * @extends Error
		 * @template T extends Message<T>
		 * @constructor
		 * @param {string} message Error message
		 * @param {Object.<string,*>} [properties] Additional properties
		 * @example
		 * try {
		 *     MyMessage.decode(someBuffer); // throws if required fields are missing
		 * } catch (e) {
		 *     if (e instanceof ProtocolError && e.instance)
		 *         console.log("decoded so far: " + JSON.stringify(e.instance));
		 * }
		 */
		util.ProtocolError = newError("ProtocolError");

		/**
		 * So far decoded message instance.
		 * @name util.ProtocolError#instance
		 * @type {Message<T>}
		 */

		/**
		 * A OneOf getter as returned by {@link util.oneOfGetter}.
		 * @typedef OneOfGetter
		 * @type {function}
		 * @returns {string|undefined} Set field name, if any
		 */

		/**
		 * Builds a getter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfGetter} Unbound getter
		 */
		util.oneOfGetter = function getOneOf(fieldNames) {
		    var fieldMap = {};
		    for (var i = 0; i < fieldNames.length; ++i)
		        fieldMap[fieldNames[i]] = 1;

		    /**
		     * @returns {string|undefined} Set field name, if any
		     * @this Object
		     * @ignore
		     */
		    return function() { // eslint-disable-line consistent-return
		        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
		            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
		                return keys[i];
		    };
		};

		/**
		 * A OneOf setter as returned by {@link util.oneOfSetter}.
		 * @typedef OneOfSetter
		 * @type {function}
		 * @param {string|undefined} value Field name
		 * @returns {undefined}
		 */

		/**
		 * Builds a setter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfSetter} Unbound setter
		 */
		util.oneOfSetter = function setOneOf(fieldNames) {

		    /**
		     * @param {string} name Field name
		     * @returns {undefined}
		     * @this Object
		     * @ignore
		     */
		    return function(name) {
		        for (var i = 0; i < fieldNames.length; ++i)
		            if (fieldNames[i] !== name)
		                delete this[fieldNames[i]];
		    };
		};

		/**
		 * Default conversion options used for {@link Message#toJSON} implementations.
		 *
		 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
		 *
		 * - Longs become strings
		 * - Enums become string keys
		 * - Bytes become base64 encoded strings
		 * - (Sub-)Messages become plain objects
		 * - Maps become plain objects with all string keys
		 * - Repeated fields become arrays
		 * - NaN and Infinity for float and double fields become strings
		 *
		 * @type {IConversionOptions}
		 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
		 */
		util.toJSONOptions = {
		    longs: String,
		    enums: String,
		    bytes: String,
		    json: true
		};

		// Sets up buffer utility according to the environment (called in index-minimal)
		util._configure = function() {
		    var Buffer = util.Buffer;
		    /* istanbul ignore if */
		    if (!Buffer) {
		        util._Buffer_from = util._Buffer_allocUnsafe = null;
		        return;
		    }
		    // because node 4.x buffers are incompatible & immutable
		    // see: https://github.com/dcodeIO/protobuf.js/pull/665
		    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
		        /* istanbul ignore next */
		        function Buffer_from(value, encoding) {
		            return new Buffer(value, encoding);
		        };
		    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
		        /* istanbul ignore next */
		        function Buffer_allocUnsafe(size) {
		            return new Buffer(size);
		        };
		};
} (minimal$6));
	return minimal$6;
}

var reader$a = Reader$b;

var util$t      = requireMinimal$5();

var BufferReader$b; // cyclic

var LongBits$b  = util$t.LongBits,
    utf8$b      = util$t.utf8;

/* istanbul ignore next */
function indexOutOfRange$5(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader$b(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array$5 = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader$b(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader$b(buffer);
        throw Error("illegal buffer");
    };

var create$b = function create() {
    return util$t.Buffer
        ? function create_buffer_setup(buffer) {
            return (Reader$b.create = function create_buffer(buffer) {
                return util$t.Buffer.isBuffer(buffer)
                    ? new BufferReader$b(buffer)
                    /* istanbul ignore next */
                    : create_array$5(buffer);
            })(buffer);
        }
        /* istanbul ignore next */
        : create_array$5;
};

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader$b.create = create$b();

Reader$b.prototype._slice = util$t.Array.prototype.subarray || /* istanbul ignore next */ util$t.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader$b.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange$5(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$b.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$b.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint$5() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits$b(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$5(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$5(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader$b.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end$5(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader$b.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$5(this, 4);

    return readFixed32_end$5(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader$b.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$5(this, 4);

    return readFixed32_end$5(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64$5(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$5(this, 8);

    return new LongBits$b(readFixed32_end$5(this.buf, this.pos += 4), readFixed32_end$5(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$b.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$5(this, 4);

    var value = util$t.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$b.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$5(this, 4);

    var value = util$t.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader$b.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange$5(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader$b.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8$b.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader$b.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange$5(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$5(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader$b.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader$b._configure = function(BufferReader_) {
    BufferReader$b = BufferReader_;
    Reader$b.create = create$b();
    BufferReader$b._configure();

    var fn = util$t.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util$t.merge(Reader$b.prototype, {

        int64: function read_int64() {
            return readLongVarint$5.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint$5.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint$5.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64$5.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64$5.call(this)[fn](false);
        }

    });
};

var reader_buffer$5 = BufferReader$a;

// extends Reader
var Reader$a = reader$a;
(BufferReader$a.prototype = Object.create(Reader$a.prototype)).constructor = BufferReader$a;

var util$s = requireMinimal$5();

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader$a(buffer) {
    Reader$a.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

BufferReader$a._configure = function () {
    /* istanbul ignore else */
    if (util$s.Buffer)
        BufferReader$a.prototype._slice = util$s.Buffer.prototype.slice;
};


/**
 * @override
 */
BufferReader$a.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice
        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))
        : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

BufferReader$a._configure();

var writer$a = Writer$b;

var util$r      = requireMinimal$5();

var BufferWriter$b; // cyclic

var LongBits$a  = util$r.LongBits,
    base64$5    = util$r.base64,
    utf8$a      = util$r.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op$5(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop$8() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State$5(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer$b() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op$5(noop$8, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

var create$a = function create() {
    return util$r.Buffer
        ? function create_buffer_setup() {
            return (Writer$b.create = function create_buffer() {
                return new BufferWriter$b();
            })();
        }
        /* istanbul ignore next */
        : function create_array() {
            return new Writer$b();
        };
};

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer$b.create = create$a();

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer$b.alloc = function alloc(size) {
    return new util$r.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util$r.Array !== Array)
    Writer$b.alloc = util$r.pool(Writer$b.alloc, util$r.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer$b.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op$5(fn, len, val);
    this.len += len;
    return this;
};

function writeByte$5(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32$5(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp$5(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp$5.prototype = Object.create(Op$5.prototype);
VarintOp$5.prototype.fn = writeVarint32$5;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp$5(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64$5, 10, LongBits$a.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64$5(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$b.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits$a.from(value);
    return this._push(writeVarint64$5, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$b.prototype.int64 = Writer$b.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$b.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits$a.from(value).zzEncode();
    return this._push(writeVarint64$5, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.bool = function write_bool(value) {
    return this._push(writeByte$5, 1, value ? 1 : 0);
};

function writeFixed32$5(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32$5, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.sfixed32 = Writer$b.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$b.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits$a.from(value);
    return this._push(writeFixed32$5, 4, bits.lo)._push(writeFixed32$5, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$b.prototype.sfixed64 = Writer$b.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.float = function write_float(value) {
    return this._push(util$r.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.double = function write_double(value) {
    return this._push(util$r.float.writeDoubleLE, 8, value);
};

var writeBytes$5 = util$r.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte$5, 1, 0);
    if (util$r.isString(value)) {
        var buf = Writer$b.alloc(len = base64$5.length(value));
        base64$5.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes$5, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer$b.prototype.string = function write_string(value) {
    var len = utf8$a.length(value);
    return len
        ? this.uint32(len)._push(utf8$a.write, len, value)
        : this._push(writeByte$5, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer$b.prototype.fork = function fork() {
    this.states = new State$5(this);
    this.head = this.tail = new Op$5(noop$8, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer$b.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op$5(noop$8, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer$b.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer$b.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer$b._configure = function(BufferWriter_) {
    BufferWriter$b = BufferWriter_;
    Writer$b.create = create$a();
    BufferWriter$b._configure();
};

var writer_buffer$5 = BufferWriter$a;

// extends Writer
var Writer$a = writer$a;
(BufferWriter$a.prototype = Object.create(Writer$a.prototype)).constructor = BufferWriter$a;

var util$q = requireMinimal$5();

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter$a() {
    Writer$a.call(this);
}

BufferWriter$a._configure = function () {
    /**
     * Allocates a buffer of the specified size.
     * @function
     * @param {number} size Buffer size
     * @returns {Buffer} Buffer
     */
    BufferWriter$a.alloc = util$q._Buffer_allocUnsafe;

    BufferWriter$a.writeBytesBuffer = util$q.Buffer && util$q.Buffer.prototype instanceof Uint8Array && util$q.Buffer.prototype.set.name === "set"
        ? function writeBytesBuffer_set(val, buf, pos) {
          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
          // also works for plain array values
        }
        /* istanbul ignore next */
        : function writeBytesBuffer_copy(val, buf, pos) {
          if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
          else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
        };
};


/**
 * @override
 */
BufferWriter$a.prototype.bytes = function write_bytes_buffer(value) {
    if (util$q.isString(value))
        value = util$q._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(BufferWriter$a.writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer$5(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util$q.utf8.write(val, buf, pos);
    else if (buf.utf8Write)
        buf.utf8Write(val, pos);
    else
        buf.write(val, pos);
}

/**
 * @override
 */
BufferWriter$a.prototype.string = function write_string_buffer(value) {
    var len = util$q.Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer$5, len, value);
    return this;
};


/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

BufferWriter$a._configure();

var minimalExports$5 = requireMinimal$5();
var util$p = /*@__PURE__*/getDefaultExportFromCjs(minimalExports$5);

// @ts-expect-error no types
function configure$4() {
    util$p._configure();
    reader$a._configure(reader_buffer$5);
    writer$a._configure(writer_buffer$5);
}
// Set up buffer utility according to the environment
configure$4();
// monkey patch the reader to add native bigint support
const methods$4 = [
    'uint64', 'int64', 'sint64', 'fixed64', 'sfixed64'
];
function patchReader$4(obj) {
    for (const method of methods$4) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function () {
            return BigInt(original.call(this).toString());
        };
    }
    return obj;
}
function reader$9(buf) {
    return patchReader$4(new reader$a(buf));
}
function patchWriter$4(obj) {
    for (const method of methods$4) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function (val) {
            return original.call(this, val.toString());
        };
    }
    return obj;
}
function writer$9() {
    return patchWriter$4(writer$a.create());
}

function decodeMessage$5(buf, codec) {
    const r = reader$9(buf instanceof Uint8Array ? buf : buf.subarray());
    return codec.decode(r);
}

function encodeMessage$4(message, codec) {
    const w = writer$9();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES$4;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES$4 || (CODEC_TYPES$4 = {}));
function createCodec$4(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function enumeration$1(v) {
    function findValue(val) {
        // Use the reverse mapping to look up the enum key for the stored value
        // https://www.typescriptlang.org/docs/handbook/enums.html#reverse-mappings
        if (v[val.toString()] == null) {
            throw new Error('Invalid enum value');
        }
        return v[val];
    }
    const encode = function enumEncode(val, writer) {
        const enumValue = findValue(val);
        writer.int32(enumValue);
    };
    const decode = function enumDecode(reader) {
        const val = reader.int32();
        return findValue(val);
    };
    // @ts-expect-error yeah yeah
    return createCodec$4('enum', CODEC_TYPES$4.VARINT, encode, decode);
}

function message$4(encode, decode) {
    return createCodec$4('message', CODEC_TYPES$4.LENGTH_DELIMITED, encode, decode);
}

/* eslint-disable import/export */
var NoiseExtensions;
(function (NoiseExtensions) {
    let _codec;
    NoiseExtensions.codec = () => {
        if (_codec == null) {
            _codec = message$4((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.webtransportCerthashes != null) {
                    for (const value of obj.webtransportCerthashes) {
                        w.uint32(10);
                        w.bytes(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    webtransportCerthashes: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.webtransportCerthashes.push(reader.bytes());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    NoiseExtensions.encode = (obj) => {
        return encodeMessage$4(obj, NoiseExtensions.codec());
    };
    NoiseExtensions.decode = (buf) => {
        return decodeMessage$5(buf, NoiseExtensions.codec());
    };
})(NoiseExtensions || (NoiseExtensions = {}));
var NoiseHandshakePayload;
(function (NoiseHandshakePayload) {
    let _codec;
    NoiseHandshakePayload.codec = () => {
        if (_codec == null) {
            _codec = message$4((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (opts.writeDefaults === true || (obj.identityKey != null && obj.identityKey.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.identityKey);
                }
                if (opts.writeDefaults === true || (obj.identitySig != null && obj.identitySig.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.identitySig);
                }
                if (obj.extensions != null) {
                    w.uint32(34);
                    NoiseExtensions.codec().encode(obj.extensions, w, {
                        writeDefaults: false
                    });
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    identityKey: new Uint8Array(0),
                    identitySig: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.identityKey = reader.bytes();
                            break;
                        case 2:
                            obj.identitySig = reader.bytes();
                            break;
                        case 4:
                            obj.extensions = NoiseExtensions.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    NoiseHandshakePayload.encode = (obj) => {
        return encodeMessage$4(obj, NoiseHandshakePayload.codec());
    };
    NoiseHandshakePayload.decode = (buf) => {
        return decodeMessage$5(buf, NoiseHandshakePayload.codec());
    };
})(NoiseHandshakePayload || (NoiseHandshakePayload = {}));

async function getPayload(localPeer, staticPublicKey, extensions) {
    const signedPayload = await signPayload(localPeer, getHandshakePayload(staticPublicKey));
    if (localPeer.publicKey == null) {
        throw new Error('PublicKey was missing from local PeerId');
    }
    return createHandshakePayload(localPeer.publicKey, signedPayload, extensions);
}
function createHandshakePayload(libp2pPublicKey, signedPayload, extensions) {
    return NoiseHandshakePayload.encode({
        identityKey: libp2pPublicKey,
        identitySig: signedPayload,
        extensions: extensions ?? { webtransportCerthashes: [] }
    }).subarray();
}
async function signPayload(peerId, payload) {
    if (peerId.privateKey == null) {
        throw new Error('PrivateKey was missing from PeerId');
    }
    const privateKey = await unmarshalPrivateKey(peerId.privateKey);
    return await privateKey.sign(payload);
}
async function getPeerIdFromPayload(payload) {
    return await peerIdFromKeys(payload.identityKey);
}
function decodePayload(payload) {
    return NoiseHandshakePayload.decode(payload);
}
function getHandshakePayload(publicKey) {
    const prefix = fromString$2('noise-libp2p-static-key:');
    return concat([prefix, publicKey], prefix.length + publicKey.length);
}
/**
 * Verifies signed payload, throws on any irregularities.
 *
 * @param {bytes} noiseStaticKey - owner's noise static key
 * @param {bytes} payload - decoded payload
 * @param {PeerId} remotePeer - owner's libp2p peer ID
 * @returns {Promise<PeerId>} - peer ID of payload owner
 */
async function verifySignedPayload(noiseStaticKey, payload, remotePeer) {
    // Unmarshaling from PublicKey protobuf
    const payloadPeerId = await peerIdFromKeys(payload.identityKey);
    if (!payloadPeerId.equals(remotePeer)) {
        throw new Error(`Payload identity key ${payloadPeerId.toString()} does not match expected remote peer ${remotePeer.toString()}`);
    }
    const generatedPayload = getHandshakePayload(noiseStaticKey);
    if (payloadPeerId.publicKey == null) {
        throw new Error('PublicKey was missing from PeerId');
    }
    if (payload.identitySig == null) {
        throw new Error('Signature was missing from message');
    }
    const publicKey = unmarshalPublicKey(payloadPeerId.publicKey);
    const valid = await publicKey.verify(generatedPayload, payload.identitySig);
    if (!valid) {
        throw new Error("Static key doesn't match to peer that signed payload!");
    }
    return payloadPeerId;
}
function isValidPublicKey(pk) {
    if (!(pk instanceof Uint8Array)) {
        return false;
    }
    if (pk.length !== 32) {
        return false;
    }
    return true;
}

var browserExports = {};
var browser$2 = {
  get exports(){ return browserExports; },
  set exports(v){ browserExports = v; },
};

/**
 * Helpers.
 */

var ms;
var hasRequiredMs;

function requireMs () {
	if (hasRequiredMs) return ms;
	hasRequiredMs = 1;
	var s = 1000;
	var m = s * 60;
	var h = m * 60;
	var d = h * 24;
	var w = d * 7;
	var y = d * 365.25;

	/**
	 * Parse or format the given `val`.
	 *
	 * Options:
	 *
	 *  - `long` verbose formatting [false]
	 *
	 * @param {String|Number} val
	 * @param {Object} [options]
	 * @throws {Error} throw an error if val is not a non-empty string or a number
	 * @return {String|Number}
	 * @api public
	 */

	ms = function(val, options) {
	  options = options || {};
	  var type = typeof val;
	  if (type === 'string' && val.length > 0) {
	    return parse(val);
	  } else if (type === 'number' && isFinite(val)) {
	    return options.long ? fmtLong(val) : fmtShort(val);
	  }
	  throw new Error(
	    'val is not a non-empty string or a valid number. val=' +
	      JSON.stringify(val)
	  );
	};

	/**
	 * Parse the given `str` and return milliseconds.
	 *
	 * @param {String} str
	 * @return {Number}
	 * @api private
	 */

	function parse(str) {
	  str = String(str);
	  if (str.length > 100) {
	    return;
	  }
	  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(
	    str
	  );
	  if (!match) {
	    return;
	  }
	  var n = parseFloat(match[1]);
	  var type = (match[2] || 'ms').toLowerCase();
	  switch (type) {
	    case 'years':
	    case 'year':
	    case 'yrs':
	    case 'yr':
	    case 'y':
	      return n * y;
	    case 'weeks':
	    case 'week':
	    case 'w':
	      return n * w;
	    case 'days':
	    case 'day':
	    case 'd':
	      return n * d;
	    case 'hours':
	    case 'hour':
	    case 'hrs':
	    case 'hr':
	    case 'h':
	      return n * h;
	    case 'minutes':
	    case 'minute':
	    case 'mins':
	    case 'min':
	    case 'm':
	      return n * m;
	    case 'seconds':
	    case 'second':
	    case 'secs':
	    case 'sec':
	    case 's':
	      return n * s;
	    case 'milliseconds':
	    case 'millisecond':
	    case 'msecs':
	    case 'msec':
	    case 'ms':
	      return n;
	    default:
	      return undefined;
	  }
	}

	/**
	 * Short format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtShort(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return Math.round(ms / d) + 'd';
	  }
	  if (msAbs >= h) {
	    return Math.round(ms / h) + 'h';
	  }
	  if (msAbs >= m) {
	    return Math.round(ms / m) + 'm';
	  }
	  if (msAbs >= s) {
	    return Math.round(ms / s) + 's';
	  }
	  return ms + 'ms';
	}

	/**
	 * Long format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtLong(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return plural(ms, msAbs, d, 'day');
	  }
	  if (msAbs >= h) {
	    return plural(ms, msAbs, h, 'hour');
	  }
	  if (msAbs >= m) {
	    return plural(ms, msAbs, m, 'minute');
	  }
	  if (msAbs >= s) {
	    return plural(ms, msAbs, s, 'second');
	  }
	  return ms + ' ms';
	}

	/**
	 * Pluralization helper.
	 */

	function plural(ms, msAbs, n, name) {
	  var isPlural = msAbs >= n * 1.5;
	  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');
	}
	return ms;
}

/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */

function setup(env) {
	createDebug.debug = createDebug;
	createDebug.default = createDebug;
	createDebug.coerce = coerce;
	createDebug.disable = disable;
	createDebug.enable = enable;
	createDebug.enabled = enabled;
	createDebug.humanize = requireMs();
	createDebug.destroy = destroy;

	Object.keys(env).forEach(key => {
		createDebug[key] = env[key];
	});

	/**
	* The currently active debug mode names, and names to skip.
	*/

	createDebug.names = [];
	createDebug.skips = [];

	/**
	* Map of special "%n" handling functions, for the debug "format" argument.
	*
	* Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
	*/
	createDebug.formatters = {};

	/**
	* Selects a color for a debug namespace
	* @param {String} namespace The namespace string for the debug instance to be colored
	* @return {Number|String} An ANSI color code for the given namespace
	* @api private
	*/
	function selectColor(namespace) {
		let hash = 0;

		for (let i = 0; i < namespace.length; i++) {
			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
			hash |= 0; // Convert to 32bit integer
		}

		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
	}
	createDebug.selectColor = selectColor;

	/**
	* Create a debugger with the given `namespace`.
	*
	* @param {String} namespace
	* @return {Function}
	* @api public
	*/
	function createDebug(namespace) {
		let prevTime;
		let enableOverride = null;
		let namespacesCache;
		let enabledCache;

		function debug(...args) {
			// Disabled?
			if (!debug.enabled) {
				return;
			}

			const self = debug;

			// Set `diff` timestamp
			const curr = Number(new Date());
			const ms = curr - (prevTime || curr);
			self.diff = ms;
			self.prev = prevTime;
			self.curr = curr;
			prevTime = curr;

			args[0] = createDebug.coerce(args[0]);

			if (typeof args[0] !== 'string') {
				// Anything else let's inspect with %O
				args.unshift('%O');
			}

			// Apply any `formatters` transformations
			let index = 0;
			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
				// If we encounter an escaped % then don't increase the array index
				if (match === '%%') {
					return '%';
				}
				index++;
				const formatter = createDebug.formatters[format];
				if (typeof formatter === 'function') {
					const val = args[index];
					match = formatter.call(self, val);

					// Now we need to remove `args[index]` since it's inlined in the `format`
					args.splice(index, 1);
					index--;
				}
				return match;
			});

			// Apply env-specific formatting (colors, etc.)
			createDebug.formatArgs.call(self, args);

			const logFn = self.log || createDebug.log;
			logFn.apply(self, args);
		}

		debug.namespace = namespace;
		debug.useColors = createDebug.useColors();
		debug.color = createDebug.selectColor(namespace);
		debug.extend = extend;
		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.

		Object.defineProperty(debug, 'enabled', {
			enumerable: true,
			configurable: false,
			get: () => {
				if (enableOverride !== null) {
					return enableOverride;
				}
				if (namespacesCache !== createDebug.namespaces) {
					namespacesCache = createDebug.namespaces;
					enabledCache = createDebug.enabled(namespace);
				}

				return enabledCache;
			},
			set: v => {
				enableOverride = v;
			}
		});

		// Env-specific initialization logic for debug instances
		if (typeof createDebug.init === 'function') {
			createDebug.init(debug);
		}

		return debug;
	}

	function extend(namespace, delimiter) {
		const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
		newDebug.log = this.log;
		return newDebug;
	}

	/**
	* Enables a debug mode by namespaces. This can include modes
	* separated by a colon and wildcards.
	*
	* @param {String} namespaces
	* @api public
	*/
	function enable(namespaces) {
		createDebug.save(namespaces);
		createDebug.namespaces = namespaces;

		createDebug.names = [];
		createDebug.skips = [];

		let i;
		const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\s,]+/);
		const len = split.length;

		for (i = 0; i < len; i++) {
			if (!split[i]) {
				// ignore empty strings
				continue;
			}

			namespaces = split[i].replace(/\*/g, '.*?');

			if (namespaces[0] === '-') {
				createDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));
			} else {
				createDebug.names.push(new RegExp('^' + namespaces + '$'));
			}
		}
	}

	/**
	* Disable debug output.
	*
	* @return {String} namespaces
	* @api public
	*/
	function disable() {
		const namespaces = [
			...createDebug.names.map(toNamespace),
			...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)
		].join(',');
		createDebug.enable('');
		return namespaces;
	}

	/**
	* Returns true if the given mode name is enabled, false otherwise.
	*
	* @param {String} name
	* @return {Boolean}
	* @api public
	*/
	function enabled(name) {
		if (name[name.length - 1] === '*') {
			return true;
		}

		let i;
		let len;

		for (i = 0, len = createDebug.skips.length; i < len; i++) {
			if (createDebug.skips[i].test(name)) {
				return false;
			}
		}

		for (i = 0, len = createDebug.names.length; i < len; i++) {
			if (createDebug.names[i].test(name)) {
				return true;
			}
		}

		return false;
	}

	/**
	* Convert regexp to namespace
	*
	* @param {RegExp} regxep
	* @return {String} namespace
	* @api private
	*/
	function toNamespace(regexp) {
		return regexp.toString()
			.substring(2, regexp.toString().length - 2)
			.replace(/\.\*\?$/, '*');
	}

	/**
	* Coerce `val`.
	*
	* @param {Mixed} val
	* @return {Mixed}
	* @api private
	*/
	function coerce(val) {
		if (val instanceof Error) {
			return val.stack || val.message;
		}
		return val;
	}

	/**
	* XXX DO NOT USE. This is a temporary stub function.
	* XXX It WILL be removed in the next major release.
	*/
	function destroy() {
		console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
	}

	createDebug.enable(createDebug.load());

	return createDebug;
}

var common = setup;

/* eslint-env browser */

(function (module, exports) {
	/**
	 * This is the web browser implementation of `debug()`.
	 */

	exports.formatArgs = formatArgs;
	exports.save = save;
	exports.load = load;
	exports.useColors = useColors;
	exports.storage = localstorage();
	exports.destroy = (() => {
		let warned = false;

		return () => {
			if (!warned) {
				warned = true;
				console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
			}
		};
	})();

	/**
	 * Colors.
	 */

	exports.colors = [
		'#0000CC',
		'#0000FF',
		'#0033CC',
		'#0033FF',
		'#0066CC',
		'#0066FF',
		'#0099CC',
		'#0099FF',
		'#00CC00',
		'#00CC33',
		'#00CC66',
		'#00CC99',
		'#00CCCC',
		'#00CCFF',
		'#3300CC',
		'#3300FF',
		'#3333CC',
		'#3333FF',
		'#3366CC',
		'#3366FF',
		'#3399CC',
		'#3399FF',
		'#33CC00',
		'#33CC33',
		'#33CC66',
		'#33CC99',
		'#33CCCC',
		'#33CCFF',
		'#6600CC',
		'#6600FF',
		'#6633CC',
		'#6633FF',
		'#66CC00',
		'#66CC33',
		'#9900CC',
		'#9900FF',
		'#9933CC',
		'#9933FF',
		'#99CC00',
		'#99CC33',
		'#CC0000',
		'#CC0033',
		'#CC0066',
		'#CC0099',
		'#CC00CC',
		'#CC00FF',
		'#CC3300',
		'#CC3333',
		'#CC3366',
		'#CC3399',
		'#CC33CC',
		'#CC33FF',
		'#CC6600',
		'#CC6633',
		'#CC9900',
		'#CC9933',
		'#CCCC00',
		'#CCCC33',
		'#FF0000',
		'#FF0033',
		'#FF0066',
		'#FF0099',
		'#FF00CC',
		'#FF00FF',
		'#FF3300',
		'#FF3333',
		'#FF3366',
		'#FF3399',
		'#FF33CC',
		'#FF33FF',
		'#FF6600',
		'#FF6633',
		'#FF9900',
		'#FF9933',
		'#FFCC00',
		'#FFCC33'
	];

	/**
	 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
	 * and the Firebug extension (any Firefox version) are known
	 * to support "%c" CSS customizations.
	 *
	 * TODO: add a `localStorage` variable to explicitly enable/disable colors
	 */

	// eslint-disable-next-line complexity
	function useColors() {
		// NB: In an Electron preload script, document will be defined but not fully
		// initialized. Since we know we're in Chrome, we'll just detect this case
		// explicitly
		if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {
			return true;
		}

		// Internet Explorer and Edge do not support colors.
		if (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/)) {
			return false;
		}

		// Is webkit? http://stackoverflow.com/a/16459606/376773
		// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632
		return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||
			// Is firebug? http://stackoverflow.com/a/398120/376773
			(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||
			// Is firefox >= v31?
			// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
			(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||
			// Double check webkit in userAgent just in case we are in a worker
			(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/));
	}

	/**
	 * Colorize log arguments if enabled.
	 *
	 * @api public
	 */

	function formatArgs(args) {
		args[0] = (this.useColors ? '%c' : '') +
			this.namespace +
			(this.useColors ? ' %c' : ' ') +
			args[0] +
			(this.useColors ? '%c ' : ' ') +
			'+' + module.exports.humanize(this.diff);

		if (!this.useColors) {
			return;
		}

		const c = 'color: ' + this.color;
		args.splice(1, 0, c, 'color: inherit');

		// The final "%c" is somewhat tricky, because there could be other
		// arguments passed either before or after the %c, so we need to
		// figure out the correct index to insert the CSS into
		let index = 0;
		let lastC = 0;
		args[0].replace(/%[a-zA-Z%]/g, match => {
			if (match === '%%') {
				return;
			}
			index++;
			if (match === '%c') {
				// We only are interested in the *last* %c
				// (the user may have provided their own)
				lastC = index;
			}
		});

		args.splice(lastC, 0, c);
	}

	/**
	 * Invokes `console.debug()` when available.
	 * No-op when `console.debug` is not a "function".
	 * If `console.debug` is not available, falls back
	 * to `console.log`.
	 *
	 * @api public
	 */
	exports.log = console.debug || console.log || (() => {});

	/**
	 * Save `namespaces`.
	 *
	 * @param {String} namespaces
	 * @api private
	 */
	function save(namespaces) {
		try {
			if (namespaces) {
				exports.storage.setItem('debug', namespaces);
			} else {
				exports.storage.removeItem('debug');
			}
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	/**
	 * Load `namespaces`.
	 *
	 * @return {String} returns the previously persisted debug modes
	 * @api private
	 */
	function load() {
		let r;
		try {
			r = exports.storage.getItem('debug');
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}

		// If debug isn't set in LS, and we're in Electron, try to load $DEBUG
		if (!r && typeof process !== 'undefined' && 'env' in process) {
			r = process.env.DEBUG;
		}

		return r;
	}

	/**
	 * Localstorage attempts to return the localstorage.
	 *
	 * This is necessary because safari throws
	 * when a user disables cookies/localstorage
	 * and you attempt to access it.
	 *
	 * @return {LocalStorage}
	 * @api private
	 */

	function localstorage() {
		try {
			// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context
			// The Browser also has localStorage in the global context.
			return localStorage;
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	module.exports = common(exports);

	const {formatters} = module.exports;

	/**
	 * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
	 */

	formatters.j = function (v) {
		try {
			return JSON.stringify(v);
		} catch (error) {
			return '[UnexpectedJSONParseError]: ' + error.message;
		}
	};
} (browser$2, browserExports));

var debug = browserExports;

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$1.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64$6.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function logger$2(name) {
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace: debug(`${name}:trace`)
    });
}

const log$U = logger$2('libp2p:noise');
let keyLogger;
if (DUMP_SESSION_KEYS) {
    keyLogger = log$U;
}
else {
    keyLogger = Object.assign(() => { }, {
        enabled: false,
        trace: () => { },
        error: () => { }
    });
}
function logLocalStaticKeys(s) {
    keyLogger(`LOCAL_STATIC_PUBLIC_KEY ${toString$7(s.publicKey, 'hex')}`);
    keyLogger(`LOCAL_STATIC_PRIVATE_KEY ${toString$7(s.privateKey, 'hex')}`);
}
function logLocalEphemeralKeys(e) {
    if (e) {
        keyLogger(`LOCAL_PUBLIC_EPHEMERAL_KEY ${toString$7(e.publicKey, 'hex')}`);
        keyLogger(`LOCAL_PRIVATE_EPHEMERAL_KEY ${toString$7(e.privateKey, 'hex')}`);
    }
    else {
        keyLogger('Missing local ephemeral keys.');
    }
}
function logRemoteStaticKey(rs) {
    keyLogger(`REMOTE_STATIC_PUBLIC_KEY ${toString$7(rs, 'hex')}`);
}
function logRemoteEphemeralKey(re) {
    keyLogger(`REMOTE_EPHEMERAL_PUBLIC_KEY ${toString$7(re, 'hex')}`);
}
function logCipherState(session) {
    if (session.cs1 && session.cs2) {
        keyLogger(`CIPHER_STATE_1 ${session.cs1.n.getUint64()} ${toString$7(session.cs1.k, 'hex')}`);
        keyLogger(`CIPHER_STATE_2 ${session.cs2.n.getUint64()} ${toString$7(session.cs2.k, 'hex')}`);
    }
    else {
        keyLogger('Missing cipher state.');
    }
}

const MIN_NONCE = 0;
// For performance reasons, the nonce is represented as a JS `number`
// Although JS `number` can safely represent integers up to 2 ** 53 - 1, we choose to only use
// 4 bytes to store the data for performance reason.
// This is a slight deviation from the noise spec, which describes the max nonce as 2 ** 64 - 2
// The effect is that this implementation will need a new handshake to be performed after fewer messages are exchanged than other implementations with full uint64 nonces.
// this MAX_NONCE is still a large number of messages, so the practical effect of this is negligible.
const MAX_NONCE = 0xffffffff;
const ERR_MAX_NONCE = 'Cipherstate has reached maximum n, a new handshake must be performed';
/**
 * The nonce is an uint that's increased over time.
 * Maintaining different representations help improve performance.
 */
class Nonce {
    constructor(n = MIN_NONCE) {
        this.n = n;
        this.bytes = new Uint8Array(12);
        this.view = new DataView(this.bytes.buffer, this.bytes.byteOffset, this.bytes.byteLength);
        this.view.setUint32(4, n, true);
    }
    increment() {
        this.n++;
        // Even though we're treating the nonce as 8 bytes, RFC7539 specifies 12 bytes for a nonce.
        this.view.setUint32(4, this.n, true);
    }
    getBytes() {
        return this.bytes;
    }
    getUint64() {
        return this.n;
    }
    assertValue() {
        if (this.n > MAX_NONCE) {
            throw new Error(ERR_MAX_NONCE);
        }
    }
}

class AbstractHandshake {
    constructor(crypto) {
        this.crypto = crypto;
    }
    encryptWithAd(cs, ad, plaintext) {
        const e = this.encrypt(cs.k, cs.n, ad, plaintext);
        cs.n.increment();
        return e;
    }
    decryptWithAd(cs, ad, ciphertext, dst) {
        const { plaintext, valid } = this.decrypt(cs.k, cs.n, ad, ciphertext, dst);
        if (valid)
            cs.n.increment();
        return { plaintext, valid };
    }
    // Cipher state related
    hasKey(cs) {
        return !this.isEmptyKey(cs.k);
    }
    createEmptyKey() {
        return new Uint8Array(32);
    }
    isEmptyKey(k) {
        const emptyKey = this.createEmptyKey();
        return equals$2(emptyKey, k);
    }
    encrypt(k, n, ad, plaintext) {
        n.assertValue();
        return this.crypto.chaCha20Poly1305Encrypt(plaintext, n.getBytes(), ad, k);
    }
    encryptAndHash(ss, plaintext) {
        let ciphertext;
        if (this.hasKey(ss.cs)) {
            ciphertext = this.encryptWithAd(ss.cs, ss.h, plaintext);
        }
        else {
            ciphertext = plaintext;
        }
        this.mixHash(ss, ciphertext);
        return ciphertext;
    }
    decrypt(k, n, ad, ciphertext, dst) {
        n.assertValue();
        const encryptedMessage = this.crypto.chaCha20Poly1305Decrypt(ciphertext, n.getBytes(), ad, k, dst);
        if (encryptedMessage) {
            return {
                plaintext: encryptedMessage,
                valid: true
            };
        }
        else {
            return {
                plaintext: new Uint8Array(0),
                valid: false
            };
        }
    }
    decryptAndHash(ss, ciphertext) {
        let plaintext;
        let valid = true;
        if (this.hasKey(ss.cs)) {
            ({ plaintext, valid } = this.decryptWithAd(ss.cs, ss.h, ciphertext));
        }
        else {
            plaintext = ciphertext;
        }
        this.mixHash(ss, ciphertext);
        return { plaintext, valid };
    }
    dh(privateKey, publicKey) {
        try {
            const derivedU8 = this.crypto.generateX25519SharedKey(privateKey, publicKey);
            if (derivedU8.length === 32) {
                return derivedU8;
            }
            return derivedU8.subarray(0, 32);
        }
        catch (e) {
            const err = e;
            log$U(err.message);
            return new Uint8Array(32);
        }
    }
    mixHash(ss, data) {
        ss.h = this.getHash(ss.h, data);
    }
    getHash(a, b) {
        const u = this.crypto.hashSHA256(concat([a, b], a.length + b.length));
        return u;
    }
    mixKey(ss, ikm) {
        const [ck, tempK] = this.crypto.getHKDF(ss.ck, ikm);
        ss.cs = this.initializeKey(tempK);
        ss.ck = ck;
    }
    initializeKey(k) {
        return { k, n: new Nonce() };
    }
    // Symmetric state related
    initializeSymmetric(protocolName) {
        const protocolNameBytes = fromString$2(protocolName, 'utf-8');
        const h = this.hashProtocolName(protocolNameBytes);
        const ck = h;
        const key = this.createEmptyKey();
        const cs = this.initializeKey(key);
        return { cs, ck, h };
    }
    hashProtocolName(protocolName) {
        if (protocolName.length <= 32) {
            const h = new Uint8Array(32);
            h.set(protocolName);
            return h;
        }
        else {
            return this.getHash(protocolName, new Uint8Array(0));
        }
    }
    split(ss) {
        const [tempk1, tempk2] = this.crypto.getHKDF(ss.ck, new Uint8Array(0));
        const cs1 = this.initializeKey(tempk1);
        const cs2 = this.initializeKey(tempk2);
        return { cs1, cs2 };
    }
    writeMessageRegular(cs, payload) {
        const ciphertext = this.encryptWithAd(cs, new Uint8Array(0), payload);
        const ne = this.createEmptyKey();
        const ns = new Uint8Array(0);
        return { ne, ns, ciphertext };
    }
    readMessageRegular(cs, message) {
        return this.decryptWithAd(cs, new Uint8Array(0), message.ciphertext);
    }
}

class XX extends AbstractHandshake {
    initializeInitiator(prologue, s, rs, psk) {
        const name = 'Noise_XX_25519_ChaChaPoly_SHA256';
        const ss = this.initializeSymmetric(name);
        this.mixHash(ss, prologue);
        const re = new Uint8Array(32);
        return { ss, s, rs, psk, re };
    }
    initializeResponder(prologue, s, rs, psk) {
        const name = 'Noise_XX_25519_ChaChaPoly_SHA256';
        const ss = this.initializeSymmetric(name);
        this.mixHash(ss, prologue);
        const re = new Uint8Array(32);
        return { ss, s, rs, psk, re };
    }
    writeMessageA(hs, payload, e) {
        const ns = new Uint8Array(0);
        if (e !== undefined) {
            hs.e = e;
        }
        else {
            hs.e = this.crypto.generateX25519KeyPair();
        }
        const ne = hs.e.publicKey;
        this.mixHash(hs.ss, ne);
        const ciphertext = this.encryptAndHash(hs.ss, payload);
        return { ne, ns, ciphertext };
    }
    writeMessageB(hs, payload) {
        hs.e = this.crypto.generateX25519KeyPair();
        const ne = hs.e.publicKey;
        this.mixHash(hs.ss, ne);
        this.mixKey(hs.ss, this.dh(hs.e.privateKey, hs.re));
        const spk = hs.s.publicKey;
        const ns = this.encryptAndHash(hs.ss, spk);
        this.mixKey(hs.ss, this.dh(hs.s.privateKey, hs.re));
        const ciphertext = this.encryptAndHash(hs.ss, payload);
        return { ne, ns, ciphertext };
    }
    writeMessageC(hs, payload) {
        const spk = hs.s.publicKey;
        const ns = this.encryptAndHash(hs.ss, spk);
        this.mixKey(hs.ss, this.dh(hs.s.privateKey, hs.re));
        const ciphertext = this.encryptAndHash(hs.ss, payload);
        const ne = this.createEmptyKey();
        const messageBuffer = { ne, ns, ciphertext };
        const { cs1, cs2 } = this.split(hs.ss);
        return { h: hs.ss.h, messageBuffer, cs1, cs2 };
    }
    readMessageA(hs, message) {
        if (isValidPublicKey(message.ne)) {
            hs.re = message.ne;
        }
        this.mixHash(hs.ss, hs.re);
        return this.decryptAndHash(hs.ss, message.ciphertext);
    }
    readMessageB(hs, message) {
        if (isValidPublicKey(message.ne)) {
            hs.re = message.ne;
        }
        this.mixHash(hs.ss, hs.re);
        if (!hs.e) {
            throw new Error('Handshake state `e` param is missing.');
        }
        this.mixKey(hs.ss, this.dh(hs.e.privateKey, hs.re));
        const { plaintext: ns, valid: valid1 } = this.decryptAndHash(hs.ss, message.ns);
        if (valid1 && isValidPublicKey(ns)) {
            hs.rs = ns;
        }
        this.mixKey(hs.ss, this.dh(hs.e.privateKey, hs.rs));
        const { plaintext, valid: valid2 } = this.decryptAndHash(hs.ss, message.ciphertext);
        return { plaintext, valid: (valid1 && valid2) };
    }
    readMessageC(hs, message) {
        const { plaintext: ns, valid: valid1 } = this.decryptAndHash(hs.ss, message.ns);
        if (valid1 && isValidPublicKey(ns)) {
            hs.rs = ns;
        }
        if (!hs.e) {
            throw new Error('Handshake state `e` param is missing.');
        }
        this.mixKey(hs.ss, this.dh(hs.e.privateKey, hs.rs));
        const { plaintext, valid: valid2 } = this.decryptAndHash(hs.ss, message.ciphertext);
        const { cs1, cs2 } = this.split(hs.ss);
        return { h: hs.ss.h, plaintext, valid: (valid1 && valid2), cs1, cs2 };
    }
    initSession(initiator, prologue, s) {
        const psk = this.createEmptyKey();
        const rs = new Uint8Array(32); // no static key yet
        let hs;
        if (initiator) {
            hs = this.initializeInitiator(prologue, s, rs, psk);
        }
        else {
            hs = this.initializeResponder(prologue, s, rs, psk);
        }
        return {
            hs,
            i: initiator,
            mc: 0
        };
    }
    sendMessage(session, message, ephemeral) {
        let messageBuffer;
        if (session.mc === 0) {
            messageBuffer = this.writeMessageA(session.hs, message, ephemeral);
        }
        else if (session.mc === 1) {
            messageBuffer = this.writeMessageB(session.hs, message);
        }
        else if (session.mc === 2) {
            const { h, messageBuffer: resultingBuffer, cs1, cs2 } = this.writeMessageC(session.hs, message);
            messageBuffer = resultingBuffer;
            session.h = h;
            session.cs1 = cs1;
            session.cs2 = cs2;
        }
        else if (session.mc > 2) {
            if (session.i) {
                if (!session.cs1) {
                    throw new Error('CS1 (cipher state) is not defined');
                }
                messageBuffer = this.writeMessageRegular(session.cs1, message);
            }
            else {
                if (!session.cs2) {
                    throw new Error('CS2 (cipher state) is not defined');
                }
                messageBuffer = this.writeMessageRegular(session.cs2, message);
            }
        }
        else {
            throw new Error('Session invalid.');
        }
        session.mc++;
        return messageBuffer;
    }
    recvMessage(session, message) {
        let plaintext = new Uint8Array(0);
        let valid = false;
        if (session.mc === 0) {
            ({ plaintext, valid } = this.readMessageA(session.hs, message));
        }
        else if (session.mc === 1) {
            ({ plaintext, valid } = this.readMessageB(session.hs, message));
        }
        else if (session.mc === 2) {
            const { h, plaintext: resultingPlaintext, valid: resultingValid, cs1, cs2 } = this.readMessageC(session.hs, message);
            plaintext = resultingPlaintext;
            valid = resultingValid;
            session.h = h;
            session.cs1 = cs1;
            session.cs2 = cs2;
        }
        session.mc++;
        return { plaintext, valid };
    }
}

class XXHandshake {
    constructor(isInitiator, payload, prologue, crypto, staticKeypair, connection, remotePeer, handshake) {
        this.remoteExtensions = { webtransportCerthashes: [] };
        this.isInitiator = isInitiator;
        this.payload = payload;
        this.prologue = prologue;
        this.staticKeypair = staticKeypair;
        this.connection = connection;
        if (remotePeer) {
            this.remotePeer = remotePeer;
        }
        this.xx = handshake ?? new XX(crypto);
        this.session = this.xx.initSession(this.isInitiator, this.prologue, this.staticKeypair);
    }
    // stage 0
    async propose() {
        logLocalStaticKeys(this.session.hs.s);
        if (this.isInitiator) {
            log$U('Stage 0 - Initiator starting to send first message.');
            const messageBuffer = this.xx.sendMessage(this.session, new Uint8Array(0));
            this.connection.writeLP(encode0(messageBuffer));
            log$U('Stage 0 - Initiator finished sending first message.');
            logLocalEphemeralKeys(this.session.hs.e);
        }
        else {
            log$U('Stage 0 - Responder waiting to receive first message...');
            const receivedMessageBuffer = decode0((await this.connection.readLP()).subarray());
            const { valid } = this.xx.recvMessage(this.session, receivedMessageBuffer);
            if (!valid) {
                throw new InvalidCryptoExchangeError('xx handshake stage 0 validation fail');
            }
            log$U('Stage 0 - Responder received first message.');
            logRemoteEphemeralKey(this.session.hs.re);
        }
    }
    // stage 1
    async exchange() {
        if (this.isInitiator) {
            log$U('Stage 1 - Initiator waiting to receive first message from responder...');
            const receivedMessageBuffer = decode1((await this.connection.readLP()).subarray());
            const { plaintext, valid } = this.xx.recvMessage(this.session, receivedMessageBuffer);
            if (!valid) {
                throw new InvalidCryptoExchangeError('xx handshake stage 1 validation fail');
            }
            log$U('Stage 1 - Initiator received the message.');
            logRemoteEphemeralKey(this.session.hs.re);
            logRemoteStaticKey(this.session.hs.rs);
            log$U("Initiator going to check remote's signature...");
            try {
                const decodedPayload = decodePayload(plaintext);
                this.remotePeer = this.remotePeer || await getPeerIdFromPayload(decodedPayload);
                await verifySignedPayload(this.session.hs.rs, decodedPayload, this.remotePeer);
                this.setRemoteNoiseExtension(decodedPayload.extensions);
            }
            catch (e) {
                const err = e;
                throw new UnexpectedPeerError(`Error occurred while verifying signed payload: ${err.message}`);
            }
            log$U('All good with the signature!');
        }
        else {
            log$U('Stage 1 - Responder sending out first message with signed payload and static key.');
            const messageBuffer = this.xx.sendMessage(this.session, this.payload);
            this.connection.writeLP(encode1(messageBuffer));
            log$U('Stage 1 - Responder sent the second handshake message with signed payload.');
            logLocalEphemeralKeys(this.session.hs.e);
        }
    }
    // stage 2
    async finish() {
        if (this.isInitiator) {
            log$U('Stage 2 - Initiator sending third handshake message.');
            const messageBuffer = this.xx.sendMessage(this.session, this.payload);
            this.connection.writeLP(encode2(messageBuffer));
            log$U('Stage 2 - Initiator sent message with signed payload.');
        }
        else {
            log$U('Stage 2 - Responder waiting for third handshake message...');
            const receivedMessageBuffer = decode2((await this.connection.readLP()).subarray());
            const { plaintext, valid } = this.xx.recvMessage(this.session, receivedMessageBuffer);
            if (!valid) {
                throw new InvalidCryptoExchangeError('xx handshake stage 2 validation fail');
            }
            log$U('Stage 2 - Responder received the message, finished handshake.');
            try {
                const decodedPayload = decodePayload(plaintext);
                this.remotePeer = this.remotePeer || await getPeerIdFromPayload(decodedPayload);
                await verifySignedPayload(this.session.hs.rs, decodedPayload, this.remotePeer);
                this.setRemoteNoiseExtension(decodedPayload.extensions);
            }
            catch (e) {
                const err = e;
                throw new UnexpectedPeerError(`Error occurred while verifying signed payload: ${err.message}`);
            }
        }
        logCipherState(this.session);
    }
    encrypt(plaintext, session) {
        const cs = this.getCS(session);
        return this.xx.encryptWithAd(cs, new Uint8Array(0), plaintext);
    }
    decrypt(ciphertext, session, dst) {
        const cs = this.getCS(session, false);
        return this.xx.decryptWithAd(cs, new Uint8Array(0), ciphertext, dst);
    }
    getRemoteStaticKey() {
        return this.session.hs.rs;
    }
    getCS(session, encryption = true) {
        if (!session.cs1 || !session.cs2) {
            throw new InvalidCryptoExchangeError('Handshake not completed properly, cipher state does not exist.');
        }
        if (this.isInitiator) {
            return encryption ? session.cs1 : session.cs2;
        }
        else {
            return encryption ? session.cs2 : session.cs1;
        }
    }
    setRemoteNoiseExtension(e) {
        if (e) {
            this.remoteExtensions = e;
        }
    }
}

function registerMetrics(metrics) {
    return {
        xxHandshakeSuccesses: metrics.registerCounter('libp2p_noise_xxhandshake_successes_total', {
            help: 'Total count of noise xxHandshakes successes_'
        }),
        xxHandshakeErrors: metrics.registerCounter('libp2p_noise_xxhandshake_error_total', {
            help: 'Total count of noise xxHandshakes errors'
        }),
        encryptedPackets: metrics.registerCounter('libp2p_noise_encrypted_packets_total', {
            help: 'Total count of noise encrypted packets successfully'
        }),
        decryptedPackets: metrics.registerCounter('libp2p_noise_decrypted_packets_total', {
            help: 'Total count of noise decrypted packets'
        }),
        decryptErrors: metrics.registerCounter('libp2p_noise_decrypt_errors_total', {
            help: 'Total count of noise decrypt errors'
        })
    };
}

class Noise {
    constructor(init = {}) {
        this.protocol = '/noise';
        const { staticNoiseKey, extensions, crypto, prologueBytes, metrics } = init;
        this.crypto = crypto ?? stablelib;
        this.extensions = extensions;
        this.metrics = metrics ? registerMetrics(metrics) : undefined;
        if (staticNoiseKey) {
            // accepts x25519 private key of length 32
            this.staticKeys = this.crypto.generateX25519KeyPairFromSeed(staticNoiseKey);
        }
        else {
            this.staticKeys = this.crypto.generateX25519KeyPair();
        }
        this.prologue = prologueBytes ?? new Uint8Array(0);
    }
    /**
     * Encrypt outgoing data to the remote party (handshake as initiator)
     *
     * @param {PeerId} localPeer - PeerId of the receiving peer
     * @param {Duplex<Uint8Array>} connection - streaming iterable duplex that will be encrypted
     * @param {PeerId} remotePeer - PeerId of the remote peer. Used to validate the integrity of the remote peer.
     * @returns {Promise<SecuredConnection>}
     */
    async secureOutbound(localPeer, connection, remotePeer) {
        const wrappedConnection = pbStream(connection, {
            lengthEncoder: uint16BEEncode,
            lengthDecoder: uint16BEDecode,
            maxDataLength: NOISE_MSG_MAX_LENGTH_BYTES
        });
        const handshake = await this.performHandshake({
            connection: wrappedConnection,
            isInitiator: true,
            localPeer,
            remotePeer
        });
        const conn = await this.createSecureConnection(wrappedConnection, handshake);
        return {
            conn,
            remoteExtensions: handshake.remoteExtensions,
            remotePeer: handshake.remotePeer
        };
    }
    /**
     * Decrypt incoming data (handshake as responder).
     *
     * @param {PeerId} localPeer - PeerId of the receiving peer.
     * @param {Duplex<Uint8Array>} connection - streaming iterable duplex that will be encryption.
     * @param {PeerId} remotePeer - optional PeerId of the initiating peer, if known. This may only exist during transport upgrades.
     * @returns {Promise<SecuredConnection>}
     */
    async secureInbound(localPeer, connection, remotePeer) {
        const wrappedConnection = pbStream(connection, {
            lengthEncoder: uint16BEEncode,
            lengthDecoder: uint16BEDecode,
            maxDataLength: NOISE_MSG_MAX_LENGTH_BYTES
        });
        const handshake = await this.performHandshake({
            connection: wrappedConnection,
            isInitiator: false,
            localPeer,
            remotePeer
        });
        const conn = await this.createSecureConnection(wrappedConnection, handshake);
        return {
            conn,
            remotePeer: handshake.remotePeer,
            remoteExtensions: handshake.remoteExtensions
        };
    }
    /**
     * If Noise pipes supported, tries IK handshake first with XX as fallback if it fails.
     * If noise pipes disabled or remote peer static key is unknown, use XX.
     *
     * @param {HandshakeParams} params
     */
    async performHandshake(params) {
        const payload = await getPayload(params.localPeer, this.staticKeys.publicKey, this.extensions);
        // run XX handshake
        return await this.performXXHandshake(params, payload);
    }
    async performXXHandshake(params, payload) {
        const { isInitiator, remotePeer, connection } = params;
        const handshake = new XXHandshake(isInitiator, payload, this.prologue, this.crypto, this.staticKeys, connection, remotePeer);
        try {
            await handshake.propose();
            await handshake.exchange();
            await handshake.finish();
            this.metrics?.xxHandshakeSuccesses.increment();
        }
        catch (e) {
            this.metrics?.xxHandshakeErrors.increment();
            if (e instanceof Error) {
                e.message = `Error occurred during XX handshake: ${e.message}`;
                throw e;
            }
        }
        return handshake;
    }
    async createSecureConnection(connection, handshake) {
        // Create encryption box/unbox wrapper
        const [secure, user] = duplexPair();
        const network = connection.unwrap();
        await pipe(secure, // write to wrapper
        encryptStream(handshake, this.metrics), // encrypt data + prefix with message length
        network, // send to the remote peer
        decode$a({ lengthDecoder: uint16BEDecode }), // read message length prefix
        decryptStream(handshake, this.metrics), // decrypt the incoming data
        secure // pipe to the wrapper
        );
        return user;
    }
}

function noise(init = {}) {
    return () => new Noise(init);
}

let AbortError$4 = class AbortError extends Error {
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.code = code ?? 'ABORT_ERR';
    }
};

function getIterator(obj) {
    if (obj != null) {
        if (typeof obj[Symbol.iterator] === 'function') {
            return obj[Symbol.iterator]();
        }
        if (typeof obj[Symbol.asyncIterator] === 'function') {
            return obj[Symbol.asyncIterator]();
        }
        if (typeof obj.next === 'function') {
            return obj; // probably an iterator
        }
    }
    throw new Error('argument is not an iterator or iterable');
}

// Wrap an iterator to make it abortable, allow cleanup when aborted via onAbort
function abortableSource(source, signal, options) {
    const opts = options ?? {};
    const iterator = getIterator(source);
    async function* abortable() {
        let nextAbortHandler;
        const abortHandler = () => {
            if (nextAbortHandler != null)
                nextAbortHandler();
        };
        signal.addEventListener('abort', abortHandler);
        while (true) {
            let result;
            try {
                if (signal.aborted) {
                    const { abortMessage, abortCode } = opts;
                    throw new AbortError$4(abortMessage, abortCode);
                }
                const abort = new Promise((resolve, reject) => {
                    nextAbortHandler = () => {
                        const { abortMessage, abortCode } = opts;
                        reject(new AbortError$4(abortMessage, abortCode));
                    };
                });
                // Race the iterator and the abort signals
                result = await Promise.race([abort, iterator.next()]);
                nextAbortHandler = null;
            }
            catch (err) {
                signal.removeEventListener('abort', abortHandler);
                // Might not have been aborted by a known signal
                const isKnownAborter = err.type === 'aborted' && signal.aborted;
                if (isKnownAborter && (opts.onAbort != null)) {
                    // Do any custom abort handling for the iterator
                    await opts.onAbort(source);
                }
                // End the iterator if it is a generator
                if (typeof iterator.return === 'function') {
                    try {
                        const p = iterator.return();
                        if (p instanceof Promise) { // eslint-disable-line max-depth
                            p.catch(err => {
                                if (opts.onReturnError != null) {
                                    opts.onReturnError(err);
                                }
                            });
                        }
                    }
                    catch (err) {
                        if (opts.onReturnError != null) { // eslint-disable-line max-depth
                            opts.onReturnError(err);
                        }
                    }
                }
                if (isKnownAborter && opts.returnOnAbort === true) {
                    return;
                }
                throw err;
            }
            if (result.done === true) {
                break;
            }
            yield result.value;
        }
        signal.removeEventListener('abort', abortHandler);
    }
    return abortable();
}
function abortableSink(sink, signal, options) {
    return (source) => sink(abortableSource(source, signal, options));
}
function abortableDuplex(duplex, signal, options) {
    return {
        sink: abortableSink(duplex.sink, signal, {
            ...options,
            onAbort: undefined
        }),
        source: abortableSource(duplex.source, signal, options)
    };
}

var encode_1 = encode$6;

var MSB$2 = 0x80
  , REST$2 = 0x7F
  , MSBALL = ~REST$2
  , INT = Math.pow(2, 31);

function encode$6(num, out, offset) {
  if (Number.MAX_SAFE_INTEGER && num > Number.MAX_SAFE_INTEGER) {
    encode$6.bytes = 0;
    throw new RangeError('Could not encode varint')
  }
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT) {
    out[offset++] = (num & 0xFF) | MSB$2;
    num /= 128;
  }
  while(num & MSBALL) {
    out[offset++] = (num & 0xFF) | MSB$2;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$6.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$4 = read$1;

var MSB$1 = 0x80
  , REST$1 = 0x7F;

function read$1(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l || shift > 49) {
      read$1.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1) << shift
      : (b & REST$1) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1)

  read$1.bytes = counter - offset;

  return res
}

var N1 = Math.pow(2,  7);
var N2 = Math.pow(2, 14);
var N3 = Math.pow(2, 21);
var N4 = Math.pow(2, 28);
var N5 = Math.pow(2, 35);
var N6 = Math.pow(2, 42);
var N7 = Math.pow(2, 49);
var N8 = Math.pow(2, 56);
var N9 = Math.pow(2, 63);

var length = function (value) {
  return (
    value < N1 ? 1
  : value < N2 ? 2
  : value < N3 ? 3
  : value < N4 ? 4
  : value < N5 ? 5
  : value < N6 ? 6
  : value < N7 ? 7
  : value < N8 ? 8
  : value < N9 ? 9
  :              10
  )
};

var varint = {
    encode: encode_1
  , decode: decode$4
  , encodingLength: length
};

function allocUnsafe(size) {
    return new Uint8Array(size);
}

var MessageTypes;
(function (MessageTypes) {
    MessageTypes[MessageTypes["NEW_STREAM"] = 0] = "NEW_STREAM";
    MessageTypes[MessageTypes["MESSAGE_RECEIVER"] = 1] = "MESSAGE_RECEIVER";
    MessageTypes[MessageTypes["MESSAGE_INITIATOR"] = 2] = "MESSAGE_INITIATOR";
    MessageTypes[MessageTypes["CLOSE_RECEIVER"] = 3] = "CLOSE_RECEIVER";
    MessageTypes[MessageTypes["CLOSE_INITIATOR"] = 4] = "CLOSE_INITIATOR";
    MessageTypes[MessageTypes["RESET_RECEIVER"] = 5] = "RESET_RECEIVER";
    MessageTypes[MessageTypes["RESET_INITIATOR"] = 6] = "RESET_INITIATOR";
})(MessageTypes || (MessageTypes = {}));
const MessageTypeNames = Object.freeze({
    0: 'NEW_STREAM',
    1: 'MESSAGE_RECEIVER',
    2: 'MESSAGE_INITIATOR',
    3: 'CLOSE_RECEIVER',
    4: 'CLOSE_INITIATOR',
    5: 'RESET_RECEIVER',
    6: 'RESET_INITIATOR'
});
const InitiatorMessageTypes = Object.freeze({
    NEW_STREAM: MessageTypes.NEW_STREAM,
    MESSAGE: MessageTypes.MESSAGE_INITIATOR,
    CLOSE: MessageTypes.CLOSE_INITIATOR,
    RESET: MessageTypes.RESET_INITIATOR
});
const ReceiverMessageTypes = Object.freeze({
    MESSAGE: MessageTypes.MESSAGE_RECEIVER,
    CLOSE: MessageTypes.CLOSE_RECEIVER,
    RESET: MessageTypes.RESET_RECEIVER
});

const DEFAULT_BATCH_SIZE = 1024 * 1024;
const DEFAULT_SERIALIZE = (buf, list) => { list.append(buf); };
async function* batchedBytes(source, options = {}) {
    let buffer = new Uint8ArrayList();
    let ended = false;
    let deferred = pDefer$1();
    let size = Number(options.size ?? DEFAULT_BATCH_SIZE);
    if (isNaN(size) || size === 0 || size < 0) {
        size = DEFAULT_BATCH_SIZE;
    }
    const yieldAfter = options.yieldAfter ?? 0;
    const serialize = options.serialize ?? DEFAULT_SERIALIZE;
    void Promise.resolve().then(async () => {
        try {
            let timeout;
            for await (const buf of source) {
                serialize(buf, buffer);
                if (buffer.byteLength >= size) {
                    clearTimeout(timeout);
                    deferred.resolve();
                    continue;
                }
                timeout = setTimeout(() => {
                    deferred.resolve();
                }, yieldAfter);
            }
            clearTimeout(timeout);
            deferred.resolve();
        }
        catch (err) {
            deferred.reject(err);
        }
        finally {
            ended = true;
        }
    });
    while (!ended) { // eslint-disable-line no-unmodified-loop-condition
        await deferred.promise;
        deferred = pDefer$1();
        if (buffer.byteLength > 0) {
            const b = buffer;
            buffer = new Uint8ArrayList();
            yield b.subarray();
        }
    }
}

const POOL_SIZE = 10 * 1024;
let Encoder$1 = class Encoder {
    constructor() {
        this._pool = allocUnsafe(POOL_SIZE);
        this._poolOffset = 0;
    }
    /**
     * Encodes the given message and adds it to the passed list
     */
    write(msg, list) {
        const pool = this._pool;
        let offset = this._poolOffset;
        varint.encode(msg.id << 3 | msg.type, pool, offset);
        offset += varint.encode.bytes ?? 0;
        if ((msg.type === MessageTypes.NEW_STREAM || msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) && msg.data != null) {
            varint.encode(msg.data.length, pool, offset);
        }
        else {
            varint.encode(0, pool, offset);
        }
        offset += varint.encode.bytes ?? 0;
        const header = pool.subarray(this._poolOffset, offset);
        if (POOL_SIZE - offset < 100) {
            this._pool = allocUnsafe(POOL_SIZE);
            this._poolOffset = 0;
        }
        else {
            this._poolOffset = offset;
        }
        list.append(header);
        if ((msg.type === MessageTypes.NEW_STREAM || msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) && msg.data != null) {
            list.append(msg.data);
        }
    }
};
const encoder = new Encoder$1();
/**
 * Encode and yield one or more messages
 */
async function* encode$5(source, minSendBytes = 0) {
    if (minSendBytes == null || minSendBytes === 0) {
        // just send the messages
        for await (const messages of source) {
            const list = new Uint8ArrayList();
            for (const msg of messages) {
                encoder.write(msg, list);
            }
            yield list.subarray();
        }
        return;
    }
    // batch messages up for sending
    yield* batchedBytes(source, {
        size: minSendBytes,
        serialize: (obj, list) => {
            for (const m of obj) {
                encoder.write(m, list);
            }
        }
    });
}

const MAX_MSG_SIZE = 1 << 20; // 1MB
const MAX_MSG_QUEUE_SIZE = 4 << 20; // 4MB
class Decoder {
    constructor(maxMessageSize = MAX_MSG_SIZE, maxUnprocessedMessageQueueSize = MAX_MSG_QUEUE_SIZE) {
        this._buffer = new Uint8ArrayList();
        this._headerInfo = null;
        this._maxMessageSize = maxMessageSize;
        this._maxUnprocessedMessageQueueSize = maxUnprocessedMessageQueueSize;
    }
    write(chunk) {
        if (chunk == null || chunk.length === 0) {
            return [];
        }
        this._buffer.append(chunk);
        if (this._buffer.byteLength > this._maxUnprocessedMessageQueueSize) {
            throw Object.assign(new Error('unprocessed message queue size too large!'), { code: 'ERR_MSG_QUEUE_TOO_BIG' });
        }
        const msgs = [];
        while (this._buffer.length !== 0) {
            if (this._headerInfo == null) {
                try {
                    this._headerInfo = this._decodeHeader(this._buffer);
                }
                catch (err) {
                    if (err.code === 'ERR_MSG_TOO_BIG') {
                        throw err;
                    }
                    break; // We haven't received enough data yet
                }
            }
            const { id, type, length, offset } = this._headerInfo;
            const bufferedDataLength = this._buffer.length - offset;
            if (bufferedDataLength < length) {
                break; // not enough data yet
            }
            const msg = {
                id,
                type
            };
            if (type === MessageTypes.NEW_STREAM || type === MessageTypes.MESSAGE_INITIATOR || type === MessageTypes.MESSAGE_RECEIVER) {
                msg.data = this._buffer.sublist(offset, offset + length);
            }
            msgs.push(msg);
            this._buffer.consume(offset + length);
            this._headerInfo = null;
        }
        return msgs;
    }
    /**
     * Attempts to decode the message header from the buffer
     */
    _decodeHeader(data) {
        const { value: h, offset } = readVarInt(data);
        const { value: length, offset: end } = readVarInt(data, offset);
        const type = h & 7;
        // @ts-expect-error h is a number not a CODE
        if (MessageTypeNames[type] == null) {
            throw new Error(`Invalid type received: ${type}`);
        }
        // test message type varint + data length
        if (length > this._maxMessageSize) {
            throw Object.assign(new Error('message size too large!'), { code: 'ERR_MSG_TOO_BIG' });
        }
        // @ts-expect-error h is a number not a CODE
        return { id: h >> 3, type, offset: offset + end, length };
    }
}
const MSB = 0x80;
const REST = 0x7F;
function readVarInt(buf, offset = 0) {
    let res = 0;
    let shift = 0;
    let counter = offset;
    let b;
    const l = buf.length;
    do {
        if (counter >= l || shift > 49) {
            offset = 0;
            throw new RangeError('Could not decode varint');
        }
        b = buf.get(counter++);
        res += shift < 28
            ? (b & REST) << shift
            : (b & REST) * Math.pow(2, shift);
        shift += 7;
    } while (b >= MSB);
    offset = counter - offset;
    return {
        value: res,
        offset
    };
}

var anySignalExports = {};
var anySignal$1 = {
  get exports(){ return anySignalExports; },
  set exports(v){ anySignalExports = v; },
};

/**
 * Takes an array of AbortSignals and returns a single signal.
 * If any signals are aborted, the returned signal will be aborted.
 * @param {Array<AbortSignal>} signals
 * @returns {AbortSignal}
 */

function anySignal (signals) {
  const controller = new globalThis.AbortController();

  function onAbort () {
    controller.abort();

    for (const signal of signals) {
      if (!signal || !signal.removeEventListener) continue
      signal.removeEventListener('abort', onAbort);
    }
  }

  for (const signal of signals) {
    if (!signal || !signal.addEventListener) continue
    if (signal.aborted) {
      onAbort();
      break
    }
    signal.addEventListener('abort', onAbort);
  }

  return controller.signal
}

anySignal$1.exports = anySignal;
var anySignal_2 = anySignalExports.anySignal = anySignal;

const log$T = logger$2('libp2p:mplex:stream');
const ERR_STREAM_RESET = 'ERR_STREAM_RESET';
const ERR_STREAM_ABORT = 'ERR_STREAM_ABORT';
const ERR_SINK_ENDED = 'ERR_SINK_ENDED';
const ERR_DOUBLE_SINK = 'ERR_DOUBLE_SINK';
function createStream(options) {
    const { id, name, send, onEnd, type = 'initiator', maxMsgSize = MAX_MSG_SIZE } = options;
    const abortController = new AbortController();
    const resetController = new AbortController();
    const closeController = new AbortController();
    const Types = type === 'initiator' ? InitiatorMessageTypes : ReceiverMessageTypes;
    const externalId = type === 'initiator' ? (`i${id}`) : `r${id}`;
    const streamName = `${name == null ? id : name}`;
    let sourceEnded = false;
    let sinkEnded = false;
    let sinkSunk = false;
    let endErr;
    const timeline = {
        open: Date.now()
    };
    const onSourceEnd = (err) => {
        if (sourceEnded) {
            return;
        }
        sourceEnded = true;
        log$T.trace('%s stream %s source end - err: %o', type, streamName, err);
        if (err != null && endErr == null) {
            endErr = err;
        }
        if (sinkEnded) {
            stream.stat.timeline.close = Date.now();
            if (onEnd != null) {
                onEnd(endErr);
            }
        }
    };
    const onSinkEnd = (err) => {
        if (sinkEnded) {
            return;
        }
        sinkEnded = true;
        log$T.trace('%s stream %s sink end - err: %o', type, streamName, err);
        if (err != null && endErr == null) {
            endErr = err;
        }
        if (sourceEnded) {
            timeline.close = Date.now();
            if (onEnd != null) {
                onEnd(endErr);
            }
        }
    };
    const streamSource = pushable({
        onEnd: onSourceEnd
    });
    const stream = {
        // Close for both Reading and Writing
        close: () => {
            log$T.trace('%s stream %s close', type, streamName);
            stream.closeRead();
            stream.closeWrite();
        },
        // Close for reading
        closeRead: () => {
            log$T.trace('%s stream %s closeRead', type, streamName);
            if (sourceEnded) {
                return;
            }
            streamSource.end();
        },
        // Close for writing
        closeWrite: () => {
            log$T.trace('%s stream %s closeWrite', type, streamName);
            if (sinkEnded) {
                return;
            }
            closeController.abort();
            try {
                send({ id, type: Types.CLOSE });
            }
            catch (err) {
                log$T.trace('%s stream %s error sending close', type, name, err);
            }
            onSinkEnd();
        },
        // Close for reading and writing (local error)
        abort: (err) => {
            log$T.trace('%s stream %s abort', type, streamName, err);
            // End the source with the passed error
            streamSource.end(err);
            abortController.abort();
            onSinkEnd(err);
        },
        // Close immediately for reading and writing (remote error)
        reset: () => {
            const err = errCode(new Error('stream reset'), ERR_STREAM_RESET);
            resetController.abort();
            streamSource.end(err);
            onSinkEnd(err);
        },
        sink: async (source) => {
            if (sinkSunk) {
                throw errCode(new Error('sink already called on stream'), ERR_DOUBLE_SINK);
            }
            sinkSunk = true;
            if (sinkEnded) {
                throw errCode(new Error('stream closed for writing'), ERR_SINK_ENDED);
            }
            source = abortableSource(source, anySignal_2([
                abortController.signal,
                resetController.signal,
                closeController.signal
            ]));
            try {
                if (type === 'initiator') { // If initiator, open a new stream
                    send({ id, type: InitiatorMessageTypes.NEW_STREAM, data: new Uint8ArrayList(fromString$2(streamName)) });
                }
                for await (let data of source) {
                    while (data.length > 0) {
                        if (data.length <= maxMsgSize) {
                            send({ id, type: Types.MESSAGE, data: data instanceof Uint8Array ? new Uint8ArrayList(data) : data });
                            break;
                        }
                        data = data instanceof Uint8Array ? new Uint8ArrayList(data) : data;
                        send({ id, type: Types.MESSAGE, data: data.sublist(0, maxMsgSize) });
                        data.consume(maxMsgSize);
                    }
                }
            }
            catch (err) {
                if (err.type === 'aborted' && err.message === 'The operation was aborted') {
                    if (closeController.signal.aborted) {
                        return;
                    }
                    if (resetController.signal.aborted) {
                        err.message = 'stream reset';
                        err.code = ERR_STREAM_RESET;
                    }
                    if (abortController.signal.aborted) {
                        err.message = 'stream aborted';
                        err.code = ERR_STREAM_ABORT;
                    }
                }
                // Send no more data if this stream was remotely reset
                if (err.code === ERR_STREAM_RESET) {
                    log$T.trace('%s stream %s reset', type, name);
                }
                else {
                    log$T.trace('%s stream %s error', type, name, err);
                    try {
                        send({ id, type: Types.RESET });
                    }
                    catch (err) {
                        log$T.trace('%s stream %s error sending reset', type, name, err);
                    }
                }
                streamSource.end(err);
                onSinkEnd(err);
                return;
            }
            try {
                send({ id, type: Types.CLOSE });
            }
            catch (err) {
                log$T.trace('%s stream %s error sending close', type, name, err);
            }
            onSinkEnd();
        },
        source: streamSource,
        sourcePush: (data) => {
            streamSource.push(data);
        },
        sourceReadableLength() {
            return streamSource.readableLength;
        },
        stat: {
            direction: type === 'initiator' ? 'outbound' : 'inbound',
            timeline
        },
        metadata: {},
        id: externalId
    };
    return stream;
}

var RateLimiterAbstract_1 = class RateLimiterAbstract {
  /**
   *
   * @param opts Object Defaults {
   *   points: 4, // Number of points
   *   duration: 1, // Per seconds
   *   blockDuration: 0, // Block if consumed more than points in current duration for blockDuration seconds
   *   execEvenly: false, // Execute allowed actions evenly over duration
   *   execEvenlyMinDelayMs: duration * 1000 / points, // ms, works with execEvenly=true option
   *   keyPrefix: 'rlflx',
   * }
   */
  constructor(opts = {}) {
    this.points = opts.points;
    this.duration = opts.duration;
    this.blockDuration = opts.blockDuration;
    this.execEvenly = opts.execEvenly;
    this.execEvenlyMinDelayMs = opts.execEvenlyMinDelayMs;
    this.keyPrefix = opts.keyPrefix;
  }

  get points() {
    return this._points;
  }

  set points(value) {
    this._points = value >= 0 ? value : 4;
  }

  get duration() {
    return this._duration;
  }

  set duration(value) {
    this._duration = typeof value === 'undefined' ? 1 : value;
  }

  get msDuration() {
    return this.duration * 1000;
  }

  get blockDuration() {
    return this._blockDuration;
  }

  set blockDuration(value) {
    this._blockDuration = typeof value === 'undefined' ? 0 : value;
  }

  get msBlockDuration() {
    return this.blockDuration * 1000;
  }

  get execEvenly() {
    return this._execEvenly;
  }

  set execEvenly(value) {
    this._execEvenly = typeof value === 'undefined' ? false : Boolean(value);
  }

  get execEvenlyMinDelayMs() {
    return this._execEvenlyMinDelayMs;
  }

  set execEvenlyMinDelayMs(value) {
    this._execEvenlyMinDelayMs = typeof value === 'undefined' ? Math.ceil(this.msDuration / this.points) : value;
  }

  get keyPrefix() {
    return this._keyPrefix;
  }

  set keyPrefix(value) {
    if (typeof value === 'undefined') {
      value = 'rlflx';
    }
    if (typeof value !== 'string') {
      throw new Error('keyPrefix must be string');
    }
    this._keyPrefix = value;
  }

  _getKeySecDuration(options = {}) {
    return options && options.customDuration >= 0
      ? options.customDuration
      : this.duration;
  }

  getKey(key) {
    return this.keyPrefix.length > 0 ? `${this.keyPrefix}:${key}` : key;
  }

  parseKey(rlKey) {
    return rlKey.substring(this.keyPrefix.length);
  }

  consume() {
    throw new Error("You have to implement the method 'consume'!");
  }

  penalty() {
    throw new Error("You have to implement the method 'penalty'!");
  }

  reward() {
    throw new Error("You have to implement the method 'reward'!");
  }

  get() {
    throw new Error("You have to implement the method 'get'!");
  }

  set() {
    throw new Error("You have to implement the method 'set'!");
  }

  block() {
    throw new Error("You have to implement the method 'block'!");
  }

  delete() {
    throw new Error("You have to implement the method 'delete'!");
  }
};

var BlockedKeys_1$1 = class BlockedKeys {
  constructor() {
    this._keys = {}; // {'key': 1526279430331}
    this._addedKeysAmount = 0;
  }

  collectExpired() {
    const now = Date.now();

    Object.keys(this._keys).forEach((key) => {
      if (this._keys[key] <= now) {
        delete this._keys[key];
      }
    });

    this._addedKeysAmount = Object.keys(this._keys).length;
  }

  /**
   * Add new blocked key
   *
   * @param key String
   * @param sec Number
   */
  add(key, sec) {
    this.addMs(key, sec * 1000);
  }

  /**
   * Add new blocked key for ms
   *
   * @param key String
   * @param ms Number
   */
  addMs(key, ms) {
    this._keys[key] = Date.now() + ms;
    this._addedKeysAmount++;
    if (this._addedKeysAmount > 999) {
      this.collectExpired();
    }
  }

  /**
   * 0 means not blocked
   *
   * @param key
   * @returns {number}
   */
  msBeforeExpire(key) {
    const expire = this._keys[key];

    if (expire && expire >= Date.now()) {
      this.collectExpired();
      const now = Date.now();
      return expire >= now ? expire - now : 0;
    }

    return 0;
  }

  /**
   * If key is not given, delete all data in memory
   * 
   * @param {string|undefined} key
   */
  delete(key) {
    if (key) {
      delete this._keys[key];
    } else {
      Object.keys(this._keys).forEach((key) => {
        delete this._keys[key];
      });
    }
  }
};

const BlockedKeys$1 = BlockedKeys_1$1;

var BlockedKeys_1 = BlockedKeys$1;

var RateLimiterRes_1 = class RateLimiterRes {
  constructor(remainingPoints, msBeforeNext, consumedPoints, isFirstInDuration) {
    this.remainingPoints = typeof remainingPoints === 'undefined' ? 0 : remainingPoints; // Remaining points in current duration
    this.msBeforeNext = typeof msBeforeNext === 'undefined' ? 0 : msBeforeNext; // Milliseconds before next action
    this.consumedPoints = typeof consumedPoints === 'undefined' ? 0 : consumedPoints; // Consumed points in current duration
    this.isFirstInDuration = typeof isFirstInDuration === 'undefined' ? false : isFirstInDuration;
  }

  get msBeforeNext() {
    return this._msBeforeNext;
  }

  set msBeforeNext(ms) {
    this._msBeforeNext = ms;
    return this;
  }

  get remainingPoints() {
    return this._remainingPoints;
  }

  set remainingPoints(p) {
    this._remainingPoints = p;
    return this;
  }

  get consumedPoints() {
    return this._consumedPoints;
  }

  set consumedPoints(p) {
    this._consumedPoints = p;
    return this;
  }

  get isFirstInDuration() {
    return this._isFirstInDuration;
  }

  set isFirstInDuration(value) {
    this._isFirstInDuration = Boolean(value);
  }

  _getDecoratedProperties() {
    return {
      remainingPoints: this.remainingPoints,
      msBeforeNext: this.msBeforeNext,
      consumedPoints: this.consumedPoints,
      isFirstInDuration: this.isFirstInDuration,
    };
  }

  [Symbol.for("nodejs.util.inspect.custom")]() {
    return this._getDecoratedProperties();
  }

  toString() {
    return JSON.stringify(this._getDecoratedProperties());
  }

  toJSON() {
    return this._getDecoratedProperties();
  }
};

const RateLimiterAbstract$3 = RateLimiterAbstract_1;
const BlockedKeys = BlockedKeys_1;
const RateLimiterRes$b = RateLimiterRes_1;

var RateLimiterStoreAbstract_1 = class RateLimiterStoreAbstract extends RateLimiterAbstract$3 {
  /**
   *
   * @param opts Object Defaults {
   *   ... see other in RateLimiterAbstract
   *
   *   inMemoryBlockOnConsumed: 40, // Number of points when key is blocked
   *   inMemoryBlockDuration: 10, // Block duration in seconds
   *   insuranceLimiter: RateLimiterAbstract
   * }
   */
  constructor(opts = {}) {
    super(opts);

    this.inMemoryBlockOnConsumed = opts.inMemoryBlockOnConsumed || opts.inmemoryBlockOnConsumed;
    this.inMemoryBlockDuration = opts.inMemoryBlockDuration || opts.inmemoryBlockDuration;
    this.insuranceLimiter = opts.insuranceLimiter;
    this._inMemoryBlockedKeys = new BlockedKeys();
  }

  get client() {
    return this._client;
  }

  set client(value) {
    if (typeof value === 'undefined') {
      throw new Error('storeClient is not set');
    }
    this._client = value;
  }

  /**
   * Have to be launched after consume
   * It blocks key and execute evenly depending on result from store
   *
   * It uses _getRateLimiterRes function to prepare RateLimiterRes from store result
   *
   * @param resolve
   * @param reject
   * @param rlKey
   * @param changedPoints
   * @param storeResult
   * @param {Object} options
   * @private
   */
  _afterConsume(resolve, reject, rlKey, changedPoints, storeResult, options = {}) {
    const res = this._getRateLimiterRes(rlKey, changedPoints, storeResult);

    if (this.inMemoryBlockOnConsumed > 0 && !(this.inMemoryBlockDuration > 0)
      && res.consumedPoints >= this.inMemoryBlockOnConsumed
    ) {
      this._inMemoryBlockedKeys.addMs(rlKey, res.msBeforeNext);
      if (res.consumedPoints > this.points) {
        return reject(res);
      } else {
        return resolve(res)
      }
    } else if (res.consumedPoints > this.points) {
      let blockPromise = Promise.resolve();
      // Block only first time when consumed more than points
      if (this.blockDuration > 0 && res.consumedPoints <= (this.points + changedPoints)) {
        res.msBeforeNext = this.msBlockDuration;
        blockPromise = this._block(rlKey, res.consumedPoints, this.msBlockDuration, options);
      }

      if (this.inMemoryBlockOnConsumed > 0 && res.consumedPoints >= this.inMemoryBlockOnConsumed) {
        // Block key for this.inMemoryBlockDuration seconds
        this._inMemoryBlockedKeys.add(rlKey, this.inMemoryBlockDuration);
        res.msBeforeNext = this.msInMemoryBlockDuration;
      }

      blockPromise
        .then(() => {
          reject(res);
        })
        .catch((err) => {
          reject(err);
        });
    } else if (this.execEvenly && res.msBeforeNext > 0 && !res.isFirstInDuration) {
      let delay = Math.ceil(res.msBeforeNext / (res.remainingPoints + 2));
      if (delay < this.execEvenlyMinDelayMs) {
        delay = res.consumedPoints * this.execEvenlyMinDelayMs;
      }

      setTimeout(resolve, delay, res);
    } else {
      resolve(res);
    }
  }

  _handleError(err, funcName, resolve, reject, key, data = false, options = {}) {
    if (!(this.insuranceLimiter instanceof RateLimiterAbstract$3)) {
      reject(err);
    } else {
      this.insuranceLimiter[funcName](key, data, options)
        .then((res) => {
          resolve(res);
        })
        .catch((res) => {
          reject(res);
        });
    }
  }

  /**
   * @deprecated Use camelCase version
   * @returns {BlockedKeys}
   * @private
   */
  get _inmemoryBlockedKeys() {
    return this._inMemoryBlockedKeys
  }

  /**
   * @deprecated Use camelCase version
   * @param rlKey
   * @returns {number}
   */
  getInmemoryBlockMsBeforeExpire(rlKey) {
    return this.getInMemoryBlockMsBeforeExpire(rlKey)
  }

  /**
   * @deprecated Use camelCase version
   * @returns {number|number}
   */
  get inmemoryBlockOnConsumed() {
    return this.inMemoryBlockOnConsumed;
  }

  /**
   * @deprecated Use camelCase version
   * @param value
   */
  set inmemoryBlockOnConsumed(value) {
    this.inMemoryBlockOnConsumed = value;
  }

  /**
   * @deprecated Use camelCase version
   * @returns {number|number}
   */
  get inmemoryBlockDuration() {
    return this.inMemoryBlockDuration;
  }

  /**
   * @deprecated Use camelCase version
   * @param value
   */
  set inmemoryBlockDuration(value) {
    this.inMemoryBlockDuration = value;
  }

  /**
   * @deprecated Use camelCase version
   * @returns {number}
   */
  get msInmemoryBlockDuration() {
    return this.inMemoryBlockDuration * 1000;
  }

  getInMemoryBlockMsBeforeExpire(rlKey) {
    if (this.inMemoryBlockOnConsumed > 0) {
      return this._inMemoryBlockedKeys.msBeforeExpire(rlKey);
    }

    return 0;
  }

  get inMemoryBlockOnConsumed() {
    return this._inMemoryBlockOnConsumed;
  }

  set inMemoryBlockOnConsumed(value) {
    this._inMemoryBlockOnConsumed = value ? parseInt(value) : 0;
    if (this.inMemoryBlockOnConsumed > 0 && this.points > this.inMemoryBlockOnConsumed) {
      throw new Error('inMemoryBlockOnConsumed option must be greater or equal "points" option');
    }
  }

  get inMemoryBlockDuration() {
    return this._inMemoryBlockDuration;
  }

  set inMemoryBlockDuration(value) {
    this._inMemoryBlockDuration = value ? parseInt(value) : 0;
    if (this.inMemoryBlockDuration > 0 && this.inMemoryBlockOnConsumed === 0) {
      throw new Error('inMemoryBlockOnConsumed option must be set up');
    }
  }

  get msInMemoryBlockDuration() {
    return this._inMemoryBlockDuration * 1000;
  }

  get insuranceLimiter() {
    return this._insuranceLimiter;
  }

  set insuranceLimiter(value) {
    if (typeof value !== 'undefined' && !(value instanceof RateLimiterAbstract$3)) {
      throw new Error('insuranceLimiter must be instance of RateLimiterAbstract');
    }
    this._insuranceLimiter = value;
    if (this._insuranceLimiter) {
      this._insuranceLimiter.blockDuration = this.blockDuration;
      this._insuranceLimiter.execEvenly = this.execEvenly;
    }
  }

  /**
   * Block any key for secDuration seconds
   *
   * @param key
   * @param secDuration
   * @param {Object} options
   *
   * @return Promise<RateLimiterRes>
   */
  block(key, secDuration, options = {}) {
    const msDuration = secDuration * 1000;
    return this._block(this.getKey(key), this.points + 1, msDuration, options);
  }

  /**
   * Set points by key for any duration
   *
   * @param key
   * @param points
   * @param secDuration
   * @param {Object} options
   *
   * @return Promise<RateLimiterRes>
   */
  set(key, points, secDuration, options = {}) {
    const msDuration = (secDuration >= 0 ? secDuration : this.duration) * 1000;
    return this._block(this.getKey(key), points, msDuration, options);
  }

  /**
   *
   * @param key
   * @param pointsToConsume
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const rlKey = this.getKey(key);

      const inMemoryBlockMsBeforeExpire = this.getInMemoryBlockMsBeforeExpire(rlKey);
      if (inMemoryBlockMsBeforeExpire > 0) {
        return reject(new RateLimiterRes$b(0, inMemoryBlockMsBeforeExpire));
      }

      this._upsert(rlKey, pointsToConsume, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          this._afterConsume(resolve, reject, rlKey, pointsToConsume, res);
        })
        .catch((err) => {
          this._handleError(err, 'consume', resolve, reject, key, pointsToConsume, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param points
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  penalty(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, points, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          resolve(this._getRateLimiterRes(rlKey, points, res));
        })
        .catch((err) => {
          this._handleError(err, 'penalty', resolve, reject, key, points, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param points
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  reward(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, -points, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          resolve(this._getRateLimiterRes(rlKey, -points, res));
        })
        .catch((err) => {
          this._handleError(err, 'reward', resolve, reject, key, points, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param {Object} options
   * @returns Promise<RateLimiterRes>|null
   */
  get(key, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._get(rlKey, options)
        .then((res) => {
          if (res === null || typeof res === 'undefined') {
            resolve(null);
          } else {
            resolve(this._getRateLimiterRes(rlKey, 0, res));
          }
        })
        .catch((err) => {
          this._handleError(err, 'get', resolve, reject, key, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param {Object} options
   * @returns Promise<boolean>
   */
  delete(key, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._delete(rlKey, options)
        .then((res) => {
          this._inMemoryBlockedKeys.delete(rlKey);
          resolve(res);
        })
        .catch((err) => {
          this._handleError(err, 'delete', resolve, reject, key, options);
        });
    });
  }

  /**
   * Cleanup keys no-matter expired or not.
   */
  deleteInMemoryBlockedAll() {
    this._inMemoryBlockedKeys.delete();
  }

  /**
   * Get RateLimiterRes object filled depending on storeResult, which specific for exact store
   *
   * @param rlKey
   * @param changedPoints
   * @param storeResult
   * @private
   */
  _getRateLimiterRes(rlKey, changedPoints, storeResult) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_getRateLimiterRes'!");
  }

  /**
   * Block key for this.msBlockDuration milliseconds
   * Usually, it just prolongs lifetime of key
   *
   * @param rlKey
   * @param initPoints
   * @param msDuration
   * @param {Object} options
   *
   * @return Promise<any>
   */
  _block(rlKey, initPoints, msDuration, options = {}) {
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, initPoints, msDuration, true, options)
        .then(() => {
          resolve(new RateLimiterRes$b(0, msDuration > 0 ? msDuration : -1, initPoints));
        })
        .catch((err) => {
          this._handleError(err, 'block', resolve, reject, this.parseKey(rlKey), msDuration / 1000, options);
        });
    });
  }

  /**
   * Have to be implemented in every limiter
   * Resolve with raw result from Store OR null if rlKey is not set
   * or Reject with error
   *
   * @param rlKey
   * @param {Object} options
   * @private
   *
   * @return Promise<any>
   */
  _get(rlKey, options = {}) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_get'!");
  }

  /**
   * Have to be implemented
   * Resolve with true OR false if rlKey doesn't exist
   * or Reject with error
   *
   * @param rlKey
   * @param {Object} options
   * @private
   *
   * @return Promise<any>
   */
  _delete(rlKey, options = {}) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_delete'!");
  }

  /**
   * Have to be implemented
   * Resolve with object used for {@link _getRateLimiterRes} to generate {@link RateLimiterRes}
   *
   * @param {string} rlKey
   * @param {number} points
   * @param {number} msDuration
   * @param {boolean} forceExpire
   * @param {Object} options
   * @abstract
   *
   * @return Promise<Object>
   */
  _upsert(rlKey, points, msDuration, forceExpire = false, options = {}) {
    throw new Error("You have to implement the method '_upsert'!");
  }
};

const RateLimiterStoreAbstract$4 = RateLimiterStoreAbstract_1;
const RateLimiterRes$a = RateLimiterRes_1;

const incrTtlLuaScript = `redis.call('set', KEYS[1], 0, 'EX', ARGV[2], 'NX') \
local consumed = redis.call('incrby', KEYS[1], ARGV[1]) \
local ttl = redis.call('pttl', KEYS[1]) \
if ttl == -1 then \
  redis.call('expire', KEYS[1], ARGV[2]) \
  ttl = 1000 * ARGV[2] \
end \
return {consumed, ttl} \
`;

let RateLimiterRedis$1 = class RateLimiterRedis extends RateLimiterStoreAbstract$4 {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   redis: RedisClient
   *   rejectIfRedisNotReady: boolean = false - reject / invoke insuranceLimiter immediately when redis connection is not "ready"
   * }
   */
  constructor(opts) {
    super(opts);
    if (opts.redis) {
      this.client = opts.redis;
    } else {
      this.client = opts.storeClient;
    }

    this._rejectIfRedisNotReady = !!opts.rejectIfRedisNotReady;

    if (typeof this.client.defineCommand === 'function') {
      this.client.defineCommand("rlflxIncr", {
        numberOfKeys: 1,
        lua: incrTtlLuaScript,
      });
    }
  }

  /**
   * Prevent actual redis call if redis connection is not ready
   * Because of different connection state checks for ioredis and node-redis, only this clients would be actually checked.
   * For any other clients all the requests would be passed directly to redis client
   * @return {boolean}
   * @private
   */
  _isRedisReady() {
    if (!this._rejectIfRedisNotReady) {
      return true;
    }
    // ioredis client
    if (this.client.status && this.client.status !== 'ready') {
      return false;
    }
    // node-redis client
    if (typeof this.client.isReady === 'function' && !this.client.isReady()) {
      return false;
    }
    return true;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    let [consumed, resTtlMs] = result;
    // Support ioredis results format
    if (Array.isArray(consumed)) {
      [, consumed] = consumed;
      [, resTtlMs] = resTtlMs;
    }

    const res = new RateLimiterRes$a();
    res.consumedPoints = parseInt(consumed);
    res.isFirstInDuration = res.consumedPoints === changedPoints;
    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = resTtlMs;

    return res;
  }

  _upsert(rlKey, points, msDuration, forceExpire = false) {
    return new Promise((resolve, reject) => {
      if (!this._isRedisReady()) {
        return reject(new Error('Redis connection is not ready'));
      }

      const secDuration = Math.floor(msDuration / 1000);
      const multi = this.client.multi();
      if (forceExpire) {
        if (secDuration > 0) {
          multi.set(rlKey, points, 'EX', secDuration);
        } else {
          multi.set(rlKey, points);
        }

        multi.pttl(rlKey)
          .exec((err, res) => {
            if (err) {
              return reject(err);
            }

            return resolve(res);
          });
      } else {
        if (secDuration > 0) {
          const incrCallback = function(err, result) {
            if (err) {
              return reject(err);
            }

            return resolve(result);
          };

          if (typeof this.client.rlflxIncr === 'function') {
            this.client.rlflxIncr(rlKey, points, secDuration, incrCallback);
          } else {
            this.client.eval(incrTtlLuaScript, 1, rlKey, points, secDuration, incrCallback);
          }
        } else {
          multi.incrby(rlKey, points)
            .pttl(rlKey)
            .exec((err, res) => {
              if (err) {
                return reject(err);
              }

              return resolve(res);
            });
        }
      }
    });
  }

  _get(rlKey) {
    return new Promise((resolve, reject) => {
      if (!this._isRedisReady()) {
        return reject(new Error('Redis connection is not ready'));
      }

      this.client
        .multi()
        .get(rlKey)
        .pttl(rlKey)
        .exec((err, res) => {
          if (err) {
            reject(err);
          } else {
            const [points] = res;
            if (points === null) {
              return resolve(null)
            }

            resolve(res);
          }
        });
    });
  }

  _delete(rlKey) {
    return new Promise((resolve, reject) => {
      this.client.del(rlKey, (err, res) => {
        if (err) {
          reject(err);
        } else {
          resolve(res > 0);
        }
      });
    });
  }
};

var RateLimiterRedis_1 = RateLimiterRedis$1;

const RateLimiterStoreAbstract$3 = RateLimiterStoreAbstract_1;
const RateLimiterRes$9 = RateLimiterRes_1;

/**
 * Get MongoDB driver version as upsert options differ
 * @params {Object} Client instance
 * @returns {Object} Version Object containing major, feature & minor versions.
 */
function getDriverVersion(client) {
  try {
    const _client = client.client ? client.client : client;

    const { version } = _client.topology.s.options.metadata.driver;
    const _v = version.split('.').map(v => parseInt(v));

    return {
      major: _v[0],
      feature: _v[1],
      patch: _v[2],
    };
  } catch (err) {
    return { major: 0, feature: 0, patch: 0 };
  }
}

let RateLimiterMongo$1 = class RateLimiterMongo extends RateLimiterStoreAbstract$3 {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   indexKeyPrefix: {attr1: 1, attr2: 1}
   *   ... see other in RateLimiterStoreAbstract
   *
   *   mongo: MongoClient
   * }
   */
  constructor(opts) {
    super(opts);

    this.dbName = opts.dbName;
    this.tableName = opts.tableName;
    this.indexKeyPrefix = opts.indexKeyPrefix;

    if (opts.mongo) {
      this.client = opts.mongo;
    } else {
      this.client = opts.storeClient;
    }
    if (typeof this.client.then === 'function') {
      // If Promise
      this.client
        .then((conn) => {
          this.client = conn;
          this._initCollection();
          this._driverVersion = getDriverVersion(this.client);
        });
    } else {
      this._initCollection();
      this._driverVersion = getDriverVersion(this.client);
    }
  }

  get dbName() {
    return this._dbName;
  }

  set dbName(value) {
    this._dbName = typeof value === 'undefined' ? RateLimiterMongo.getDbName() : value;
  }

  static getDbName() {
    return 'node-rate-limiter-flexible';
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get client() {
    return this._client;
  }

  set client(value) {
    if (typeof value === 'undefined') {
      throw new Error('mongo is not set');
    }
    this._client = value;
  }

  get indexKeyPrefix() {
    return this._indexKeyPrefix;
  }

  set indexKeyPrefix(obj) {
    this._indexKeyPrefix = obj || {};
  }

  _initCollection() {
    const db = typeof this.client.db === 'function'
      ? this.client.db(this.dbName)
      : this.client;

    const collection = db.collection(this.tableName);
    collection.createIndex({ expire: -1 }, { expireAfterSeconds: 0 });
    collection.createIndex(Object.assign({}, this.indexKeyPrefix, { key: 1 }), { unique: true });

    this._collection = collection;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$9();

    let doc;
    if (typeof result.value === 'undefined') {
      doc = result;
    } else {
      doc = result.value;
    }

    res.isFirstInDuration = doc.points === changedPoints;
    res.consumedPoints = doc.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = doc.expire !== null
      ? Math.max(new Date(doc.expire).getTime() - Date.now(), 0)
      : -1;

    return res;
  }

  _upsert(key, points, msDuration, forceExpire = false, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};

    let where;
    let upsertData;
    if (forceExpire) {
      where = { key };
      where = Object.assign(where, docAttrs);
      upsertData = {
        $set: {
          key,
          points,
          expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
        },
      };
      upsertData.$set = Object.assign(upsertData.$set, docAttrs);
    } else {
      where = {
        $or: [
          { expire: { $gt: new Date() } },
          { expire: { $eq: null } },
        ],
        key,
      };
      where = Object.assign(where, docAttrs);
      upsertData = {
        $setOnInsert: {
          key,
          expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
        },
        $inc: { points },
      };
      upsertData.$setOnInsert = Object.assign(upsertData.$setOnInsert, docAttrs);
    }

    // Options for collection updates differ between driver versions
    const upsertOptions = {
      upsert: true,
    };
    if ((this._driverVersion.major >= 4) ||
        (this._driverVersion.major === 3 &&
          (this._driverVersion.feature >=7) || 
          (this._driverVersion.feature >= 6 && 
              this._driverVersion.patch >= 7 ))) 
    {
      upsertOptions.returnDocument = 'after';
    } else {
      upsertOptions.returnOriginal = false;
    }

    /*
     * 1. Find actual limit and increment points
     * 2. If limit expired, but Mongo doesn't clean doc by TTL yet, try to replace limit doc completely
     * 3. If 2 or more Mongo threads try to insert the new limit doc, only the first succeed
     * 4. Try to upsert from step 1. Actual limit is created now, points are incremented without problems
     */
    return new Promise((resolve, reject) => {
      this._collection.findOneAndUpdate(
        where,
        upsertData,
        upsertOptions
      ).then((res) => {
        resolve(res);
      }).catch((errUpsert) => {
        if (errUpsert && errUpsert.code === 11000) { // E11000 duplicate key error collection
          const replaceWhere = Object.assign({ // try to replace OLD limit doc
            $or: [
              { expire: { $lte: new Date() } },
              { expire: { $eq: null } },
            ],
            key,
          }, docAttrs);

          const replaceTo = {
            $set: Object.assign({
              key,
              points,
              expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
            }, docAttrs)
          };

          this._collection.findOneAndUpdate(
            replaceWhere,
            replaceTo,
            upsertOptions
          ).then((res) => {
            resolve(res);
          }).catch((errReplace) => {
            if (errReplace && errReplace.code === 11000) { // E11000 duplicate key error collection
              this._upsert(key, points, msDuration, forceExpire)
                .then(res => resolve(res))
                .catch(err => reject(err));
            } else {
              reject(errReplace);
            }
          });
        } else {
          reject(errUpsert);
        }
      });
    });
  }

  _get(rlKey, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};

    const where = Object.assign({
      key: rlKey,
      $or: [
        { expire: { $gt: new Date() } },
        { expire: { $eq: null } },
      ],
    }, docAttrs);

    return this._collection.findOne(where);
  }

  _delete(rlKey, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};
    const where = Object.assign({ key: rlKey }, docAttrs);

    return this._collection.deleteOne(where)
      .then(res => res.deletedCount > 0);
  }
};

var RateLimiterMongo_1 = RateLimiterMongo$1;

const RateLimiterStoreAbstract$2 = RateLimiterStoreAbstract_1;
const RateLimiterRes$8 = RateLimiterRes_1;

let RateLimiterMySQL$1 = class RateLimiterMySQL extends RateLimiterStoreAbstract$2 {
  /**
   * @callback callback
   * @param {Object} err
   *
   * @param {Object} opts
   * @param {callback} cb
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: anySqlClient,
   *   storeType: 'knex', // required only for Knex instance
   *   dbName: 'string',
   *   tableName: 'string',
   * }
   */
  constructor(opts, cb = null) {
    super(opts);

    this.client = opts.storeClient;
    this.clientType = opts.storeType;

    this.dbName = opts.dbName;
    this.tableName = opts.tableName;

    this.clearExpiredByTimeout = opts.clearExpiredByTimeout;

    this.tableCreated = opts.tableCreated;
    if (!this.tableCreated) {
      this._createDbAndTable()
        .then(() => {
          this.tableCreated = true;
          if (this.clearExpiredByTimeout) {
            this._clearExpiredHourAgo();
          }
          if (typeof cb === 'function') {
            cb();
          }
        })
        .catch((err) => {
          if (typeof cb === 'function') {
            cb(err);
          } else {
            throw err;
          }
        });
    } else {
      if (this.clearExpiredByTimeout) {
        this._clearExpiredHourAgo();
      }
      if (typeof cb === 'function') {
        cb();
      }
    }
  }

  clearExpired(expire) {
    return new Promise((resolve) => {
      this._getConnection()
        .then((conn) => {
          conn.query(`DELETE FROM ??.?? WHERE expire < ?`, [this.dbName, this.tableName, expire], () => {
            this._releaseConnection(conn);
            resolve();
          });
        })
        .catch(() => {
          resolve();
        });
    });
  }

  _clearExpiredHourAgo() {
    if (this._clearExpiredTimeoutId) {
      clearTimeout(this._clearExpiredTimeoutId);
    }
    this._clearExpiredTimeoutId = setTimeout(() => {
      this.clearExpired(Date.now() - 3600000) // Never rejected
        .then(() => {
          this._clearExpiredHourAgo();
        });
    }, 300000);
    this._clearExpiredTimeoutId.unref();
  }

  /**
   *
   * @return Promise<any>
   * @private
   */
  _getConnection() {
    switch (this.clientType) {
      case 'pool':
        return new Promise((resolve, reject) => {
          this.client.getConnection((errConn, conn) => {
            if (errConn) {
              return reject(errConn);
            }

            resolve(conn);
          });
        });
      case 'sequelize':
        return this.client.connectionManager.getConnection();
      case 'knex':
        return this.client.client.acquireConnection();
      default:
        return Promise.resolve(this.client);
    }
  }

  _releaseConnection(conn) {
    switch (this.clientType) {
      case 'pool':
        return conn.release();
      case 'sequelize':
        return this.client.connectionManager.releaseConnection(conn);
      case 'knex':
        return this.client.client.releaseConnection(conn);
      default:
        return true;
    }
  }

  /**
   *
   * @returns {Promise<any>}
   * @private
   */
  _createDbAndTable() {
    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(`CREATE DATABASE IF NOT EXISTS \`${this.dbName}\`;`, (errDb) => {
            if (errDb) {
              this._releaseConnection(conn);
              return reject(errDb);
            }
            conn.query(this._getCreateTableStmt(), (err) => {
              if (err) {
                this._releaseConnection(conn);
                return reject(err);
              }
              this._releaseConnection(conn);
              resolve();
            });
          });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _getCreateTableStmt() {
    return `CREATE TABLE IF NOT EXISTS \`${this.dbName}\`.\`${this.tableName}\` (` +
      '`key` VARCHAR(255) CHARACTER SET utf8 NOT NULL,' +
      '`points` INT(9) NOT NULL default 0,' +
      '`expire` BIGINT UNSIGNED,' +
      'PRIMARY KEY (`key`)' +
      ') ENGINE = INNODB;';
  }

  get clientType() {
    return this._clientType;
  }

  set clientType(value) {
    if (typeof value === 'undefined') {
      if (this.client.constructor.name === 'Connection') {
        value = 'connection';
      } else if (this.client.constructor.name === 'Pool') {
        value = 'pool';
      } else if (this.client.constructor.name === 'Sequelize') {
        value = 'sequelize';
      } else {
        throw new Error('storeType is not defined');
      }
    }
    this._clientType = value.toLowerCase();
  }

  get dbName() {
    return this._dbName;
  }

  set dbName(value) {
    this._dbName = typeof value === 'undefined' ? 'rtlmtrflx' : value;
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get tableCreated() {
    return this._tableCreated
  }

  set tableCreated(value) {
    this._tableCreated = typeof value === 'undefined' ? false : !!value;
  }

  get clearExpiredByTimeout() {
    return this._clearExpiredByTimeout;
  }

  set clearExpiredByTimeout(value) {
    this._clearExpiredByTimeout = typeof value === 'undefined' ? true : Boolean(value);
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$8();
    const [row] = result;

    res.isFirstInDuration = changedPoints === row.points;
    res.consumedPoints = res.isFirstInDuration ? changedPoints : row.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = row.expire
      ? Math.max(row.expire - Date.now(), 0)
      : -1;

    return res;
  }

  _upsertTransaction(conn, key, points, msDuration, forceExpire) {
    return new Promise((resolve, reject) => {
      conn.query('BEGIN', (errBegin) => {
        if (errBegin) {
          conn.rollback();

          return reject(errBegin);
        }

        const dateNow = Date.now();
        const newExpire = msDuration > 0 ? dateNow + msDuration : null;

        let q;
        let values;
        if (forceExpire) {
          q = `INSERT INTO ??.?? VALUES (?, ?, ?)
          ON DUPLICATE KEY UPDATE 
            points = ?, 
            expire = ?;`;
          values = [
            this.dbName, this.tableName, key, points, newExpire,
            points,
            newExpire,
          ];
        } else {
          q = `INSERT INTO ??.?? VALUES (?, ?, ?)
          ON DUPLICATE KEY UPDATE 
            points = IF(expire <= ?, ?, points + (?)), 
            expire = IF(expire <= ?, ?, expire);`;
          values = [
            this.dbName, this.tableName, key, points, newExpire,
            dateNow, points, points,
            dateNow, newExpire,
          ];
        }

        conn.query(q, values, (errUpsert) => {
          if (errUpsert) {
            conn.rollback();

            return reject(errUpsert);
          }
          conn.query('SELECT points, expire FROM ??.?? WHERE `key` = ?;', [this.dbName, this.tableName, key], (errSelect, res) => {
            if (errSelect) {
              conn.rollback();

              return reject(errSelect);
            }

            conn.query('COMMIT', (err) => {
              if (err) {
                conn.rollback();

                return reject(err);
              }

              resolve(res);
            });
          });
        });
      });
    });
  }

  _upsert(key, points, msDuration, forceExpire = false) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          this._upsertTransaction(conn, key, points, msDuration, forceExpire)
            .then((res) => {
              resolve(res);
              this._releaseConnection(conn);
            })
            .catch((err) => {
              reject(err);
              this._releaseConnection(conn);
            });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _get(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(
            'SELECT points, expire FROM ??.?? WHERE `key` = ? AND (`expire` > ? OR `expire` IS NULL)',
            [this.dbName, this.tableName, rlKey, Date.now()],
            (err, res) => {
              if (err) {
                reject(err);
              } else if (res.length === 0) {
                resolve(null);
              } else {
                resolve(res);
              }

              this._releaseConnection(conn);
            } // eslint-disable-line
          );
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _delete(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(
            'DELETE FROM ??.?? WHERE `key` = ?',
            [this.dbName, this.tableName, rlKey],
            (err, res) => {
              if (err) {
                reject(err);
              } else {
                resolve(res.affectedRows > 0);
              }

              this._releaseConnection(conn);
            } // eslint-disable-line
          );
        })
        .catch((err) => {
          reject(err);
        });
    });
  }
};

var RateLimiterMySQL_1 = RateLimiterMySQL$1;

const RateLimiterStoreAbstract$1 = RateLimiterStoreAbstract_1;
const RateLimiterRes$7 = RateLimiterRes_1;

let RateLimiterPostgres$1 = class RateLimiterPostgres extends RateLimiterStoreAbstract$1 {
  /**
   * @callback callback
   * @param {Object} err
   *
   * @param {Object} opts
   * @param {callback} cb
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: postgresClient,
   *   storeType: 'knex', // required only for Knex instance
   *   tableName: 'string',
   * }
   */
  constructor(opts, cb = null) {
    super(opts);

    this.client = opts.storeClient;
    this.clientType = opts.storeType;

    this.tableName = opts.tableName;

    this.clearExpiredByTimeout = opts.clearExpiredByTimeout;

    this.tableCreated = opts.tableCreated;
    if (!this.tableCreated) {
      this._createTable()
        .then(() => {
          this.tableCreated = true;
          if (this.clearExpiredByTimeout) {
            this._clearExpiredHourAgo();
          }
          if (typeof cb === 'function') {
            cb();
          }
        })
        .catch((err) => {
          if (typeof cb === 'function') {
            cb(err);
          } else {
            throw err;
          }
        });
    } else {
      if (typeof cb === 'function') {
        cb();
      }
    }
  }

  clearExpired(expire) {
    return new Promise((resolve) => {
      const q = {
        name: 'rlflx-clear-expired',
        text: `DELETE FROM ${this.tableName} WHERE expire < $1`,
        values: [expire],
      };
      this._query(q)
        .then(() => {
          resolve();
        })
        .catch(() => {
          // Deleting expired query is not critical
          resolve();
        });
    });
  }

  /**
   * Delete all rows expired 1 hour ago once per 5 minutes
   *
   * @private
   */
  _clearExpiredHourAgo() {
    if (this._clearExpiredTimeoutId) {
      clearTimeout(this._clearExpiredTimeoutId);
    }
    this._clearExpiredTimeoutId = setTimeout(() => {
      this.clearExpired(Date.now() - 3600000) // Never rejected
        .then(() => {
          this._clearExpiredHourAgo();
        });
    }, 300000);
    this._clearExpiredTimeoutId.unref();
  }

  /**
   *
   * @return Promise<any>
   * @private
   */
  _getConnection() {
    switch (this.clientType) {
      case 'pool':
        return Promise.resolve(this.client);
      case 'sequelize':
        return this.client.connectionManager.getConnection();
      case 'knex':
        return this.client.client.acquireConnection();
      case 'typeorm':
        return Promise.resolve(this.client.driver.master);
      default:
        return Promise.resolve(this.client);
    }
  }

  _releaseConnection(conn) {
    switch (this.clientType) {
      case 'pool':
        return true;
      case 'sequelize':
        return this.client.connectionManager.releaseConnection(conn);
      case 'knex':
        return this.client.client.releaseConnection(conn);
      case 'typeorm':
        return true;
      default:
        return true;
    }
  }

  /**
   *
   * @returns {Promise<any>}
   * @private
   */
  _createTable() {
    return new Promise((resolve, reject) => {
      this._query({
        text: this._getCreateTableStmt(),
      })
        .then(() => {
          resolve();
        })
        .catch((err) => {
          if (err.code === '23505') {
            // Error: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
            // Postgres doesn't handle concurrent table creation
            // It is supposed, that table is created by another worker
            resolve();
          } else {
            reject(err);
          }
        });
    });
  }

  _getCreateTableStmt() {
    return `CREATE TABLE IF NOT EXISTS ${this.tableName} ( 
      key varchar(255) PRIMARY KEY,
      points integer NOT NULL DEFAULT 0,
      expire bigint
    );`;
  }

  get clientType() {
    return this._clientType;
  }

  set clientType(value) {
    const constructorName = this.client.constructor.name;

    if (typeof value === 'undefined') {
      if (constructorName === 'Client') {
        value = 'client';
      } else if (
        constructorName === 'Pool' ||
        constructorName === 'BoundPool'
      ) {
        value = 'pool';
      } else if (constructorName === 'Sequelize') {
        value = 'sequelize';
      } else {
        throw new Error('storeType is not defined');
      }
    }

    this._clientType = value.toLowerCase();
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get tableCreated() {
    return this._tableCreated
  }

  set tableCreated(value) {
    this._tableCreated = typeof value === 'undefined' ? false : !!value;
  }

  get clearExpiredByTimeout() {
    return this._clearExpiredByTimeout;
  }

  set clearExpiredByTimeout(value) {
    this._clearExpiredByTimeout = typeof value === 'undefined' ? true : Boolean(value);
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$7();
    const row = result.rows[0];

    res.isFirstInDuration = changedPoints === row.points;
    res.consumedPoints = res.isFirstInDuration ? changedPoints : row.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = row.expire
      ? Math.max(row.expire - Date.now(), 0)
      : -1;

    return res;
  }

  _query(q) {
    const prefix = this.tableName.toLowerCase();
    const queryObj = { name: `${prefix}:${q.name}`, text: q.text, values: q.values };
    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(queryObj)
            .then((res) => {
              resolve(res);
              this._releaseConnection(conn);
            })
            .catch((err) => {
              reject(err);
              this._releaseConnection(conn);
            });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _upsert(key, points, msDuration, forceExpire = false) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    const newExpire = msDuration > 0 ? Date.now() + msDuration : null;
    const expireQ = forceExpire
      ? ' $3 '
      : ` CASE
             WHEN ${this.tableName}.expire <= $4 THEN $3
             ELSE ${this.tableName}.expire
            END `;

    return this._query({
      name: forceExpire ? 'rlflx-upsert-force' : 'rlflx-upsert',
      text: `
            INSERT INTO ${this.tableName} VALUES ($1, $2, $3)
              ON CONFLICT(key) DO UPDATE SET
                points = CASE
                          WHEN (${this.tableName}.expire <= $4 OR 1=${forceExpire ? 1 : 0}) THEN $2
                          ELSE ${this.tableName}.points + ($2)
                         END,
                expire = ${expireQ}
            RETURNING points, expire;`,
      values: [key, points, newExpire, Date.now()],
    });
  }

  _get(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._query({
        name: 'rlflx-get',
        text: `
            SELECT points, expire FROM ${this.tableName} WHERE key = $1 AND (expire > $2 OR expire IS NULL);`,
        values: [rlKey, Date.now()],
      })
        .then((res) => {
          if (res.rowCount === 0) {
            res = null;
          }
          resolve(res);
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _delete(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return this._query({
      name: 'rlflx-delete',
      text: `DELETE FROM ${this.tableName} WHERE key = $1`,
      values: [rlKey],
    })
      .then(res => res.rowCount > 0);
  }
};

var RateLimiterPostgres_1 = RateLimiterPostgres$1;

var Record_1 = class Record {
  /**
   *
   * @param value int
   * @param expiresAt Date|int
   * @param timeoutId
   */
  constructor(value, expiresAt, timeoutId = null) {
    this.value = value;
    this.expiresAt = expiresAt;
    this.timeoutId = timeoutId;
  }

  get value() {
    return this._value;
  }

  set value(value) {
    this._value = parseInt(value);
  }

  get expiresAt() {
    return this._expiresAt;
  }

  set expiresAt(value) {
    if (!(value instanceof Date) && Number.isInteger(value)) {
      value = new Date(value);
    }
    this._expiresAt = value;
  }

  get timeoutId() {
    return this._timeoutId;
  }

  set timeoutId(value) {
    this._timeoutId = value;
  }
};

const Record = Record_1;
const RateLimiterRes$6 = RateLimiterRes_1;

var MemoryStorage_1 = class MemoryStorage {
  constructor() {
    /**
     * @type {Object.<string, Record>}
     * @private
     */
    this._storage = {};
  }

  incrby(key, value, durationSec) {
    if (this._storage[key]) {
      const msBeforeExpires = this._storage[key].expiresAt
        ? this._storage[key].expiresAt.getTime() - new Date().getTime()
        : -1;
      if (msBeforeExpires !== 0) {
        // Change value
        this._storage[key].value = this._storage[key].value + value;

        return new RateLimiterRes$6(0, msBeforeExpires, this._storage[key].value, false);
      }

      return this.set(key, value, durationSec);
    }
    return this.set(key, value, durationSec);
  }

  set(key, value, durationSec) {
    const durationMs = durationSec * 1000;

    if (this._storage[key] && this._storage[key].timeoutId) {
      clearTimeout(this._storage[key].timeoutId);
    }

    this._storage[key] = new Record(
      value,
      durationMs > 0 ? new Date(Date.now() + durationMs) : null
    );
    if (durationMs > 0) {
      this._storage[key].timeoutId = setTimeout(() => {
        delete this._storage[key];
      }, durationMs);
      if (this._storage[key].timeoutId.unref) {
        this._storage[key].timeoutId.unref();
      }
    }

    return new RateLimiterRes$6(0, durationMs === 0 ? -1 : durationMs, this._storage[key].value, true);
  }

  /**
   *
   * @param key
   * @returns {*}
   */
  get(key) {
    if (this._storage[key]) {
      const msBeforeExpires = this._storage[key].expiresAt
        ? this._storage[key].expiresAt.getTime() - new Date().getTime()
        : -1;
      return new RateLimiterRes$6(0, msBeforeExpires, this._storage[key].value, false);
    }
    return null;
  }

  /**
   *
   * @param key
   * @returns {boolean}
   */
  delete(key) {
    if (this._storage[key]) {
      if (this._storage[key].timeoutId) {
        clearTimeout(this._storage[key].timeoutId);
      }
      delete this._storage[key];
      return true;
    }
    return false;
  }
};

const RateLimiterAbstract$2 = RateLimiterAbstract_1;
const MemoryStorage = MemoryStorage_1;
const RateLimiterRes$5 = RateLimiterRes_1;

let RateLimiterMemory$2 = class RateLimiterMemory extends RateLimiterAbstract$2 {
  constructor(opts = {}) {
    super(opts);

    this._memoryStorage = new MemoryStorage();
  }
  /**
   *
   * @param key
   * @param pointsToConsume
   * @param {Object} options
   * @returns {Promise<RateLimiterRes>}
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const rlKey = this.getKey(key);
      const secDuration = this._getKeySecDuration(options);
      let res = this._memoryStorage.incrby(rlKey, pointsToConsume, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);

      if (res.consumedPoints > this.points) {
        // Block only first time when consumed more than points
        if (this.blockDuration > 0 && res.consumedPoints <= (this.points + pointsToConsume)) {
          // Block key
          res = this._memoryStorage.set(rlKey, res.consumedPoints, this.blockDuration);
        }
        reject(res);
      } else if (this.execEvenly && res.msBeforeNext > 0 && !res.isFirstInDuration) {
        // Execute evenly
        let delay = Math.ceil(res.msBeforeNext / (res.remainingPoints + 2));
        if (delay < this.execEvenlyMinDelayMs) {
          delay = res.consumedPoints * this.execEvenlyMinDelayMs;
        }

        setTimeout(resolve, delay, res);
      } else {
        resolve(res);
      }
    });
  }

  penalty(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve) => {
      const secDuration = this._getKeySecDuration(options);
      const res = this._memoryStorage.incrby(rlKey, points, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
      resolve(res);
    });
  }

  reward(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve) => {
      const secDuration = this._getKeySecDuration(options);
      const res = this._memoryStorage.incrby(rlKey, -points, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
      resolve(res);
    });
  }

  /**
   * Block any key for secDuration seconds
   *
   * @param key
   * @param secDuration
   */
  block(key, secDuration) {
    const msDuration = secDuration * 1000;
    const initPoints = this.points + 1;

    this._memoryStorage.set(this.getKey(key), initPoints, secDuration);
    return Promise.resolve(
      new RateLimiterRes$5(0, msDuration === 0 ? -1 : msDuration, initPoints)
    );
  }

  set(key, points, secDuration) {
    const msDuration = (secDuration >= 0 ? secDuration : this.duration) * 1000;

    this._memoryStorage.set(this.getKey(key), points, secDuration);
    return Promise.resolve(
      new RateLimiterRes$5(0, msDuration === 0 ? -1 : msDuration, points)
    );
  }

  get(key) {
    const res = this._memoryStorage.get(this.getKey(key));
    if (res !== null) {
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    }

    return Promise.resolve(res);
  }

  delete(key) {
    return Promise.resolve(this._memoryStorage.delete(this.getKey(key)));
  }
};

var RateLimiterMemory_1 = RateLimiterMemory$2;

/**
 * Implements rate limiting in cluster using built-in IPC
 *
 * Two classes are described here: master and worker
 * Master have to be create in the master process without any options.
 * Any number of rate limiters can be created in workers, but each rate limiter must be with unique keyPrefix
 *
 * Workflow:
 * 1. master rate limiter created in master process
 * 2. worker rate limiter sends 'init' message with necessary options during creating
 * 3. master receives options and adds new rate limiter by keyPrefix if it isn't created yet
 * 4. master sends 'init' back to worker's rate limiter
 * 5. worker can process requests immediately,
 *    but they will be postponed by 'workerWaitInit' until master sends 'init' to worker
 * 6. every request to worker rate limiter creates a promise
 * 7. if master doesn't response for 'timeout', promise is rejected
 * 8. master sends 'resolve' or 'reject' command to worker
 * 9. worker resolves or rejects promise depending on message from master
 *
 */

const cluster = require$$1;
const crypto$1 = require$$1;
const RateLimiterAbstract$1 = RateLimiterAbstract_1;
const RateLimiterMemory$1 = RateLimiterMemory_1;
const RateLimiterRes$4 = RateLimiterRes_1;

const channel = 'rate_limiter_flexible';
let masterInstance = null;

const masterSendToWorker = function (worker, msg, type, res) {
  let data;
  if (res === null || res === true || res === false) {
    data = res;
  } else {
    data = {
      remainingPoints: res.remainingPoints,
      msBeforeNext: res.msBeforeNext,
      consumedPoints: res.consumedPoints,
      isFirstInDuration: res.isFirstInDuration,
    };
  }
  worker.send({
    channel,
    keyPrefix: msg.keyPrefix, // which rate limiter exactly
    promiseId: msg.promiseId,
    type,
    data,
  });
};

const workerWaitInit = function (payload) {
  setTimeout(() => {
    if (this._initiated) {
      process.send(payload);
      // Promise will be removed by timeout if too long
    } else if (typeof this._promises[payload.promiseId] !== 'undefined') {
      workerWaitInit.call(this, payload);
    }
  }, 30);
};

const workerSendToMaster = function (func, promiseId, key, arg, opts) {
  const payload = {
    channel,
    keyPrefix: this.keyPrefix,
    func,
    promiseId,
    data: {
      key,
      arg,
      opts,
    },
  };

  if (!this._initiated) {
    // Wait init before sending messages to master
    workerWaitInit.call(this, payload);
  } else {
    process.send(payload);
  }
};

const masterProcessMsg = function (worker, msg) {
  if (!msg || msg.channel !== channel || typeof this._rateLimiters[msg.keyPrefix] === 'undefined') {
    return false;
  }

  let promise;

  switch (msg.func) {
    case 'consume':
      promise = this._rateLimiters[msg.keyPrefix].consume(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'penalty':
      promise = this._rateLimiters[msg.keyPrefix].penalty(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'reward':
      promise = this._rateLimiters[msg.keyPrefix].reward(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'block':
      promise = this._rateLimiters[msg.keyPrefix].block(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'get':
      promise = this._rateLimiters[msg.keyPrefix].get(msg.data.key, msg.data.opts);
      break;
    case 'delete':
      promise = this._rateLimiters[msg.keyPrefix].delete(msg.data.key, msg.data.opts);
      break;
    default:
      return false;
  }

  if (promise) {
    promise
      .then((res) => {
        masterSendToWorker(worker, msg, 'resolve', res);
      })
      .catch((rejRes) => {
        masterSendToWorker(worker, msg, 'reject', rejRes);
      });
  }
};

const workerProcessMsg = function (msg) {
  if (!msg || msg.channel !== channel || msg.keyPrefix !== this.keyPrefix) {
    return false;
  }

  if (this._promises[msg.promiseId]) {
    clearTimeout(this._promises[msg.promiseId].timeoutId);
    let res;
    if (msg.data === null || msg.data === true || msg.data === false) {
      res = msg.data;
    } else {
      res = new RateLimiterRes$4(
        msg.data.remainingPoints,
        msg.data.msBeforeNext,
        msg.data.consumedPoints,
        msg.data.isFirstInDuration // eslint-disable-line comma-dangle
      );
    }

    switch (msg.type) {
      case 'resolve':
        this._promises[msg.promiseId].resolve(res);
        break;
      case 'reject':
        this._promises[msg.promiseId].reject(res);
        break;
      default:
        throw new Error(`RateLimiterCluster: no such message type '${msg.type}'`);
    }

    delete this._promises[msg.promiseId];
  }
};
/**
 * Prepare options to send to master
 * Master will create rate limiter depending on options
 *
 * @returns {{points: *, duration: *, blockDuration: *, execEvenly: *, execEvenlyMinDelayMs: *, keyPrefix: *}}
 */
const getOpts = function () {
  return {
    points: this.points,
    duration: this.duration,
    blockDuration: this.blockDuration,
    execEvenly: this.execEvenly,
    execEvenlyMinDelayMs: this.execEvenlyMinDelayMs,
    keyPrefix: this.keyPrefix,
  };
};

const savePromise = function (resolve, reject) {
  const hrtime = process.hrtime();
  let promiseId = hrtime[0].toString() + hrtime[1].toString();

  if (typeof this._promises[promiseId] !== 'undefined') {
    promiseId += crypto$1.randomBytes(12).toString('base64');
  }

  this._promises[promiseId] = {
    resolve,
    reject,
    timeoutId: setTimeout(() => {
      delete this._promises[promiseId];
      reject(new Error('RateLimiterCluster timeout: no answer from master in time'));
    }, this.timeoutMs),
  };

  return promiseId;
};

let RateLimiterClusterMaster$1 = class RateLimiterClusterMaster {
  constructor() {
    if (masterInstance) {
      return masterInstance;
    }

    this._rateLimiters = {};

    cluster.setMaxListeners(0);

    cluster.on('message', (worker, msg) => {
      if (msg && msg.channel === channel && msg.type === 'init') {
        // If init request, check or create rate limiter by key prefix and send 'init' back to worker
        if (typeof this._rateLimiters[msg.opts.keyPrefix] === 'undefined') {
          this._rateLimiters[msg.opts.keyPrefix] = new RateLimiterMemory$1(msg.opts);
        }

        worker.send({
          channel,
          type: 'init',
          keyPrefix: msg.opts.keyPrefix,
        });
      } else {
        masterProcessMsg.call(this, worker, msg);
      }
    });

    masterInstance = this;
  }
};

let RateLimiterClusterMasterPM2$1 = class RateLimiterClusterMasterPM2 {
  constructor(pm2) {
    if (masterInstance) {
      return masterInstance;
    }

    this._rateLimiters = {};

    pm2.launchBus((err, pm2Bus) => {
      pm2Bus.on('process:msg', (packet) => {
        const msg = packet.raw;
        if (msg && msg.channel === channel && msg.type === 'init') {
          // If init request, check or create rate limiter by key prefix and send 'init' back to worker
          if (typeof this._rateLimiters[msg.opts.keyPrefix] === 'undefined') {
            this._rateLimiters[msg.opts.keyPrefix] = new RateLimiterMemory$1(msg.opts);
          }

          pm2.sendDataToProcessId(packet.process.pm_id, {
            data: {},
            topic: channel,
            channel,
            type: 'init',
            keyPrefix: msg.opts.keyPrefix,
          }, (sendErr, res) => {
            if (sendErr) {
              console.log(sendErr, res);
            }
          });
        } else {
          const worker = {
            send: (msgData) => {
              const pm2Message = msgData;
              pm2Message.topic = channel;
              if (typeof pm2Message.data === 'undefined') {
                pm2Message.data = {};
              }
              pm2.sendDataToProcessId(packet.process.pm_id, pm2Message, (sendErr, res) => {
                if (sendErr) {
                  console.log(sendErr, res);
                }
              });
            },
          };
          masterProcessMsg.call(this, worker, msg);
        }
      });
    });

    masterInstance = this;
  }
};

class RateLimiterClusterWorker extends RateLimiterAbstract$1 {
  get timeoutMs() {
    return this._timeoutMs;
  }

  set timeoutMs(value) {
    this._timeoutMs = typeof value === 'undefined' ? 5000 : Math.abs(parseInt(value));
  }

  constructor(opts = {}) {
    super(opts);

    process.setMaxListeners(0);

    this.timeoutMs = opts.timeoutMs;

    this._initiated = false;

    process.on('message', (msg) => {
      if (msg && msg.channel === channel && msg.type === 'init' && msg.keyPrefix === this.keyPrefix) {
        this._initiated = true;
      } else {
        workerProcessMsg.call(this, msg);
      }
    });

    // Create limiter on master with specific options
    process.send({
      channel,
      type: 'init',
      opts: getOpts.call(this),
    });

    this._promises = {};
  }

  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'consume', promiseId, key, pointsToConsume, options);
    });
  }

  penalty(key, points = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'penalty', promiseId, key, points, options);
    });
  }

  reward(key, points = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'reward', promiseId, key, points, options);
    });
  }

  block(key, secDuration, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'block', promiseId, key, secDuration, options);
    });
  }

  get(key, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'get', promiseId, key, options);
    });
  }

  delete(key, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'delete', promiseId, key, options);
    });
  }
}

var RateLimiterCluster$1 = {
  RateLimiterClusterMaster: RateLimiterClusterMaster$1,
  RateLimiterClusterMasterPM2: RateLimiterClusterMasterPM2$1,
  RateLimiterCluster: RateLimiterClusterWorker,
};

const RateLimiterStoreAbstract = RateLimiterStoreAbstract_1;
const RateLimiterRes$3 = RateLimiterRes_1;

let RateLimiterMemcache$1 = class RateLimiterMemcache extends RateLimiterStoreAbstract {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: memcacheClient
   * }
   */
  constructor(opts) {
    super(opts);

    this.client = opts.storeClient;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$3();
    res.consumedPoints = parseInt(result.consumedPoints);
    res.isFirstInDuration = result.consumedPoints === changedPoints;
    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = result.msBeforeNext;

    return res;
  }

  _upsert(rlKey, points, msDuration, forceExpire = false, options = {}) {
    return new Promise((resolve, reject) => {
      const nowMs = Date.now();
      const secDuration = Math.floor(msDuration / 1000);

      if (forceExpire) {
        this.client.set(rlKey, points, secDuration, (err) => {
          if (!err) {
            this.client.set(
              `${rlKey}_expire`,
              secDuration > 0 ? nowMs + (secDuration * 1000) : -1,
              secDuration,
              () => {
                const res = {
                  consumedPoints: points,
                  msBeforeNext: secDuration > 0 ? secDuration * 1000 : -1,
                };
                resolve(res);
              }
            );
          } else {
            reject(err);
          }
        });
      } else {
        this.client.incr(rlKey, points, (err, consumedPoints) => {
          if (err || consumedPoints === false) {
            this.client.add(rlKey, points, secDuration, (errAddKey, createdNew) => {
              if (errAddKey || !createdNew) {
                // Try to upsert again in case of race condition
                if (typeof options.attemptNumber === 'undefined' || options.attemptNumber < 3) {
                  const nextOptions = Object.assign({}, options);
                  nextOptions.attemptNumber = nextOptions.attemptNumber ? (nextOptions.attemptNumber + 1) : 1;

                  this._upsert(rlKey, points, msDuration, forceExpire, nextOptions)
                    .then(resUpsert => resolve(resUpsert))
                    .catch(errUpsert => reject(errUpsert));
                } else {
                  reject(new Error('Can not add key'));
                }
              } else {
                this.client.add(
                  `${rlKey}_expire`,
                  secDuration > 0 ? nowMs + (secDuration * 1000) : -1,
                  secDuration,
                  () => {
                    const res = {
                      consumedPoints: points,
                      msBeforeNext: secDuration > 0 ? secDuration * 1000 : -1,
                    };
                    resolve(res);
                  }
                );
              }
            });
          } else {
            this.client.get(`${rlKey}_expire`, (errGetExpire, resGetExpireMs) => {
              if (errGetExpire) {
                reject(errGetExpire);
              } else {
                const expireMs = resGetExpireMs === false ? 0 : resGetExpireMs;
                const res = {
                  consumedPoints,
                  msBeforeNext: expireMs >= 0 ? Math.max(expireMs - nowMs, 0) : -1,
                };
                resolve(res);
              }
            });
          }
        });
      }
    });
  }

  _get(rlKey) {
    return new Promise((resolve, reject) => {
      const nowMs = Date.now();

      this.client.get(rlKey, (err, consumedPoints) => {
        if (!consumedPoints) {
          resolve(null);
        } else {
          this.client.get(`${rlKey}_expire`, (errGetExpire, resGetExpireMs) => {
            if (errGetExpire) {
              reject(errGetExpire);
            } else {
              const expireMs = resGetExpireMs === false ? 0 : resGetExpireMs;
              const res = {
                consumedPoints,
                msBeforeNext: expireMs >= 0 ? Math.max(expireMs - nowMs, 0) : -1,
              };
              resolve(res);
            }
          });
        }
      });
    });
  }

  _delete(rlKey) {
    return new Promise((resolve, reject) => {
      this.client.del(rlKey, (err, res) => {
        if (err) {
          reject(err);
        } else if (res === false) {
          resolve(res);
        } else {
          this.client.del(`${rlKey}_expire`, (errDelExpire) => {
            if (errDelExpire) {
              reject(errDelExpire);
            } else {
              resolve(res);
            }
          });
        }
      });
    });
  }
};

var RateLimiterMemcache_1 = RateLimiterMemcache$1;

const RateLimiterRes$2 = RateLimiterRes_1;

var RLWrapperBlackAndWhite_1 = class RLWrapperBlackAndWhite {
  constructor(opts = {}) {
    this.limiter = opts.limiter;
    this.blackList = opts.blackList;
    this.whiteList = opts.whiteList;
    this.isBlackListed = opts.isBlackListed;
    this.isWhiteListed = opts.isWhiteListed;
    this.runActionAnyway = opts.runActionAnyway;
  }

  get limiter() {
    return this._limiter;
  }

  set limiter(value) {
    if (typeof value === 'undefined') {
      throw new Error('limiter is not set');
    }

    this._limiter = value;
  }

  get runActionAnyway() {
    return this._runActionAnyway;
  }

  set runActionAnyway(value) {
    this._runActionAnyway = typeof value === 'undefined' ? false : value;
  }

  get blackList() {
    return this._blackList;
  }

  set blackList(value) {
    this._blackList = Array.isArray(value) ? value : [];
  }

  get isBlackListed() {
    return this._isBlackListed;
  }

  set isBlackListed(func) {
    if (typeof func === 'undefined') {
      func = () => false;
    }
    if (typeof func !== 'function') {
      throw new Error('isBlackListed must be function');
    }
    this._isBlackListed = func;
  }

  get whiteList() {
    return this._whiteList;
  }

  set whiteList(value) {
    this._whiteList = Array.isArray(value) ? value : [];
  }

  get isWhiteListed() {
    return this._isWhiteListed;
  }

  set isWhiteListed(func) {
    if (typeof func === 'undefined') {
      func = () => false;
    }
    if (typeof func !== 'function') {
      throw new Error('isWhiteListed must be function');
    }
    this._isWhiteListed = func;
  }

  isBlackListedSomewhere(key) {
    return this.blackList.indexOf(key) >= 0 || this.isBlackListed(key);
  }

  isWhiteListedSomewhere(key) {
    return this.whiteList.indexOf(key) >= 0 || this.isWhiteListed(key);
  }

  getBlackRes() {
    return new RateLimiterRes$2(0, Number.MAX_SAFE_INTEGER, 0, false);
  }

  getWhiteRes() {
    return new RateLimiterRes$2(Number.MAX_SAFE_INTEGER, 0, 0, false);
  }

  rejectBlack() {
    return Promise.reject(this.getBlackRes());
  }

  resolveBlack() {
    return Promise.resolve(this.getBlackRes());
  }

  resolveWhite() {
    return Promise.resolve(this.getWhiteRes());
  }

  consume(key, pointsToConsume = 1) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.rejectBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.consume(key, pointsToConsume);
    }

    if (this.runActionAnyway) {
      this.limiter.consume(key, pointsToConsume).catch(() => {});
    }
    return res;
  }

  block(key, secDuration) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.block(key, secDuration);
    }

    if (this.runActionAnyway) {
      this.limiter.block(key, secDuration).catch(() => {});
    }
    return res;
  }

  penalty(key, points) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.penalty(key, points);
    }

    if (this.runActionAnyway) {
      this.limiter.penalty(key, points).catch(() => {});
    }
    return res;
  }

  reward(key, points) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.reward(key, points);
    }

    if (this.runActionAnyway) {
      this.limiter.reward(key, points).catch(() => {});
    }
    return res;
  }

  get(key) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined' || this.runActionAnyway) {
      return this.limiter.get(key);
    }

    return res;
  }

  delete(key) {
    return this.limiter.delete(key);
  }
};

const RateLimiterAbstract = RateLimiterAbstract_1;

var RateLimiterUnion_1 = class RateLimiterUnion {
  constructor(...limiters) {
    if (limiters.length < 1) {
      throw new Error('RateLimiterUnion: at least one limiter have to be passed');
    }
    limiters.forEach((limiter) => {
      if (!(limiter instanceof RateLimiterAbstract)) {
        throw new Error('RateLimiterUnion: all limiters have to be instance of RateLimiterAbstract');
      }
    });

    this._limiters = limiters;
  }

  consume(key, points = 1) {
    return new Promise((resolve, reject) => {
      const promises = [];
      this._limiters.forEach((limiter) => {
        promises.push(limiter.consume(key, points).catch(rej => ({ rejected: true, rej })));
      });

      Promise.all(promises)
        .then((res) => {
          const resObj = {};
          let rejected = false;

          res.forEach((item) => {
            if (item.rejected === true) {
              rejected = true;
            }
          });

          for (let i = 0; i < res.length; i++) {
            if (rejected && res[i].rejected === true) {
              resObj[this._limiters[i].keyPrefix] = res[i].rej;
            } else if (!rejected) {
              resObj[this._limiters[i].keyPrefix] = res[i];
            }
          }

          if (rejected) {
            reject(resObj);
          } else {
            resolve(resObj);
          }
        });
    });
  }
};

var RateLimiterQueueError_1 = class RateLimiterQueueError extends Error {
  constructor(message, extra) {
    super();
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, this.constructor);
    }
    this.name = 'CustomError';
    this.message = message;
    if (extra) {
      this.extra = extra;
    }
  }
};

const RateLimiterQueueError = RateLimiterQueueError_1;
const MAX_QUEUE_SIZE = 4294967295;
const KEY_DEFAULT = 'limiter';

var RateLimiterQueue_1 = class RateLimiterQueue {
  constructor(limiterFlexible, opts = {
    maxQueueSize: MAX_QUEUE_SIZE,
  }) {
    this._queueLimiters = {
      KEY_DEFAULT: new RateLimiterQueueInternal(limiterFlexible, opts)
    };
    this._limiterFlexible = limiterFlexible;
    this._maxQueueSize = opts.maxQueueSize;
  }

  getTokensRemaining(key = KEY_DEFAULT) {
    if (this._queueLimiters[key]) {
      return this._queueLimiters[key].getTokensRemaining()
    } else {
      return Promise.resolve(this._limiterFlexible.points)
    }
  }

  removeTokens(tokens, key = KEY_DEFAULT) {
    if (!this._queueLimiters[key]) {
      this._queueLimiters[key] = new RateLimiterQueueInternal(
        this._limiterFlexible, {
          key,
          maxQueueSize: this._maxQueueSize,
        });
    }

    return this._queueLimiters[key].removeTokens(tokens)
  }
};

class RateLimiterQueueInternal {

  constructor(limiterFlexible, opts = {
    maxQueueSize: MAX_QUEUE_SIZE,
    key: KEY_DEFAULT,
  }) {
    this._key = opts.key;
    this._waitTimeout = null;
    this._queue = [];
    this._limiterFlexible = limiterFlexible;

    this._maxQueueSize = opts.maxQueueSize;
  }

  getTokensRemaining() {
    return this._limiterFlexible.get(this._key)
      .then((rlRes) => {
        return rlRes !== null ? rlRes.remainingPoints : this._limiterFlexible.points;
      })
  }

  removeTokens(tokens) {
    const _this = this;

    return new Promise((resolve, reject) => {
      if (tokens > _this._limiterFlexible.points) {
        reject(new RateLimiterQueueError(`Requested tokens ${tokens} exceeds maximum ${_this._limiterFlexible.points} tokens per interval`));
        return
      }

      if (_this._queue.length > 0) {
        _this._queueRequest.call(_this, resolve, reject, tokens);
      } else {
        _this._limiterFlexible.consume(_this._key, tokens)
          .then((res) => {
            resolve(res.remainingPoints);
          })
          .catch((rej) => {
            if (rej instanceof Error) {
              reject(rej);
            } else {
              _this._queueRequest.call(_this, resolve, reject, tokens);
              if (_this._waitTimeout === null) {
                _this._waitTimeout = setTimeout(_this._processFIFO.bind(_this), rej.msBeforeNext);
              }
            }
          });
      }
    })
  }

  _queueRequest(resolve, reject, tokens) {
    const _this = this;
    if (_this._queue.length < _this._maxQueueSize) {
      _this._queue.push({resolve, reject, tokens});
    } else {
      reject(new RateLimiterQueueError(`Number of requests reached it's maximum ${_this._maxQueueSize}`));
    }
  }

  _processFIFO() {
    const _this = this;

    if (_this._waitTimeout !== null) {
      clearTimeout(_this._waitTimeout);
      _this._waitTimeout = null;
    }

    if (_this._queue.length === 0) {
      return;
    }

    const item = _this._queue.shift();
    _this._limiterFlexible.consume(_this._key, item.tokens)
      .then((res) => {
        item.resolve(res.remainingPoints);
        _this._processFIFO.call(_this);
      })
      .catch((rej) => {
        if (rej instanceof Error) {
          item.reject(rej);
          _this._processFIFO.call(_this);
        } else {
          _this._queue.unshift(item);
          if (_this._waitTimeout === null) {
            _this._waitTimeout = setTimeout(_this._processFIFO.bind(_this), rej.msBeforeNext);
          }
        }
      });
  }
}

const RateLimiterRes$1 = RateLimiterRes_1;

/**
 * Bursty rate limiter exposes only msBeforeNext time and doesn't expose points from bursty limiter by default
 * @type {BurstyRateLimiter}
 */
var BurstyRateLimiter_1 = class BurstyRateLimiter {
  constructor(rateLimiter, burstLimiter) {
    this._rateLimiter = rateLimiter;
    this._burstLimiter = burstLimiter;
  }

  /**
   * Merge rate limiter response objects. Responses can be null
   *
   * @param {RateLimiterRes} [rlRes] Rate limiter response
   * @param {RateLimiterRes} [blRes] Bursty limiter response
   */
  _combineRes(rlRes, blRes) {
    return new RateLimiterRes$1(
      rlRes.remainingPoints,
      Math.min(rlRes.msBeforeNext, blRes.msBeforeNext),
      rlRes.consumedPoints,
      rlRes.isFirstInDuration
    )
  }

  /**
   * @param key
   * @param pointsToConsume
   * @param options
   * @returns {Promise<any>}
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return this._rateLimiter.consume(key, pointsToConsume, options)
      .catch((rlRej) => {
        if (rlRej instanceof RateLimiterRes$1) {
          return this._burstLimiter.consume(key, pointsToConsume, options)
            .then((blRes) => {
              return Promise.resolve(this._combineRes(rlRej, blRes))
            })
            .catch((blRej) => {
                if (blRej instanceof RateLimiterRes$1) {
                  return Promise.reject(this._combineRes(rlRej, blRej))
                } else {
                  return Promise.reject(blRej)
                }
              }
            )
        } else {
          return Promise.reject(rlRej)
        }
      })
  }

  /**
   * It doesn't expose available points from burstLimiter
   *
   * @param key
   * @returns {Promise<RateLimiterRes>}
   */
  get(key) {
    return Promise.all([
      this._rateLimiter.get(key),
      this._burstLimiter.get(key),
    ]).then(([rlRes, blRes]) => {
      return this._combineRes(rlRes, blRes);
    });
  }

  get points() {
    return this._rateLimiter.points;
  }
};

const RateLimiterRedis = RateLimiterRedis_1;
const RateLimiterMongo = RateLimiterMongo_1;
const RateLimiterMySQL = RateLimiterMySQL_1;
const RateLimiterPostgres = RateLimiterPostgres_1;
const {RateLimiterClusterMaster, RateLimiterClusterMasterPM2, RateLimiterCluster} = RateLimiterCluster$1;
const RateLimiterMemory = RateLimiterMemory_1;
const RateLimiterMemcache = RateLimiterMemcache_1;
const RLWrapperBlackAndWhite = RLWrapperBlackAndWhite_1;
const RateLimiterUnion = RateLimiterUnion_1;
const RateLimiterQueue = RateLimiterQueue_1;
const BurstyRateLimiter = BurstyRateLimiter_1;
const RateLimiterRes = RateLimiterRes_1;

var rateLimiterFlexible = {
  RateLimiterRedis,
  RateLimiterMongo,
  RateLimiterMySQL,
  RateLimiterPostgres,
  RateLimiterMemory,
  RateLimiterMemcache,
  RateLimiterClusterMaster,
  RateLimiterClusterMasterPM2,
  RateLimiterCluster,
  RLWrapperBlackAndWhite,
  RateLimiterUnion,
  RateLimiterQueue,
  BurstyRateLimiter,
  RateLimiterRes,
};

const log$S = logger$2('libp2p:mplex');
const MAX_STREAMS_INBOUND_STREAMS_PER_CONNECTION = 1024;
const MAX_STREAMS_OUTBOUND_STREAMS_PER_CONNECTION = 1024;
const MAX_STREAM_BUFFER_SIZE = 1024 * 1024 * 4; // 4MB
const DISCONNECT_THRESHOLD = 5;
function printMessage(msg) {
    const output = {
        ...msg,
        type: `${MessageTypeNames[msg.type]} (${msg.type})`
    };
    if (msg.type === MessageTypes.NEW_STREAM) {
        output.data = toString$7(msg.data instanceof Uint8Array ? msg.data : msg.data.subarray());
    }
    if (msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) {
        output.data = toString$7(msg.data instanceof Uint8Array ? msg.data : msg.data.subarray(), 'base16');
    }
    return output;
}
class MplexStreamMuxer {
    constructor(init) {
        this.protocol = '/mplex/6.7.0';
        init = init ?? {};
        this._streamId = 0;
        this._streams = {
            /**
             * Stream to ids map
             */
            initiators: new Map(),
            /**
             * Stream to ids map
             */
            receivers: new Map()
        };
        this._init = init;
        /**
         * An iterable sink
         */
        this.sink = this._createSink();
        /**
         * An iterable source
         */
        const source = this._createSource();
        this._source = source;
        this.source = source;
        /**
         * Close controller
         */
        this.closeController = new AbortController();
        this.rateLimiter = new rateLimiterFlexible.RateLimiterMemory({
            points: init.disconnectThreshold ?? DISCONNECT_THRESHOLD,
            duration: 1
        });
    }
    /**
     * Returns a Map of streams and their ids
     */
    get streams() {
        // Inbound and Outbound streams may have the same ids, so we need to make those unique
        const streams = [];
        for (const stream of this._streams.initiators.values()) {
            streams.push(stream);
        }
        for (const stream of this._streams.receivers.values()) {
            streams.push(stream);
        }
        return streams;
    }
    /**
     * Initiate a new stream with the given name. If no name is
     * provided, the id of the stream will be used.
     */
    newStream(name) {
        if (this.closeController.signal.aborted) {
            throw new Error('Muxer already closed');
        }
        const id = this._streamId++;
        name = name == null ? id.toString() : name.toString();
        const registry = this._streams.initiators;
        return this._newStream({ id, name, type: 'initiator', registry });
    }
    /**
     * Close or abort all tracked streams and stop the muxer
     */
    close(err) {
        if (this.closeController.signal.aborted)
            return;
        if (err != null) {
            this.streams.forEach(s => s.abort(err));
        }
        else {
            this.streams.forEach(s => s.close());
        }
        this.closeController.abort();
    }
    /**
     * Called whenever an inbound stream is created
     */
    _newReceiverStream(options) {
        const { id, name } = options;
        const registry = this._streams.receivers;
        return this._newStream({ id, name, type: 'receiver', registry });
    }
    _newStream(options) {
        const { id, name, type, registry } = options;
        log$S('new %s stream %s', type, id);
        if (type === 'initiator' && this._streams.initiators.size === (this._init.maxOutboundStreams ?? MAX_STREAMS_OUTBOUND_STREAMS_PER_CONNECTION)) {
            throw errCode(new Error('Too many outbound streams open'), 'ERR_TOO_MANY_OUTBOUND_STREAMS');
        }
        if (registry.has(id)) {
            throw new Error(`${type} stream ${id} already exists!`);
        }
        const send = (msg) => {
            if (log$S.enabled) {
                log$S.trace('%s stream %s send', type, id, printMessage(msg));
            }
            this._source.push(msg);
        };
        const onEnd = () => {
            log$S('%s stream with id %s and protocol %s ended', type, id, stream.stat.protocol);
            registry.delete(id);
            if (this._init.onStreamEnd != null) {
                this._init.onStreamEnd(stream);
            }
        };
        const stream = createStream({ id, name, send, type, onEnd, maxMsgSize: this._init.maxMsgSize });
        registry.set(id, stream);
        return stream;
    }
    /**
     * Creates a sink with an abortable source. Incoming messages will
     * also have their size restricted. All messages will be varint decoded.
     */
    _createSink() {
        const sink = async (source) => {
            // see: https://github.com/jacobheun/any-signal/pull/18
            const abortSignals = [this.closeController.signal];
            if (this._init.signal != null) {
                abortSignals.push(this._init.signal);
            }
            source = abortableSource(source, anySignalExports(abortSignals));
            try {
                const decoder = new Decoder(this._init.maxMsgSize, this._init.maxUnprocessedMessageQueueSize);
                for await (const chunk of source) {
                    for (const msg of decoder.write(chunk)) {
                        await this._handleIncoming(msg);
                    }
                }
                this._source.end();
            }
            catch (err) {
                log$S('error in sink', err);
                this._source.end(err); // End the source with an error
            }
        };
        return sink;
    }
    /**
     * Creates a source that restricts outgoing message sizes
     * and varint encodes them
     */
    _createSource() {
        const onEnd = (err) => {
            this.close(err);
        };
        const source = pushableV({
            objectMode: true,
            onEnd
        });
        return Object.assign(encode$5(source, this._init.minSendBytes), {
            push: source.push,
            end: source.end,
            return: source.return
        });
    }
    async _handleIncoming(message) {
        const { id, type } = message;
        if (log$S.enabled) {
            log$S.trace('incoming message', printMessage(message));
        }
        // Create a new stream?
        if (message.type === MessageTypes.NEW_STREAM) {
            if (this._streams.receivers.size === (this._init.maxInboundStreams ?? MAX_STREAMS_INBOUND_STREAMS_PER_CONNECTION)) {
                log$S('too many inbound streams open');
                // not going to allow this stream, send the reset message manually
                // instead of setting it up just to tear it down
                this._source.push({
                    id,
                    type: MessageTypes.RESET_RECEIVER
                });
                // if we've hit our stream limit, and the remote keeps trying to open
                // more new streams, if they are doing this very quickly maybe they
                // are attacking us and we should close the connection
                try {
                    await this.rateLimiter.consume('new-stream', 1);
                }
                catch {
                    log$S('rate limit hit when opening too many new streams over the inbound stream limit - closing remote connection');
                    // since there's no backpressure in mplex, the only thing we can really do to protect ourselves is close the connection
                    this._source.end(new Error('Too many open streams'));
                    return;
                }
                return;
            }
            const stream = this._newReceiverStream({ id, name: toString$7(message.data instanceof Uint8Array ? message.data : message.data.subarray()) });
            if (this._init.onIncomingStream != null) {
                this._init.onIncomingStream(stream);
            }
            return;
        }
        const list = (type & 1) === 1 ? this._streams.initiators : this._streams.receivers;
        const stream = list.get(id);
        if (stream == null) {
            log$S('missing stream %s for message type %s', id, MessageTypeNames[type]);
            return;
        }
        const maxBufferSize = this._init.maxStreamBufferSize ?? MAX_STREAM_BUFFER_SIZE;
        switch (type) {
            case MessageTypes.MESSAGE_INITIATOR:
            case MessageTypes.MESSAGE_RECEIVER:
                if (stream.sourceReadableLength() > maxBufferSize) {
                    // Stream buffer has got too large, reset the stream
                    this._source.push({
                        id: message.id,
                        type: type === MessageTypes.MESSAGE_INITIATOR ? MessageTypes.RESET_RECEIVER : MessageTypes.RESET_INITIATOR
                    });
                    // Inform the stream consumer they are not fast enough
                    const error = errCode(new Error('Input buffer full - increase Mplex maxBufferSize to accommodate slow consumers'), 'ERR_STREAM_INPUT_BUFFER_FULL');
                    stream.abort(error);
                    return;
                }
                // We got data from the remote, push it into our local stream
                stream.sourcePush(message.data);
                break;
            case MessageTypes.CLOSE_INITIATOR:
            case MessageTypes.CLOSE_RECEIVER:
                // We should expect no more data from the remote, stop reading
                stream.closeRead();
                break;
            case MessageTypes.RESET_INITIATOR:
            case MessageTypes.RESET_RECEIVER:
                // Stop reading and writing to the stream immediately
                stream.reset();
                break;
            default:
                log$S('unknown message type %s', type);
        }
    }
}

class Mplex {
    constructor(init = {}) {
        this.protocol = '/mplex/6.7.0';
        this._init = init;
    }
    createStreamMuxer(init = {}) {
        return new MplexStreamMuxer({
            ...init,
            ...this._init
        });
    }
}
function mplex(init = {}) {
    return () => new Mplex(init);
}

/* eslint-env browser */
var WebSocket$1 = WebSocket;

var dom = {};

var eventIterator = {};

Object.defineProperty(eventIterator, "__esModule", { value: true });
class EventQueue {
    constructor() {
        this.pullQueue = [];
        this.pushQueue = [];
        this.eventHandlers = {};
        this.isPaused = false;
        this.isStopped = false;
    }
    push(value) {
        if (this.isStopped)
            return;
        const resolution = { value, done: false };
        if (this.pullQueue.length) {
            const placeholder = this.pullQueue.shift();
            if (placeholder)
                placeholder.resolve(resolution);
        }
        else {
            this.pushQueue.push(Promise.resolve(resolution));
            if (this.highWaterMark !== undefined &&
                this.pushQueue.length >= this.highWaterMark &&
                !this.isPaused) {
                this.isPaused = true;
                if (this.eventHandlers.highWater) {
                    this.eventHandlers.highWater();
                }
                else if (console) {
                    console.warn(`EventIterator queue reached ${this.pushQueue.length} items`);
                }
            }
        }
    }
    stop() {
        if (this.isStopped)
            return;
        this.isStopped = true;
        this.remove();
        for (const placeholder of this.pullQueue) {
            placeholder.resolve({ value: undefined, done: true });
        }
        this.pullQueue.length = 0;
    }
    fail(error) {
        if (this.isStopped)
            return;
        this.isStopped = true;
        this.remove();
        if (this.pullQueue.length) {
            for (const placeholder of this.pullQueue) {
                placeholder.reject(error);
            }
            this.pullQueue.length = 0;
        }
        else {
            const rejection = Promise.reject(error);
            /* Attach error handler to avoid leaking an unhandled promise rejection. */
            rejection.catch(() => { });
            this.pushQueue.push(rejection);
        }
    }
    remove() {
        Promise.resolve().then(() => {
            if (this.removeCallback)
                this.removeCallback();
        });
    }
    [Symbol.asyncIterator]() {
        return {
            next: (value) => {
                const result = this.pushQueue.shift();
                if (result) {
                    if (this.lowWaterMark !== undefined &&
                        this.pushQueue.length <= this.lowWaterMark &&
                        this.isPaused) {
                        this.isPaused = false;
                        if (this.eventHandlers.lowWater) {
                            this.eventHandlers.lowWater();
                        }
                    }
                    return result;
                }
                else if (this.isStopped) {
                    return Promise.resolve({ value: undefined, done: true });
                }
                else {
                    return new Promise((resolve, reject) => {
                        this.pullQueue.push({ resolve, reject });
                    });
                }
            },
            return: () => {
                this.isStopped = true;
                this.pushQueue.length = 0;
                this.remove();
                return Promise.resolve({ value: undefined, done: true });
            },
        };
    }
}
let EventIterator$1 = class EventIterator {
    constructor(listen, { highWaterMark = 100, lowWaterMark = 1 } = {}) {
        const queue = new EventQueue();
        queue.highWaterMark = highWaterMark;
        queue.lowWaterMark = lowWaterMark;
        queue.removeCallback =
            listen({
                push: value => queue.push(value),
                stop: () => queue.stop(),
                fail: error => queue.fail(error),
                on: (event, fn) => {
                    queue.eventHandlers[event] = fn;
                },
            }) || (() => { });
        this[Symbol.asyncIterator] = () => queue[Symbol.asyncIterator]();
        Object.freeze(this);
    }
};
eventIterator.EventIterator = EventIterator$1;
eventIterator.default = EventIterator$1;

Object.defineProperty(dom, "__esModule", { value: true });
const event_iterator_1 = eventIterator;
var EventIterator = dom.EventIterator = event_iterator_1.EventIterator;
function subscribe(event, options, evOptions) {
    return new event_iterator_1.EventIterator(({ push }) => {
        this.addEventListener(event, push, options);
        return () => this.removeEventListener(event, push, options);
    }, evOptions);
}
dom.subscribe = subscribe;
dom.default = event_iterator_1.EventIterator;

// copied from github.com/feross/buffer
// Some ArrayBuffers are not passing the instanceof check, so we need to do a bit more work :(
function isArrayBuffer(obj) {
    return (obj instanceof ArrayBuffer) ||
        (obj?.constructor?.name === 'ArrayBuffer' && typeof obj?.byteLength === 'number');
}
var source = (socket) => {
    socket.binaryType = 'arraybuffer';
    const connected = async () => await new Promise((resolve, reject) => {
        if (isConnected) {
            return resolve();
        }
        if (connError != null) {
            return reject(connError);
        }
        const cleanUp = (cont) => {
            socket.removeEventListener('open', onOpen);
            socket.removeEventListener('error', onError);
            cont();
        };
        const onOpen = () => cleanUp(resolve);
        const onError = (event) => {
            cleanUp(() => reject(event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`)));
        };
        socket.addEventListener('open', onOpen);
        socket.addEventListener('error', onError);
    });
    const source = (async function* () {
        const messages = new EventIterator(({ push, stop, fail }) => {
            const onMessage = (event) => {
                let data = null;
                if (typeof event.data === 'string') {
                    data = fromString$2(event.data);
                }
                if (isArrayBuffer(event.data)) {
                    data = new Uint8Array(event.data);
                }
                if (event.data instanceof Uint8Array) {
                    data = event.data;
                }
                if (data == null) {
                    return;
                }
                push(data);
            };
            const onError = (event) => fail(event.error ?? new Error('Socket error'));
            socket.addEventListener('message', onMessage);
            socket.addEventListener('error', onError);
            socket.addEventListener('close', stop);
            return () => {
                socket.removeEventListener('message', onMessage);
                socket.removeEventListener('error', onError);
                socket.removeEventListener('close', stop);
            };
        }, { highWaterMark: Infinity });
        await connected();
        for await (const chunk of messages) {
            yield isArrayBuffer(chunk) ? new Uint8Array(chunk) : chunk;
        }
    }());
    let isConnected = socket.readyState === 1;
    let connError;
    socket.addEventListener('open', () => {
        isConnected = true;
        connError = null;
    });
    socket.addEventListener('close', () => {
        isConnected = false;
        connError = null;
    });
    socket.addEventListener('error', event => {
        if (!isConnected) {
            connError = event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`);
        }
    });
    return Object.assign(source, {
        connected
    });
};

var ready = (socket) => {
    // if the socket is closing or closed, return end
    if (socket.readyState >= 2) {
        throw new Error('socket closed');
    }
    // if open, return
    if (socket.readyState === 1) {
        return;
    }
    return new Promise((resolve, reject) => {
        function cleanup() {
            socket.removeEventListener('open', handleOpen);
            socket.removeEventListener('error', handleErr);
        }
        function handleOpen() {
            cleanup();
            resolve();
        }
        function handleErr(event) {
            cleanup();
            reject(event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`));
        }
        socket.addEventListener('open', handleOpen);
        socket.addEventListener('error', handleErr);
    });
};

var sink = (socket, options) => {
    options = options ?? {};
    options.closeOnEnd = options.closeOnEnd !== false;
    const sink = async (source) => {
        for await (const data of source) {
            try {
                await ready(socket);
            }
            catch (err) {
                if (err.message === 'socket closed')
                    break;
                throw err;
            }
            socket.send(data);
        }
        if (options.closeOnEnd != null && socket.readyState <= 1) {
            return await new Promise((resolve, reject) => {
                socket.addEventListener('close', event => {
                    if (event.wasClean || event.code === 1006) {
                        resolve();
                    }
                    else {
                        const err = Object.assign(new Error('ws error'), { event });
                        reject(err);
                    }
                });
                setTimeout(() => socket.close());
            });
        }
    };
    return sink;
};

var duplex = (socket, options) => {
    options = options ?? {};
    const connectedSource = source(socket);
    let remoteAddress = options.remoteAddress;
    let remotePort = options.remotePort;
    if (socket.url != null) {
        // only client->server sockets have urls, server->client connections do not
        try {
            const url = new URL(socket.url);
            remoteAddress = url.hostname;
            remotePort = parseInt(url.port, 10);
        }
        catch { }
    }
    if (remoteAddress == null || remotePort == null) {
        throw new Error('Remote connection did not have address and/or port');
    }
    const duplex = {
        sink: sink(socket, options),
        source: connectedSource,
        connected: async () => await connectedSource.connected(),
        close: async () => {
            if (socket.readyState === socket.CONNECTING || socket.readyState === socket.OPEN) {
                await new Promise((resolve) => {
                    socket.addEventListener('close', () => {
                        resolve();
                    });
                    socket.close();
                });
            }
        },
        destroy: () => {
            if (socket.terminate != null) {
                socket.terminate();
            }
            else {
                socket.close();
            }
        },
        remoteAddress,
        remotePort,
        socket
    };
    return duplex;
};

const isReactNative$1 =
    typeof navigator !== 'undefined' &&
    navigator.product === 'ReactNative';

function getDefaultBase () {
  if (isReactNative$1) {
    return 'http://localhost'
  }
  // in some environments i.e. cloudflare workers location is not available
  if (!self.location) {
    return ''
  }

  return self.location.protocol + '//' + self.location.host
}

const URL$2 = self.URL;
const defaultBase$1 = getDefaultBase();

let URLWithLegacySupport$2 = class URLWithLegacySupport {
  constructor (url = '', base = defaultBase$1) {
    this.super = new URL$2(url, base);
    this.path = this.pathname + this.search;
    this.auth =
            this.username && this.password
              ? this.username + ':' + this.password
              : null;

    this.query =
            this.search && this.search.startsWith('?')
              ? this.search.slice(1)
              : null;
  }

  get hash () {
    return this.super.hash
  }

  get host () {
    return this.super.host
  }

  get hostname () {
    return this.super.hostname
  }

  get href () {
    return this.super.href
  }

  get origin () {
    return this.super.origin
  }

  get password () {
    return this.super.password
  }

  get pathname () {
    return this.super.pathname
  }

  get port () {
    return this.super.port
  }

  get protocol () {
    return this.super.protocol
  }

  get search () {
    return this.super.search
  }

  get searchParams () {
    return this.super.searchParams
  }

  get username () {
    return this.super.username
  }

  set hash (hash) {
    this.super.hash = hash;
  }

  set host (host) {
    this.super.host = host;
  }

  set hostname (hostname) {
    this.super.hostname = hostname;
  }

  set href (href) {
    this.super.href = href;
  }

  set password (password) {
    this.super.password = password;
  }

  set pathname (pathname) {
    this.super.pathname = pathname;
  }

  set port (port) {
    this.super.port = port;
  }

  set protocol (protocol) {
    this.super.protocol = protocol;
  }

  set search (search) {
    this.super.search = search;
  }

  set username (username) {
    this.super.username = username;
  }

  /**
   * @param {any} o
   */
  static createObjectURL (o) {
    return URL$2.createObjectURL(o)
  }

  /**
   * @param {string} o
   */
  static revokeObjectURL (o) {
    URL$2.revokeObjectURL(o);
  }

  toJSON () {
    return this.super.toJSON()
  }

  toString () {
    return this.super.toString()
  }

  format () {
    return this.toString()
  }
};

/**
 * @param {string | import('url').UrlObject} obj
 */
function format$2 (obj) {
  if (typeof obj === 'string') {
    const url = new URL$2(obj);

    return url.toString()
  }

  if (!(obj instanceof URL$2)) {
    const userPass =
            // @ts-ignore its not supported in node but we normalise
            obj.username && obj.password
              // @ts-ignore its not supported in node but we normalise
              ? `${obj.username}:${obj.password}@`
              : '';
    const auth = obj.auth ? obj.auth + '@' : '';
    const port = obj.port ? ':' + obj.port : '';
    const protocol = obj.protocol ? obj.protocol + '//' : '';
    const host = obj.host || '';
    const hostname = obj.hostname || '';
    const search = obj.search || (obj.query ? '?' + obj.query : '');
    const hash = obj.hash || '';
    const pathname = obj.pathname || '';
    // @ts-ignore - path is not supported in node but we normalise
    const path = obj.path || pathname + search;

    return `${protocol}${userPass || auth}${
            host || hostname + port
        }${path}${hash}`
  }
}

var urlBrowser = {
  URLWithLegacySupport: URLWithLegacySupport$2,
  URLSearchParams: self.URLSearchParams,
  defaultBase: defaultBase$1,
  format: format$2
};

const { URLWithLegacySupport: URLWithLegacySupport$1, format: format$1 } = urlBrowser;

/**
 * @param {string | undefined} url
 * @param {any} [location]
 * @param {any} [protocolMap]
 * @param {any} [defaultProtocol]
 */
var relative$1 = (url, location = {}, protocolMap = {}, defaultProtocol) => {
  let protocol = location.protocol
    ? location.protocol.replace(':', '')
    : 'http';

  // Check protocol map
  protocol = (protocolMap[protocol] || defaultProtocol || protocol) + ':';
  let urlParsed;

  try {
    urlParsed = new URLWithLegacySupport$1(url);
  } catch (err) {
    urlParsed = {};
  }

  const base = Object.assign({}, location, {
    protocol: protocol || urlParsed.protocol,
    host: location.host || urlParsed.host
  });

  return new URLWithLegacySupport$1(url, format$1(base)).toString()
};

const {
  URLWithLegacySupport,
  format,
  URLSearchParams,
  defaultBase
} = urlBrowser;
const relative = relative$1;

var isoUrl = {
  URL: URLWithLegacySupport,
  URLSearchParams,
  format,
  relative,
  defaultBase
};

const map$1 = { http: 'ws', https: 'wss' };
const def = 'ws';
var wsurl = (url, location) => isoUrl.relative(url, location, map$1, def);

// load websocket library if we are not in the browser
function connect(addr, opts) {
    const location = typeof window === 'undefined' ? '' : window.location;
    opts = opts ?? {};
    const url = wsurl(addr, location.toString());
    const socket = new WebSocket$1(url, opts.websocket);
    return duplex(socket, opts);
}

/* eslint-disable @typescript-eslint/no-unsafe-return */
class Parser {
    index = 0;
    input = "";
    new(input) {
        this.index = 0;
        this.input = input;
        return this;
    }
    /** Run a parser, and restore the pre-parse state if it fails. */
    readAtomically(fn) {
        const index = this.index;
        const result = fn();
        if (result === undefined) {
            this.index = index;
        }
        return result;
    }
    /** Run a parser, but fail if the entire input wasn't consumed. Doesn't run atomically. */
    parseWith(fn) {
        const result = fn();
        if (this.index !== this.input.length) {
            return undefined;
        }
        return result;
    }
    /** Peek the next character from the input */
    peekChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index];
    }
    /** Read the next character from the input */
    readChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index++];
    }
    /** Read the next character from the input if it matches the target. */
    readGivenChar(target) {
        return this.readAtomically(() => {
            const char = this.readChar();
            if (char !== target) {
                return undefined;
            }
            return char;
        });
    }
    /**
     * Helper for reading separators in an indexed loop. Reads the separator
     * character iff index > 0, then runs the parser. When used in a loop,
     * the separator character will only be read on index > 0 (see
     * readIPv4Addr for an example)
     */
    readSeparator(sep, index, inner) {
        return this.readAtomically(() => {
            if (index > 0) {
                if (this.readGivenChar(sep) === undefined) {
                    return undefined;
                }
            }
            return inner();
        });
    }
    /**
     * Read a number off the front of the input in the given radix, stopping
     * at the first non-digit character or eof. Fails if the number has more
     * digits than max_digits or if there is no number.
     */
    readNumber(radix, maxDigits, allowZeroPrefix, maxBytes) {
        return this.readAtomically(() => {
            let result = 0;
            let digitCount = 0;
            const leadingChar = this.peekChar();
            if (leadingChar === undefined) {
                return undefined;
            }
            const hasLeadingZero = leadingChar === "0";
            const maxValue = 2 ** (8 * maxBytes) - 1;
            // eslint-disable-next-line no-constant-condition
            while (true) {
                const digit = this.readAtomically(() => {
                    const char = this.readChar();
                    if (char === undefined) {
                        return undefined;
                    }
                    const num = Number.parseInt(char, radix);
                    if (Number.isNaN(num)) {
                        return undefined;
                    }
                    return num;
                });
                if (digit === undefined) {
                    break;
                }
                result *= radix;
                result += digit;
                if (result > maxValue) {
                    return undefined;
                }
                digitCount += 1;
                if (maxDigits !== undefined) {
                    if (digitCount > maxDigits) {
                        return undefined;
                    }
                }
            }
            if (digitCount === 0) {
                return undefined;
            }
            else if (!allowZeroPrefix && hasLeadingZero && digitCount > 1) {
                return undefined;
            }
            else {
                return result;
            }
        });
    }
    /** Read an IPv4 address. */
    readIPv4Addr() {
        return this.readAtomically(() => {
            const out = new Uint8Array(4);
            for (let i = 0; i < out.length; i++) {
                const ix = this.readSeparator(".", i, () => this.readNumber(10, 3, false, 1));
                if (ix === undefined) {
                    return undefined;
                }
                out[i] = ix;
            }
            return out;
        });
    }
    /** Read an IPv6 Address. */
    readIPv6Addr() {
        /**
         * Read a chunk of an IPv6 address into `groups`. Returns the number
         * of groups read, along with a bool indicating if an embedded
         * trailing IPv4 address was read. Specifically, read a series of
         * colon-separated IPv6 groups (0x0000 - 0xFFFF), with an optional
         * trailing embedded IPv4 address.
         */
        const readGroups = (groups) => {
            for (let i = 0; i < groups.length / 2; i++) {
                const ix = i * 2;
                // Try to read a trailing embedded IPv4 address. There must be at least 4 groups left.
                if (i < groups.length - 3) {
                    const ipv4 = this.readSeparator(":", i, () => this.readIPv4Addr());
                    if (ipv4 !== undefined) {
                        groups[ix] = ipv4[0];
                        groups[ix + 1] = ipv4[1];
                        groups[ix + 2] = ipv4[2];
                        groups[ix + 3] = ipv4[3];
                        return [ix + 4, true];
                    }
                }
                const group = this.readSeparator(":", i, () => this.readNumber(16, 4, true, 2));
                if (group === undefined) {
                    return [ix, false];
                }
                groups[ix] = group >> 8;
                groups[ix + 1] = group & 255;
            }
            return [groups.length, false];
        };
        return this.readAtomically(() => {
            // Read the front part of the address; either the whole thing, or up to the first ::
            const head = new Uint8Array(16);
            const [headSize, headIp4] = readGroups(head);
            if (headSize === 16) {
                return head;
            }
            // IPv4 part is not allowed before `::`
            if (headIp4) {
                return undefined;
            }
            // Read `::` if previous code parsed less than 8 groups.
            // `::` indicates one or more groups of 16 bits of zeros.
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            // Read the back part of the address. The :: must contain at least one
            // set of zeroes, so our max length is 7.
            const tail = new Uint8Array(14);
            const limit = 16 - (headSize + 2);
            const [tailSize] = readGroups(tail.subarray(0, limit));
            // Concat the head and tail of the IP address
            head.set(tail.subarray(0, tailSize), 16 - tailSize);
            return head;
        });
    }
    /** Read an IP Address, either IPv4 or IPv6. */
    readIPAddr() {
        return this.readIPv4Addr() ?? this.readIPv6Addr();
    }
}

// See https://stackoverflow.com/questions/166132/maximum-length-of-the-textual-representation-of-an-ipv6-address
const MAX_IPV6_LENGTH = 45;
const MAX_IPV4_LENGTH = 15;
const parser = new Parser();
/** Parse `input` into IPv4 bytes. */
function parseIPv4(input) {
    if (input.length > MAX_IPV4_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv4Addr());
}
/** Parse `input` into IPv6 bytes. */
function parseIPv6(input) {
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv6Addr());
}
/** Parse `input` into IPv4 or IPv6 bytes. */
function parseIP(input) {
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPAddr());
}

/** Check if `input` is IPv4. */
function isIPv4(input) {
    return Boolean(parseIPv4(input));
}
/** Check if `input` is IPv6. */
function isIPv6(input) {
    return Boolean(parseIPv6(input));
}
/** Check if `input` is IPv4 or IPv6. */
function isIP(input) {
    return Boolean(parseIP(input));
}

const isV4$1 = isIPv4;
const isV6$1 = isIPv6;
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const toBytes$2 = function (ip) {
    let offset = 0;
    ip = ip.toString().trim();
    if (isV4$1(ip)) {
        const bytes = new Uint8Array(offset + 4);
        ip.split(/\./g).forEach((byte) => {
            bytes[offset++] = parseInt(byte, 10) & 0xff;
        });
        return bytes;
    }
    if (isV6$1(ip)) {
        const sections = ip.split(':', 8);
        let i;
        for (i = 0; i < sections.length; i++) {
            const isv4 = isV4$1(sections[i]);
            let v4Buffer;
            if (isv4) {
                v4Buffer = toBytes$2(sections[i]);
                sections[i] = toString$7(v4Buffer.slice(0, 2), 'base16');
            }
            if (v4Buffer != null && ++i < 8) {
                sections.splice(i, 0, toString$7(v4Buffer.slice(2, 4), 'base16'));
            }
        }
        if (sections[0] === '') {
            while (sections.length < 8)
                sections.unshift('0');
        }
        else if (sections[sections.length - 1] === '') {
            while (sections.length < 8)
                sections.push('0');
        }
        else if (sections.length < 8) {
            for (i = 0; i < sections.length && sections[i] !== ''; i++)
                ;
            const argv = [i, 1];
            for (i = 9 - sections.length; i > 0; i--) {
                argv.push('0');
            }
            sections.splice.apply(sections, argv);
        }
        const bytes = new Uint8Array(offset + 16);
        for (i = 0; i < sections.length; i++) {
            const word = parseInt(sections[i], 16);
            bytes[offset++] = (word >> 8) & 0xff;
            bytes[offset++] = word & 0xff;
        }
        return bytes;
    }
    throw new Error('invalid ip address');
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L63
const toString$6 = function (buf, offset = 0, length) {
    offset = ~~offset;
    length = length ?? (buf.length - offset);
    const view = new DataView(buf.buffer);
    if (length === 4) {
        const result = [];
        // IPv4
        for (let i = 0; i < length; i++) {
            result.push(buf[offset + i]);
        }
        return result.join('.');
    }
    if (length === 16) {
        const result = [];
        // IPv6
        for (let i = 0; i < length; i += 2) {
            result.push(view.getUint16(offset + i).toString(16));
        }
        return result.join(':')
            .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')
            .replace(/:{3,4}/, '::');
    }
    return '';
};

const V$1 = -1;
const names$1 = {};
const codes$4 = {};
const table$1 = [
    [4, 32, 'ip4'],
    [6, 16, 'tcp'],
    [33, 16, 'dccp'],
    [41, 128, 'ip6'],
    [42, V$1, 'ip6zone'],
    [43, 8, 'ipcidr'],
    [53, V$1, 'dns', true],
    [54, V$1, 'dns4', true],
    [55, V$1, 'dns6', true],
    [56, V$1, 'dnsaddr', true],
    [132, 16, 'sctp'],
    [273, 16, 'udp'],
    [275, 0, 'p2p-webrtc-star'],
    [276, 0, 'p2p-webrtc-direct'],
    [277, 0, 'p2p-stardust'],
    [280, 0, 'webrtc'],
    [281, 0, 'webrtc-w3c'],
    [290, 0, 'p2p-circuit'],
    [301, 0, 'udt'],
    [302, 0, 'utp'],
    [400, V$1, 'unix', false, true],
    // `ipfs` is added before `p2p` for legacy support.
    // All text representations will default to `p2p`, but `ipfs` will
    // still be supported
    [421, V$1, 'ipfs'],
    // `p2p` is the preferred name for 421, and is now the default
    [421, V$1, 'p2p'],
    [443, 0, 'https'],
    [444, 96, 'onion'],
    [445, 296, 'onion3'],
    [446, V$1, 'garlic64'],
    [448, 0, 'tls'],
    [449, V$1, 'sni'],
    [460, 0, 'quic'],
    [461, 0, 'quic-v1'],
    [465, 0, 'webtransport'],
    [466, V$1, 'certhash'],
    [477, 0, 'ws'],
    [478, 0, 'wss'],
    [479, 0, 'p2p-websocket-star'],
    [480, 0, 'http'],
    [777, V$1, 'memory']
];
// populate tables
table$1.forEach(row => {
    const proto = createProtocol$1(...row);
    codes$4[proto.code] = proto;
    names$1[proto.name] = proto;
});
function createProtocol$1(code, size, name, resolvable, path) {
    return {
        code,
        size,
        name,
        resolvable: Boolean(resolvable),
        path: Boolean(path)
    };
}
/**
 * For the passed proto string or number, return a {@link Protocol}
 *
 * @example
 *
 * ```js
 * import { protocol } from '@multiformats/multiaddr'
 *
 * console.info(protocol(4))
 * // { code: 4, size: 32, name: 'ip4', resolvable: false, path: false }
 * ```
 */
function getProtocol$1(proto) {
    if (typeof proto === 'number') {
        if (codes$4[proto] != null) {
            return codes$4[proto];
        }
        throw new Error(`no protocol with code: ${proto}`);
    }
    else if (typeof proto === 'string') {
        if (names$1[proto] != null) {
            return names$1[proto];
        }
        throw new Error(`no protocol with name: ${proto}`);
    }
    throw new Error(`invalid protocol id type: ${typeof proto}`);
}

/**
 * @packageDocumentation
 *
 * Provides methods for converting
 */
/**
 * Convert [code,Uint8Array] to string
 */
function convertToString$1(proto, buf) {
    const protocol = getProtocol$1(proto);
    switch (protocol.code) {
        case 4: // ipv4
        case 41: // ipv6
            return bytes2ip$1(buf);
        case 42: // ipv6zone
            return bytes2str$1(buf);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return bytes2port$1(buf).toString();
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return bytes2str$1(buf);
        case 421: // ipfs
            return bytes2mh$1(buf);
        case 444: // onion
            return bytes2onion$1(buf);
        case 445: // onion3
            return bytes2onion$1(buf);
        case 466: // certhash
            return bytes2mb$1(buf);
        default:
            return toString$7(buf, 'base16'); // no clue. convert to hex
    }
}
function convertToBytes$1(proto, str) {
    const protocol = getProtocol$1(proto);
    switch (protocol.code) {
        case 4: // ipv4
            return ip2bytes$1(str);
        case 41: // ipv6
            return ip2bytes$1(str);
        case 42: // ipv6zone
            return str2bytes$1(str);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return port2bytes$1(parseInt(str, 10));
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return str2bytes$1(str);
        case 421: // ipfs
            return mh2bytes$1(str);
        case 444: // onion
            return onion2bytes$1(str);
        case 445: // onion3
            return onion32bytes$1(str);
        case 466: // certhash
            return mb2bytes$1(str);
        default:
            return fromString$2(str, 'base16'); // no clue. convert from hex
    }
}
const decoders$1 = Object.values(bases).map((c) => c.decoder);
const anybaseDecoder$1 = (function () {
    let acc = decoders$1[0].or(decoders$1[1]);
    decoders$1.slice(2).forEach((d) => (acc = acc.or(d)));
    return acc;
})();
function ip2bytes$1(ipString) {
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return toBytes$2(ipString);
}
function bytes2ip$1(ipBuff) {
    const ipString = toString$6(ipBuff, 0, ipBuff.length);
    if (ipString == null) {
        throw new Error('ipBuff is required');
    }
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return ipString;
}
function port2bytes$1(port) {
    const buf = new ArrayBuffer(2);
    const view = new DataView(buf);
    view.setUint16(0, port);
    return new Uint8Array(buf);
}
function bytes2port$1(buf) {
    const view = new DataView(buf.buffer);
    return view.getUint16(buf.byteOffset);
}
function str2bytes$1(str) {
    const buf = fromString$2(str);
    const size = Uint8Array.from(varint.encode(buf.length));
    return concat([size, buf], size.length + buf.length);
}
function bytes2str$1(buf) {
    const size = varint.decode(buf);
    buf = buf.slice(varint.decode.bytes);
    if (buf.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$7(buf);
}
function mh2bytes$1(hash) {
    let mh;
    if (hash[0] === 'Q' || hash[0] === '1') {
        mh = decode$5(base58btc.decode(`z${hash}`)).bytes;
    }
    else {
        mh = CID.parse(hash).multihash.bytes;
    }
    // the address is a varint prefixed multihash string representation
    const size = Uint8Array.from(varint.encode(mh.length));
    return concat([size, mh], size.length + mh.length);
}
function mb2bytes$1(mbstr) {
    const mb = anybaseDecoder$1.decode(mbstr);
    const size = Uint8Array.from(varint.encode(mb.length));
    return concat([size, mb], size.length + mb.length);
}
function bytes2mb$1(buf) {
    const size = varint.decode(buf);
    const hash = buf.slice(varint.decode.bytes);
    if (hash.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return 'u' + toString$7(hash, 'base64url');
}
/**
 * Converts bytes to bas58btc string
 */
function bytes2mh$1(buf) {
    const size = varint.decode(buf);
    const address = buf.slice(varint.decode.bytes);
    if (address.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$7(address, 'base58btc');
}
function onion2bytes$1(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 16) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$1.decode('b' + addr[0]);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes$1(port);
    return concat([buf, portBuf], buf.length + portBuf.length);
}
function onion32bytes$1(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 56) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion3 address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$1.decode(`b${addr[0]}`);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes$1(port);
    return concat([buf, portBuf], buf.length + portBuf.length);
}
function bytes2onion$1(buf) {
    const addrBytes = buf.slice(0, buf.length - 2);
    const portBytes = buf.slice(buf.length - 2);
    const addr = toString$7(addrBytes, 'base32');
    const port = bytes2port$1(portBytes);
    return `${addr}:${port}`;
}

/**
 * string -> [[str name, str addr]... ]
 */
function stringToStringTuples$1(str) {
    const tuples = [];
    const parts = str.split('/').slice(1); // skip first empty elem
    if (parts.length === 1 && parts[0] === '') {
        return [];
    }
    for (let p = 0; p < parts.length; p++) {
        const part = parts[p];
        const proto = getProtocol$1(part);
        if (proto.size === 0) {
            tuples.push([part]);
            // eslint-disable-next-line no-continue
            continue;
        }
        p++; // advance addr part
        if (p >= parts.length) {
            throw ParseError$1('invalid address: ' + str);
        }
        // if it's a path proto, take the rest
        if (proto.path === true) {
            tuples.push([
                part,
                // should we need to check each path part to see if it's a proto?
                // This would allow for other protocols to be added after a unix path,
                // however it would have issues if the path had a protocol name in the path
                cleanPath$1(parts.slice(p).join('/'))
            ]);
            break;
        }
        tuples.push([part, parts[p]]);
    }
    return tuples;
}
/**
 * [[str name, str addr]... ] -> string
 */
function stringTuplesToString$1(tuples) {
    const parts = [];
    tuples.map((tup) => {
        const proto = protoFromTuple$1(tup);
        parts.push(proto.name);
        if (tup.length > 1 && tup[1] != null) {
            parts.push(tup[1]);
        }
        return null;
    });
    return cleanPath$1(parts.join('/'));
}
/**
 * [[str name, str addr]... ] -> [[int code, Uint8Array]... ]
 */
function stringTuplesToTuples$1(tuples) {
    return tuples.map((tup) => {
        if (!Array.isArray(tup)) {
            tup = [tup];
        }
        const proto = protoFromTuple$1(tup);
        if (tup.length > 1) {
            return [proto.code, convertToBytes$1(proto.code, tup[1])];
        }
        return [proto.code];
    });
}
/**
 * Convert tuples to string tuples
 *
 * [[int code, Uint8Array]... ] -> [[int code, str addr]... ]
 */
function tuplesToStringTuples$1(tuples) {
    return tuples.map(tup => {
        const proto = protoFromTuple$1(tup);
        if (tup[1] != null) {
            return [proto.code, convertToString$1(proto.code, tup[1])];
        }
        return [proto.code];
    });
}
/**
 * [[int code, Uint8Array ]... ] -> Uint8Array
 */
function tuplesToBytes$1(tuples) {
    return fromBytes$1(concat(tuples.map((tup) => {
        const proto = protoFromTuple$1(tup);
        let buf = Uint8Array.from(varint.encode(proto.code));
        if (tup.length > 1 && tup[1] != null) {
            buf = concat([buf, tup[1]]); // add address buffer
        }
        return buf;
    })));
}
/**
 * For the passed address, return the serialized size
 */
function sizeForAddr$1(p, addr) {
    if (p.size > 0) {
        return p.size / 8;
    }
    else if (p.size === 0) {
        return 0;
    }
    else {
        const size = varint.decode(addr);
        return size + (varint.decode.bytes ?? 0);
    }
}
function bytesToTuples$1(buf) {
    const tuples = [];
    let i = 0;
    while (i < buf.length) {
        const code = varint.decode(buf, i);
        const n = varint.decode.bytes ?? 0;
        const p = getProtocol$1(code);
        const size = sizeForAddr$1(p, buf.slice(i + n));
        if (size === 0) {
            tuples.push([code]);
            i += n;
            // eslint-disable-next-line no-continue
            continue;
        }
        const addr = buf.slice(i + n, i + n + size);
        i += (size + n);
        if (i > buf.length) { // did not end _exactly_ at buffer.length
            throw ParseError$1('Invalid address Uint8Array: ' + toString$7(buf, 'base16'));
        }
        // ok, tuple seems good.
        tuples.push([code, addr]);
    }
    return tuples;
}
/**
 * Uint8Array -> String
 */
function bytesToString$1(buf) {
    const a = bytesToTuples$1(buf);
    const b = tuplesToStringTuples$1(a);
    return stringTuplesToString$1(b);
}
/**
 * String -> Uint8Array
 */
function stringToBytes$1(str) {
    str = cleanPath$1(str);
    const a = stringToStringTuples$1(str);
    const b = stringTuplesToTuples$1(a);
    return tuplesToBytes$1(b);
}
/**
 * String -> Uint8Array
 */
function fromString$1(str) {
    return stringToBytes$1(str);
}
/**
 * Uint8Array -> Uint8Array
 */
function fromBytes$1(buf) {
    const err = validateBytes$1(buf);
    if (err != null) {
        throw err;
    }
    return Uint8Array.from(buf); // copy
}
function validateBytes$1(buf) {
    try {
        bytesToTuples$1(buf); // try to parse. will throw if breaks
    }
    catch (err) {
        return err;
    }
}
function cleanPath$1(str) {
    return '/' + str.trim().split('/').filter((a) => a).join('/');
}
function ParseError$1(str) {
    return new Error('Error parsing address: ' + str);
}
function protoFromTuple$1(tup) {
    const proto = getProtocol$1(tup[0]);
    return proto;
}

/**
 * @packageDocumentation
 *
 * An implementation of a Multiaddr in JavaScript
 *
 * @example
 *
 * ```js
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const ma = multiaddr('/ip4/127.0.0.1/tcp/1234')
 * ```
 */
var __classPrivateFieldGet$4 = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var __classPrivateFieldSet$2 = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return (kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;
};
var _DefaultMultiaddr_string$1, _DefaultMultiaddr_tuples$1, _DefaultMultiaddr_stringTuples$1, _a$1;
const inspect$1 = Symbol.for('nodejs.util.inspect.custom');
const DNS_CODES$1 = [
    getProtocol$1('dns').code,
    getProtocol$1('dns4').code,
    getProtocol$1('dns6').code,
    getProtocol$1('dnsaddr').code
];
/**
 * All configured {@link Resolver}s
 */
const resolvers$2 = new Map();
const symbol$4 = Symbol.for('@multiformats/js-multiaddr/multiaddr');
/**
 * Creates a Multiaddr from a node-friendly address object
 *
 * @example
 * ```js
 * import { fromNodeAddress } from '@multiformats/multiaddr'
 *
 * fromNodeAddress({address: '127.0.0.1', port: '4001'}, 'tcp')
 * // Multiaddr(/ip4/127.0.0.1/tcp/4001)
 * ```
 */
function fromNodeAddress(addr, transport) {
    if (addr == null) {
        throw new Error('requires node address object');
    }
    if (transport == null) {
        throw new Error('requires transport protocol');
    }
    let ip;
    let host = addr.address;
    switch (addr.family) {
        case 4:
            ip = 'ip4';
            break;
        case 6:
            ip = 'ip6';
            if (host.includes('%')) {
                const parts = host.split('%');
                if (parts.length !== 2) {
                    throw Error('Multiple ip6 zones in multiaddr');
                }
                host = parts[0];
                const zone = parts[1];
                ip = `/ip6zone/${zone}/ip6`;
            }
            break;
        default:
            throw Error('Invalid addr family, should be 4 or 6.');
    }
    return new DefaultMultiaddr$1('/' + [ip, host, transport, addr.port].join('/'));
}
/**
 * Check if object is a {@link Multiaddr} instance
 *
 * @example
 *
 * ```js
 * import { isMultiaddr, multiaddr } from '@multiformats/multiaddr'
 *
 * isMultiaddr(5)
 * // false
 * isMultiaddr(multiaddr('/ip4/127.0.0.1'))
 * // true
 * ```
 */
function isMultiaddr$1(value) {
    return Boolean(value?.[symbol$4]);
}
/**
 * Creates a {@link Multiaddr} from a {@link MultiaddrInput}
 */
let DefaultMultiaddr$1 = class DefaultMultiaddr {
    constructor(addr) {
        _DefaultMultiaddr_string$1.set(this, void 0);
        _DefaultMultiaddr_tuples$1.set(this, void 0);
        _DefaultMultiaddr_stringTuples$1.set(this, void 0);
        this[_a$1] = true;
        // default
        if (addr == null) {
            addr = '';
        }
        if (addr instanceof Uint8Array) {
            this.bytes = fromBytes$1(addr);
        }
        else if (typeof addr === 'string') {
            if (addr.length > 0 && addr.charAt(0) !== '/') {
                throw new Error(`multiaddr "${addr}" must start with a "/"`);
            }
            this.bytes = fromString$1(addr);
        }
        else if (isMultiaddr$1(addr)) { // Multiaddr
            this.bytes = fromBytes$1(addr.bytes); // validate + copy buffer
        }
        else {
            throw new Error('addr must be a string, Buffer, or another Multiaddr');
        }
    }
    toString() {
        if (__classPrivateFieldGet$4(this, _DefaultMultiaddr_string$1, "f") == null) {
            __classPrivateFieldSet$2(this, _DefaultMultiaddr_string$1, bytesToString$1(this.bytes), "f");
        }
        return __classPrivateFieldGet$4(this, _DefaultMultiaddr_string$1, "f");
    }
    toJSON() {
        return this.toString();
    }
    toOptions() {
        let family;
        let transport;
        let host;
        let port;
        let zone = '';
        const tcp = getProtocol$1('tcp');
        const udp = getProtocol$1('udp');
        const ip4 = getProtocol$1('ip4');
        const ip6 = getProtocol$1('ip6');
        const dns6 = getProtocol$1('dns6');
        const ip6zone = getProtocol$1('ip6zone');
        for (const [code, value] of this.stringTuples()) {
            if (code === ip6zone.code) {
                zone = `%${value ?? ''}`;
            }
            // default to https when protocol & port are omitted from DNS addrs
            if (DNS_CODES$1.includes(code)) {
                transport = tcp.name;
                port = 443;
                host = `${value ?? ''}${zone}`;
                family = code === dns6.code ? 6 : 4;
            }
            if (code === tcp.code || code === udp.code) {
                transport = getProtocol$1(code).name;
                port = parseInt(value ?? '');
            }
            if (code === ip4.code || code === ip6.code) {
                transport = getProtocol$1(code).name;
                host = `${value ?? ''}${zone}`;
                family = code === ip6.code ? 6 : 4;
            }
        }
        if (family == null || transport == null || host == null || port == null) {
            throw new Error('multiaddr must have a valid format: "/{ip4, ip6, dns4, dns6, dnsaddr}/{address}/{tcp, udp}/{port}".');
        }
        const opts = {
            family,
            host,
            transport,
            port
        };
        return opts;
    }
    protos() {
        return this.protoCodes().map(code => Object.assign({}, getProtocol$1(code)));
    }
    protoCodes() {
        const codes = [];
        const buf = this.bytes;
        let i = 0;
        while (i < buf.length) {
            const code = varint.decode(buf, i);
            const n = varint.decode.bytes ?? 0;
            const p = getProtocol$1(code);
            const size = sizeForAddr$1(p, buf.slice(i + n));
            i += (size + n);
            codes.push(code);
        }
        return codes;
    }
    protoNames() {
        return this.protos().map(proto => proto.name);
    }
    tuples() {
        if (__classPrivateFieldGet$4(this, _DefaultMultiaddr_tuples$1, "f") == null) {
            __classPrivateFieldSet$2(this, _DefaultMultiaddr_tuples$1, bytesToTuples$1(this.bytes), "f");
        }
        return __classPrivateFieldGet$4(this, _DefaultMultiaddr_tuples$1, "f");
    }
    stringTuples() {
        if (__classPrivateFieldGet$4(this, _DefaultMultiaddr_stringTuples$1, "f") == null) {
            __classPrivateFieldSet$2(this, _DefaultMultiaddr_stringTuples$1, tuplesToStringTuples$1(this.tuples()), "f");
        }
        return __classPrivateFieldGet$4(this, _DefaultMultiaddr_stringTuples$1, "f");
    }
    encapsulate(addr) {
        addr = new DefaultMultiaddr(addr);
        return new DefaultMultiaddr(this.toString() + addr.toString());
    }
    decapsulate(addr) {
        const addrString = addr.toString();
        const s = this.toString();
        const i = s.lastIndexOf(addrString);
        if (i < 0) {
            throw new Error(`Address ${this.toString()} does not contain subaddress: ${addr.toString()}`);
        }
        return new DefaultMultiaddr(s.slice(0, i));
    }
    decapsulateCode(code) {
        const tuples = this.tuples();
        for (let i = tuples.length - 1; i >= 0; i--) {
            if (tuples[i][0] === code) {
                return new DefaultMultiaddr(tuplesToBytes$1(tuples.slice(0, i)));
            }
        }
        return this;
    }
    getPeerId() {
        try {
            const tuples = this.stringTuples().filter((tuple) => {
                if (tuple[0] === names$1.ipfs.code) {
                    return true;
                }
                return false;
            });
            // Get the last ipfs tuple ['ipfs', 'peerid string']
            const tuple = tuples.pop();
            if (tuple?.[1] != null) {
                const peerIdStr = tuple[1];
                // peer id is base58btc encoded string but not multibase encoded so add the `z`
                // prefix so we can validate that it is correctly encoded
                if (peerIdStr[0] === 'Q' || peerIdStr[0] === '1') {
                    return toString$7(base58btc.decode(`z${peerIdStr}`), 'base58btc');
                }
                // try to parse peer id as CID
                return toString$7(CID.parse(peerIdStr).multihash.bytes, 'base58btc');
            }
            return null;
        }
        catch (e) {
            return null;
        }
    }
    getPath() {
        let path = null;
        try {
            path = this.stringTuples().filter((tuple) => {
                const proto = getProtocol$1(tuple[0]);
                if (proto.path === true) {
                    return true;
                }
                return false;
            })[0][1];
            if (path == null) {
                path = null;
            }
        }
        catch {
            path = null;
        }
        return path;
    }
    equals(addr) {
        return equals$2(this.bytes, addr.bytes);
    }
    async resolve(options) {
        const resolvableProto = this.protos().find((p) => p.resolvable);
        // Multiaddr is not resolvable?
        if (resolvableProto == null) {
            return [this];
        }
        const resolver = resolvers$2.get(resolvableProto.name);
        if (resolver == null) {
            throw errCode(new Error(`no available resolver for ${resolvableProto.name}`), 'ERR_NO_AVAILABLE_RESOLVER');
        }
        const addresses = await resolver(this, options);
        return addresses.map((a) => new DefaultMultiaddr(a));
    }
    nodeAddress() {
        const options = this.toOptions();
        if (options.transport !== 'tcp' && options.transport !== 'udp') {
            throw new Error(`multiaddr must have a valid format - no protocol with name: "${options.transport}". Must have a valid transport protocol: "{tcp, udp}"`);
        }
        return {
            family: options.family,
            address: options.host,
            port: options.port
        };
    }
    isThinWaistAddress(addr) {
        const protos = (addr ?? this).protos();
        if (protos.length !== 2) {
            return false;
        }
        if (protos[0].code !== 4 && protos[0].code !== 41) {
            return false;
        }
        if (protos[1].code !== 6 && protos[1].code !== 273) {
            return false;
        }
        return true;
    }
    /**
     * Returns Multiaddr as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { multiaddr } from '@multiformats/multiaddr'
     *
     * console.info(multiaddr('/ip4/127.0.0.1/tcp/4001'))
     * // 'Multiaddr(/ip4/127.0.0.1/tcp/4001)'
     * ```
     */
    [(_DefaultMultiaddr_string$1 = new WeakMap(), _DefaultMultiaddr_tuples$1 = new WeakMap(), _DefaultMultiaddr_stringTuples$1 = new WeakMap(), _a$1 = symbol$4, inspect$1)]() {
        return `Multiaddr(${bytesToString$1(this.bytes)})`;
    }
};
/**
 * A function that takes a {@link MultiaddrInput} and returns a {@link Multiaddr}
 *
 * @example
 * ```js
 * import { multiaddr } from '@libp2p/multiaddr'
 *
 * multiaddr('/ip4/127.0.0.1/tcp/4001')
 * // Multiaddr(/ip4/127.0.0.1/tcp/4001)
 * ```
 *
 * @param {MultiaddrInput} [addr] - If String or Uint8Array, needs to adhere to the address format of a [multiaddr](https://github.com/multiformats/multiaddr#string-format)
 */
function multiaddr$1(addr) {
    return new DefaultMultiaddr$1(addr);
}

const reduceValue = (_, v) => v;
const tcpUri = (str, port, parts, opts) => {
    // return tcp when explicitly requested
    if ((opts != null) && opts.assumeHttp === false)
        return `tcp://${str}:${port}`;
    // check if tcp is the last protocol in multiaddr
    let protocol = 'tcp';
    let explicitPort = `:${port}`;
    const last = parts[parts.length - 1];
    if (last.protocol === 'tcp') {
        // assume http and produce clean urls
        protocol = port === '443' ? 'https' : 'http';
        explicitPort = port === '443' || port === '80' ? '' : explicitPort;
    }
    return `${protocol}://${str}${explicitPort}`;
};
const Reducers = {
    ip4: reduceValue,
    ip6: (str, content, i, parts) => (parts.length === 1 && parts[0].protocol === 'ip6'
        ? content
        : `[${content}]`),
    tcp: (str, content, i, parts, opts) => (parts.some(p => ['http', 'https', 'ws', 'wss'].includes(p.protocol))
        ? `${str}:${content}`
        : tcpUri(str, content, parts, opts)),
    udp: (str, content) => `udp://${str}:${content}`,
    dnsaddr: reduceValue,
    dns4: reduceValue,
    dns6: reduceValue,
    ipfs: (str, content) => `${str}/ipfs/${content}`,
    p2p: (str, content) => `${str}/p2p/${content}`,
    http: str => `http://${str}`,
    https: str => `https://${str}`,
    ws: str => `ws://${str}`,
    wss: str => `wss://${str}`,
    'p2p-websocket-star': str => `${str}/p2p-websocket-star`,
    'p2p-webrtc-star': str => `${str}/p2p-webrtc-star`,
    'p2p-webrtc-direct': str => `${str}/p2p-webrtc-direct`
};
function multiaddrToUri(input, opts) {
    const ma = multiaddr$1(input);
    const parts = ma.toString().split('/').slice(1);
    return ma
        .tuples()
        .map(tuple => ({
        protocol: parts.shift() ?? '',
        content: (tuple[1] != null) ? parts.shift() ?? '' : ''
    }))
        .reduce((str, part, i, parts) => {
        const reduce = Reducers[part.protocol];
        if (reduce == null) {
            throw new Error(`Unsupported protocol ${part.protocol}`);
        }
        return reduce(str, part.content, i, parts, opts);
    }, '');
}

// https://github.com/electron/electron/issues/2288
function isElectron$1() {
    // Renderer process
    if (typeof window !== 'undefined' && typeof window.process === 'object' && window.process.type === 'renderer') {
        return true;
    }

    // Main process
    if (typeof process !== 'undefined' && typeof process.versions === 'object' && !!process.versions.electron) {
        return true;
    }

    // Detect the user agent when the `nodeIntegration` option is set to false
    if (typeof navigator === 'object' && typeof navigator.userAgent === 'string' && navigator.userAgent.indexOf('Electron') >= 0) {
        return true;
    }

    return false;
}

var isElectron_1 = isElectron$1;

const isEnvWithDom = typeof window === 'object' && typeof document === 'object' && document.nodeType === 9;
const isElectron = isElectron_1();

/**
 * Detects browser main thread  **NOT** web worker or service worker
 */
const isBrowser$1 = isEnvWithDom && !isElectron;
const isElectronMain = isElectron && !isEnvWithDom;
const isElectronRenderer = isElectron && isEnvWithDom;
const isNode = typeof globalThis.process !== 'undefined' && typeof globalThis.process.release !== 'undefined' && globalThis.process.release.name === 'node' && !isElectron;
// @ts-ignore
// eslint-disable-next-line no-undef
const isWebWorker = typeof importScripts === 'function' && typeof self !== 'undefined' && typeof WorkerGlobalScope !== 'undefined' && self instanceof WorkerGlobalScope;

// defeat bundlers replacing process.env.NODE_ENV with "development" or whatever
typeof globalThis.process !== 'undefined' && typeof globalThis.process.env !== 'undefined' && globalThis.process.env['NODE' + (() => '_')() + 'ENV'] === 'test';
const isReactNative = typeof navigator !== 'undefined' && navigator.product === 'ReactNative';

function createListener$1() {
    throw new Error('WebSocket Servers can not be created in the browser!');
}

// p2p multi-address code
const CODE_P2P = 421;
const CODE_CIRCUIT = 290;
// Time to wait for a connection to close gracefully before destroying it manually
const CLOSE_TIMEOUT = 2000;

let TimeoutError$2 = class TimeoutError extends Error {
	constructor(message) {
		super(message);
		this.name = 'TimeoutError';
	}
};

/**
An error to be thrown when the request is aborted by AbortController.
DOMException is thrown instead of this Error when DOMException is available.
*/
let AbortError$3 = class AbortError extends Error {
	constructor(message) {
		super();
		this.name = 'AbortError';
		this.message = message;
	}
};

/**
TODO: Remove AbortError and just throw DOMException when targeting Node 18.
*/
const getDOMException$1 = errorMessage => globalThis.DOMException === undefined
	? new AbortError$3(errorMessage)
	: new DOMException(errorMessage);

/**
TODO: Remove below function and just 'reject(signal.reason)' when targeting Node 18.
*/
const getAbortedReason$1 = signal => {
	const reason = signal.reason === undefined
		? getDOMException$1('This operation was aborted.')
		: signal.reason;

	return reason instanceof Error ? reason : getDOMException$1(reason);
};

function pTimeout$1(promise, options) {
	const {
		milliseconds,
		fallback,
		message,
		customTimers = {setTimeout, clearTimeout},
	} = options;

	let timer;

	const cancelablePromise = new Promise((resolve, reject) => {
		if (typeof milliseconds !== 'number' || Math.sign(milliseconds) !== 1) {
			throw new TypeError(`Expected \`milliseconds\` to be a positive number, got \`${milliseconds}\``);
		}

		if (milliseconds === Number.POSITIVE_INFINITY) {
			resolve(promise);
			return;
		}

		if (options.signal) {
			const {signal} = options;
			if (signal.aborted) {
				reject(getAbortedReason$1(signal));
			}

			signal.addEventListener('abort', () => {
				reject(getAbortedReason$1(signal));
			});
		}

		// We create the error outside of `setTimeout` to preserve the stack trace.
		const timeoutError = new TimeoutError$2();

		timer = customTimers.setTimeout.call(undefined, () => {
			if (fallback) {
				try {
					resolve(fallback());
				} catch (error) {
					reject(error);
				}

				return;
			}

			if (typeof promise.cancel === 'function') {
				promise.cancel();
			}

			if (message === false) {
				resolve();
			} else if (message instanceof Error) {
				reject(message);
			} else {
				timeoutError.message = message ?? `Promise timed out after ${milliseconds} milliseconds`;
				reject(timeoutError);
			}
		}, milliseconds);

		(async () => {
			try {
				resolve(await promise);
			} catch (error) {
				reject(error);
			} finally {
				customTimers.clearTimeout.call(undefined, timer);
			}
		})();
	});

	cancelablePromise.clear = () => {
		customTimers.clearTimeout.call(undefined, timer);
		timer = undefined;
	};

	return cancelablePromise;
}

const log$R = logger$2('libp2p:websockets:socket');
// Convert a stream into a MultiaddrConnection
// https://github.com/libp2p/interface-transport#multiaddrconnection
function socketToMaConn(stream, remoteAddr, options) {
    options = options ?? {};
    const maConn = {
        async sink(source) {
            if ((options?.signal) != null) {
                source = abortableSource(source, options.signal);
            }
            try {
                await stream.sink(source);
            }
            catch (err) {
                if (err.type !== 'aborted') {
                    log$R.error(err);
                }
            }
        },
        source: (options.signal != null) ? abortableSource(stream.source, options.signal) : stream.source,
        remoteAddr,
        timeline: { open: Date.now() },
        async close() {
            const start = Date.now();
            try {
                await pTimeout$1(stream.close(), {
                    milliseconds: CLOSE_TIMEOUT
                });
            }
            catch (err) {
                const { host, port } = maConn.remoteAddr.toOptions();
                log$R('timeout closing stream to %s:%s after %dms, destroying it manually', host, port, Date.now() - start);
                stream.destroy();
            }
            finally {
                maConn.timeline.close = Date.now();
            }
        }
    };
    stream.socket.addEventListener('close', () => {
        // In instances where `close` was not explicitly called,
        // such as an iterable stream ending, ensure we have set the close
        // timeline
        if (maConn.timeline.close == null) {
            maConn.timeline.close = Date.now();
        }
    }, { once: true });
    return maConn;
}

/*
 * Valid combinations
 */
const DNS4 = base('dns4');
const DNS6 = base('dns6');
const DNSADDR = base('dnsaddr');
const DNS = or(base('dns'), DNSADDR, DNS4, DNS6);
const IP = or(base('ip4'), base('ip6'));
const TCP = or(and(IP, base('tcp')), and(DNS, base('tcp')));
const UDP = and(IP, base('udp'));
const UTP = and(UDP, base('utp'));
const QUIC = and(UDP, base('quic'));
const WebSockets$1 = or(and(TCP, base('ws')), and(DNS, base('ws')));
const WebSocketsSecure = or(and(TCP, base('wss')), and(DNS, base('wss')), and(TCP, base('tls'), base('ws')), and(DNS, base('tls'), base('ws')));
const HTTP = or(and(TCP, base('http')), and(IP, base('http')), and(DNS, base('http')));
const HTTPS = or(and(TCP, base('https')), and(IP, base('https')), and(DNS, base('https')));
const _WebRTC = and(UDP, base('webrtc'), base('certhash'));
const WebRTC = or(and(_WebRTC, base('p2p')), _WebRTC);
const WebRTCStar = or(and(WebSockets$1, base('p2p-webrtc-star'), base('p2p')), and(WebSocketsSecure, base('p2p-webrtc-star'), base('p2p')), and(WebSockets$1, base('p2p-webrtc-star')), and(WebSocketsSecure, base('p2p-webrtc-star')));
const WebRTCDirect = or(and(HTTP, base('p2p-webrtc-direct'), base('p2p')), and(HTTPS, base('p2p-webrtc-direct'), base('p2p')), and(HTTP, base('p2p-webrtc-direct')), and(HTTPS, base('p2p-webrtc-direct')));
const Reliable = or(WebSockets$1, WebSocketsSecure, HTTP, HTTPS, WebRTCStar, WebRTCDirect, TCP, UTP, QUIC, DNS, WebRTC);
const _P2P = or(and(Reliable, base('p2p')), WebRTCStar, WebRTCDirect, WebRTC, base('p2p'));
const _Circuit = or(and(_P2P, base('p2p-circuit'), _P2P), and(_P2P, base('p2p-circuit')), and(base('p2p-circuit'), _P2P), and(Reliable, base('p2p-circuit')), and(base('p2p-circuit'), Reliable), base('p2p-circuit'));
const CircuitRecursive = () => or(and(_Circuit, CircuitRecursive), _Circuit);
const Circuit$1 = CircuitRecursive();
/*
 * Validation funcs
 */
function makeMatchesFunction(partialMatch) {
    function matches(a) {
        let ma;
        try {
            ma = multiaddr$1(a);
        }
        catch (err) { // catch error
            return false; // also if it's invalid it's probably not matching as well so return false
        }
        const out = partialMatch(ma.protoNames());
        if (out === null) {
            return false;
        }
        if (out === true || out === false) {
            return out;
        }
        return out.length === 0;
    }
    return matches;
}
function and(...args) {
    function partialMatch(a) {
        if (a.length < args.length) {
            return null;
        }
        let out = a;
        args.some((arg) => {
            out = typeof arg === 'function'
                ? arg().partialMatch(a)
                : arg.partialMatch(a);
            if (Array.isArray(out)) {
                a = out;
            }
            if (out === null) {
                return true;
            }
            return false;
        });
        return out;
    }
    return {
        toString: function () { return '{ ' + args.join(' ') + ' }'; },
        input: args,
        matches: makeMatchesFunction(partialMatch),
        partialMatch: partialMatch
    };
}
function or(...args) {
    function partialMatch(a) {
        let out = null;
        args.some((arg) => {
            const res = typeof arg === 'function'
                ? arg().partialMatch(a)
                : arg.partialMatch(a);
            if (res != null) {
                out = res;
                return true;
            }
            return false;
        });
        return out;
    }
    const result = {
        toString: function () { return '{ ' + args.join(' ') + ' }'; },
        input: args,
        matches: makeMatchesFunction(partialMatch),
        partialMatch: partialMatch
    };
    return result;
}
function base(n) {
    const name = n;
    function matches(a) {
        let ma;
        try {
            ma = multiaddr$1(a);
        }
        catch (err) { // catch error
            return false; // also if it's invalid it's probably not matching as well so return false
        }
        const pnames = ma.protoNames();
        if (pnames.length === 1 && pnames[0] === name) {
            return true;
        }
        return false;
    }
    function partialMatch(protos) {
        if (protos.length === 0) {
            return null;
        }
        if (protos[0] === name) {
            return protos.slice(1);
        }
        return null;
    }
    return {
        toString: function () { return name; },
        matches: matches,
        partialMatch: partialMatch
    };
}

function all$1(multiaddrs) {
    return multiaddrs.filter((ma) => {
        if (ma.protoCodes().includes(CODE_CIRCUIT)) {
            return false;
        }
        const testMa = ma.decapsulateCode(CODE_P2P);
        return WebSockets$1.matches(testMa) ||
            WebSocketsSecure.matches(testMa);
    });
}
function wss(multiaddrs) {
    return multiaddrs.filter((ma) => {
        if (ma.protoCodes().includes(CODE_CIRCUIT)) {
            return false;
        }
        const testMa = ma.decapsulateCode(CODE_P2P);
        return WebSocketsSecure.matches(testMa);
    });
}

const symbol$3 = Symbol.for('@libp2p/transport');
/**
 * Enum Transport Manager Fault Tolerance values
 */
var FaultTolerance;
(function (FaultTolerance) {
    /**
     * should be used for failing in any listen circumstance
     */
    FaultTolerance[FaultTolerance["FATAL_ALL"] = 0] = "FATAL_ALL";
    /**
     * should be used for not failing when not listening
     */
    FaultTolerance[FaultTolerance["NO_FATAL"] = 1] = "NO_FATAL";
})(FaultTolerance || (FaultTolerance = {}));

const log$Q = logger$2('libp2p:websockets');
class WebSockets {
    constructor(init) {
        this.init = init;
    }
    get [Symbol.toStringTag]() {
        return '@libp2p/websockets';
    }
    get [symbol$3]() {
        return true;
    }
    async dial(ma, options) {
        log$Q('dialing %s', ma);
        options = options ?? {};
        const socket = await this._connect(ma, options);
        const maConn = socketToMaConn(socket, ma);
        log$Q('new outbound connection %s', maConn.remoteAddr);
        const conn = await options.upgrader.upgradeOutbound(maConn);
        log$Q('outbound connection %s upgraded', maConn.remoteAddr);
        return conn;
    }
    async _connect(ma, options) {
        if (options?.signal?.aborted === true) {
            throw new AbortError$5();
        }
        const cOpts = ma.toOptions();
        log$Q('dialing %s:%s', cOpts.host, cOpts.port);
        const errorPromise = pDefer$1();
        const errfn = (err) => {
            log$Q.error('connection error:', err);
            errorPromise.reject(err);
        };
        const rawSocket = connect(multiaddrToUri(ma), this.init);
        if (rawSocket.socket.on != null) {
            rawSocket.socket.on('error', errfn);
        }
        else {
            rawSocket.socket.onerror = errfn;
        }
        if (options.signal == null) {
            await Promise.race([rawSocket.connected(), errorPromise.promise]);
            log$Q('connected %s', ma);
            return rawSocket;
        }
        // Allow abort via signal during connect
        let onAbort;
        const abort = new Promise((resolve, reject) => {
            onAbort = () => {
                reject(new AbortError$5());
                rawSocket.close().catch(err => {
                    log$Q.error('error closing raw socket', err);
                });
            };
            // Already aborted?
            if (options?.signal?.aborted === true) {
                onAbort();
                return;
            }
            options?.signal?.addEventListener('abort', onAbort);
        });
        try {
            await Promise.race([abort, errorPromise.promise, rawSocket.connected()]);
        }
        finally {
            if (onAbort != null) {
                options?.signal?.removeEventListener('abort', onAbort);
            }
        }
        log$Q('connected %s', ma);
        return rawSocket;
    }
    /**
     * Creates a Websockets listener. The provided `handler` function will be called
     * anytime a new incoming Connection has been successfully upgraded via
     * `upgrader.upgradeInbound`
     */
    createListener(options) {
        return createListener$1({ ...this.init, ...options });
    }
    /**
     * Takes a list of `Multiaddr`s and returns only valid Websockets addresses.
     * By default, in a browser environment only DNS+WSS multiaddr is accepted,
     * while in a Node.js environment DNS+{WS, WSS} multiaddrs are accepted.
     */
    filter(multiaddrs) {
        multiaddrs = Array.isArray(multiaddrs) ? multiaddrs : [multiaddrs];
        if (this.init?.filter != null) {
            return this.init?.filter(multiaddrs);
        }
        // Browser
        if (isBrowser$1 || isWebWorker) {
            return wss(multiaddrs);
        }
        return all$1(multiaddrs);
    }
}
function webSockets(init = {}) {
    return () => {
        return new WebSockets(init);
    };
}

/**
 * DefaultPubSubTopic is the default gossipsub topic to use for Waku.
 */
const DefaultPubSubTopic = "/waku/2/default-waku/proto";

var Protocols;
(function (Protocols) {
    Protocols["Relay"] = "relay";
    Protocols["Store"] = "store";
    Protocols["LightPush"] = "lightpush";
    Protocols["Filter"] = "filter";
})(Protocols || (Protocols = {}));

var PageDirection$1;
(function (PageDirection) {
    PageDirection["BACKWARD"] = "backward";
    PageDirection["FORWARD"] = "forward";
})(PageDirection$1 || (PageDirection$1 = {}));

var Tags$1;
(function (Tags) {
    Tags["BOOTSTRAP"] = "bootstrap";
    Tags["PEER_EXCHANGE"] = "peer-exchange";
})(Tags$1 || (Tags$1 = {}));

/**
 * RelayCodec is the libp2p identifier for the waku relay protocol
 */
const RelayCodecs = ["/vac/waku/relay/2.0.0"];
const RelayPingContentTopic = "/relay-ping/1/ping/null";

const log$P = debug("waku:keep-alive");
class KeepAliveManager {
    constructor(options, relay) {
        this.pingKeepAliveTimers = new Map();
        this.relayKeepAliveTimers = new Map();
        this.options = options;
        this.relay = relay;
    }
    start(peerId, libp2pPing) {
        // Just in case a timer already exist for this peer
        this.stop(peerId);
        const { pingKeepAlive: pingPeriodSecs, relayKeepAlive: relayPeriodSecs } = this.options;
        const peerIdStr = peerId.toString();
        if (pingPeriodSecs !== 0) {
            const interval = setInterval(() => {
                libp2pPing(peerId).catch((e) => {
                    log$P(`Ping failed (${peerIdStr})`, e);
                });
            }, pingPeriodSecs * 1000);
            this.pingKeepAliveTimers.set(peerIdStr, interval);
        }
        const relay = this.relay;
        if (relay && relayPeriodSecs !== 0) {
            const encoder = createEncoder({
                contentTopic: RelayPingContentTopic,
                ephemeral: true,
            });
            const interval = setInterval(() => {
                log$P("Sending Waku Relay ping message");
                relay
                    .send(encoder, { payload: new Uint8Array([1]) })
                    .catch((e) => log$P("Failed to send relay ping", e));
            }, relayPeriodSecs * 1000);
            this.relayKeepAliveTimers.set(peerId, interval);
        }
    }
    stop(peerId) {
        const peerIdStr = peerId.toString();
        if (this.pingKeepAliveTimers.has(peerIdStr)) {
            clearInterval(this.pingKeepAliveTimers.get(peerIdStr));
            this.pingKeepAliveTimers.delete(peerIdStr);
        }
        if (this.relayKeepAliveTimers.has(peerId)) {
            clearInterval(this.relayKeepAliveTimers.get(peerId));
            this.relayKeepAliveTimers.delete(peerId);
        }
    }
    stopAll() {
        for (const timer of [
            ...Object.values(this.pingKeepAliveTimers),
            ...Object.values(this.relayKeepAliveTimers),
        ]) {
            clearInterval(timer);
        }
        this.pingKeepAliveTimers.clear();
        this.relayKeepAliveTimers.clear();
    }
}

const log$O = debug("waku:connection-manager");
const DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED = 1;
const DEFAULT_MAX_DIAL_ATTEMPTS_FOR_PEER = 3;
class ConnectionManager {
    static create(peerId, libp2p, keepAliveOptions, relay, options) {
        let instance = ConnectionManager.instances.get(peerId);
        if (!instance) {
            instance = new ConnectionManager(libp2p, keepAliveOptions, relay, options);
            ConnectionManager.instances.set(peerId, instance);
        }
        return instance;
    }
    constructor(libp2pComponents, keepAliveOptions, relay, options) {
        this.dialAttemptsForPeer = new Map();
        this.onEventHandlers = {
            "peer:discovery": async (evt) => {
                const { id: peerId } = evt.detail;
                if (!(await this.shouldDialPeer(peerId)))
                    return;
                this.dialPeer(peerId).catch((err) => log$O(`Error dialing peer ${peerId.toString()} : ${err}`));
            },
            "peer:connect": (evt) => {
                {
                    this.keepAliveManager.start(evt.detail.remotePeer, this.libp2pComponents.ping.bind(this));
                }
            },
            "peer:disconnect": () => {
                return (evt) => {
                    this.keepAliveManager.stop(evt.detail.remotePeer);
                };
            },
        };
        this.libp2pComponents = libp2pComponents;
        this.options = {
            maxDialAttemptsForPeer: DEFAULT_MAX_DIAL_ATTEMPTS_FOR_PEER,
            maxBootstrapPeersAllowed: DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED,
            ...options,
        };
        this.keepAliveManager = new KeepAliveManager(keepAliveOptions, relay);
        this.run()
            .then(() => log$O(`Connection Manager is now running`))
            .catch((error) => log$O(`Unexpected error while running service`, error));
    }
    async run() {
        // start event listeners
        this.startPeerDiscoveryListener();
        this.startPeerConnectionListener();
        this.startPeerDisconnectionListener();
    }
    stop() {
        this.keepAliveManager.stopAll();
        this.libp2pComponents.removeEventListener("peer:connect", this.onEventHandlers["peer:connect"]);
        this.libp2pComponents.removeEventListener("peer:disconnect", this.onEventHandlers["peer:disconnect"]);
        this.libp2pComponents.removeEventListener("peer:discovery", this.onEventHandlers["peer:discovery"]);
    }
    async dialPeer(peerId) {
        let dialAttempt = 0;
        while (dialAttempt <= this.options.maxDialAttemptsForPeer) {
            try {
                log$O(`Dialing peer ${peerId.toString()}`);
                await this.libp2pComponents.dial(peerId);
                const tags = await this.getTagNamesForPeer(peerId);
                // add tag to connection describing discovery mechanism
                // don't add duplicate tags
                this.libp2pComponents
                    .getConnections(peerId)
                    .forEach((conn) => (conn.tags = Array.from(new Set([...conn.tags, ...tags]))));
                this.dialAttemptsForPeer.delete(peerId.toString());
                return;
            }
            catch (error) {
                log$O(`
          Error dialing peer ${peerId.toString()}`);
                dialAttempt = this.dialAttemptsForPeer.get(peerId.toString()) ?? 1;
                this.dialAttemptsForPeer.set(peerId.toString(), dialAttempt + 1);
                if (dialAttempt <= this.options.maxDialAttemptsForPeer) {
                    log$O(`Reattempting dial (${dialAttempt})`);
                }
            }
        }
        try {
            log$O(`Deleting undialable peer ${peerId.toString()} from peer store`);
            return await this.libp2pComponents.peerStore.delete(peerId);
        }
        catch (error) {
            throw `Error deleting undialable peer ${peerId.toString()} from peer store - ${error}`;
        }
    }
    startPeerDiscoveryListener() {
        this.libp2pComponents.peerStore.addEventListener("peer", this.onEventHandlers["peer:discovery"]);
    }
    startPeerConnectionListener() {
        this.libp2pComponents.addEventListener("peer:connect", this.onEventHandlers["peer:connect"]);
    }
    startPeerDisconnectionListener() {
        // TODO: ensure that these following issues are updated and confirmed
        /**
         * NOTE: Event is not being emitted on closing nor losing a connection.
         * @see https://github.com/libp2p/js-libp2p/issues/939
         * @see https://github.com/status-im/js-waku/issues/252
         *
         * >This event will be triggered anytime we are disconnected from another peer,
         * >regardless of the circumstances of that disconnection.
         * >If we happen to have multiple connections to a peer,
         * >this event will **only** be triggered when the last connection is closed.
         * @see https://github.com/libp2p/js-libp2p/blob/bad9e8c0ff58d60a78314077720c82ae331cc55b/doc/API.md?plain=1#L2100
         */
        this.libp2pComponents.addEventListener("peer:disconnect", this.onEventHandlers["peer:disconnect"]);
    }
    /**
     * Checks if the peer is dialable based on the following conditions:
     * 1. If the peer is a bootstrap peer, it is only dialable if the number of current bootstrap connections is less than the max allowed.
     * 2. If the peer is not a bootstrap peer
     */
    async shouldDialPeer(peerId) {
        const isConnected = this.libp2pComponents.getConnections(peerId).length > 0;
        if (isConnected)
            return false;
        const isBootstrap = (await this.getTagNamesForPeer(peerId)).some((tagName) => tagName === Tags$1.BOOTSTRAP);
        if (isBootstrap) {
            const currentBootstrapConnections = this.libp2pComponents
                .getConnections()
                .filter((conn) => {
                conn.tags.find((name) => name === Tags$1.BOOTSTRAP);
            }).length;
            if (currentBootstrapConnections < this.options.maxBootstrapPeersAllowed)
                return true;
        }
        else {
            return true;
        }
        return false;
    }
    /**
     * Fetches the tag names for a given peer
     */
    async getTagNamesForPeer(peerId) {
        const tags = (await this.libp2pComponents.peerStore.getTags(peerId)).map((tag) => tag.name);
        return tags;
    }
}
ConnectionManager.instances = new Map();

const DefaultPingKeepAliveValueSecs = 0;
const DefaultRelayKeepAliveValueSecs = 5 * 60;
const DefaultUserAgent = "js-waku";
const log$N = debug("waku:waku");
class WakuNode {
    constructor(options, libp2p, store, lightPush, filter, relay) {
        this.libp2p = libp2p;
        if (store) {
            this.store = store(libp2p);
        }
        if (filter) {
            this.filter = filter(libp2p);
        }
        if (lightPush) {
            this.lightPush = lightPush(libp2p);
        }
        if (relay) {
            this.relay = relay(libp2p);
        }
        const pingKeepAlive = options.pingKeepAlive || DefaultPingKeepAliveValueSecs;
        const relayKeepAlive = this.relay
            ? options.relayKeepAlive || DefaultRelayKeepAliveValueSecs
            : 0;
        const peerId = this.libp2p.peerId.toString();
        this.connectionManager = ConnectionManager.create(peerId, libp2p, { pingKeepAlive, relayKeepAlive }, this.relay);
        log$N("Waku node created", peerId, `relay: ${!!this.relay}, store: ${!!this.store}, light push: ${!!this
            .lightPush}, filter: ${!!this.filter}`);
    }
    /**
     * Dials to the provided peer.
     *
     * @param peer The peer to dial
     * @param protocols Waku protocols we expect from the peer; Defaults to mounted protocols
     */
    async dial(peer, protocols) {
        const _protocols = protocols ?? [];
        if (typeof protocols === "undefined") {
            this.relay && _protocols.push(Protocols.Relay);
            this.store && _protocols.push(Protocols.Store);
            this.filter && _protocols.push(Protocols.Filter);
            this.lightPush && _protocols.push(Protocols.LightPush);
        }
        const codecs = [];
        if (_protocols.includes(Protocols.Relay)) {
            if (this.relay) {
                this.relay.gossipSub.multicodecs.forEach((codec) => codecs.push(codec));
            }
            else {
                log$N("Relay codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.Store)) {
            if (this.store) {
                codecs.push(this.store.multicodec);
            }
            else {
                log$N("Store codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.LightPush)) {
            if (this.lightPush) {
                codecs.push(this.lightPush.multicodec);
            }
            else {
                log$N("Light Push codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.Filter)) {
            if (this.filter) {
                codecs.push(this.filter.multicodec);
            }
            else {
                log$N("Filter codec not included in dial codec: protocol not mounted locally");
            }
        }
        log$N(`Dialing to ${peer.toString()} with protocols ${_protocols}`);
        return this.libp2p.dialProtocol(peer, codecs);
    }
    async start() {
        await this.libp2p.start();
    }
    async stop() {
        this.connectionManager.stop();
        await this.libp2p.stop();
    }
    isStarted() {
        return this.libp2p.isStarted();
    }
    /**
     * Return the local multiaddr with peer id on which libp2p is listening.
     *
     * @throws if libp2p is not listening on localhost.
     */
    getLocalMultiaddrWithID() {
        const localMultiaddr = this.libp2p
            .getMultiaddrs()
            .find((addr) => addr.toString().match(/127\.0\.0\.1/));
        if (!localMultiaddr || localMultiaddr.toString() === "") {
            throw "Not listening on localhost";
        }
        return localMultiaddr + "/p2p/" + this.libp2p.peerId.toString();
    }
}

var minimal$5 = {};

var longbits$4;
var hasRequiredLongbits$4;

function requireLongbits$4 () {
	if (hasRequiredLongbits$4) return longbits$4;
	hasRequiredLongbits$4 = 1;
	longbits$4 = LongBits;

	var util = requireMinimal$4();

	/**
	 * Constructs new long bits.
	 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
	 * @memberof util
	 * @constructor
	 * @param {number} lo Low 32 bits, unsigned
	 * @param {number} hi High 32 bits, unsigned
	 */
	function LongBits(lo, hi) {

	    // note that the casts below are theoretically unnecessary as of today, but older statically
	    // generated converter code might still call the ctor with signed 32bits. kept for compat.

	    /**
	     * Low bits.
	     * @type {number}
	     */
	    this.lo = lo >>> 0;

	    /**
	     * High bits.
	     * @type {number}
	     */
	    this.hi = hi >>> 0;
	}

	/**
	 * Zero bits.
	 * @memberof util.LongBits
	 * @type {util.LongBits}
	 */
	var zero = LongBits.zero = new LongBits(0, 0);

	zero.toNumber = function() { return 0; };
	zero.zzEncode = zero.zzDecode = function() { return this; };
	zero.length = function() { return 1; };

	/**
	 * Zero hash.
	 * @memberof util.LongBits
	 * @type {string}
	 */
	var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

	/**
	 * Constructs new long bits from the specified number.
	 * @param {number} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.fromNumber = function fromNumber(value) {
	    if (value === 0)
	        return zero;
	    var sign = value < 0;
	    if (sign)
	        value = -value;
	    var lo = value >>> 0,
	        hi = (value - lo) / 4294967296 >>> 0;
	    if (sign) {
	        hi = ~hi >>> 0;
	        lo = ~lo >>> 0;
	        if (++lo > 4294967295) {
	            lo = 0;
	            if (++hi > 4294967295)
	                hi = 0;
	        }
	    }
	    return new LongBits(lo, hi);
	};

	/**
	 * Constructs new long bits from a number, long or string.
	 * @param {Long|number|string} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.from = function from(value) {
	    if (typeof value === "number")
	        return LongBits.fromNumber(value);
	    if (util.isString(value)) {
	        /* istanbul ignore else */
	        if (util.Long)
	            value = util.Long.fromString(value);
	        else
	            return LongBits.fromNumber(parseInt(value, 10));
	    }
	    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
	};

	/**
	 * Converts this long bits to a possibly unsafe JavaScript number.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {number} Possibly unsafe number
	 */
	LongBits.prototype.toNumber = function toNumber(unsigned) {
	    if (!unsigned && this.hi >>> 31) {
	        var lo = ~this.lo + 1 >>> 0,
	            hi = ~this.hi     >>> 0;
	        if (!lo)
	            hi = hi + 1 >>> 0;
	        return -(lo + hi * 4294967296);
	    }
	    return this.lo + this.hi * 4294967296;
	};

	/**
	 * Converts this long bits to a long.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {Long} Long
	 */
	LongBits.prototype.toLong = function toLong(unsigned) {
	    return util.Long
	        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
	        /* istanbul ignore next */
	        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
	};

	var charCodeAt = String.prototype.charCodeAt;

	/**
	 * Constructs new long bits from the specified 8 characters long hash.
	 * @param {string} hash Hash
	 * @returns {util.LongBits} Bits
	 */
	LongBits.fromHash = function fromHash(hash) {
	    if (hash === zeroHash)
	        return zero;
	    return new LongBits(
	        ( charCodeAt.call(hash, 0)
	        | charCodeAt.call(hash, 1) << 8
	        | charCodeAt.call(hash, 2) << 16
	        | charCodeAt.call(hash, 3) << 24) >>> 0
	    ,
	        ( charCodeAt.call(hash, 4)
	        | charCodeAt.call(hash, 5) << 8
	        | charCodeAt.call(hash, 6) << 16
	        | charCodeAt.call(hash, 7) << 24) >>> 0
	    );
	};

	/**
	 * Converts this long bits to a 8 characters long hash.
	 * @returns {string} Hash
	 */
	LongBits.prototype.toHash = function toHash() {
	    return String.fromCharCode(
	        this.lo        & 255,
	        this.lo >>> 8  & 255,
	        this.lo >>> 16 & 255,
	        this.lo >>> 24      ,
	        this.hi        & 255,
	        this.hi >>> 8  & 255,
	        this.hi >>> 16 & 255,
	        this.hi >>> 24
	    );
	};

	/**
	 * Zig-zag encodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzEncode = function zzEncode() {
	    var mask =   this.hi >> 31;
	    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
	    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Zig-zag decodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzDecode = function zzDecode() {
	    var mask = -(this.lo & 1);
	    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
	    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Calculates the length of this longbits when encoded as a varint.
	 * @returns {number} Length
	 */
	LongBits.prototype.length = function length() {
	    var part0 =  this.lo,
	        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
	        part2 =  this.hi >>> 24;
	    return part2 === 0
	         ? part1 === 0
	           ? part0 < 16384
	             ? part0 < 128 ? 1 : 2
	             : part0 < 2097152 ? 3 : 4
	           : part1 < 16384
	             ? part1 < 128 ? 5 : 6
	             : part1 < 2097152 ? 7 : 8
	         : part2 < 128 ? 9 : 10;
	};
	return longbits$4;
}

var hasRequiredMinimal$4;

function requireMinimal$4 () {
	if (hasRequiredMinimal$4) return minimal$5;
	hasRequiredMinimal$4 = 1;
	(function (exports) {
		var util = exports;

		// used to return a Promise where callback is omitted
		util.asPromise = aspromise;

		// converts to / from base64 encoded strings
		util.base64 = base64$9;

		// base class of rpc.Service
		util.EventEmitter = eventemitter;

		// float handling accross browsers
		util.float = float;

		// requires modules optionally and hides the call from bundlers
		util.inquire = inquire_1;

		// converts to / from utf8 encoded strings
		util.utf8 = utf8$e;

		// provides a node-like buffer pool in the browser
		util.pool = pool_1;

		// utility to work with the low and high bits of a 64 bit value
		util.LongBits = requireLongbits$4();

		/**
		 * Whether running within node or not.
		 * @memberof util
		 * @type {boolean}
		 */
		util.isNode = Boolean(typeof commonjsGlobal !== "undefined"
		                   && commonjsGlobal
		                   && commonjsGlobal.process
		                   && commonjsGlobal.process.versions
		                   && commonjsGlobal.process.versions.node);

		/**
		 * Global object reference.
		 * @memberof util
		 * @type {Object}
		 */
		util.global = util.isNode && commonjsGlobal
		           || typeof window !== "undefined" && window
		           || typeof self   !== "undefined" && self
		           || commonjsGlobal; // eslint-disable-line no-invalid-this

		/**
		 * An immuable empty array.
		 * @memberof util
		 * @type {Array.<*>}
		 * @const
		 */
		util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

		/**
		 * An immutable empty object.
		 * @type {Object}
		 * @const
		 */
		util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

		/**
		 * Tests if the specified value is an integer.
		 * @function
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is an integer
		 */
		util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
		    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
		};

		/**
		 * Tests if the specified value is a string.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a string
		 */
		util.isString = function isString(value) {
		    return typeof value === "string" || value instanceof String;
		};

		/**
		 * Tests if the specified value is a non-null object.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a non-null object
		 */
		util.isObject = function isObject(value) {
		    return value && typeof value === "object";
		};

		/**
		 * Checks if a property on a message is considered to be present.
		 * This is an alias of {@link util.isSet}.
		 * @function
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isset =

		/**
		 * Checks if a property on a message is considered to be present.
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isSet = function isSet(obj, prop) {
		    var value = obj[prop];
		    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
		        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
		    return false;
		};

		/**
		 * Any compatible Buffer instance.
		 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
		 * @interface Buffer
		 * @extends Uint8Array
		 */

		/**
		 * Node's Buffer class if available.
		 * @type {Constructor<Buffer>}
		 */
		util.Buffer = (function() {
		    try {
		        var Buffer = util.inquire("buffer").Buffer;
		        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
		        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
		    } catch (e) {
		        /* istanbul ignore next */
		        return null;
		    }
		})();

		// Internal alias of or polyfull for Buffer.from.
		util._Buffer_from = null;

		// Internal alias of or polyfill for Buffer.allocUnsafe.
		util._Buffer_allocUnsafe = null;

		/**
		 * Creates a new buffer of whatever type supported by the environment.
		 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
		 * @returns {Uint8Array|Buffer} Buffer
		 */
		util.newBuffer = function newBuffer(sizeOrArray) {
		    /* istanbul ignore next */
		    return typeof sizeOrArray === "number"
		        ? util.Buffer
		            ? util._Buffer_allocUnsafe(sizeOrArray)
		            : new util.Array(sizeOrArray)
		        : util.Buffer
		            ? util._Buffer_from(sizeOrArray)
		            : typeof Uint8Array === "undefined"
		                ? sizeOrArray
		                : new Uint8Array(sizeOrArray);
		};

		/**
		 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
		 * @type {Constructor<Uint8Array>}
		 */
		util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

		/**
		 * Any compatible Long instance.
		 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
		 * @interface Long
		 * @property {number} low Low bits
		 * @property {number} high High bits
		 * @property {boolean} unsigned Whether unsigned or not
		 */

		/**
		 * Long.js's Long class if available.
		 * @type {Constructor<Long>}
		 */
		util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
		         || /* istanbul ignore next */ util.global.Long
		         || util.inquire("long");

		/**
		 * Regular expression used to verify 2 bit (`bool`) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key2Re = /^true|false|0|1$/;

		/**
		 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

		/**
		 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

		/**
		 * Converts a number or long to an 8 characters long hash string.
		 * @param {Long|number} value Value to convert
		 * @returns {string} Hash
		 */
		util.longToHash = function longToHash(value) {
		    return value
		        ? util.LongBits.from(value).toHash()
		        : util.LongBits.zeroHash;
		};

		/**
		 * Converts an 8 characters long hash string to a long or number.
		 * @param {string} hash Hash
		 * @param {boolean} [unsigned=false] Whether unsigned or not
		 * @returns {Long|number} Original value
		 */
		util.longFromHash = function longFromHash(hash, unsigned) {
		    var bits = util.LongBits.fromHash(hash);
		    if (util.Long)
		        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
		    return bits.toNumber(Boolean(unsigned));
		};

		/**
		 * Merges the properties of the source object into the destination object.
		 * @memberof util
		 * @param {Object.<string,*>} dst Destination object
		 * @param {Object.<string,*>} src Source object
		 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
		 * @returns {Object.<string,*>} Destination object
		 */
		function merge(dst, src, ifNotSet) { // used by converters
		    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
		        if (dst[keys[i]] === undefined || !ifNotSet)
		            dst[keys[i]] = src[keys[i]];
		    return dst;
		}

		util.merge = merge;

		/**
		 * Converts the first character of a string to lower case.
		 * @param {string} str String to convert
		 * @returns {string} Converted string
		 */
		util.lcFirst = function lcFirst(str) {
		    return str.charAt(0).toLowerCase() + str.substring(1);
		};

		/**
		 * Creates a custom error constructor.
		 * @memberof util
		 * @param {string} name Error name
		 * @returns {Constructor<Error>} Custom error constructor
		 */
		function newError(name) {

		    function CustomError(message, properties) {

		        if (!(this instanceof CustomError))
		            return new CustomError(message, properties);

		        // Error.call(this, message);
		        // ^ just returns a new error instance because the ctor can be called as a function

		        Object.defineProperty(this, "message", { get: function() { return message; } });

		        /* istanbul ignore next */
		        if (Error.captureStackTrace) // node
		            Error.captureStackTrace(this, CustomError);
		        else
		            Object.defineProperty(this, "stack", { value: new Error().stack || "" });

		        if (properties)
		            merge(this, properties);
		    }

		    CustomError.prototype = Object.create(Error.prototype, {
		        constructor: {
		            value: CustomError,
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		        name: {
		            get: function get() { return name; },
		            set: undefined,
		            enumerable: false,
		            // configurable: false would accurately preserve the behavior of
		            // the original, but I'm guessing that was not intentional.
		            // For an actual error subclass, this property would
		            // be configurable.
		            configurable: true,
		        },
		        toString: {
		            value: function value() { return this.name + ": " + this.message; },
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		    });

		    return CustomError;
		}

		util.newError = newError;

		/**
		 * Constructs a new protocol error.
		 * @classdesc Error subclass indicating a protocol specifc error.
		 * @memberof util
		 * @extends Error
		 * @template T extends Message<T>
		 * @constructor
		 * @param {string} message Error message
		 * @param {Object.<string,*>} [properties] Additional properties
		 * @example
		 * try {
		 *     MyMessage.decode(someBuffer); // throws if required fields are missing
		 * } catch (e) {
		 *     if (e instanceof ProtocolError && e.instance)
		 *         console.log("decoded so far: " + JSON.stringify(e.instance));
		 * }
		 */
		util.ProtocolError = newError("ProtocolError");

		/**
		 * So far decoded message instance.
		 * @name util.ProtocolError#instance
		 * @type {Message<T>}
		 */

		/**
		 * A OneOf getter as returned by {@link util.oneOfGetter}.
		 * @typedef OneOfGetter
		 * @type {function}
		 * @returns {string|undefined} Set field name, if any
		 */

		/**
		 * Builds a getter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfGetter} Unbound getter
		 */
		util.oneOfGetter = function getOneOf(fieldNames) {
		    var fieldMap = {};
		    for (var i = 0; i < fieldNames.length; ++i)
		        fieldMap[fieldNames[i]] = 1;

		    /**
		     * @returns {string|undefined} Set field name, if any
		     * @this Object
		     * @ignore
		     */
		    return function() { // eslint-disable-line consistent-return
		        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
		            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
		                return keys[i];
		    };
		};

		/**
		 * A OneOf setter as returned by {@link util.oneOfSetter}.
		 * @typedef OneOfSetter
		 * @type {function}
		 * @param {string|undefined} value Field name
		 * @returns {undefined}
		 */

		/**
		 * Builds a setter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfSetter} Unbound setter
		 */
		util.oneOfSetter = function setOneOf(fieldNames) {

		    /**
		     * @param {string} name Field name
		     * @returns {undefined}
		     * @this Object
		     * @ignore
		     */
		    return function(name) {
		        for (var i = 0; i < fieldNames.length; ++i)
		            if (fieldNames[i] !== name)
		                delete this[fieldNames[i]];
		    };
		};

		/**
		 * Default conversion options used for {@link Message#toJSON} implementations.
		 *
		 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
		 *
		 * - Longs become strings
		 * - Enums become string keys
		 * - Bytes become base64 encoded strings
		 * - (Sub-)Messages become plain objects
		 * - Maps become plain objects with all string keys
		 * - Repeated fields become arrays
		 * - NaN and Infinity for float and double fields become strings
		 *
		 * @type {IConversionOptions}
		 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
		 */
		util.toJSONOptions = {
		    longs: String,
		    enums: String,
		    bytes: String,
		    json: true
		};

		// Sets up buffer utility according to the environment (called in index-minimal)
		util._configure = function() {
		    var Buffer = util.Buffer;
		    /* istanbul ignore if */
		    if (!Buffer) {
		        util._Buffer_from = util._Buffer_allocUnsafe = null;
		        return;
		    }
		    // because node 4.x buffers are incompatible & immutable
		    // see: https://github.com/dcodeIO/protobuf.js/pull/665
		    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
		        /* istanbul ignore next */
		        function Buffer_from(value, encoding) {
		            return new Buffer(value, encoding);
		        };
		    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
		        /* istanbul ignore next */
		        function Buffer_allocUnsafe(size) {
		            return new Buffer(size);
		        };
		};
} (minimal$5));
	return minimal$5;
}

var reader$8 = Reader$9;

var util$o      = requireMinimal$4();

var BufferReader$9; // cyclic

var LongBits$9  = util$o.LongBits,
    utf8$9      = util$o.utf8;

/* istanbul ignore next */
function indexOutOfRange$4(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader$9(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array$4 = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader$9(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader$9(buffer);
        throw Error("illegal buffer");
    };

var create$9 = function create() {
    return util$o.Buffer
        ? function create_buffer_setup(buffer) {
            return (Reader$9.create = function create_buffer(buffer) {
                return util$o.Buffer.isBuffer(buffer)
                    ? new BufferReader$9(buffer)
                    /* istanbul ignore next */
                    : create_array$4(buffer);
            })(buffer);
        }
        /* istanbul ignore next */
        : create_array$4;
};

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader$9.create = create$9();

Reader$9.prototype._slice = util$o.Array.prototype.subarray || /* istanbul ignore next */ util$o.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader$9.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange$4(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$9.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$9.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint$4() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits$9(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$4(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$4(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader$9.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end$4(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader$9.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$4(this, 4);

    return readFixed32_end$4(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader$9.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$4(this, 4);

    return readFixed32_end$4(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64$4(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$4(this, 8);

    return new LongBits$9(readFixed32_end$4(this.buf, this.pos += 4), readFixed32_end$4(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$9.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$4(this, 4);

    var value = util$o.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$9.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$4(this, 4);

    var value = util$o.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader$9.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange$4(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader$9.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8$9.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader$9.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange$4(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$4(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader$9.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader$9._configure = function(BufferReader_) {
    BufferReader$9 = BufferReader_;
    Reader$9.create = create$9();
    BufferReader$9._configure();

    var fn = util$o.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util$o.merge(Reader$9.prototype, {

        int64: function read_int64() {
            return readLongVarint$4.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint$4.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint$4.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64$4.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64$4.call(this)[fn](false);
        }

    });
};

var reader_buffer$4 = BufferReader$8;

// extends Reader
var Reader$8 = reader$8;
(BufferReader$8.prototype = Object.create(Reader$8.prototype)).constructor = BufferReader$8;

var util$n = requireMinimal$4();

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader$8(buffer) {
    Reader$8.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

BufferReader$8._configure = function () {
    /* istanbul ignore else */
    if (util$n.Buffer)
        BufferReader$8.prototype._slice = util$n.Buffer.prototype.slice;
};


/**
 * @override
 */
BufferReader$8.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice
        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))
        : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

BufferReader$8._configure();

var minimalExports$4 = requireMinimal$4();
var util$m = /*@__PURE__*/getDefaultExportFromCjs(minimalExports$4);

var writer$8 = Writer$9;

var util$l      = requireMinimal$4();

var BufferWriter$9; // cyclic

var LongBits$8  = util$l.LongBits,
    base64$4    = util$l.base64,
    utf8$8      = util$l.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op$4(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop$7() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State$4(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer$9() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op$4(noop$7, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

var create$8 = function create() {
    return util$l.Buffer
        ? function create_buffer_setup() {
            return (Writer$9.create = function create_buffer() {
                return new BufferWriter$9();
            })();
        }
        /* istanbul ignore next */
        : function create_array() {
            return new Writer$9();
        };
};

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer$9.create = create$8();

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer$9.alloc = function alloc(size) {
    return new util$l.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util$l.Array !== Array)
    Writer$9.alloc = util$l.pool(Writer$9.alloc, util$l.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer$9.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op$4(fn, len, val);
    this.len += len;
    return this;
};

function writeByte$4(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32$4(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp$4(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp$4.prototype = Object.create(Op$4.prototype);
VarintOp$4.prototype.fn = writeVarint32$4;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp$4(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64$4, 10, LongBits$8.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64$4(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$9.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits$8.from(value);
    return this._push(writeVarint64$4, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$9.prototype.int64 = Writer$9.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$9.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits$8.from(value).zzEncode();
    return this._push(writeVarint64$4, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.bool = function write_bool(value) {
    return this._push(writeByte$4, 1, value ? 1 : 0);
};

function writeFixed32$4(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32$4, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.sfixed32 = Writer$9.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$9.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits$8.from(value);
    return this._push(writeFixed32$4, 4, bits.lo)._push(writeFixed32$4, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$9.prototype.sfixed64 = Writer$9.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.float = function write_float(value) {
    return this._push(util$l.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.double = function write_double(value) {
    return this._push(util$l.float.writeDoubleLE, 8, value);
};

var writeBytes$4 = util$l.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte$4, 1, 0);
    if (util$l.isString(value)) {
        var buf = Writer$9.alloc(len = base64$4.length(value));
        base64$4.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes$4, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer$9.prototype.string = function write_string(value) {
    var len = utf8$8.length(value);
    return len
        ? this.uint32(len)._push(utf8$8.write, len, value)
        : this._push(writeByte$4, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer$9.prototype.fork = function fork() {
    this.states = new State$4(this);
    this.head = this.tail = new Op$4(noop$7, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer$9.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op$4(noop$7, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer$9.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer$9.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer$9._configure = function(BufferWriter_) {
    BufferWriter$9 = BufferWriter_;
    Writer$9.create = create$8();
    BufferWriter$9._configure();
};

var writer_buffer$4 = BufferWriter$8;

// extends Writer
var Writer$8 = writer$8;
(BufferWriter$8.prototype = Object.create(Writer$8.prototype)).constructor = BufferWriter$8;

var util$k = requireMinimal$4();

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter$8() {
    Writer$8.call(this);
}

BufferWriter$8._configure = function () {
    /**
     * Allocates a buffer of the specified size.
     * @function
     * @param {number} size Buffer size
     * @returns {Buffer} Buffer
     */
    BufferWriter$8.alloc = util$k._Buffer_allocUnsafe;

    BufferWriter$8.writeBytesBuffer = util$k.Buffer && util$k.Buffer.prototype instanceof Uint8Array && util$k.Buffer.prototype.set.name === "set"
        ? function writeBytesBuffer_set(val, buf, pos) {
          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
          // also works for plain array values
        }
        /* istanbul ignore next */
        : function writeBytesBuffer_copy(val, buf, pos) {
          if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
          else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
        };
};


/**
 * @override
 */
BufferWriter$8.prototype.bytes = function write_bytes_buffer(value) {
    if (util$k.isString(value))
        value = util$k._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(BufferWriter$8.writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer$4(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util$k.utf8.write(val, buf, pos);
    else if (buf.utf8Write)
        buf.utf8Write(val, pos);
    else
        buf.write(val, pos);
}

/**
 * @override
 */
BufferWriter$8.prototype.string = function write_string_buffer(value) {
    var len = util$k.Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer$4, len, value);
    return this;
};


/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

BufferWriter$8._configure();

// @ts-expect-error no types
function configure$3() {
    util$m._configure();
    reader$8._configure(reader_buffer$4);
    writer$8._configure(writer_buffer$4);
}
// Set up buffer utility according to the environment
configure$3();
// monkey patch the reader to add native bigint support
const methods$3 = [
    'uint64', 'int64', 'sint64', 'fixed64', 'sfixed64'
];
function patchReader$3(obj) {
    for (const method of methods$3) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function () {
            return BigInt(original.call(this).toString());
        };
    }
    return obj;
}
function reader$7(buf) {
    return patchReader$3(new reader$8(buf));
}
function patchWriter$3(obj) {
    for (const method of methods$3) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function (val) {
            return original.call(this, val.toString());
        };
    }
    return obj;
}
function writer$7() {
    return patchWriter$3(writer$8.create());
}

function decodeMessage$4(buf, codec) {
    const r = reader$7(buf instanceof Uint8Array ? buf : buf.subarray());
    return codec.decode(r);
}

function encodeMessage$3(message, codec) {
    const w = writer$7();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES$3;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES$3 || (CODEC_TYPES$3 = {}));
function createCodec$3(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function enumeration(v) {
    function findValue(val) {
        // Use the reverse mapping to look up the enum key for the stored value
        // https://www.typescriptlang.org/docs/handbook/enums.html#reverse-mappings
        if (v[val.toString()] == null) {
            throw new Error('Invalid enum value');
        }
        return v[val];
    }
    const encode = function enumEncode(val, writer) {
        const enumValue = findValue(val);
        writer.int32(enumValue);
    };
    const decode = function enumDecode(reader) {
        const val = reader.int32();
        return findValue(val);
    };
    // @ts-expect-error yeah yeah
    return createCodec$3('enum', CODEC_TYPES$3.VARINT, encode, decode);
}

function message$3(encode, decode) {
    return createCodec$3('message', CODEC_TYPES$3.LENGTH_DELIMITED, encode, decode);
}

/* eslint-disable import/export */
var RateLimitProof$3;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.proof != null && obj.proof.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if (obj.merkleRoot != null && obj.merkleRoot.byteLength > 0) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if (obj.epoch != null && obj.epoch.byteLength > 0) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if (obj.shareX != null && obj.shareX.byteLength > 0) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if (obj.shareY != null && obj.shareY.byteLength > 0) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if (obj.nullifier != null && obj.nullifier.byteLength > 0) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if (obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0),
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage$3(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$4(buf, RateLimitProof.codec());
    };
})(RateLimitProof$3 || (RateLimitProof$3 = {}));
var WakuMessage$3;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.payload != null && obj.payload.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if (obj.contentTopic != null && obj.contentTopic !== "") {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$3.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof$3.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage$3(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$4(buf, WakuMessage.codec());
    };
})(WakuMessage$3 || (WakuMessage$3 = {}));

/* eslint-disable import/export */
var FilterRequest;
(function (FilterRequest) {
    (function (ContentFilter) {
        let _codec;
        ContentFilter.codec = () => {
            if (_codec == null) {
                _codec = message$3((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if (obj.contentTopic != null && obj.contentTopic !== "") {
                        w.uint32(10);
                        w.string(obj.contentTopic);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        contentTopic: "",
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.contentTopic = reader.string();
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        ContentFilter.encode = (obj) => {
            return encodeMessage$3(obj, ContentFilter.codec());
        };
        ContentFilter.decode = (buf) => {
            return decodeMessage$4(buf, ContentFilter.codec());
        };
    })(FilterRequest.ContentFilter || (FilterRequest.ContentFilter = {}));
    let _codec;
    FilterRequest.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.subscribe != null && obj.subscribe !== false) {
                    w.uint32(8);
                    w.bool(obj.subscribe);
                }
                if (obj.topic != null && obj.topic !== "") {
                    w.uint32(18);
                    w.string(obj.topic);
                }
                if (obj.contentFilters != null) {
                    for (const value of obj.contentFilters) {
                        w.uint32(26);
                        FilterRequest.ContentFilter.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    subscribe: false,
                    topic: "",
                    contentFilters: [],
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.subscribe = reader.bool();
                            break;
                        case 2:
                            obj.topic = reader.string();
                            break;
                        case 3:
                            obj.contentFilters.push(FilterRequest.ContentFilter.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterRequest.encode = (obj) => {
        return encodeMessage$3(obj, FilterRequest.codec());
    };
    FilterRequest.decode = (buf) => {
        return decodeMessage$4(buf, FilterRequest.codec());
    };
})(FilterRequest || (FilterRequest = {}));
var MessagePush;
(function (MessagePush) {
    let _codec;
    MessagePush.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.messages != null) {
                    for (const value of obj.messages) {
                        w.uint32(10);
                        WakuMessage$2.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    messages: [],
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.messages.push(WakuMessage$2.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    MessagePush.encode = (obj) => {
        return encodeMessage$3(obj, MessagePush.codec());
    };
    MessagePush.decode = (buf) => {
        return decodeMessage$4(buf, MessagePush.codec());
    };
})(MessagePush || (MessagePush = {}));
var FilterRpc$1;
(function (FilterRpc) {
    let _codec;
    FilterRpc.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.requestId != null && obj.requestId !== "") {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.request != null) {
                    w.uint32(18);
                    FilterRequest.codec().encode(obj.request, w);
                }
                if (obj.push != null) {
                    w.uint32(26);
                    MessagePush.codec().encode(obj.push, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    requestId: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.requestId = reader.string();
                            break;
                        case 2:
                            obj.request = FilterRequest.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.push = MessagePush.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterRpc.encode = (obj) => {
        return encodeMessage$3(obj, FilterRpc.codec());
    };
    FilterRpc.decode = (buf) => {
        return decodeMessage$4(buf, FilterRpc.codec());
    };
})(FilterRpc$1 || (FilterRpc$1 = {}));
var RateLimitProof$2;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.proof != null && obj.proof.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if (obj.merkleRoot != null && obj.merkleRoot.byteLength > 0) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if (obj.epoch != null && obj.epoch.byteLength > 0) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if (obj.shareX != null && obj.shareX.byteLength > 0) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if (obj.shareY != null && obj.shareY.byteLength > 0) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if (obj.nullifier != null && obj.nullifier.byteLength > 0) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if (obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0),
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage$3(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$4(buf, RateLimitProof.codec());
    };
})(RateLimitProof$2 || (RateLimitProof$2 = {}));
var WakuMessage$2;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.payload != null && obj.payload.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if (obj.contentTopic != null && obj.contentTopic !== "") {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$2.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof$2.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage$3(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$4(buf, WakuMessage.codec());
    };
})(WakuMessage$2 || (WakuMessage$2 = {}));

/* eslint-disable import/export */
var TopicOnlyMessage$1;
(function (TopicOnlyMessage) {
    let _codec;
    TopicOnlyMessage.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.contentTopic != null && obj.contentTopic !== "") {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    contentTopic: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    TopicOnlyMessage.encode = (obj) => {
        return encodeMessage$3(obj, TopicOnlyMessage.codec());
    };
    TopicOnlyMessage.decode = (buf) => {
        return decodeMessage$4(buf, TopicOnlyMessage.codec());
    };
})(TopicOnlyMessage$1 || (TopicOnlyMessage$1 = {}));

/* eslint-disable import/export */
var PushRequest;
(function (PushRequest) {
    let _codec;
    PushRequest.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.pubsubTopic != null && obj.pubsubTopic !== "") {
                    w.uint32(10);
                    w.string(obj.pubsubTopic);
                }
                if (obj.message != null) {
                    w.uint32(18);
                    WakuMessage$1.codec().encode(obj.message, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    pubsubTopic: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.pubsubTopic = reader.string();
                            break;
                        case 2:
                            obj.message = WakuMessage$1.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushRequest.encode = (obj) => {
        return encodeMessage$3(obj, PushRequest.codec());
    };
    PushRequest.decode = (buf) => {
        return decodeMessage$4(buf, PushRequest.codec());
    };
})(PushRequest || (PushRequest = {}));
var PushResponse;
(function (PushResponse) {
    let _codec;
    PushResponse.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.isSuccess != null && obj.isSuccess !== false) {
                    w.uint32(8);
                    w.bool(obj.isSuccess);
                }
                if (obj.info != null) {
                    w.uint32(18);
                    w.string(obj.info);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    isSuccess: false,
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.isSuccess = reader.bool();
                            break;
                        case 2:
                            obj.info = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushResponse.encode = (obj) => {
        return encodeMessage$3(obj, PushResponse.codec());
    };
    PushResponse.decode = (buf) => {
        return decodeMessage$4(buf, PushResponse.codec());
    };
})(PushResponse || (PushResponse = {}));
var PushRpc$1;
(function (PushRpc) {
    let _codec;
    PushRpc.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.requestId != null && obj.requestId !== "") {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.request != null) {
                    w.uint32(18);
                    PushRequest.codec().encode(obj.request, w);
                }
                if (obj.response != null) {
                    w.uint32(26);
                    PushResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    requestId: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.requestId = reader.string();
                            break;
                        case 2:
                            obj.request = PushRequest.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.response = PushResponse.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushRpc.encode = (obj) => {
        return encodeMessage$3(obj, PushRpc.codec());
    };
    PushRpc.decode = (buf) => {
        return decodeMessage$4(buf, PushRpc.codec());
    };
})(PushRpc$1 || (PushRpc$1 = {}));
var RateLimitProof$1;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.proof != null && obj.proof.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if (obj.merkleRoot != null && obj.merkleRoot.byteLength > 0) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if (obj.epoch != null && obj.epoch.byteLength > 0) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if (obj.shareX != null && obj.shareX.byteLength > 0) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if (obj.shareY != null && obj.shareY.byteLength > 0) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if (obj.nullifier != null && obj.nullifier.byteLength > 0) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if (obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0),
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage$3(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$4(buf, RateLimitProof.codec());
    };
})(RateLimitProof$1 || (RateLimitProof$1 = {}));
var WakuMessage$1;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.payload != null && obj.payload.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if (obj.contentTopic != null && obj.contentTopic !== "") {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$1.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof$1.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage$3(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$4(buf, WakuMessage.codec());
    };
})(WakuMessage$1 || (WakuMessage$1 = {}));

/* eslint-disable import/export */
var Index;
(function (Index) {
    let _codec;
    Index.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.digest != null && obj.digest.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.digest);
                }
                if (obj.receiverTime != null && obj.receiverTime !== 0n) {
                    w.uint32(16);
                    w.sint64(obj.receiverTime);
                }
                if (obj.senderTime != null && obj.senderTime !== 0n) {
                    w.uint32(24);
                    w.sint64(obj.senderTime);
                }
                if (obj.pubsubTopic != null && obj.pubsubTopic !== "") {
                    w.uint32(34);
                    w.string(obj.pubsubTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    digest: new Uint8Array(0),
                    receiverTime: 0n,
                    senderTime: 0n,
                    pubsubTopic: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.digest = reader.bytes();
                            break;
                        case 2:
                            obj.receiverTime = reader.sint64();
                            break;
                        case 3:
                            obj.senderTime = reader.sint64();
                            break;
                        case 4:
                            obj.pubsubTopic = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Index.encode = (obj) => {
        return encodeMessage$3(obj, Index.codec());
    };
    Index.decode = (buf) => {
        return decodeMessage$4(buf, Index.codec());
    };
})(Index || (Index = {}));
var PagingInfo;
(function (PagingInfo) {
    (function (Direction) {
        Direction["BACKWARD"] = "BACKWARD";
        Direction["FORWARD"] = "FORWARD";
    })(PagingInfo.Direction || (PagingInfo.Direction = {}));
    let __DirectionValues;
    (function (__DirectionValues) {
        __DirectionValues[__DirectionValues["BACKWARD"] = 0] = "BACKWARD";
        __DirectionValues[__DirectionValues["FORWARD"] = 1] = "FORWARD";
    })(__DirectionValues || (__DirectionValues = {}));
    (function (Direction) {
        Direction.codec = () => {
            return enumeration(__DirectionValues);
        };
    })(PagingInfo.Direction || (PagingInfo.Direction = {}));
    let _codec;
    PagingInfo.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.pageSize != null) {
                    w.uint32(8);
                    w.uint64(obj.pageSize);
                }
                if (obj.cursor != null) {
                    w.uint32(18);
                    Index.codec().encode(obj.cursor, w);
                }
                if (obj.direction != null) {
                    w.uint32(24);
                    PagingInfo.Direction.codec().encode(obj.direction, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.pageSize = reader.uint64();
                            break;
                        case 2:
                            obj.cursor = Index.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.direction = PagingInfo.Direction.codec().decode(reader);
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PagingInfo.encode = (obj) => {
        return encodeMessage$3(obj, PagingInfo.codec());
    };
    PagingInfo.decode = (buf) => {
        return decodeMessage$4(buf, PagingInfo.codec());
    };
})(PagingInfo || (PagingInfo = {}));
var ContentFilter;
(function (ContentFilter) {
    let _codec;
    ContentFilter.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.contentTopic != null && obj.contentTopic !== "") {
                    w.uint32(10);
                    w.string(obj.contentTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    contentTopic: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.contentTopic = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    ContentFilter.encode = (obj) => {
        return encodeMessage$3(obj, ContentFilter.codec());
    };
    ContentFilter.decode = (buf) => {
        return decodeMessage$4(buf, ContentFilter.codec());
    };
})(ContentFilter || (ContentFilter = {}));
var HistoryQuery;
(function (HistoryQuery) {
    let _codec;
    HistoryQuery.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(18);
                    w.string(obj.pubsubTopic);
                }
                if (obj.contentFilters != null) {
                    for (const value of obj.contentFilters) {
                        w.uint32(26);
                        ContentFilter.codec().encode(value, w);
                    }
                }
                if (obj.pagingInfo != null) {
                    w.uint32(34);
                    PagingInfo.codec().encode(obj.pagingInfo, w);
                }
                if (obj.startTime != null) {
                    w.uint32(40);
                    w.sint64(obj.startTime);
                }
                if (obj.endTime != null) {
                    w.uint32(48);
                    w.sint64(obj.endTime);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    contentFilters: [],
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2:
                            obj.pubsubTopic = reader.string();
                            break;
                        case 3:
                            obj.contentFilters.push(ContentFilter.codec().decode(reader, reader.uint32()));
                            break;
                        case 4:
                            obj.pagingInfo = PagingInfo.codec().decode(reader, reader.uint32());
                            break;
                        case 5:
                            obj.startTime = reader.sint64();
                            break;
                        case 6:
                            obj.endTime = reader.sint64();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    HistoryQuery.encode = (obj) => {
        return encodeMessage$3(obj, HistoryQuery.codec());
    };
    HistoryQuery.decode = (buf) => {
        return decodeMessage$4(buf, HistoryQuery.codec());
    };
})(HistoryQuery || (HistoryQuery = {}));
var HistoryResponse;
(function (HistoryResponse) {
    let HistoryError;
    (function (HistoryError) {
        HistoryError["NONE"] = "NONE";
        HistoryError["INVALID_CURSOR"] = "INVALID_CURSOR";
    })(HistoryError = HistoryResponse.HistoryError || (HistoryResponse.HistoryError = {}));
    let __HistoryErrorValues;
    (function (__HistoryErrorValues) {
        __HistoryErrorValues[__HistoryErrorValues["NONE"] = 0] = "NONE";
        __HistoryErrorValues[__HistoryErrorValues["INVALID_CURSOR"] = 1] = "INVALID_CURSOR";
    })(__HistoryErrorValues || (__HistoryErrorValues = {}));
    (function (HistoryError) {
        HistoryError.codec = () => {
            return enumeration(__HistoryErrorValues);
        };
    })(HistoryError = HistoryResponse.HistoryError || (HistoryResponse.HistoryError = {}));
    let _codec;
    HistoryResponse.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.messages != null) {
                    for (const value of obj.messages) {
                        w.uint32(18);
                        WakuMessage.codec().encode(value, w);
                    }
                }
                if (obj.pagingInfo != null) {
                    w.uint32(26);
                    PagingInfo.codec().encode(obj.pagingInfo, w);
                }
                if (obj.error != null && __HistoryErrorValues[obj.error] !== 0) {
                    w.uint32(32);
                    HistoryResponse.HistoryError.codec().encode(obj.error, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    messages: [],
                    error: HistoryError.NONE,
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2:
                            obj.messages.push(WakuMessage.codec().decode(reader, reader.uint32()));
                            break;
                        case 3:
                            obj.pagingInfo = PagingInfo.codec().decode(reader, reader.uint32());
                            break;
                        case 4:
                            obj.error = HistoryResponse.HistoryError.codec().decode(reader);
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    HistoryResponse.encode = (obj) => {
        return encodeMessage$3(obj, HistoryResponse.codec());
    };
    HistoryResponse.decode = (buf) => {
        return decodeMessage$4(buf, HistoryResponse.codec());
    };
})(HistoryResponse || (HistoryResponse = {}));
var HistoryRpc$1;
(function (HistoryRpc) {
    let _codec;
    HistoryRpc.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.requestId != null && obj.requestId !== "") {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.query != null) {
                    w.uint32(18);
                    HistoryQuery.codec().encode(obj.query, w);
                }
                if (obj.response != null) {
                    w.uint32(26);
                    HistoryResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    requestId: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.requestId = reader.string();
                            break;
                        case 2:
                            obj.query = HistoryQuery.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.response = HistoryResponse.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    HistoryRpc.encode = (obj) => {
        return encodeMessage$3(obj, HistoryRpc.codec());
    };
    HistoryRpc.decode = (buf) => {
        return decodeMessage$4(buf, HistoryRpc.codec());
    };
})(HistoryRpc$1 || (HistoryRpc$1 = {}));
var RateLimitProof;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.proof != null && obj.proof.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if (obj.merkleRoot != null && obj.merkleRoot.byteLength > 0) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if (obj.epoch != null && obj.epoch.byteLength > 0) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if (obj.shareX != null && obj.shareX.byteLength > 0) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if (obj.shareY != null && obj.shareY.byteLength > 0) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if (obj.nullifier != null && obj.nullifier.byteLength > 0) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if (obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0),
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage$3(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$4(buf, RateLimitProof.codec());
    };
})(RateLimitProof || (RateLimitProof = {}));
var WakuMessage;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.payload != null && obj.payload.byteLength > 0) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if (obj.contentTopic != null && obj.contentTopic !== "") {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: "",
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage$3(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$4(buf, WakuMessage.codec());
    };
})(WakuMessage || (WakuMessage = {}));

/* eslint-disable import/export */
var PeerInfo;
(function (PeerInfo) {
    let _codec;
    PeerInfo.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.enr != null) {
                    w.uint32(10);
                    w.bytes(obj.enr);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.enr = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerInfo.encode = (obj) => {
        return encodeMessage$3(obj, PeerInfo.codec());
    };
    PeerInfo.decode = (buf) => {
        return decodeMessage$4(buf, PeerInfo.codec());
    };
})(PeerInfo || (PeerInfo = {}));
var PeerExchangeQuery;
(function (PeerExchangeQuery) {
    let _codec;
    PeerExchangeQuery.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.numPeers != null) {
                    w.uint32(8);
                    w.uint64(obj.numPeers);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.numPeers = reader.uint64();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeQuery.encode = (obj) => {
        return encodeMessage$3(obj, PeerExchangeQuery.codec());
    };
    PeerExchangeQuery.decode = (buf) => {
        return decodeMessage$4(buf, PeerExchangeQuery.codec());
    };
})(PeerExchangeQuery || (PeerExchangeQuery = {}));
var PeerExchangeResponse;
(function (PeerExchangeResponse) {
    let _codec;
    PeerExchangeResponse.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.peerInfos != null) {
                    for (const value of obj.peerInfos) {
                        w.uint32(10);
                        PeerInfo.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    peerInfos: [],
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.peerInfos.push(PeerInfo.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeResponse.encode = (obj) => {
        return encodeMessage$3(obj, PeerExchangeResponse.codec());
    };
    PeerExchangeResponse.decode = (buf) => {
        return decodeMessage$4(buf, PeerExchangeResponse.codec());
    };
})(PeerExchangeResponse || (PeerExchangeResponse = {}));
var PeerExchangeRPC;
(function (PeerExchangeRPC) {
    let _codec;
    PeerExchangeRPC.codec = () => {
        if (_codec == null) {
            _codec = message$3((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.query != null) {
                    w.uint32(10);
                    PeerExchangeQuery.codec().encode(obj.query, w);
                }
                if (obj.response != null) {
                    w.uint32(18);
                    PeerExchangeResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.query = PeerExchangeQuery.codec().decode(reader, reader.uint32());
                            break;
                        case 2:
                            obj.response = PeerExchangeResponse.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeRPC.encode = (obj) => {
        return encodeMessage$3(obj, PeerExchangeRPC.codec());
    };
    PeerExchangeRPC.decode = (buf) => {
        return decodeMessage$4(buf, PeerExchangeRPC.codec());
    };
})(PeerExchangeRPC || (PeerExchangeRPC = {}));

debug("waku:message:version-0");
const OneMillion$1 = BigInt(1000000);
const Version = 0;
class Encoder {
    constructor(contentTopic, ephemeral = false, metaSetter) {
        this.contentTopic = contentTopic;
        this.ephemeral = ephemeral;
        this.metaSetter = metaSetter;
    }
    async toWire(message) {
        return WakuMessage$3.encode(await this.toProtoObj(message));
    }
    async toProtoObj(message) {
        const timestamp = message.timestamp ?? new Date();
        const protoMessage = {
            payload: message.payload,
            version: Version,
            contentTopic: this.contentTopic,
            timestamp: BigInt(timestamp.valueOf()) * OneMillion$1,
            meta: undefined,
            rateLimitProof: message.rateLimitProof,
            ephemeral: this.ephemeral,
        };
        if (this.metaSetter) {
            const meta = this.metaSetter(protoMessage);
            return { ...protoMessage, meta };
        }
        return protoMessage;
    }
}
/**
 * Creates an encoder that encode messages without Waku level encryption or signature.
 *
 * An encoder is used to encode messages in the [`14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/)
 * format to be sent over the Waku network. The resulting encoder can then be
 * pass to { @link @waku/interfaces.LightPush.push } or
 * { @link @waku/interfaces.Relay.send } to automatically encode outgoing
 * messages.
 */
function createEncoder({ contentTopic, ephemeral, metaSetter, }) {
    return new Encoder(contentTopic, ephemeral, metaSetter);
}

const log$M = debug("waku:message:topic-only");
class TopicOnlyMessage {
    constructor(pubSubTopic, proto) {
        this.pubSubTopic = pubSubTopic;
        this.proto = proto;
        this.payload = new Uint8Array();
    }
    get contentTopic() {
        return this.proto.contentTopic;
    }
}
class TopicOnlyDecoder {
    constructor() {
        this.contentTopic = "";
    }
    fromWireToProtoObj(bytes) {
        const protoMessage = TopicOnlyMessage$1.decode(bytes);
        log$M("Message decoded", protoMessage);
        return Promise.resolve({
            contentTopic: protoMessage.contentTopic,
            payload: new Uint8Array(),
            rateLimitProof: undefined,
            timestamp: undefined,
            meta: undefined,
            version: undefined,
            ephemeral: undefined,
        });
    }
    async fromProtoObj(pubSubTopic, proto) {
        return new TopicOnlyMessage(pubSubTopic, proto);
    }
}

/**
 * Collects all values from an (async) iterable and returns them as an array
 */
async function all(source) {
    const arr = [];
    for await (const entry of source) {
        arr.push(entry);
    }
    return arr;
}

const log$L = debug("waku:libp2p-utils");
/**
 * Returns a pseudo-random peer that supports the given protocol.
 * Useful for protocols such as store and light push
 */
function selectRandomPeer(peers) {
    if (peers.length === 0)
        return;
    const index = Math.round(Math.random() * (peers.length - 1));
    return peers[index];
}
/**
 * Returns the list of peers that supports the given protocol.
 */
async function getPeersForProtocol(peerStore, protocols) {
    const peers = [];
    await peerStore.forEach((peer) => {
        for (let i = 0; i < protocols.length; i++) {
            if (peer.protocols.includes(protocols[i])) {
                peers.push(peer);
                break;
            }
        }
    });
    return peers;
}
async function selectPeerForProtocol(peerStore, protocols, peerId) {
    let peer;
    if (peerId) {
        peer = await peerStore.get(peerId);
        if (!peer) {
            throw new Error(`Failed to retrieve connection details for provided peer in peer store: ${peerId.toString()}`);
        }
    }
    else {
        const peers = await getPeersForProtocol(peerStore, protocols);
        peer = selectRandomPeer(peers);
        if (!peer) {
            throw new Error(`Failed to find known peer that registers protocols: ${protocols}`);
        }
    }
    let protocol;
    for (const codec of protocols) {
        if (peer.protocols.includes(codec)) {
            protocol = codec;
            // Do not break as we want to keep the last value
        }
    }
    log$L(`Using codec ${protocol}`);
    if (!protocol) {
        throw new Error(`Peer does not register required protocols (${peer.id.toString()}): ${protocols}`);
    }
    return { peer, protocol };
}
function selectConnection(connections) {
    if (!connections.length)
        return;
    if (connections.length === 1)
        return connections[0];
    let latestConnection;
    connections.forEach((connection) => {
        if (connection.stat.status === "OPEN") {
            if (!latestConnection) {
                latestConnection = connection;
            }
            else if (connection.stat.timeline.open > latestConnection.stat.timeline.open) {
                latestConnection = connection;
            }
        }
    });
    return latestConnection;
}

/**
 * A class with predefined helpers, to be used as a base to implement Waku
 * Protocols.
 */
class BaseProtocol {
    constructor(multicodec, peerStore, getConnections) {
        this.multicodec = multicodec;
        this.peerStore = peerStore;
        this.getConnections = getConnections;
    }
    /**
     * Returns known peers from the address book (`libp2p.peerStore`) that support
     * the class protocol. Waku may or may not be currently connected to these
     * peers.
     */
    async peers() {
        return getPeersForProtocol(this.peerStore, [this.multicodec]);
    }
    async getPeer(peerId) {
        const { peer } = await selectPeerForProtocol(this.peerStore, [this.multicodec], peerId);
        return peer;
    }
    async newStream(peer) {
        const connections = this.getConnections(peer.id);
        const connection = selectConnection(connections);
        if (!connection) {
            throw new Error("Failed to get a connection to the peer");
        }
        return connection.newStream(this.multicodec);
    }
}

function groupByContentTopic(values) {
    const groupedDecoders = new Map();
    values.forEach((value) => {
        let decs = groupedDecoders.get(value.contentTopic);
        if (!decs) {
            groupedDecoders.set(value.contentTopic, []);
            decs = groupedDecoders.get(value.contentTopic);
        }
        decs.push(value);
    });
    return groupedDecoders;
}

const EmptyMessage = {
    payload: new Uint8Array(),
    contentTopic: "",
    version: undefined,
    timestamp: undefined,
    meta: undefined,
    rateLimitProof: undefined,
    ephemeral: undefined,
};
function toProtoMessage(wire) {
    return { ...EmptyMessage, ...wire };
}

// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
let getRandomValues;
const rnds8 = new Uint8Array(16);
function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);

    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }

  return getRandomValues(rnds8);
}

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */

const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).slice(1));
}

function unsafeStringify(arr, offset = 0) {
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();
}

const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var native = {
  randomUUID
};

function v4$2(options, buf, offset) {
  if (native.randomUUID && !buf && !options) {
    return native.randomUUID();
  }

  options = options || {};
  const rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`

  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  if (buf) {
    offset = offset || 0;

    for (let i = 0; i < 16; ++i) {
      buf[offset + i] = rnds[i];
    }

    return buf;
  }

  return unsafeStringify(rnds);
}

/**
 * FilterRPC represents a message conforming to the Waku Filter protocol
 */
class FilterRpc {
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(topic, contentFilters, requestId, subscribe = true) {
        return new FilterRpc({
            requestId: requestId || v4$2(),
            request: {
                subscribe,
                topic,
                contentFilters,
            },
            push: undefined,
        });
    }
    /**
     *
     * @param bytes Uint8Array of bytes from a FilterRPC message
     * @returns FilterRpc
     */
    static decode(bytes) {
        const res = FilterRpc$1.decode(bytes);
        return new FilterRpc(res);
    }
    /**
     * Encode the current FilterRPC request to bytes
     * @returns Uint8Array
     */
    encode() {
        return FilterRpc$1.encode(this.proto);
    }
    get push() {
        return this.proto.push;
    }
    get requestId() {
        return this.proto.requestId;
    }
}

const FilterCodec = "/vac/waku/filter/2.0.0-beta1";
const log$K = debug("waku:filter");
/**
 * Implements client side of the [Waku v2 Filter protocol](https://rfc.vac.dev/spec/12/).
 *
 * Note this currently only works in NodeJS when the Waku node is listening on a port, see:
 * - https://github.com/status-im/go-waku/issues/245
 * - https://github.com/status-im/nwaku/issues/948
 */
class Filter extends BaseProtocol {
    constructor(libp2p, options) {
        super(FilterCodec, libp2p.peerStore, libp2p.getConnections.bind(libp2p));
        this.libp2p = libp2p;
        this.options = options ?? {};
        this.subscriptions = new Map();
        this.libp2p
            .handle(this.multicodec, this.onRequest.bind(this))
            .catch((e) => log$K("Failed to register filter protocol", e));
    }
    /**
     * @param decoders Decoder or array of Decoders to use to decode messages, it also specifies the content topics.
     * @param callback A function that will be called on each message returned by the filter.
     * @param opts The FilterSubscriptionOpts used to narrow which messages are returned, and which peer to connect to.
     * @returns Unsubscribe function that can be used to end the subscription.
     */
    async subscribe(decoders, callback, opts) {
        const decodersArray = Array.isArray(decoders) ? decoders : [decoders];
        const { pubSubTopic = DefaultPubSubTopic } = this.options;
        const contentTopics = Array.from(groupByContentTopic(decodersArray).keys());
        const contentFilters = contentTopics.map((contentTopic) => ({
            contentTopic,
        }));
        const request = FilterRpc.createRequest(pubSubTopic, contentFilters, undefined, true);
        const requestId = request.requestId;
        const peer = await this.getPeer(opts?.peerId);
        const stream = await this.newStream(peer);
        try {
            const res = await pipe([request.encode()], encode$b(), stream, decode$a(), async (source) => await all(source));
            log$K("response", res);
        }
        catch (e) {
            log$K("Error subscribing to peer ", peer.id.toString(), "for content topics", contentTopics, ": ", e);
            throw e;
        }
        const subscription = {
            callback,
            decoders: decodersArray,
            pubSubTopic,
        };
        this.subscriptions.set(requestId, subscription);
        return async () => {
            await this.unsubscribe(pubSubTopic, contentFilters, requestId, peer);
            this.subscriptions.delete(requestId);
        };
    }
    getActiveSubscriptions() {
        const map = new Map();
        const subscriptions = this.subscriptions;
        for (const item of subscriptions.values()) {
            const values = map.get(item.pubSubTopic) || [];
            const nextValues = item.decoders.map((decoder) => decoder.contentTopic);
            map.set(item.pubSubTopic, [...values, ...nextValues]);
        }
        return map;
    }
    onRequest(streamData) {
        log$K("Receiving message push");
        try {
            pipe(streamData.stream, decode$a(), async (source) => {
                for await (const bytes of source) {
                    const res = FilterRpc.decode(bytes.slice());
                    if (res.requestId && res.push?.messages?.length) {
                        await this.pushMessages(res.requestId, res.push.messages);
                    }
                }
            }).then(() => {
                log$K("Receiving pipe closed.");
            }, (e) => {
                log$K("Error with receiving pipe", e);
            });
        }
        catch (e) {
            log$K("Error decoding message", e);
        }
    }
    async pushMessages(requestId, messages) {
        const subscription = this.subscriptions.get(requestId);
        if (!subscription) {
            log$K(`No subscription locally registered for request ID ${requestId}`);
            return;
        }
        const { decoders, callback, pubSubTopic } = subscription;
        if (!decoders || !decoders.length) {
            log$K(`No decoder registered for request ID ${requestId}`);
            return;
        }
        for (const protoMessage of messages) {
            const contentTopic = protoMessage.contentTopic;
            if (!contentTopic) {
                log$K("Message has no content topic, skipping");
                return;
            }
            let didDecodeMsg = false;
            // We don't want to wait for decoding failure, just attempt to decode
            // all messages and do the call back on the one that works
            // noinspection ES6MissingAwait
            decoders.forEach(async (dec) => {
                if (didDecodeMsg)
                    return;
                const decoded = await dec.fromProtoObj(pubSubTopic, toProtoMessage(protoMessage));
                if (!decoded) {
                    log$K("Not able to decode message");
                    return;
                }
                // This is just to prevent more decoding attempt
                // TODO: Could be better if we were to abort promises
                didDecodeMsg = Boolean(decoded);
                await callback(decoded);
            });
        }
    }
    async unsubscribe(topic, contentFilters, requestId, peer) {
        const unsubscribeRequest = FilterRpc.createRequest(topic, contentFilters, requestId, false);
        const stream = await this.newStream(peer);
        try {
            await pipe([unsubscribeRequest.encode()], encode$b(), stream.sink);
        }
        catch (e) {
            log$K("Error unsubscribing", e);
            throw e;
        }
    }
}
function wakuFilter(init = {}) {
    return (libp2p) => new Filter(libp2p, init);
}

class PushRpc {
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(message, pubSubTopic) {
        return new PushRpc({
            requestId: v4$2(),
            request: {
                message: message,
                pubsubTopic: pubSubTopic,
            },
            response: undefined,
        });
    }
    static decode(bytes) {
        const res = PushRpc$1.decode(bytes);
        return new PushRpc(res);
    }
    encode() {
        return PushRpc$1.encode(this.proto);
    }
    get query() {
        return this.proto.request;
    }
    get response() {
        return this.proto.response;
    }
}

const log$J = debug("waku:light-push");
const LightPushCodec = "/vac/waku/lightpush/2.0.0-beta1";
/**
 * Implements the [Waku v2 Light Push protocol](https://rfc.vac.dev/spec/19/).
 */
class LightPush extends BaseProtocol {
    constructor(libp2p, options) {
        super(LightPushCodec, libp2p.peerStore, libp2p.getConnections.bind(libp2p));
        this.libp2p = libp2p;
        this.options = options || {};
    }
    async send(encoder, message, opts) {
        const { pubSubTopic = DefaultPubSubTopic } = this.options;
        const peer = await this.getPeer(opts?.peerId);
        const stream = await this.newStream(peer);
        const recipients = [];
        try {
            const protoMessage = await encoder.toProtoObj(message);
            if (!protoMessage) {
                log$J("Failed to encode to protoMessage, aborting push");
                return { recipients };
            }
            const query = PushRpc.createRequest(protoMessage, pubSubTopic);
            const res = await pipe([query.encode()], encode$b(), stream, decode$a(), async (source) => await all(source));
            try {
                const bytes = new Uint8ArrayList();
                res.forEach((chunk) => {
                    bytes.append(chunk);
                });
                const response = PushRpc.decode(bytes).response;
                if (!response) {
                    log$J("No response in PushRPC");
                    return { recipients };
                }
                if (response.isSuccess) {
                    recipients.push(peer.id);
                }
            }
            catch (err) {
                log$J("Failed to decode push reply", err);
            }
        }
        catch (err) {
            log$J("Failed to send waku light push request", err);
        }
        return { recipients };
    }
}
function wakuLightPush(init = {}) {
    return (libp2p) => new LightPush(libp2p, init);
}

const codes$3 = {
    ERR_SIGNATURE_NOT_VALID: 'ERR_SIGNATURE_NOT_VALID'
};

var minimal$4 = {};

var longbits$3;
var hasRequiredLongbits$3;

function requireLongbits$3 () {
	if (hasRequiredLongbits$3) return longbits$3;
	hasRequiredLongbits$3 = 1;
	longbits$3 = LongBits;

	var util = requireMinimal$3();

	/**
	 * Constructs new long bits.
	 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
	 * @memberof util
	 * @constructor
	 * @param {number} lo Low 32 bits, unsigned
	 * @param {number} hi High 32 bits, unsigned
	 */
	function LongBits(lo, hi) {

	    // note that the casts below are theoretically unnecessary as of today, but older statically
	    // generated converter code might still call the ctor with signed 32bits. kept for compat.

	    /**
	     * Low bits.
	     * @type {number}
	     */
	    this.lo = lo >>> 0;

	    /**
	     * High bits.
	     * @type {number}
	     */
	    this.hi = hi >>> 0;
	}

	/**
	 * Zero bits.
	 * @memberof util.LongBits
	 * @type {util.LongBits}
	 */
	var zero = LongBits.zero = new LongBits(0, 0);

	zero.toNumber = function() { return 0; };
	zero.zzEncode = zero.zzDecode = function() { return this; };
	zero.length = function() { return 1; };

	/**
	 * Zero hash.
	 * @memberof util.LongBits
	 * @type {string}
	 */
	var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

	/**
	 * Constructs new long bits from the specified number.
	 * @param {number} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.fromNumber = function fromNumber(value) {
	    if (value === 0)
	        return zero;
	    var sign = value < 0;
	    if (sign)
	        value = -value;
	    var lo = value >>> 0,
	        hi = (value - lo) / 4294967296 >>> 0;
	    if (sign) {
	        hi = ~hi >>> 0;
	        lo = ~lo >>> 0;
	        if (++lo > 4294967295) {
	            lo = 0;
	            if (++hi > 4294967295)
	                hi = 0;
	        }
	    }
	    return new LongBits(lo, hi);
	};

	/**
	 * Constructs new long bits from a number, long or string.
	 * @param {Long|number|string} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.from = function from(value) {
	    if (typeof value === "number")
	        return LongBits.fromNumber(value);
	    if (util.isString(value)) {
	        /* istanbul ignore else */
	        if (util.Long)
	            value = util.Long.fromString(value);
	        else
	            return LongBits.fromNumber(parseInt(value, 10));
	    }
	    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
	};

	/**
	 * Converts this long bits to a possibly unsafe JavaScript number.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {number} Possibly unsafe number
	 */
	LongBits.prototype.toNumber = function toNumber(unsigned) {
	    if (!unsigned && this.hi >>> 31) {
	        var lo = ~this.lo + 1 >>> 0,
	            hi = ~this.hi     >>> 0;
	        if (!lo)
	            hi = hi + 1 >>> 0;
	        return -(lo + hi * 4294967296);
	    }
	    return this.lo + this.hi * 4294967296;
	};

	/**
	 * Converts this long bits to a long.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {Long} Long
	 */
	LongBits.prototype.toLong = function toLong(unsigned) {
	    return util.Long
	        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
	        /* istanbul ignore next */
	        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
	};

	var charCodeAt = String.prototype.charCodeAt;

	/**
	 * Constructs new long bits from the specified 8 characters long hash.
	 * @param {string} hash Hash
	 * @returns {util.LongBits} Bits
	 */
	LongBits.fromHash = function fromHash(hash) {
	    if (hash === zeroHash)
	        return zero;
	    return new LongBits(
	        ( charCodeAt.call(hash, 0)
	        | charCodeAt.call(hash, 1) << 8
	        | charCodeAt.call(hash, 2) << 16
	        | charCodeAt.call(hash, 3) << 24) >>> 0
	    ,
	        ( charCodeAt.call(hash, 4)
	        | charCodeAt.call(hash, 5) << 8
	        | charCodeAt.call(hash, 6) << 16
	        | charCodeAt.call(hash, 7) << 24) >>> 0
	    );
	};

	/**
	 * Converts this long bits to a 8 characters long hash.
	 * @returns {string} Hash
	 */
	LongBits.prototype.toHash = function toHash() {
	    return String.fromCharCode(
	        this.lo        & 255,
	        this.lo >>> 8  & 255,
	        this.lo >>> 16 & 255,
	        this.lo >>> 24      ,
	        this.hi        & 255,
	        this.hi >>> 8  & 255,
	        this.hi >>> 16 & 255,
	        this.hi >>> 24
	    );
	};

	/**
	 * Zig-zag encodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzEncode = function zzEncode() {
	    var mask =   this.hi >> 31;
	    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
	    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Zig-zag decodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzDecode = function zzDecode() {
	    var mask = -(this.lo & 1);
	    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
	    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Calculates the length of this longbits when encoded as a varint.
	 * @returns {number} Length
	 */
	LongBits.prototype.length = function length() {
	    var part0 =  this.lo,
	        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
	        part2 =  this.hi >>> 24;
	    return part2 === 0
	         ? part1 === 0
	           ? part0 < 16384
	             ? part0 < 128 ? 1 : 2
	             : part0 < 2097152 ? 3 : 4
	           : part1 < 16384
	             ? part1 < 128 ? 5 : 6
	             : part1 < 2097152 ? 7 : 8
	         : part2 < 128 ? 9 : 10;
	};
	return longbits$3;
}

var hasRequiredMinimal$3;

function requireMinimal$3 () {
	if (hasRequiredMinimal$3) return minimal$4;
	hasRequiredMinimal$3 = 1;
	(function (exports) {
		var util = exports;

		// used to return a Promise where callback is omitted
		util.asPromise = aspromise;

		// converts to / from base64 encoded strings
		util.base64 = base64$9;

		// base class of rpc.Service
		util.EventEmitter = eventemitter;

		// float handling accross browsers
		util.float = float;

		// requires modules optionally and hides the call from bundlers
		util.inquire = inquire_1;

		// converts to / from utf8 encoded strings
		util.utf8 = utf8$e;

		// provides a node-like buffer pool in the browser
		util.pool = pool_1;

		// utility to work with the low and high bits of a 64 bit value
		util.LongBits = requireLongbits$3();

		/**
		 * Whether running within node or not.
		 * @memberof util
		 * @type {boolean}
		 */
		util.isNode = Boolean(typeof commonjsGlobal !== "undefined"
		                   && commonjsGlobal
		                   && commonjsGlobal.process
		                   && commonjsGlobal.process.versions
		                   && commonjsGlobal.process.versions.node);

		/**
		 * Global object reference.
		 * @memberof util
		 * @type {Object}
		 */
		util.global = util.isNode && commonjsGlobal
		           || typeof window !== "undefined" && window
		           || typeof self   !== "undefined" && self
		           || commonjsGlobal; // eslint-disable-line no-invalid-this

		/**
		 * An immuable empty array.
		 * @memberof util
		 * @type {Array.<*>}
		 * @const
		 */
		util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

		/**
		 * An immutable empty object.
		 * @type {Object}
		 * @const
		 */
		util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

		/**
		 * Tests if the specified value is an integer.
		 * @function
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is an integer
		 */
		util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
		    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
		};

		/**
		 * Tests if the specified value is a string.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a string
		 */
		util.isString = function isString(value) {
		    return typeof value === "string" || value instanceof String;
		};

		/**
		 * Tests if the specified value is a non-null object.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a non-null object
		 */
		util.isObject = function isObject(value) {
		    return value && typeof value === "object";
		};

		/**
		 * Checks if a property on a message is considered to be present.
		 * This is an alias of {@link util.isSet}.
		 * @function
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isset =

		/**
		 * Checks if a property on a message is considered to be present.
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isSet = function isSet(obj, prop) {
		    var value = obj[prop];
		    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
		        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
		    return false;
		};

		/**
		 * Any compatible Buffer instance.
		 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
		 * @interface Buffer
		 * @extends Uint8Array
		 */

		/**
		 * Node's Buffer class if available.
		 * @type {Constructor<Buffer>}
		 */
		util.Buffer = (function() {
		    try {
		        var Buffer = util.inquire("buffer").Buffer;
		        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
		        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
		    } catch (e) {
		        /* istanbul ignore next */
		        return null;
		    }
		})();

		// Internal alias of or polyfull for Buffer.from.
		util._Buffer_from = null;

		// Internal alias of or polyfill for Buffer.allocUnsafe.
		util._Buffer_allocUnsafe = null;

		/**
		 * Creates a new buffer of whatever type supported by the environment.
		 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
		 * @returns {Uint8Array|Buffer} Buffer
		 */
		util.newBuffer = function newBuffer(sizeOrArray) {
		    /* istanbul ignore next */
		    return typeof sizeOrArray === "number"
		        ? util.Buffer
		            ? util._Buffer_allocUnsafe(sizeOrArray)
		            : new util.Array(sizeOrArray)
		        : util.Buffer
		            ? util._Buffer_from(sizeOrArray)
		            : typeof Uint8Array === "undefined"
		                ? sizeOrArray
		                : new Uint8Array(sizeOrArray);
		};

		/**
		 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
		 * @type {Constructor<Uint8Array>}
		 */
		util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

		/**
		 * Any compatible Long instance.
		 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
		 * @interface Long
		 * @property {number} low Low bits
		 * @property {number} high High bits
		 * @property {boolean} unsigned Whether unsigned or not
		 */

		/**
		 * Long.js's Long class if available.
		 * @type {Constructor<Long>}
		 */
		util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
		         || /* istanbul ignore next */ util.global.Long
		         || util.inquire("long");

		/**
		 * Regular expression used to verify 2 bit (`bool`) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key2Re = /^true|false|0|1$/;

		/**
		 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

		/**
		 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

		/**
		 * Converts a number or long to an 8 characters long hash string.
		 * @param {Long|number} value Value to convert
		 * @returns {string} Hash
		 */
		util.longToHash = function longToHash(value) {
		    return value
		        ? util.LongBits.from(value).toHash()
		        : util.LongBits.zeroHash;
		};

		/**
		 * Converts an 8 characters long hash string to a long or number.
		 * @param {string} hash Hash
		 * @param {boolean} [unsigned=false] Whether unsigned or not
		 * @returns {Long|number} Original value
		 */
		util.longFromHash = function longFromHash(hash, unsigned) {
		    var bits = util.LongBits.fromHash(hash);
		    if (util.Long)
		        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
		    return bits.toNumber(Boolean(unsigned));
		};

		/**
		 * Merges the properties of the source object into the destination object.
		 * @memberof util
		 * @param {Object.<string,*>} dst Destination object
		 * @param {Object.<string,*>} src Source object
		 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
		 * @returns {Object.<string,*>} Destination object
		 */
		function merge(dst, src, ifNotSet) { // used by converters
		    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
		        if (dst[keys[i]] === undefined || !ifNotSet)
		            dst[keys[i]] = src[keys[i]];
		    return dst;
		}

		util.merge = merge;

		/**
		 * Converts the first character of a string to lower case.
		 * @param {string} str String to convert
		 * @returns {string} Converted string
		 */
		util.lcFirst = function lcFirst(str) {
		    return str.charAt(0).toLowerCase() + str.substring(1);
		};

		/**
		 * Creates a custom error constructor.
		 * @memberof util
		 * @param {string} name Error name
		 * @returns {Constructor<Error>} Custom error constructor
		 */
		function newError(name) {

		    function CustomError(message, properties) {

		        if (!(this instanceof CustomError))
		            return new CustomError(message, properties);

		        // Error.call(this, message);
		        // ^ just returns a new error instance because the ctor can be called as a function

		        Object.defineProperty(this, "message", { get: function() { return message; } });

		        /* istanbul ignore next */
		        if (Error.captureStackTrace) // node
		            Error.captureStackTrace(this, CustomError);
		        else
		            Object.defineProperty(this, "stack", { value: new Error().stack || "" });

		        if (properties)
		            merge(this, properties);
		    }

		    CustomError.prototype = Object.create(Error.prototype, {
		        constructor: {
		            value: CustomError,
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		        name: {
		            get: function get() { return name; },
		            set: undefined,
		            enumerable: false,
		            // configurable: false would accurately preserve the behavior of
		            // the original, but I'm guessing that was not intentional.
		            // For an actual error subclass, this property would
		            // be configurable.
		            configurable: true,
		        },
		        toString: {
		            value: function value() { return this.name + ": " + this.message; },
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		    });

		    return CustomError;
		}

		util.newError = newError;

		/**
		 * Constructs a new protocol error.
		 * @classdesc Error subclass indicating a protocol specifc error.
		 * @memberof util
		 * @extends Error
		 * @template T extends Message<T>
		 * @constructor
		 * @param {string} message Error message
		 * @param {Object.<string,*>} [properties] Additional properties
		 * @example
		 * try {
		 *     MyMessage.decode(someBuffer); // throws if required fields are missing
		 * } catch (e) {
		 *     if (e instanceof ProtocolError && e.instance)
		 *         console.log("decoded so far: " + JSON.stringify(e.instance));
		 * }
		 */
		util.ProtocolError = newError("ProtocolError");

		/**
		 * So far decoded message instance.
		 * @name util.ProtocolError#instance
		 * @type {Message<T>}
		 */

		/**
		 * A OneOf getter as returned by {@link util.oneOfGetter}.
		 * @typedef OneOfGetter
		 * @type {function}
		 * @returns {string|undefined} Set field name, if any
		 */

		/**
		 * Builds a getter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfGetter} Unbound getter
		 */
		util.oneOfGetter = function getOneOf(fieldNames) {
		    var fieldMap = {};
		    for (var i = 0; i < fieldNames.length; ++i)
		        fieldMap[fieldNames[i]] = 1;

		    /**
		     * @returns {string|undefined} Set field name, if any
		     * @this Object
		     * @ignore
		     */
		    return function() { // eslint-disable-line consistent-return
		        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
		            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
		                return keys[i];
		    };
		};

		/**
		 * A OneOf setter as returned by {@link util.oneOfSetter}.
		 * @typedef OneOfSetter
		 * @type {function}
		 * @param {string|undefined} value Field name
		 * @returns {undefined}
		 */

		/**
		 * Builds a setter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfSetter} Unbound setter
		 */
		util.oneOfSetter = function setOneOf(fieldNames) {

		    /**
		     * @param {string} name Field name
		     * @returns {undefined}
		     * @this Object
		     * @ignore
		     */
		    return function(name) {
		        for (var i = 0; i < fieldNames.length; ++i)
		            if (fieldNames[i] !== name)
		                delete this[fieldNames[i]];
		    };
		};

		/**
		 * Default conversion options used for {@link Message#toJSON} implementations.
		 *
		 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
		 *
		 * - Longs become strings
		 * - Enums become string keys
		 * - Bytes become base64 encoded strings
		 * - (Sub-)Messages become plain objects
		 * - Maps become plain objects with all string keys
		 * - Repeated fields become arrays
		 * - NaN and Infinity for float and double fields become strings
		 *
		 * @type {IConversionOptions}
		 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
		 */
		util.toJSONOptions = {
		    longs: String,
		    enums: String,
		    bytes: String,
		    json: true
		};

		// Sets up buffer utility according to the environment (called in index-minimal)
		util._configure = function() {
		    var Buffer = util.Buffer;
		    /* istanbul ignore if */
		    if (!Buffer) {
		        util._Buffer_from = util._Buffer_allocUnsafe = null;
		        return;
		    }
		    // because node 4.x buffers are incompatible & immutable
		    // see: https://github.com/dcodeIO/protobuf.js/pull/665
		    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
		        /* istanbul ignore next */
		        function Buffer_from(value, encoding) {
		            return new Buffer(value, encoding);
		        };
		    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
		        /* istanbul ignore next */
		        function Buffer_allocUnsafe(size) {
		            return new Buffer(size);
		        };
		};
} (minimal$4));
	return minimal$4;
}

var reader$6 = Reader$7;

var util$j      = requireMinimal$3();

var BufferReader$7; // cyclic

var LongBits$7  = util$j.LongBits,
    utf8$7      = util$j.utf8;

/* istanbul ignore next */
function indexOutOfRange$3(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader$7(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array$3 = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader$7(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader$7(buffer);
        throw Error("illegal buffer");
    };

var create$7 = function create() {
    return util$j.Buffer
        ? function create_buffer_setup(buffer) {
            return (Reader$7.create = function create_buffer(buffer) {
                return util$j.Buffer.isBuffer(buffer)
                    ? new BufferReader$7(buffer)
                    /* istanbul ignore next */
                    : create_array$3(buffer);
            })(buffer);
        }
        /* istanbul ignore next */
        : create_array$3;
};

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader$7.create = create$7();

Reader$7.prototype._slice = util$j.Array.prototype.subarray || /* istanbul ignore next */ util$j.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader$7.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange$3(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$7.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$7.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint$3() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits$7(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$3(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$3(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader$7.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end$3(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader$7.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$3(this, 4);

    return readFixed32_end$3(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader$7.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$3(this, 4);

    return readFixed32_end$3(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64$3(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$3(this, 8);

    return new LongBits$7(readFixed32_end$3(this.buf, this.pos += 4), readFixed32_end$3(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$7.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$3(this, 4);

    var value = util$j.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$7.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$3(this, 4);

    var value = util$j.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader$7.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange$3(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader$7.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8$7.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader$7.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange$3(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$3(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader$7.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader$7._configure = function(BufferReader_) {
    BufferReader$7 = BufferReader_;
    Reader$7.create = create$7();
    BufferReader$7._configure();

    var fn = util$j.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util$j.merge(Reader$7.prototype, {

        int64: function read_int64() {
            return readLongVarint$3.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint$3.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint$3.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64$3.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64$3.call(this)[fn](false);
        }

    });
};

var reader_buffer$3 = BufferReader$6;

// extends Reader
var Reader$6 = reader$6;
(BufferReader$6.prototype = Object.create(Reader$6.prototype)).constructor = BufferReader$6;

var util$i = requireMinimal$3();

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader$6(buffer) {
    Reader$6.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

BufferReader$6._configure = function () {
    /* istanbul ignore else */
    if (util$i.Buffer)
        BufferReader$6.prototype._slice = util$i.Buffer.prototype.slice;
};


/**
 * @override
 */
BufferReader$6.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice
        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))
        : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

BufferReader$6._configure();

var minimalExports$3 = requireMinimal$3();
var util$h = /*@__PURE__*/getDefaultExportFromCjs(minimalExports$3);

var writer$6 = Writer$7;

var util$g      = requireMinimal$3();

var BufferWriter$7; // cyclic

var LongBits$6  = util$g.LongBits,
    base64$3    = util$g.base64,
    utf8$6      = util$g.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op$3(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop$6() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State$3(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer$7() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op$3(noop$6, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

var create$6 = function create() {
    return util$g.Buffer
        ? function create_buffer_setup() {
            return (Writer$7.create = function create_buffer() {
                return new BufferWriter$7();
            })();
        }
        /* istanbul ignore next */
        : function create_array() {
            return new Writer$7();
        };
};

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer$7.create = create$6();

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer$7.alloc = function alloc(size) {
    return new util$g.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util$g.Array !== Array)
    Writer$7.alloc = util$g.pool(Writer$7.alloc, util$g.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer$7.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op$3(fn, len, val);
    this.len += len;
    return this;
};

function writeByte$3(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32$3(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp$3(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp$3.prototype = Object.create(Op$3.prototype);
VarintOp$3.prototype.fn = writeVarint32$3;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp$3(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64$3, 10, LongBits$6.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64$3(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$7.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits$6.from(value);
    return this._push(writeVarint64$3, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$7.prototype.int64 = Writer$7.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$7.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits$6.from(value).zzEncode();
    return this._push(writeVarint64$3, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.bool = function write_bool(value) {
    return this._push(writeByte$3, 1, value ? 1 : 0);
};

function writeFixed32$3(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32$3, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.sfixed32 = Writer$7.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$7.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits$6.from(value);
    return this._push(writeFixed32$3, 4, bits.lo)._push(writeFixed32$3, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$7.prototype.sfixed64 = Writer$7.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.float = function write_float(value) {
    return this._push(util$g.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.double = function write_double(value) {
    return this._push(util$g.float.writeDoubleLE, 8, value);
};

var writeBytes$3 = util$g.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte$3, 1, 0);
    if (util$g.isString(value)) {
        var buf = Writer$7.alloc(len = base64$3.length(value));
        base64$3.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes$3, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer$7.prototype.string = function write_string(value) {
    var len = utf8$6.length(value);
    return len
        ? this.uint32(len)._push(utf8$6.write, len, value)
        : this._push(writeByte$3, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer$7.prototype.fork = function fork() {
    this.states = new State$3(this);
    this.head = this.tail = new Op$3(noop$6, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer$7.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op$3(noop$6, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer$7.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer$7.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer$7._configure = function(BufferWriter_) {
    BufferWriter$7 = BufferWriter_;
    Writer$7.create = create$6();
    BufferWriter$7._configure();
};

var writer_buffer$3 = BufferWriter$6;

// extends Writer
var Writer$6 = writer$6;
(BufferWriter$6.prototype = Object.create(Writer$6.prototype)).constructor = BufferWriter$6;

var util$f = requireMinimal$3();

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter$6() {
    Writer$6.call(this);
}

BufferWriter$6._configure = function () {
    /**
     * Allocates a buffer of the specified size.
     * @function
     * @param {number} size Buffer size
     * @returns {Buffer} Buffer
     */
    BufferWriter$6.alloc = util$f._Buffer_allocUnsafe;

    BufferWriter$6.writeBytesBuffer = util$f.Buffer && util$f.Buffer.prototype instanceof Uint8Array && util$f.Buffer.prototype.set.name === "set"
        ? function writeBytesBuffer_set(val, buf, pos) {
          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
          // also works for plain array values
        }
        /* istanbul ignore next */
        : function writeBytesBuffer_copy(val, buf, pos) {
          if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
          else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
        };
};


/**
 * @override
 */
BufferWriter$6.prototype.bytes = function write_bytes_buffer(value) {
    if (util$f.isString(value))
        value = util$f._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(BufferWriter$6.writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer$3(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util$f.utf8.write(val, buf, pos);
    else if (buf.utf8Write)
        buf.utf8Write(val, pos);
    else
        buf.write(val, pos);
}

/**
 * @override
 */
BufferWriter$6.prototype.string = function write_string_buffer(value) {
    var len = util$f.Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer$3, len, value);
    return this;
};


/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

BufferWriter$6._configure();

// @ts-expect-error no types
function configure$2() {
    util$h._configure();
    reader$6._configure(reader_buffer$3);
    writer$6._configure(writer_buffer$3);
}
// Set up buffer utility according to the environment
configure$2();
// monkey patch the reader to add native bigint support
const methods$2 = [
    'uint64', 'int64', 'sint64', 'fixed64', 'sfixed64'
];
function patchReader$2(obj) {
    for (const method of methods$2) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function () {
            return BigInt(original.call(this).toString());
        };
    }
    return obj;
}
function reader$5(buf) {
    return patchReader$2(new reader$6(buf));
}
function patchWriter$2(obj) {
    for (const method of methods$2) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function (val) {
            return original.call(this, val.toString());
        };
    }
    return obj;
}
function writer$5() {
    return patchWriter$2(writer$6.create());
}

function decodeMessage$3(buf, codec) {
    const r = reader$5(buf instanceof Uint8Array ? buf : buf.subarray());
    return codec.decode(r);
}

function encodeMessage$2(message, codec) {
    const w = writer$5();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES$2;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES$2 || (CODEC_TYPES$2 = {}));
function createCodec$2(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function message$2(encode, decode) {
    return createCodec$2('message', CODEC_TYPES$2.LENGTH_DELIMITED, encode, decode);
}

/* eslint-disable import/export */
var Envelope;
(function (Envelope) {
    let _codec;
    Envelope.codec = () => {
        if (_codec == null) {
            _codec = message$2((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.publicKey != null && obj.publicKey.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.publicKey);
                }
                if ((obj.payloadType != null && obj.payloadType.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.payloadType);
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.payload);
                }
                if ((obj.signature != null && obj.signature.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.signature);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    publicKey: new Uint8Array(0),
                    payloadType: new Uint8Array(0),
                    payload: new Uint8Array(0),
                    signature: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.publicKey = reader.bytes();
                            break;
                        case 2:
                            obj.payloadType = reader.bytes();
                            break;
                        case 3:
                            obj.payload = reader.bytes();
                            break;
                        case 5:
                            obj.signature = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Envelope.encode = (obj) => {
        return encodeMessage$2(obj, Envelope.codec());
    };
    Envelope.decode = (buf) => {
        return decodeMessage$3(buf, Envelope.codec());
    };
})(Envelope || (Envelope = {}));

class RecordEnvelope {
    /**
     * The Envelope is responsible for keeping an arbitrary signed record
     * by a libp2p peer.
     */
    constructor(init) {
        const { peerId, payloadType, payload, signature } = init;
        this.peerId = peerId;
        this.payloadType = payloadType;
        this.payload = payload;
        this.signature = signature;
    }
    /**
     * Marshal the envelope content
     */
    marshal() {
        if (this.peerId.publicKey == null) {
            throw new Error('Missing public key');
        }
        if (this.marshaled == null) {
            this.marshaled = Envelope.encode({
                publicKey: this.peerId.publicKey,
                payloadType: this.payloadType,
                payload: this.payload.subarray(),
                signature: this.signature
            });
        }
        return this.marshaled;
    }
    /**
     * Verifies if the other Envelope is identical to this one
     */
    equals(other) {
        return equals$2(this.marshal(), other.marshal());
    }
    /**
     * Validate envelope data signature for the given domain
     */
    async validate(domain) {
        const signData = formatSignaturePayload(domain, this.payloadType, this.payload);
        if (this.peerId.publicKey == null) {
            throw new Error('Missing public key');
        }
        const key = unmarshalPublicKey(this.peerId.publicKey);
        return await key.verify(signData.subarray(), this.signature);
    }
}
/**
 * Unmarshal a serialized Envelope protobuf message
 */
RecordEnvelope.createFromProtobuf = async (data) => {
    const envelopeData = Envelope.decode(data);
    const peerId = await peerIdFromKeys(envelopeData.publicKey);
    return new RecordEnvelope({
        peerId,
        payloadType: envelopeData.payloadType,
        payload: envelopeData.payload,
        signature: envelopeData.signature
    });
};
/**
 * Seal marshals the given Record, places the marshaled bytes inside an Envelope
 * and signs it with the given peerId's private key
 */
RecordEnvelope.seal = async (record, peerId) => {
    if (peerId.privateKey == null) {
        throw new Error('Missing private key');
    }
    const domain = record.domain;
    const payloadType = record.codec;
    const payload = record.marshal();
    const signData = formatSignaturePayload(domain, payloadType, payload);
    const key = await unmarshalPrivateKey(peerId.privateKey);
    const signature = await key.sign(signData.subarray());
    return new RecordEnvelope({
        peerId,
        payloadType,
        payload,
        signature
    });
};
/**
 * Open and certify a given marshalled envelope.
 * Data is unmarshalled and the signature validated for the given domain.
 */
RecordEnvelope.openAndCertify = async (data, domain) => {
    const envelope = await RecordEnvelope.createFromProtobuf(data);
    const valid = await envelope.validate(domain);
    if (!valid) {
        throw new CodeError('envelope signature is not valid for the given domain', codes$3.ERR_SIGNATURE_NOT_VALID);
    }
    return envelope;
};
/**
 * Helper function that prepares a Uint8Array to sign or verify a signature
 */
const formatSignaturePayload = (domain, payloadType, payload) => {
    // When signing, a peer will prepare a Uint8Array by concatenating the following:
    // - The length of the domain separation string string in bytes
    // - The domain separation string, encoded as UTF-8
    // - The length of the payload_type field in bytes
    // - The value of the payload_type field
    // - The length of the payload field in bytes
    // - The value of the payload field
    const domainUint8Array = fromString$2(domain);
    const domainLength = unsigned.encode(domainUint8Array.byteLength);
    const payloadTypeLength = unsigned.encode(payloadType.length);
    const payloadLength = unsigned.encode(payload.length);
    return new Uint8ArrayList(domainLength, domainUint8Array, payloadTypeLength, payloadType, payloadLength, payload);
};

/**
 * @packageDocumentation
 *
 * Provides strategies ensure arrays are equivalent.
 *
 * @example
 *
 * ```typescript
 * import { arrayEquals } from '@libp2p/utils/array-equals'
 * import { multiaddr } from '@multformats/multiaddr'
 *
 * const ma1 = multiaddr('/ip4/127.0.0.1/tcp/9000'),
 * const ma2 = multiaddr('/ip4/82.41.53.1/tcp/9000')
 *
 * console.info(arrayEquals([ma1], [ma1])) // true
 * console.info(arrayEquals([ma1], [ma2])) // false
 * ```
 */
/**
 * Verify if two arrays of non primitive types with the "equals" function are equal.
 * Compatible with multiaddr, peer-id and others.
 */
function arrayEquals(a, b) {
    const sort = (a, b) => a.toString().localeCompare(b.toString());
    if (a.length !== b.length) {
        return false;
    }
    b.sort(sort);
    return a.sort(sort).every((item, index) => b[index].equals(item));
}

/* eslint-disable import/export */
var PeerRecord$1;
(function (PeerRecord) {
    (function (AddressInfo) {
        let _codec;
        AddressInfo.codec = () => {
            if (_codec == null) {
                _codec = message$2((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.multiaddr != null && obj.multiaddr.byteLength > 0)) {
                        w.uint32(10);
                        w.bytes(obj.multiaddr);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        multiaddr: new Uint8Array(0)
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.multiaddr = reader.bytes();
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        AddressInfo.encode = (obj) => {
            return encodeMessage$2(obj, AddressInfo.codec());
        };
        AddressInfo.decode = (buf) => {
            return decodeMessage$3(buf, AddressInfo.codec());
        };
    })(PeerRecord.AddressInfo || (PeerRecord.AddressInfo = {}));
    let _codec;
    PeerRecord.codec = () => {
        if (_codec == null) {
            _codec = message$2((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.peerId != null && obj.peerId.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.peerId);
                }
                if ((obj.seq != null && obj.seq !== 0n)) {
                    w.uint32(16);
                    w.uint64(obj.seq);
                }
                if (obj.addresses != null) {
                    for (const value of obj.addresses) {
                        w.uint32(26);
                        PeerRecord.AddressInfo.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    peerId: new Uint8Array(0),
                    seq: 0n,
                    addresses: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.peerId = reader.bytes();
                            break;
                        case 2:
                            obj.seq = reader.uint64();
                            break;
                        case 3:
                            obj.addresses.push(PeerRecord.AddressInfo.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerRecord.encode = (obj) => {
        return encodeMessage$2(obj, PeerRecord.codec());
    };
    PeerRecord.decode = (buf) => {
        return decodeMessage$3(buf, PeerRecord.codec());
    };
})(PeerRecord$1 || (PeerRecord$1 = {}));

// The domain string used for peer records contained in a Envelope.
const ENVELOPE_DOMAIN_PEER_RECORD = 'libp2p-peer-record';
// The type hint used to identify peer records in a Envelope.
// Defined in https://github.com/multiformats/multicodec/blob/master/table.csv
// with name "libp2p-peer-record"
const ENVELOPE_PAYLOAD_TYPE_PEER_RECORD = Uint8Array.from([3, 1]);

/**
 * The PeerRecord is used for distributing peer routing records across the network.
 * It contains the peer's reachable listen addresses.
 */
class PeerRecord {
    constructor(init) {
        this.domain = PeerRecord.DOMAIN;
        this.codec = PeerRecord.CODEC;
        const { peerId, multiaddrs, seqNumber } = init;
        this.peerId = peerId;
        this.multiaddrs = multiaddrs ?? [];
        this.seqNumber = seqNumber ?? BigInt(Date.now());
    }
    /**
     * Marshal a record to be used in an envelope
     */
    marshal() {
        if (this.marshaled == null) {
            this.marshaled = PeerRecord$1.encode({
                peerId: this.peerId.toBytes(),
                seq: BigInt(this.seqNumber),
                addresses: this.multiaddrs.map((m) => ({
                    multiaddr: m.bytes
                }))
            });
        }
        return this.marshaled;
    }
    /**
     * Returns true if `this` record equals the `other`
     */
    equals(other) {
        if (!(other instanceof PeerRecord)) {
            return false;
        }
        // Validate PeerId
        if (!this.peerId.equals(other.peerId)) {
            return false;
        }
        // Validate seqNumber
        if (this.seqNumber !== other.seqNumber) {
            return false;
        }
        // Validate multiaddrs
        if (!arrayEquals(this.multiaddrs, other.multiaddrs)) {
            return false;
        }
        return true;
    }
}
/**
 * Unmarshal Peer Record Protobuf
 */
PeerRecord.createFromProtobuf = (buf) => {
    const peerRecord = PeerRecord$1.decode(buf);
    const peerId = peerIdFromBytes(peerRecord.peerId);
    const multiaddrs = (peerRecord.addresses ?? []).map((a) => multiaddr$1(a.multiaddr));
    const seqNumber = peerRecord.seq;
    return new PeerRecord({ peerId, multiaddrs, seqNumber });
};
PeerRecord.DOMAIN = ENVELOPE_DOMAIN_PEER_RECORD;
PeerRecord.CODEC = ENVELOPE_PAYLOAD_TYPE_PEER_RECORD;

const topologySymbol = Symbol.for('@libp2p/topology');
function isTopology(other) {
    return other != null && Boolean(other[topologySymbol]);
}

const noop$5 = () => { };
class TopologyImpl {
    constructor(init) {
        this.min = init.min ?? 0;
        this.max = init.max ?? Infinity;
        this.peers = new Set();
        this.onConnect = init.onConnect ?? noop$5;
        this.onDisconnect = init.onDisconnect ?? noop$5;
    }
    get [Symbol.toStringTag]() {
        return topologySymbol.toString();
    }
    get [topologySymbol]() {
        return true;
    }
    async setRegistrar(registrar) {
        this.registrar = registrar;
    }
    /**
     * Notify about peer disconnected event
     */
    disconnect(peerId) {
        this.onDisconnect(peerId);
    }
}
function createTopology(init) {
    return new TopologyImpl(init);
}

var __classPrivateFieldGet$3 = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var _EventEmitter_listeners;
/**
 * Adds types to the EventTarget class. Hopefully this won't be necessary forever.
 *
 * https://github.com/microsoft/TypeScript/issues/28357
 * https://github.com/microsoft/TypeScript/issues/43477
 * https://github.com/microsoft/TypeScript/issues/299
 * etc
 */
let EventEmitter$1 = class EventEmitter extends EventTarget {
    constructor() {
        super(...arguments);
        _EventEmitter_listeners.set(this, new Map());
    }
    listenerCount(type) {
        const listeners = __classPrivateFieldGet$3(this, _EventEmitter_listeners, "f").get(type);
        if (listeners == null) {
            return 0;
        }
        return listeners.length;
    }
    addEventListener(type, listener, options) {
        super.addEventListener(type, listener, options);
        let list = __classPrivateFieldGet$3(this, _EventEmitter_listeners, "f").get(type);
        if (list == null) {
            list = [];
            __classPrivateFieldGet$3(this, _EventEmitter_listeners, "f").set(type, list);
        }
        list.push({
            callback: listener,
            once: (options !== true && options !== false && options?.once) ?? false
        });
    }
    removeEventListener(type, listener, options) {
        super.removeEventListener(type.toString(), listener ?? null, options);
        let list = __classPrivateFieldGet$3(this, _EventEmitter_listeners, "f").get(type);
        if (list == null) {
            return;
        }
        list = list.filter(({ callback }) => callback !== listener);
        __classPrivateFieldGet$3(this, _EventEmitter_listeners, "f").set(type, list);
    }
    dispatchEvent(event) {
        const result = super.dispatchEvent(event);
        let list = __classPrivateFieldGet$3(this, _EventEmitter_listeners, "f").get(event.type);
        if (list == null) {
            return result;
        }
        list = list.filter(({ once }) => !once);
        __classPrivateFieldGet$3(this, _EventEmitter_listeners, "f").set(event.type, list);
        return result;
    }
    safeDispatchEvent(type, detail) {
        return this.dispatchEvent(new CustomEvent(type, detail));
    }
};
_EventEmitter_listeners = new WeakMap();
/**
 * CustomEvent is a standard event but it's not supported by node.
 *
 * Remove this when https://github.com/nodejs/node/issues/40678 is closed.
 *
 * Ref: https://developer.mozilla.org/en-US/docs/Web/API/CustomEvent
 */
class CustomEventPolyfill extends Event {
    constructor(message, data) {
        super(message, data);
        // @ts-expect-error could be undefined
        this.detail = data?.detail;
    }
}
const CustomEvent = globalThis.CustomEvent ?? CustomEventPolyfill;

class MessageCache {
    /**
     * Holds history of messages in timebounded history arrays
     */
    constructor(
    /**
     * The number of indices in the cache history used for gossiping. That means that a message
     * won't get gossiped anymore when shift got called `gossip` many times after inserting the
     * message in the cache.
     */
    gossip, historyCapacity, msgIdToStrFn) {
        this.gossip = gossip;
        this.msgs = new Map();
        this.history = [];
        /** Track with accounting of messages in the mcache that are not yet validated */
        this.notValidatedCount = 0;
        this.msgIdToStrFn = msgIdToStrFn;
        for (let i = 0; i < historyCapacity; i++) {
            this.history[i] = [];
        }
    }
    get size() {
        return this.msgs.size;
    }
    /**
     * Adds a message to the current window and the cache
     * Returns true if the message is not known and is inserted in the cache
     */
    put(messageId, msg, validated = false) {
        const { msgIdStr } = messageId;
        // Don't add duplicate entries to the cache.
        if (this.msgs.has(msgIdStr)) {
            return false;
        }
        this.msgs.set(msgIdStr, {
            message: msg,
            validated,
            originatingPeers: new Set(),
            iwantCounts: new Map()
        });
        this.history[0].push({ ...messageId, topic: msg.topic });
        if (!validated) {
            this.notValidatedCount++;
        }
        return true;
    }
    observeDuplicate(msgId, fromPeerIdStr) {
        const entry = this.msgs.get(msgId);
        if (entry &&
            // if the message is already validated, we don't need to store extra peers sending us
            // duplicates as the message has already been forwarded
            !entry.validated) {
            entry.originatingPeers.add(fromPeerIdStr);
        }
    }
    /**
     * Retrieves a message from the cache by its ID, if it is still present
     */
    get(msgId) {
        return this.msgs.get(this.msgIdToStrFn(msgId))?.message;
    }
    /**
     * Increases the iwant count for the given message by one and returns the message together
     * with the iwant if the message exists.
     */
    getWithIWantCount(msgIdStr, p) {
        const msg = this.msgs.get(msgIdStr);
        if (!msg) {
            return null;
        }
        const count = (msg.iwantCounts.get(p) ?? 0) + 1;
        msg.iwantCounts.set(p, count);
        return { msg: msg.message, count };
    }
    /**
     * Retrieves a list of message IDs for a set of topics
     */
    getGossipIDs(topics) {
        const msgIdsByTopic = new Map();
        for (let i = 0; i < this.gossip; i++) {
            this.history[i].forEach((entry) => {
                const msg = this.msgs.get(entry.msgIdStr);
                if (msg && msg.validated && topics.has(entry.topic)) {
                    let msgIds = msgIdsByTopic.get(entry.topic);
                    if (!msgIds) {
                        msgIds = [];
                        msgIdsByTopic.set(entry.topic, msgIds);
                    }
                    msgIds.push(entry.msgId);
                }
            });
        }
        return msgIdsByTopic;
    }
    /**
     * Gets a message with msgId and tags it as validated.
     * This function also returns the known peers that have sent us this message. This is used to
     * prevent us sending redundant messages to peers who have already propagated it.
     */
    validate(msgId) {
        const entry = this.msgs.get(msgId);
        if (!entry) {
            return null;
        }
        if (!entry.validated) {
            this.notValidatedCount--;
        }
        const { message, originatingPeers } = entry;
        entry.validated = true;
        // Clear the known peers list (after a message is validated, it is forwarded and we no
        // longer need to store the originating peers).
        entry.originatingPeers = new Set();
        return { message, originatingPeers };
    }
    /**
     * Shifts the current window, discarding messages older than this.history.length of the cache
     */
    shift() {
        const lastCacheEntries = this.history[this.history.length - 1];
        lastCacheEntries.forEach((cacheEntry) => {
            const entry = this.msgs.get(cacheEntry.msgIdStr);
            if (entry) {
                this.msgs.delete(cacheEntry.msgIdStr);
                if (!entry.validated) {
                    this.notValidatedCount--;
                }
            }
        });
        this.history.pop();
        this.history.unshift([]);
    }
    remove(msgId) {
        const entry = this.msgs.get(msgId);
        if (!entry) {
            return null;
        }
        // Keep the message on the history vector, it will be dropped on a shift()
        this.msgs.delete(msgId);
        return entry;
    }
}

var rpcExports = {};
var rpc$1 = {
  get exports(){ return rpcExports; },
  set exports(v){ rpcExports = v; },
};

var minimalExports$2 = {};
var minimal$3 = {
  get exports(){ return minimalExports$2; },
  set exports(v){ minimalExports$2 = v; },
};

var indexMinimal = {};

var minimal$2 = {};

var longbits$2;
var hasRequiredLongbits$2;

function requireLongbits$2 () {
	if (hasRequiredLongbits$2) return longbits$2;
	hasRequiredLongbits$2 = 1;
	longbits$2 = LongBits;

	var util = requireMinimal$2();

	/**
	 * Constructs new long bits.
	 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
	 * @memberof util
	 * @constructor
	 * @param {number} lo Low 32 bits, unsigned
	 * @param {number} hi High 32 bits, unsigned
	 */
	function LongBits(lo, hi) {

	    // note that the casts below are theoretically unnecessary as of today, but older statically
	    // generated converter code might still call the ctor with signed 32bits. kept for compat.

	    /**
	     * Low bits.
	     * @type {number}
	     */
	    this.lo = lo >>> 0;

	    /**
	     * High bits.
	     * @type {number}
	     */
	    this.hi = hi >>> 0;
	}

	/**
	 * Zero bits.
	 * @memberof util.LongBits
	 * @type {util.LongBits}
	 */
	var zero = LongBits.zero = new LongBits(0, 0);

	zero.toNumber = function() { return 0; };
	zero.zzEncode = zero.zzDecode = function() { return this; };
	zero.length = function() { return 1; };

	/**
	 * Zero hash.
	 * @memberof util.LongBits
	 * @type {string}
	 */
	var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

	/**
	 * Constructs new long bits from the specified number.
	 * @param {number} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.fromNumber = function fromNumber(value) {
	    if (value === 0)
	        return zero;
	    var sign = value < 0;
	    if (sign)
	        value = -value;
	    var lo = value >>> 0,
	        hi = (value - lo) / 4294967296 >>> 0;
	    if (sign) {
	        hi = ~hi >>> 0;
	        lo = ~lo >>> 0;
	        if (++lo > 4294967295) {
	            lo = 0;
	            if (++hi > 4294967295)
	                hi = 0;
	        }
	    }
	    return new LongBits(lo, hi);
	};

	/**
	 * Constructs new long bits from a number, long or string.
	 * @param {Long|number|string} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.from = function from(value) {
	    if (typeof value === "number")
	        return LongBits.fromNumber(value);
	    if (util.isString(value)) {
	        /* istanbul ignore else */
	        if (util.Long)
	            value = util.Long.fromString(value);
	        else
	            return LongBits.fromNumber(parseInt(value, 10));
	    }
	    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
	};

	/**
	 * Converts this long bits to a possibly unsafe JavaScript number.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {number} Possibly unsafe number
	 */
	LongBits.prototype.toNumber = function toNumber(unsigned) {
	    if (!unsigned && this.hi >>> 31) {
	        var lo = ~this.lo + 1 >>> 0,
	            hi = ~this.hi     >>> 0;
	        if (!lo)
	            hi = hi + 1 >>> 0;
	        return -(lo + hi * 4294967296);
	    }
	    return this.lo + this.hi * 4294967296;
	};

	/**
	 * Converts this long bits to a long.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {Long} Long
	 */
	LongBits.prototype.toLong = function toLong(unsigned) {
	    return util.Long
	        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
	        /* istanbul ignore next */
	        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
	};

	var charCodeAt = String.prototype.charCodeAt;

	/**
	 * Constructs new long bits from the specified 8 characters long hash.
	 * @param {string} hash Hash
	 * @returns {util.LongBits} Bits
	 */
	LongBits.fromHash = function fromHash(hash) {
	    if (hash === zeroHash)
	        return zero;
	    return new LongBits(
	        ( charCodeAt.call(hash, 0)
	        | charCodeAt.call(hash, 1) << 8
	        | charCodeAt.call(hash, 2) << 16
	        | charCodeAt.call(hash, 3) << 24) >>> 0
	    ,
	        ( charCodeAt.call(hash, 4)
	        | charCodeAt.call(hash, 5) << 8
	        | charCodeAt.call(hash, 6) << 16
	        | charCodeAt.call(hash, 7) << 24) >>> 0
	    );
	};

	/**
	 * Converts this long bits to a 8 characters long hash.
	 * @returns {string} Hash
	 */
	LongBits.prototype.toHash = function toHash() {
	    return String.fromCharCode(
	        this.lo        & 255,
	        this.lo >>> 8  & 255,
	        this.lo >>> 16 & 255,
	        this.lo >>> 24      ,
	        this.hi        & 255,
	        this.hi >>> 8  & 255,
	        this.hi >>> 16 & 255,
	        this.hi >>> 24
	    );
	};

	/**
	 * Zig-zag encodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzEncode = function zzEncode() {
	    var mask =   this.hi >> 31;
	    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
	    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Zig-zag decodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzDecode = function zzDecode() {
	    var mask = -(this.lo & 1);
	    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
	    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Calculates the length of this longbits when encoded as a varint.
	 * @returns {number} Length
	 */
	LongBits.prototype.length = function length() {
	    var part0 =  this.lo,
	        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
	        part2 =  this.hi >>> 24;
	    return part2 === 0
	         ? part1 === 0
	           ? part0 < 16384
	             ? part0 < 128 ? 1 : 2
	             : part0 < 2097152 ? 3 : 4
	           : part1 < 16384
	             ? part1 < 128 ? 5 : 6
	             : part1 < 2097152 ? 7 : 8
	         : part2 < 128 ? 9 : 10;
	};
	return longbits$2;
}

var hasRequiredMinimal$2;

function requireMinimal$2 () {
	if (hasRequiredMinimal$2) return minimal$2;
	hasRequiredMinimal$2 = 1;
	(function (exports) {
		var util = exports;

		// used to return a Promise where callback is omitted
		util.asPromise = aspromise;

		// converts to / from base64 encoded strings
		util.base64 = base64$9;

		// base class of rpc.Service
		util.EventEmitter = eventemitter;

		// float handling accross browsers
		util.float = float;

		// requires modules optionally and hides the call from bundlers
		util.inquire = inquire_1;

		// converts to / from utf8 encoded strings
		util.utf8 = utf8$e;

		// provides a node-like buffer pool in the browser
		util.pool = pool_1;

		// utility to work with the low and high bits of a 64 bit value
		util.LongBits = requireLongbits$2();

		/**
		 * Whether running within node or not.
		 * @memberof util
		 * @type {boolean}
		 */
		util.isNode = Boolean(typeof commonjsGlobal !== "undefined"
		                   && commonjsGlobal
		                   && commonjsGlobal.process
		                   && commonjsGlobal.process.versions
		                   && commonjsGlobal.process.versions.node);

		/**
		 * Global object reference.
		 * @memberof util
		 * @type {Object}
		 */
		util.global = util.isNode && commonjsGlobal
		           || typeof window !== "undefined" && window
		           || typeof self   !== "undefined" && self
		           || commonjsGlobal; // eslint-disable-line no-invalid-this

		/**
		 * An immuable empty array.
		 * @memberof util
		 * @type {Array.<*>}
		 * @const
		 */
		util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

		/**
		 * An immutable empty object.
		 * @type {Object}
		 * @const
		 */
		util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

		/**
		 * Tests if the specified value is an integer.
		 * @function
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is an integer
		 */
		util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
		    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
		};

		/**
		 * Tests if the specified value is a string.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a string
		 */
		util.isString = function isString(value) {
		    return typeof value === "string" || value instanceof String;
		};

		/**
		 * Tests if the specified value is a non-null object.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a non-null object
		 */
		util.isObject = function isObject(value) {
		    return value && typeof value === "object";
		};

		/**
		 * Checks if a property on a message is considered to be present.
		 * This is an alias of {@link util.isSet}.
		 * @function
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isset =

		/**
		 * Checks if a property on a message is considered to be present.
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isSet = function isSet(obj, prop) {
		    var value = obj[prop];
		    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
		        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
		    return false;
		};

		/**
		 * Any compatible Buffer instance.
		 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
		 * @interface Buffer
		 * @extends Uint8Array
		 */

		/**
		 * Node's Buffer class if available.
		 * @type {Constructor<Buffer>}
		 */
		util.Buffer = (function() {
		    try {
		        var Buffer = util.inquire("buffer").Buffer;
		        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
		        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
		    } catch (e) {
		        /* istanbul ignore next */
		        return null;
		    }
		})();

		// Internal alias of or polyfull for Buffer.from.
		util._Buffer_from = null;

		// Internal alias of or polyfill for Buffer.allocUnsafe.
		util._Buffer_allocUnsafe = null;

		/**
		 * Creates a new buffer of whatever type supported by the environment.
		 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
		 * @returns {Uint8Array|Buffer} Buffer
		 */
		util.newBuffer = function newBuffer(sizeOrArray) {
		    /* istanbul ignore next */
		    return typeof sizeOrArray === "number"
		        ? util.Buffer
		            ? util._Buffer_allocUnsafe(sizeOrArray)
		            : new util.Array(sizeOrArray)
		        : util.Buffer
		            ? util._Buffer_from(sizeOrArray)
		            : typeof Uint8Array === "undefined"
		                ? sizeOrArray
		                : new Uint8Array(sizeOrArray);
		};

		/**
		 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
		 * @type {Constructor<Uint8Array>}
		 */
		util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

		/**
		 * Any compatible Long instance.
		 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
		 * @interface Long
		 * @property {number} low Low bits
		 * @property {number} high High bits
		 * @property {boolean} unsigned Whether unsigned or not
		 */

		/**
		 * Long.js's Long class if available.
		 * @type {Constructor<Long>}
		 */
		util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
		         || /* istanbul ignore next */ util.global.Long
		         || util.inquire("long");

		/**
		 * Regular expression used to verify 2 bit (`bool`) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key2Re = /^true|false|0|1$/;

		/**
		 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

		/**
		 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

		/**
		 * Converts a number or long to an 8 characters long hash string.
		 * @param {Long|number} value Value to convert
		 * @returns {string} Hash
		 */
		util.longToHash = function longToHash(value) {
		    return value
		        ? util.LongBits.from(value).toHash()
		        : util.LongBits.zeroHash;
		};

		/**
		 * Converts an 8 characters long hash string to a long or number.
		 * @param {string} hash Hash
		 * @param {boolean} [unsigned=false] Whether unsigned or not
		 * @returns {Long|number} Original value
		 */
		util.longFromHash = function longFromHash(hash, unsigned) {
		    var bits = util.LongBits.fromHash(hash);
		    if (util.Long)
		        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
		    return bits.toNumber(Boolean(unsigned));
		};

		/**
		 * Merges the properties of the source object into the destination object.
		 * @memberof util
		 * @param {Object.<string,*>} dst Destination object
		 * @param {Object.<string,*>} src Source object
		 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
		 * @returns {Object.<string,*>} Destination object
		 */
		function merge(dst, src, ifNotSet) { // used by converters
		    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
		        if (dst[keys[i]] === undefined || !ifNotSet)
		            dst[keys[i]] = src[keys[i]];
		    return dst;
		}

		util.merge = merge;

		/**
		 * Converts the first character of a string to lower case.
		 * @param {string} str String to convert
		 * @returns {string} Converted string
		 */
		util.lcFirst = function lcFirst(str) {
		    return str.charAt(0).toLowerCase() + str.substring(1);
		};

		/**
		 * Creates a custom error constructor.
		 * @memberof util
		 * @param {string} name Error name
		 * @returns {Constructor<Error>} Custom error constructor
		 */
		function newError(name) {

		    function CustomError(message, properties) {

		        if (!(this instanceof CustomError))
		            return new CustomError(message, properties);

		        // Error.call(this, message);
		        // ^ just returns a new error instance because the ctor can be called as a function

		        Object.defineProperty(this, "message", { get: function() { return message; } });

		        /* istanbul ignore next */
		        if (Error.captureStackTrace) // node
		            Error.captureStackTrace(this, CustomError);
		        else
		            Object.defineProperty(this, "stack", { value: new Error().stack || "" });

		        if (properties)
		            merge(this, properties);
		    }

		    (CustomError.prototype = Object.create(Error.prototype)).constructor = CustomError;

		    Object.defineProperty(CustomError.prototype, "name", { get: function() { return name; } });

		    CustomError.prototype.toString = function toString() {
		        return this.name + ": " + this.message;
		    };

		    return CustomError;
		}

		util.newError = newError;

		/**
		 * Constructs a new protocol error.
		 * @classdesc Error subclass indicating a protocol specifc error.
		 * @memberof util
		 * @extends Error
		 * @template T extends Message<T>
		 * @constructor
		 * @param {string} message Error message
		 * @param {Object.<string,*>} [properties] Additional properties
		 * @example
		 * try {
		 *     MyMessage.decode(someBuffer); // throws if required fields are missing
		 * } catch (e) {
		 *     if (e instanceof ProtocolError && e.instance)
		 *         console.log("decoded so far: " + JSON.stringify(e.instance));
		 * }
		 */
		util.ProtocolError = newError("ProtocolError");

		/**
		 * So far decoded message instance.
		 * @name util.ProtocolError#instance
		 * @type {Message<T>}
		 */

		/**
		 * A OneOf getter as returned by {@link util.oneOfGetter}.
		 * @typedef OneOfGetter
		 * @type {function}
		 * @returns {string|undefined} Set field name, if any
		 */

		/**
		 * Builds a getter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfGetter} Unbound getter
		 */
		util.oneOfGetter = function getOneOf(fieldNames) {
		    var fieldMap = {};
		    for (var i = 0; i < fieldNames.length; ++i)
		        fieldMap[fieldNames[i]] = 1;

		    /**
		     * @returns {string|undefined} Set field name, if any
		     * @this Object
		     * @ignore
		     */
		    return function() { // eslint-disable-line consistent-return
		        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
		            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
		                return keys[i];
		    };
		};

		/**
		 * A OneOf setter as returned by {@link util.oneOfSetter}.
		 * @typedef OneOfSetter
		 * @type {function}
		 * @param {string|undefined} value Field name
		 * @returns {undefined}
		 */

		/**
		 * Builds a setter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfSetter} Unbound setter
		 */
		util.oneOfSetter = function setOneOf(fieldNames) {

		    /**
		     * @param {string} name Field name
		     * @returns {undefined}
		     * @this Object
		     * @ignore
		     */
		    return function(name) {
		        for (var i = 0; i < fieldNames.length; ++i)
		            if (fieldNames[i] !== name)
		                delete this[fieldNames[i]];
		    };
		};

		/**
		 * Default conversion options used for {@link Message#toJSON} implementations.
		 *
		 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
		 *
		 * - Longs become strings
		 * - Enums become string keys
		 * - Bytes become base64 encoded strings
		 * - (Sub-)Messages become plain objects
		 * - Maps become plain objects with all string keys
		 * - Repeated fields become arrays
		 * - NaN and Infinity for float and double fields become strings
		 *
		 * @type {IConversionOptions}
		 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
		 */
		util.toJSONOptions = {
		    longs: String,
		    enums: String,
		    bytes: String,
		    json: true
		};

		// Sets up buffer utility according to the environment (called in index-minimal)
		util._configure = function() {
		    var Buffer = util.Buffer;
		    /* istanbul ignore if */
		    if (!Buffer) {
		        util._Buffer_from = util._Buffer_allocUnsafe = null;
		        return;
		    }
		    // because node 4.x buffers are incompatible & immutable
		    // see: https://github.com/dcodeIO/protobuf.js/pull/665
		    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
		        /* istanbul ignore next */
		        function Buffer_from(value, encoding) {
		            return new Buffer(value, encoding);
		        };
		    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
		        /* istanbul ignore next */
		        function Buffer_allocUnsafe(size) {
		            return new Buffer(size);
		        };
		};
} (minimal$2));
	return minimal$2;
}

var writer$4 = Writer$5;

var util$e      = requireMinimal$2();

var BufferWriter$5; // cyclic

var LongBits$5  = util$e.LongBits,
    base64$2    = util$e.base64,
    utf8$5      = util$e.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op$2(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop$4() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State$2(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer$5() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op$2(noop$4, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

var create$5 = function create() {
    return util$e.Buffer
        ? function create_buffer_setup() {
            return (Writer$5.create = function create_buffer() {
                return new BufferWriter$5();
            })();
        }
        /* istanbul ignore next */
        : function create_array() {
            return new Writer$5();
        };
};

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer$5.create = create$5();

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer$5.alloc = function alloc(size) {
    return new util$e.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util$e.Array !== Array)
    Writer$5.alloc = util$e.pool(Writer$5.alloc, util$e.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer$5.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op$2(fn, len, val);
    this.len += len;
    return this;
};

function writeByte$2(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32$2(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp$2(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp$2.prototype = Object.create(Op$2.prototype);
VarintOp$2.prototype.fn = writeVarint32$2;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp$2(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64$2, 10, LongBits$5.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64$2(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$5.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits$5.from(value);
    return this._push(writeVarint64$2, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$5.prototype.int64 = Writer$5.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$5.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits$5.from(value).zzEncode();
    return this._push(writeVarint64$2, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.bool = function write_bool(value) {
    return this._push(writeByte$2, 1, value ? 1 : 0);
};

function writeFixed32$2(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32$2, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.sfixed32 = Writer$5.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$5.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits$5.from(value);
    return this._push(writeFixed32$2, 4, bits.lo)._push(writeFixed32$2, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$5.prototype.sfixed64 = Writer$5.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.float = function write_float(value) {
    return this._push(util$e.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.double = function write_double(value) {
    return this._push(util$e.float.writeDoubleLE, 8, value);
};

var writeBytes$2 = util$e.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte$2, 1, 0);
    if (util$e.isString(value)) {
        var buf = Writer$5.alloc(len = base64$2.length(value));
        base64$2.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes$2, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer$5.prototype.string = function write_string(value) {
    var len = utf8$5.length(value);
    return len
        ? this.uint32(len)._push(utf8$5.write, len, value)
        : this._push(writeByte$2, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer$5.prototype.fork = function fork() {
    this.states = new State$2(this);
    this.head = this.tail = new Op$2(noop$4, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer$5.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op$2(noop$4, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer$5.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer$5.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer$5._configure = function(BufferWriter_) {
    BufferWriter$5 = BufferWriter_;
    Writer$5.create = create$5();
    BufferWriter$5._configure();
};

var writer_buffer$2 = BufferWriter$4;

// extends Writer
var Writer$4 = writer$4;
(BufferWriter$4.prototype = Object.create(Writer$4.prototype)).constructor = BufferWriter$4;

var util$d = requireMinimal$2();

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter$4() {
    Writer$4.call(this);
}

BufferWriter$4._configure = function () {
    /**
     * Allocates a buffer of the specified size.
     * @function
     * @param {number} size Buffer size
     * @returns {Buffer} Buffer
     */
    BufferWriter$4.alloc = util$d._Buffer_allocUnsafe;

    BufferWriter$4.writeBytesBuffer = util$d.Buffer && util$d.Buffer.prototype instanceof Uint8Array && util$d.Buffer.prototype.set.name === "set"
        ? function writeBytesBuffer_set(val, buf, pos) {
          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
          // also works for plain array values
        }
        /* istanbul ignore next */
        : function writeBytesBuffer_copy(val, buf, pos) {
          if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
          else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
        };
};


/**
 * @override
 */
BufferWriter$4.prototype.bytes = function write_bytes_buffer(value) {
    if (util$d.isString(value))
        value = util$d._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(BufferWriter$4.writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer$2(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util$d.utf8.write(val, buf, pos);
    else if (buf.utf8Write)
        buf.utf8Write(val, pos);
    else
        buf.write(val, pos);
}

/**
 * @override
 */
BufferWriter$4.prototype.string = function write_string_buffer(value) {
    var len = util$d.Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer$2, len, value);
    return this;
};


/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

BufferWriter$4._configure();

var reader$4 = Reader$5;

var util$c      = requireMinimal$2();

var BufferReader$5; // cyclic

var LongBits$4  = util$c.LongBits,
    utf8$4      = util$c.utf8;

/* istanbul ignore next */
function indexOutOfRange$2(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader$5(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array$2 = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader$5(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader$5(buffer);
        throw Error("illegal buffer");
    };

var create$4 = function create() {
    return util$c.Buffer
        ? function create_buffer_setup(buffer) {
            return (Reader$5.create = function create_buffer(buffer) {
                return util$c.Buffer.isBuffer(buffer)
                    ? new BufferReader$5(buffer)
                    /* istanbul ignore next */
                    : create_array$2(buffer);
            })(buffer);
        }
        /* istanbul ignore next */
        : create_array$2;
};

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader$5.create = create$4();

Reader$5.prototype._slice = util$c.Array.prototype.subarray || /* istanbul ignore next */ util$c.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader$5.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange$2(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$5.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$5.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint$2() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits$4(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$2(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$2(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader$5.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end$2(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader$5.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$2(this, 4);

    return readFixed32_end$2(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader$5.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$2(this, 4);

    return readFixed32_end$2(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64$2(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$2(this, 8);

    return new LongBits$4(readFixed32_end$2(this.buf, this.pos += 4), readFixed32_end$2(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$5.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$2(this, 4);

    var value = util$c.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$5.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$2(this, 4);

    var value = util$c.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader$5.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange$2(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader$5.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8$4.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader$5.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange$2(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$2(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader$5.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader$5._configure = function(BufferReader_) {
    BufferReader$5 = BufferReader_;
    Reader$5.create = create$4();
    BufferReader$5._configure();

    var fn = util$c.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util$c.merge(Reader$5.prototype, {

        int64: function read_int64() {
            return readLongVarint$2.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint$2.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint$2.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64$2.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64$2.call(this)[fn](false);
        }

    });
};

var reader_buffer$2 = BufferReader$4;

// extends Reader
var Reader$4 = reader$4;
(BufferReader$4.prototype = Object.create(Reader$4.prototype)).constructor = BufferReader$4;

var util$b = requireMinimal$2();

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader$4(buffer) {
    Reader$4.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

BufferReader$4._configure = function () {
    /* istanbul ignore else */
    if (util$b.Buffer)
        BufferReader$4.prototype._slice = util$b.Buffer.prototype.slice;
};


/**
 * @override
 */
BufferReader$4.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice
        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))
        : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

BufferReader$4._configure();

var rpc = {};

var service = Service;

var util$a = requireMinimal$2();

// Extends EventEmitter
(Service.prototype = Object.create(util$a.EventEmitter.prototype)).constructor = Service;

/**
 * A service method callback as used by {@link rpc.ServiceMethod|ServiceMethod}.
 *
 * Differs from {@link RPCImplCallback} in that it is an actual callback of a service method which may not return `response = null`.
 * @typedef rpc.ServiceMethodCallback
 * @template TRes extends Message<TRes>
 * @type {function}
 * @param {Error|null} error Error, if any
 * @param {TRes} [response] Response message
 * @returns {undefined}
 */

/**
 * A service method part of a {@link rpc.Service} as created by {@link Service.create}.
 * @typedef rpc.ServiceMethod
 * @template TReq extends Message<TReq>
 * @template TRes extends Message<TRes>
 * @type {function}
 * @param {TReq|Properties<TReq>} request Request message or plain object
 * @param {rpc.ServiceMethodCallback<TRes>} [callback] Node-style callback called with the error, if any, and the response message
 * @returns {Promise<Message<TRes>>} Promise if `callback` has been omitted, otherwise `undefined`
 */

/**
 * Constructs a new RPC service instance.
 * @classdesc An RPC service as returned by {@link Service#create}.
 * @exports rpc.Service
 * @extends util.EventEmitter
 * @constructor
 * @param {RPCImpl} rpcImpl RPC implementation
 * @param {boolean} [requestDelimited=false] Whether requests are length-delimited
 * @param {boolean} [responseDelimited=false] Whether responses are length-delimited
 */
function Service(rpcImpl, requestDelimited, responseDelimited) {

    if (typeof rpcImpl !== "function")
        throw TypeError("rpcImpl must be a function");

    util$a.EventEmitter.call(this);

    /**
     * RPC implementation. Becomes `null` once the service is ended.
     * @type {RPCImpl|null}
     */
    this.rpcImpl = rpcImpl;

    /**
     * Whether requests are length-delimited.
     * @type {boolean}
     */
    this.requestDelimited = Boolean(requestDelimited);

    /**
     * Whether responses are length-delimited.
     * @type {boolean}
     */
    this.responseDelimited = Boolean(responseDelimited);
}

/**
 * Calls a service method through {@link rpc.Service#rpcImpl|rpcImpl}.
 * @param {Method|rpc.ServiceMethod<TReq,TRes>} method Reflected or static method
 * @param {Constructor<TReq>} requestCtor Request constructor
 * @param {Constructor<TRes>} responseCtor Response constructor
 * @param {TReq|Properties<TReq>} request Request message or plain object
 * @param {rpc.ServiceMethodCallback<TRes>} callback Service callback
 * @returns {undefined}
 * @template TReq extends Message<TReq>
 * @template TRes extends Message<TRes>
 */
Service.prototype.rpcCall = function rpcCall(method, requestCtor, responseCtor, request, callback) {

    if (!request)
        throw TypeError("request must be specified");

    var self = this;
    if (!callback)
        return util$a.asPromise(rpcCall, self, method, requestCtor, responseCtor, request);

    if (!self.rpcImpl) {
        setTimeout(function() { callback(Error("already ended")); }, 0);
        return undefined;
    }

    try {
        return self.rpcImpl(
            method,
            requestCtor[self.requestDelimited ? "encodeDelimited" : "encode"](request).finish(),
            function rpcCallback(err, response) {

                if (err) {
                    self.emit("error", err, method);
                    return callback(err);
                }

                if (response === null) {
                    self.end(/* endedByRPC */ true);
                    return undefined;
                }

                if (!(response instanceof responseCtor)) {
                    try {
                        response = responseCtor[self.responseDelimited ? "decodeDelimited" : "decode"](response);
                    } catch (err) {
                        self.emit("error", err, method);
                        return callback(err);
                    }
                }

                self.emit("data", response, method);
                return callback(null, response);
            }
        );
    } catch (err) {
        self.emit("error", err, method);
        setTimeout(function() { callback(err); }, 0);
        return undefined;
    }
};

/**
 * Ends this service and emits the `end` event.
 * @param {boolean} [endedByRPC=false] Whether the service has been ended by the RPC implementation.
 * @returns {rpc.Service} `this`
 */
Service.prototype.end = function end(endedByRPC) {
    if (this.rpcImpl) {
        if (!endedByRPC) // signal end to rpcImpl
            this.rpcImpl(null, null, null);
        this.rpcImpl = null;
        this.emit("end").off();
    }
    return this;
};

(function (exports) {

	/**
	 * Streaming RPC helpers.
	 * @namespace
	 */
	var rpc = exports;

	/**
	 * RPC implementation passed to {@link Service#create} performing a service request on network level, i.e. by utilizing http requests or websockets.
	 * @typedef RPCImpl
	 * @type {function}
	 * @param {Method|rpc.ServiceMethod<Message<{}>,Message<{}>>} method Reflected or static method being called
	 * @param {Uint8Array} requestData Request data
	 * @param {RPCImplCallback} callback Callback function
	 * @returns {undefined}
	 * @example
	 * function rpcImpl(method, requestData, callback) {
	 *     if (protobuf.util.lcFirst(method.name) !== "myMethod") // compatible with static code
	 *         throw Error("no such method");
	 *     asynchronouslyObtainAResponse(requestData, function(err, responseData) {
	 *         callback(err, responseData);
	 *     });
	 * }
	 */

	/**
	 * Node-style callback as used by {@link RPCImpl}.
	 * @typedef RPCImplCallback
	 * @type {function}
	 * @param {Error|null} error Error, if any, otherwise `null`
	 * @param {Uint8Array|null} [response] Response data or `null` to signal end of stream, if there hasn't been an error
	 * @returns {undefined}
	 */

	rpc.Service = service;
} (rpc));

var roots = {};

(function (exports) {
	var protobuf = exports;

	/**
	 * Build type, one of `"full"`, `"light"` or `"minimal"`.
	 * @name build
	 * @type {string}
	 * @const
	 */
	protobuf.build = "minimal";

	// Serialization
	protobuf.Writer       = writer$4;
	protobuf.BufferWriter = writer_buffer$2;
	protobuf.Reader       = reader$4;
	protobuf.BufferReader = reader_buffer$2;

	// Utility
	protobuf.util         = requireMinimal$2();
	protobuf.rpc          = rpc;
	protobuf.roots        = roots;
	protobuf.configure    = configure;

	/* istanbul ignore next */
	/**
	 * Reconfigures the library according to the environment.
	 * @returns {undefined}
	 */
	function configure() {
	    protobuf.util._configure();
	    protobuf.Writer._configure(protobuf.BufferWriter);
	    protobuf.Reader._configure(protobuf.BufferReader);
	}

	// Set up buffer utility according to the environment
	configure();
} (indexMinimal));

(function (module) {
	module.exports = indexMinimal;
} (minimal$3));

var protobuf = /*@__PURE__*/getDefaultExportFromCjs(minimalExports$2);

(function (module) {
	// @ts-nocheck
	/*eslint-disable*/
	(function(global, factory) { /* global define, require, module */

	    /* AMD */ if (typeof commonjsRequire === 'function' && 'object' === 'object' && module && module.exports)
	        module.exports = factory(minimalExports$2);

	})(commonjsGlobal, function($protobuf) {

	    // Common aliases
	    var $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;

	    // Exported root namespace
	    var $root = $protobuf.roots["default"] || ($protobuf.roots["default"] = {});

	    $root.RPC = (function() {

	        /**
	         * Properties of a RPC.
	         * @exports IRPC
	         * @interface IRPC
	         * @property {Array.<RPC.ISubOpts>|null} [subscriptions] RPC subscriptions
	         * @property {Array.<RPC.IMessage>|null} [messages] RPC messages
	         * @property {RPC.IControlMessage|null} [control] RPC control
	         */

	        /**
	         * Constructs a new RPC.
	         * @exports RPC
	         * @classdesc Represents a RPC.
	         * @implements IRPC
	         * @constructor
	         * @param {IRPC=} [p] Properties to set
	         */
	        function RPC(p) {
	            this.subscriptions = [];
	            this.messages = [];
	            if (p)
	                for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                    if (p[ks[i]] != null)
	                        this[ks[i]] = p[ks[i]];
	        }

	        /**
	         * RPC subscriptions.
	         * @member {Array.<RPC.ISubOpts>} subscriptions
	         * @memberof RPC
	         * @instance
	         */
	        RPC.prototype.subscriptions = $util.emptyArray;

	        /**
	         * RPC messages.
	         * @member {Array.<RPC.IMessage>} messages
	         * @memberof RPC
	         * @instance
	         */
	        RPC.prototype.messages = $util.emptyArray;

	        /**
	         * RPC control.
	         * @member {RPC.IControlMessage|null|undefined} control
	         * @memberof RPC
	         * @instance
	         */
	        RPC.prototype.control = null;

	        // OneOf field names bound to virtual getters and setters
	        var $oneOfFields;

	        /**
	         * RPC _control.
	         * @member {"control"|undefined} _control
	         * @memberof RPC
	         * @instance
	         */
	        Object.defineProperty(RPC.prototype, "_control", {
	            get: $util.oneOfGetter($oneOfFields = ["control"]),
	            set: $util.oneOfSetter($oneOfFields)
	        });

	        /**
	         * Encodes the specified RPC message. Does not implicitly {@link RPC.verify|verify} messages.
	         * @function encode
	         * @memberof RPC
	         * @static
	         * @param {IRPC} m RPC message or plain object to encode
	         * @param {$protobuf.Writer} [w] Writer to encode to
	         * @returns {$protobuf.Writer} Writer
	         */
	        RPC.encode = function encode(m, w) {
	            if (!w)
	                w = $Writer.create();
	            if (m.subscriptions != null && m.subscriptions.length) {
	                for (var i = 0; i < m.subscriptions.length; ++i)
	                    $root.RPC.SubOpts.encode(m.subscriptions[i], w.uint32(10).fork()).ldelim();
	            }
	            if (m.messages != null && m.messages.length) {
	                for (var i = 0; i < m.messages.length; ++i)
	                    $root.RPC.Message.encode(m.messages[i], w.uint32(18).fork()).ldelim();
	            }
	            if (m.control != null && Object.hasOwnProperty.call(m, "control"))
	                $root.RPC.ControlMessage.encode(m.control, w.uint32(26).fork()).ldelim();
	            return w;
	        };

	        /**
	         * Decodes a RPC message from the specified reader or buffer.
	         * @function decode
	         * @memberof RPC
	         * @static
	         * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	         * @param {number} [l] Message length if known beforehand
	         * @returns {RPC} RPC
	         * @throws {Error} If the payload is not a reader or valid buffer
	         * @throws {$protobuf.util.ProtocolError} If required fields are missing
	         */
	        RPC.decode = function decode(r, l) {
	            if (!(r instanceof $Reader))
	                r = $Reader.create(r);
	            var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC();
	            while (r.pos < c) {
	                var t = r.uint32();
	                switch (t >>> 3) {
	                case 1:
	                    if (!(m.subscriptions && m.subscriptions.length))
	                        m.subscriptions = [];
	                    m.subscriptions.push($root.RPC.SubOpts.decode(r, r.uint32()));
	                    break;
	                case 2:
	                    if (!(m.messages && m.messages.length))
	                        m.messages = [];
	                    m.messages.push($root.RPC.Message.decode(r, r.uint32()));
	                    break;
	                case 3:
	                    m.control = $root.RPC.ControlMessage.decode(r, r.uint32());
	                    break;
	                default:
	                    r.skipType(t & 7);
	                    break;
	                }
	            }
	            return m;
	        };

	        /**
	         * Creates a RPC message from a plain object. Also converts values to their respective internal types.
	         * @function fromObject
	         * @memberof RPC
	         * @static
	         * @param {Object.<string,*>} d Plain object
	         * @returns {RPC} RPC
	         */
	        RPC.fromObject = function fromObject(d) {
	            if (d instanceof $root.RPC)
	                return d;
	            var m = new $root.RPC();
	            if (d.subscriptions) {
	                if (!Array.isArray(d.subscriptions))
	                    throw TypeError(".RPC.subscriptions: array expected");
	                m.subscriptions = [];
	                for (var i = 0; i < d.subscriptions.length; ++i) {
	                    if (typeof d.subscriptions[i] !== "object")
	                        throw TypeError(".RPC.subscriptions: object expected");
	                    m.subscriptions[i] = $root.RPC.SubOpts.fromObject(d.subscriptions[i]);
	                }
	            }
	            if (d.messages) {
	                if (!Array.isArray(d.messages))
	                    throw TypeError(".RPC.messages: array expected");
	                m.messages = [];
	                for (var i = 0; i < d.messages.length; ++i) {
	                    if (typeof d.messages[i] !== "object")
	                        throw TypeError(".RPC.messages: object expected");
	                    m.messages[i] = $root.RPC.Message.fromObject(d.messages[i]);
	                }
	            }
	            if (d.control != null) {
	                if (typeof d.control !== "object")
	                    throw TypeError(".RPC.control: object expected");
	                m.control = $root.RPC.ControlMessage.fromObject(d.control);
	            }
	            return m;
	        };

	        /**
	         * Creates a plain object from a RPC message. Also converts values to other types if specified.
	         * @function toObject
	         * @memberof RPC
	         * @static
	         * @param {RPC} m RPC
	         * @param {$protobuf.IConversionOptions} [o] Conversion options
	         * @returns {Object.<string,*>} Plain object
	         */
	        RPC.toObject = function toObject(m, o) {
	            if (!o)
	                o = {};
	            var d = {};
	            if (o.arrays || o.defaults) {
	                d.subscriptions = [];
	                d.messages = [];
	            }
	            if (m.subscriptions && m.subscriptions.length) {
	                d.subscriptions = [];
	                for (var j = 0; j < m.subscriptions.length; ++j) {
	                    d.subscriptions[j] = $root.RPC.SubOpts.toObject(m.subscriptions[j], o);
	                }
	            }
	            if (m.messages && m.messages.length) {
	                d.messages = [];
	                for (var j = 0; j < m.messages.length; ++j) {
	                    d.messages[j] = $root.RPC.Message.toObject(m.messages[j], o);
	                }
	            }
	            if (m.control != null && m.hasOwnProperty("control")) {
	                d.control = $root.RPC.ControlMessage.toObject(m.control, o);
	                if (o.oneofs)
	                    d._control = "control";
	            }
	            return d;
	        };

	        /**
	         * Converts this RPC to JSON.
	         * @function toJSON
	         * @memberof RPC
	         * @instance
	         * @returns {Object.<string,*>} JSON object
	         */
	        RPC.prototype.toJSON = function toJSON() {
	            return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	        };

	        RPC.SubOpts = (function() {

	            /**
	             * Properties of a SubOpts.
	             * @memberof RPC
	             * @interface ISubOpts
	             * @property {boolean|null} [subscribe] SubOpts subscribe
	             * @property {string|null} [topic] SubOpts topic
	             */

	            /**
	             * Constructs a new SubOpts.
	             * @memberof RPC
	             * @classdesc Represents a SubOpts.
	             * @implements ISubOpts
	             * @constructor
	             * @param {RPC.ISubOpts=} [p] Properties to set
	             */
	            function SubOpts(p) {
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * SubOpts subscribe.
	             * @member {boolean|null|undefined} subscribe
	             * @memberof RPC.SubOpts
	             * @instance
	             */
	            SubOpts.prototype.subscribe = null;

	            /**
	             * SubOpts topic.
	             * @member {string|null|undefined} topic
	             * @memberof RPC.SubOpts
	             * @instance
	             */
	            SubOpts.prototype.topic = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * SubOpts _subscribe.
	             * @member {"subscribe"|undefined} _subscribe
	             * @memberof RPC.SubOpts
	             * @instance
	             */
	            Object.defineProperty(SubOpts.prototype, "_subscribe", {
	                get: $util.oneOfGetter($oneOfFields = ["subscribe"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * SubOpts _topic.
	             * @member {"topic"|undefined} _topic
	             * @memberof RPC.SubOpts
	             * @instance
	             */
	            Object.defineProperty(SubOpts.prototype, "_topic", {
	                get: $util.oneOfGetter($oneOfFields = ["topic"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified SubOpts message. Does not implicitly {@link RPC.SubOpts.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.SubOpts
	             * @static
	             * @param {RPC.ISubOpts} m SubOpts message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            SubOpts.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.subscribe != null && Object.hasOwnProperty.call(m, "subscribe"))
	                    w.uint32(8).bool(m.subscribe);
	                if (m.topic != null && Object.hasOwnProperty.call(m, "topic"))
	                    w.uint32(18).string(m.topic);
	                return w;
	            };

	            /**
	             * Decodes a SubOpts message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.SubOpts
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.SubOpts} SubOpts
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            SubOpts.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.SubOpts();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.subscribe = r.bool();
	                        break;
	                    case 2:
	                        m.topic = r.string();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a SubOpts message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.SubOpts
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.SubOpts} SubOpts
	             */
	            SubOpts.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.SubOpts)
	                    return d;
	                var m = new $root.RPC.SubOpts();
	                if (d.subscribe != null) {
	                    m.subscribe = Boolean(d.subscribe);
	                }
	                if (d.topic != null) {
	                    m.topic = String(d.topic);
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a SubOpts message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.SubOpts
	             * @static
	             * @param {RPC.SubOpts} m SubOpts
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            SubOpts.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (m.subscribe != null && m.hasOwnProperty("subscribe")) {
	                    d.subscribe = m.subscribe;
	                    if (o.oneofs)
	                        d._subscribe = "subscribe";
	                }
	                if (m.topic != null && m.hasOwnProperty("topic")) {
	                    d.topic = m.topic;
	                    if (o.oneofs)
	                        d._topic = "topic";
	                }
	                return d;
	            };

	            /**
	             * Converts this SubOpts to JSON.
	             * @function toJSON
	             * @memberof RPC.SubOpts
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            SubOpts.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return SubOpts;
	        })();

	        RPC.Message = (function() {

	            /**
	             * Properties of a Message.
	             * @memberof RPC
	             * @interface IMessage
	             * @property {Uint8Array|null} [from] Message from
	             * @property {Uint8Array|null} [data] Message data
	             * @property {Uint8Array|null} [seqno] Message seqno
	             * @property {string} topic Message topic
	             * @property {Uint8Array|null} [signature] Message signature
	             * @property {Uint8Array|null} [key] Message key
	             */

	            /**
	             * Constructs a new Message.
	             * @memberof RPC
	             * @classdesc Represents a Message.
	             * @implements IMessage
	             * @constructor
	             * @param {RPC.IMessage=} [p] Properties to set
	             */
	            function Message(p) {
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * Message from.
	             * @member {Uint8Array|null|undefined} from
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.from = null;

	            /**
	             * Message data.
	             * @member {Uint8Array|null|undefined} data
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.data = null;

	            /**
	             * Message seqno.
	             * @member {Uint8Array|null|undefined} seqno
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.seqno = null;

	            /**
	             * Message topic.
	             * @member {string} topic
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.topic = "";

	            /**
	             * Message signature.
	             * @member {Uint8Array|null|undefined} signature
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.signature = null;

	            /**
	             * Message key.
	             * @member {Uint8Array|null|undefined} key
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.key = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * Message _from.
	             * @member {"from"|undefined} _from
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_from", {
	                get: $util.oneOfGetter($oneOfFields = ["from"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Message _data.
	             * @member {"data"|undefined} _data
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_data", {
	                get: $util.oneOfGetter($oneOfFields = ["data"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Message _seqno.
	             * @member {"seqno"|undefined} _seqno
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_seqno", {
	                get: $util.oneOfGetter($oneOfFields = ["seqno"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Message _signature.
	             * @member {"signature"|undefined} _signature
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_signature", {
	                get: $util.oneOfGetter($oneOfFields = ["signature"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Message _key.
	             * @member {"key"|undefined} _key
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_key", {
	                get: $util.oneOfGetter($oneOfFields = ["key"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified Message message. Does not implicitly {@link RPC.Message.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.Message
	             * @static
	             * @param {RPC.IMessage} m Message message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            Message.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.from != null && Object.hasOwnProperty.call(m, "from"))
	                    w.uint32(10).bytes(m.from);
	                if (m.data != null && Object.hasOwnProperty.call(m, "data"))
	                    w.uint32(18).bytes(m.data);
	                if (m.seqno != null && Object.hasOwnProperty.call(m, "seqno"))
	                    w.uint32(26).bytes(m.seqno);
	                w.uint32(34).string(m.topic);
	                if (m.signature != null && Object.hasOwnProperty.call(m, "signature"))
	                    w.uint32(42).bytes(m.signature);
	                if (m.key != null && Object.hasOwnProperty.call(m, "key"))
	                    w.uint32(50).bytes(m.key);
	                return w;
	            };

	            /**
	             * Decodes a Message message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.Message
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.Message} Message
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            Message.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.Message();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.from = r.bytes();
	                        break;
	                    case 2:
	                        m.data = r.bytes();
	                        break;
	                    case 3:
	                        m.seqno = r.bytes();
	                        break;
	                    case 4:
	                        m.topic = r.string();
	                        break;
	                    case 5:
	                        m.signature = r.bytes();
	                        break;
	                    case 6:
	                        m.key = r.bytes();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                if (!m.hasOwnProperty("topic"))
	                    throw $util.ProtocolError("missing required 'topic'", { instance: m });
	                return m;
	            };

	            /**
	             * Creates a Message message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.Message
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.Message} Message
	             */
	            Message.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.Message)
	                    return d;
	                var m = new $root.RPC.Message();
	                if (d.from != null) {
	                    if (typeof d.from === "string")
	                        $util.base64.decode(d.from, m.from = $util.newBuffer($util.base64.length(d.from)), 0);
	                    else if (d.from.length)
	                        m.from = d.from;
	                }
	                if (d.data != null) {
	                    if (typeof d.data === "string")
	                        $util.base64.decode(d.data, m.data = $util.newBuffer($util.base64.length(d.data)), 0);
	                    else if (d.data.length)
	                        m.data = d.data;
	                }
	                if (d.seqno != null) {
	                    if (typeof d.seqno === "string")
	                        $util.base64.decode(d.seqno, m.seqno = $util.newBuffer($util.base64.length(d.seqno)), 0);
	                    else if (d.seqno.length)
	                        m.seqno = d.seqno;
	                }
	                if (d.topic != null) {
	                    m.topic = String(d.topic);
	                }
	                if (d.signature != null) {
	                    if (typeof d.signature === "string")
	                        $util.base64.decode(d.signature, m.signature = $util.newBuffer($util.base64.length(d.signature)), 0);
	                    else if (d.signature.length)
	                        m.signature = d.signature;
	                }
	                if (d.key != null) {
	                    if (typeof d.key === "string")
	                        $util.base64.decode(d.key, m.key = $util.newBuffer($util.base64.length(d.key)), 0);
	                    else if (d.key.length)
	                        m.key = d.key;
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a Message message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.Message
	             * @static
	             * @param {RPC.Message} m Message
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            Message.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.defaults) {
	                    d.topic = "";
	                }
	                if (m.from != null && m.hasOwnProperty("from")) {
	                    d.from = o.bytes === String ? $util.base64.encode(m.from, 0, m.from.length) : o.bytes === Array ? Array.prototype.slice.call(m.from) : m.from;
	                    if (o.oneofs)
	                        d._from = "from";
	                }
	                if (m.data != null && m.hasOwnProperty("data")) {
	                    d.data = o.bytes === String ? $util.base64.encode(m.data, 0, m.data.length) : o.bytes === Array ? Array.prototype.slice.call(m.data) : m.data;
	                    if (o.oneofs)
	                        d._data = "data";
	                }
	                if (m.seqno != null && m.hasOwnProperty("seqno")) {
	                    d.seqno = o.bytes === String ? $util.base64.encode(m.seqno, 0, m.seqno.length) : o.bytes === Array ? Array.prototype.slice.call(m.seqno) : m.seqno;
	                    if (o.oneofs)
	                        d._seqno = "seqno";
	                }
	                if (m.topic != null && m.hasOwnProperty("topic")) {
	                    d.topic = m.topic;
	                }
	                if (m.signature != null && m.hasOwnProperty("signature")) {
	                    d.signature = o.bytes === String ? $util.base64.encode(m.signature, 0, m.signature.length) : o.bytes === Array ? Array.prototype.slice.call(m.signature) : m.signature;
	                    if (o.oneofs)
	                        d._signature = "signature";
	                }
	                if (m.key != null && m.hasOwnProperty("key")) {
	                    d.key = o.bytes === String ? $util.base64.encode(m.key, 0, m.key.length) : o.bytes === Array ? Array.prototype.slice.call(m.key) : m.key;
	                    if (o.oneofs)
	                        d._key = "key";
	                }
	                return d;
	            };

	            /**
	             * Converts this Message to JSON.
	             * @function toJSON
	             * @memberof RPC.Message
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            Message.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return Message;
	        })();

	        RPC.ControlMessage = (function() {

	            /**
	             * Properties of a ControlMessage.
	             * @memberof RPC
	             * @interface IControlMessage
	             * @property {Array.<RPC.IControlIHave>|null} [ihave] ControlMessage ihave
	             * @property {Array.<RPC.IControlIWant>|null} [iwant] ControlMessage iwant
	             * @property {Array.<RPC.IControlGraft>|null} [graft] ControlMessage graft
	             * @property {Array.<RPC.IControlPrune>|null} [prune] ControlMessage prune
	             */

	            /**
	             * Constructs a new ControlMessage.
	             * @memberof RPC
	             * @classdesc Represents a ControlMessage.
	             * @implements IControlMessage
	             * @constructor
	             * @param {RPC.IControlMessage=} [p] Properties to set
	             */
	            function ControlMessage(p) {
	                this.ihave = [];
	                this.iwant = [];
	                this.graft = [];
	                this.prune = [];
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlMessage ihave.
	             * @member {Array.<RPC.IControlIHave>} ihave
	             * @memberof RPC.ControlMessage
	             * @instance
	             */
	            ControlMessage.prototype.ihave = $util.emptyArray;

	            /**
	             * ControlMessage iwant.
	             * @member {Array.<RPC.IControlIWant>} iwant
	             * @memberof RPC.ControlMessage
	             * @instance
	             */
	            ControlMessage.prototype.iwant = $util.emptyArray;

	            /**
	             * ControlMessage graft.
	             * @member {Array.<RPC.IControlGraft>} graft
	             * @memberof RPC.ControlMessage
	             * @instance
	             */
	            ControlMessage.prototype.graft = $util.emptyArray;

	            /**
	             * ControlMessage prune.
	             * @member {Array.<RPC.IControlPrune>} prune
	             * @memberof RPC.ControlMessage
	             * @instance
	             */
	            ControlMessage.prototype.prune = $util.emptyArray;

	            /**
	             * Encodes the specified ControlMessage message. Does not implicitly {@link RPC.ControlMessage.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlMessage
	             * @static
	             * @param {RPC.IControlMessage} m ControlMessage message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlMessage.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.ihave != null && m.ihave.length) {
	                    for (var i = 0; i < m.ihave.length; ++i)
	                        $root.RPC.ControlIHave.encode(m.ihave[i], w.uint32(10).fork()).ldelim();
	                }
	                if (m.iwant != null && m.iwant.length) {
	                    for (var i = 0; i < m.iwant.length; ++i)
	                        $root.RPC.ControlIWant.encode(m.iwant[i], w.uint32(18).fork()).ldelim();
	                }
	                if (m.graft != null && m.graft.length) {
	                    for (var i = 0; i < m.graft.length; ++i)
	                        $root.RPC.ControlGraft.encode(m.graft[i], w.uint32(26).fork()).ldelim();
	                }
	                if (m.prune != null && m.prune.length) {
	                    for (var i = 0; i < m.prune.length; ++i)
	                        $root.RPC.ControlPrune.encode(m.prune[i], w.uint32(34).fork()).ldelim();
	                }
	                return w;
	            };

	            /**
	             * Decodes a ControlMessage message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlMessage
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlMessage} ControlMessage
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlMessage.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlMessage();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        if (!(m.ihave && m.ihave.length))
	                            m.ihave = [];
	                        m.ihave.push($root.RPC.ControlIHave.decode(r, r.uint32()));
	                        break;
	                    case 2:
	                        if (!(m.iwant && m.iwant.length))
	                            m.iwant = [];
	                        m.iwant.push($root.RPC.ControlIWant.decode(r, r.uint32()));
	                        break;
	                    case 3:
	                        if (!(m.graft && m.graft.length))
	                            m.graft = [];
	                        m.graft.push($root.RPC.ControlGraft.decode(r, r.uint32()));
	                        break;
	                    case 4:
	                        if (!(m.prune && m.prune.length))
	                            m.prune = [];
	                        m.prune.push($root.RPC.ControlPrune.decode(r, r.uint32()));
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlMessage message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlMessage
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlMessage} ControlMessage
	             */
	            ControlMessage.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlMessage)
	                    return d;
	                var m = new $root.RPC.ControlMessage();
	                if (d.ihave) {
	                    if (!Array.isArray(d.ihave))
	                        throw TypeError(".RPC.ControlMessage.ihave: array expected");
	                    m.ihave = [];
	                    for (var i = 0; i < d.ihave.length; ++i) {
	                        if (typeof d.ihave[i] !== "object")
	                            throw TypeError(".RPC.ControlMessage.ihave: object expected");
	                        m.ihave[i] = $root.RPC.ControlIHave.fromObject(d.ihave[i]);
	                    }
	                }
	                if (d.iwant) {
	                    if (!Array.isArray(d.iwant))
	                        throw TypeError(".RPC.ControlMessage.iwant: array expected");
	                    m.iwant = [];
	                    for (var i = 0; i < d.iwant.length; ++i) {
	                        if (typeof d.iwant[i] !== "object")
	                            throw TypeError(".RPC.ControlMessage.iwant: object expected");
	                        m.iwant[i] = $root.RPC.ControlIWant.fromObject(d.iwant[i]);
	                    }
	                }
	                if (d.graft) {
	                    if (!Array.isArray(d.graft))
	                        throw TypeError(".RPC.ControlMessage.graft: array expected");
	                    m.graft = [];
	                    for (var i = 0; i < d.graft.length; ++i) {
	                        if (typeof d.graft[i] !== "object")
	                            throw TypeError(".RPC.ControlMessage.graft: object expected");
	                        m.graft[i] = $root.RPC.ControlGraft.fromObject(d.graft[i]);
	                    }
	                }
	                if (d.prune) {
	                    if (!Array.isArray(d.prune))
	                        throw TypeError(".RPC.ControlMessage.prune: array expected");
	                    m.prune = [];
	                    for (var i = 0; i < d.prune.length; ++i) {
	                        if (typeof d.prune[i] !== "object")
	                            throw TypeError(".RPC.ControlMessage.prune: object expected");
	                        m.prune[i] = $root.RPC.ControlPrune.fromObject(d.prune[i]);
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlMessage message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlMessage
	             * @static
	             * @param {RPC.ControlMessage} m ControlMessage
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlMessage.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.arrays || o.defaults) {
	                    d.ihave = [];
	                    d.iwant = [];
	                    d.graft = [];
	                    d.prune = [];
	                }
	                if (m.ihave && m.ihave.length) {
	                    d.ihave = [];
	                    for (var j = 0; j < m.ihave.length; ++j) {
	                        d.ihave[j] = $root.RPC.ControlIHave.toObject(m.ihave[j], o);
	                    }
	                }
	                if (m.iwant && m.iwant.length) {
	                    d.iwant = [];
	                    for (var j = 0; j < m.iwant.length; ++j) {
	                        d.iwant[j] = $root.RPC.ControlIWant.toObject(m.iwant[j], o);
	                    }
	                }
	                if (m.graft && m.graft.length) {
	                    d.graft = [];
	                    for (var j = 0; j < m.graft.length; ++j) {
	                        d.graft[j] = $root.RPC.ControlGraft.toObject(m.graft[j], o);
	                    }
	                }
	                if (m.prune && m.prune.length) {
	                    d.prune = [];
	                    for (var j = 0; j < m.prune.length; ++j) {
	                        d.prune[j] = $root.RPC.ControlPrune.toObject(m.prune[j], o);
	                    }
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlMessage to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlMessage
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlMessage.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlMessage;
	        })();

	        RPC.ControlIHave = (function() {

	            /**
	             * Properties of a ControlIHave.
	             * @memberof RPC
	             * @interface IControlIHave
	             * @property {string|null} [topicID] ControlIHave topicID
	             * @property {Array.<Uint8Array>|null} [messageIDs] ControlIHave messageIDs
	             */

	            /**
	             * Constructs a new ControlIHave.
	             * @memberof RPC
	             * @classdesc Represents a ControlIHave.
	             * @implements IControlIHave
	             * @constructor
	             * @param {RPC.IControlIHave=} [p] Properties to set
	             */
	            function ControlIHave(p) {
	                this.messageIDs = [];
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlIHave topicID.
	             * @member {string|null|undefined} topicID
	             * @memberof RPC.ControlIHave
	             * @instance
	             */
	            ControlIHave.prototype.topicID = null;

	            /**
	             * ControlIHave messageIDs.
	             * @member {Array.<Uint8Array>} messageIDs
	             * @memberof RPC.ControlIHave
	             * @instance
	             */
	            ControlIHave.prototype.messageIDs = $util.emptyArray;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * ControlIHave _topicID.
	             * @member {"topicID"|undefined} _topicID
	             * @memberof RPC.ControlIHave
	             * @instance
	             */
	            Object.defineProperty(ControlIHave.prototype, "_topicID", {
	                get: $util.oneOfGetter($oneOfFields = ["topicID"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified ControlIHave message. Does not implicitly {@link RPC.ControlIHave.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlIHave
	             * @static
	             * @param {RPC.IControlIHave} m ControlIHave message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlIHave.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.topicID != null && Object.hasOwnProperty.call(m, "topicID"))
	                    w.uint32(10).string(m.topicID);
	                if (m.messageIDs != null && m.messageIDs.length) {
	                    for (var i = 0; i < m.messageIDs.length; ++i)
	                        w.uint32(18).bytes(m.messageIDs[i]);
	                }
	                return w;
	            };

	            /**
	             * Decodes a ControlIHave message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlIHave
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlIHave} ControlIHave
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlIHave.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlIHave();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.topicID = r.string();
	                        break;
	                    case 2:
	                        if (!(m.messageIDs && m.messageIDs.length))
	                            m.messageIDs = [];
	                        m.messageIDs.push(r.bytes());
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlIHave message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlIHave
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlIHave} ControlIHave
	             */
	            ControlIHave.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlIHave)
	                    return d;
	                var m = new $root.RPC.ControlIHave();
	                if (d.topicID != null) {
	                    m.topicID = String(d.topicID);
	                }
	                if (d.messageIDs) {
	                    if (!Array.isArray(d.messageIDs))
	                        throw TypeError(".RPC.ControlIHave.messageIDs: array expected");
	                    m.messageIDs = [];
	                    for (var i = 0; i < d.messageIDs.length; ++i) {
	                        if (typeof d.messageIDs[i] === "string")
	                            $util.base64.decode(d.messageIDs[i], m.messageIDs[i] = $util.newBuffer($util.base64.length(d.messageIDs[i])), 0);
	                        else if (d.messageIDs[i].length)
	                            m.messageIDs[i] = d.messageIDs[i];
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlIHave message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlIHave
	             * @static
	             * @param {RPC.ControlIHave} m ControlIHave
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlIHave.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.arrays || o.defaults) {
	                    d.messageIDs = [];
	                }
	                if (m.topicID != null && m.hasOwnProperty("topicID")) {
	                    d.topicID = m.topicID;
	                    if (o.oneofs)
	                        d._topicID = "topicID";
	                }
	                if (m.messageIDs && m.messageIDs.length) {
	                    d.messageIDs = [];
	                    for (var j = 0; j < m.messageIDs.length; ++j) {
	                        d.messageIDs[j] = o.bytes === String ? $util.base64.encode(m.messageIDs[j], 0, m.messageIDs[j].length) : o.bytes === Array ? Array.prototype.slice.call(m.messageIDs[j]) : m.messageIDs[j];
	                    }
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlIHave to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlIHave
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlIHave.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlIHave;
	        })();

	        RPC.ControlIWant = (function() {

	            /**
	             * Properties of a ControlIWant.
	             * @memberof RPC
	             * @interface IControlIWant
	             * @property {Array.<Uint8Array>|null} [messageIDs] ControlIWant messageIDs
	             */

	            /**
	             * Constructs a new ControlIWant.
	             * @memberof RPC
	             * @classdesc Represents a ControlIWant.
	             * @implements IControlIWant
	             * @constructor
	             * @param {RPC.IControlIWant=} [p] Properties to set
	             */
	            function ControlIWant(p) {
	                this.messageIDs = [];
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlIWant messageIDs.
	             * @member {Array.<Uint8Array>} messageIDs
	             * @memberof RPC.ControlIWant
	             * @instance
	             */
	            ControlIWant.prototype.messageIDs = $util.emptyArray;

	            /**
	             * Encodes the specified ControlIWant message. Does not implicitly {@link RPC.ControlIWant.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlIWant
	             * @static
	             * @param {RPC.IControlIWant} m ControlIWant message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlIWant.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.messageIDs != null && m.messageIDs.length) {
	                    for (var i = 0; i < m.messageIDs.length; ++i)
	                        w.uint32(10).bytes(m.messageIDs[i]);
	                }
	                return w;
	            };

	            /**
	             * Decodes a ControlIWant message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlIWant
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlIWant} ControlIWant
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlIWant.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlIWant();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        if (!(m.messageIDs && m.messageIDs.length))
	                            m.messageIDs = [];
	                        m.messageIDs.push(r.bytes());
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlIWant message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlIWant
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlIWant} ControlIWant
	             */
	            ControlIWant.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlIWant)
	                    return d;
	                var m = new $root.RPC.ControlIWant();
	                if (d.messageIDs) {
	                    if (!Array.isArray(d.messageIDs))
	                        throw TypeError(".RPC.ControlIWant.messageIDs: array expected");
	                    m.messageIDs = [];
	                    for (var i = 0; i < d.messageIDs.length; ++i) {
	                        if (typeof d.messageIDs[i] === "string")
	                            $util.base64.decode(d.messageIDs[i], m.messageIDs[i] = $util.newBuffer($util.base64.length(d.messageIDs[i])), 0);
	                        else if (d.messageIDs[i].length)
	                            m.messageIDs[i] = d.messageIDs[i];
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlIWant message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlIWant
	             * @static
	             * @param {RPC.ControlIWant} m ControlIWant
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlIWant.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.arrays || o.defaults) {
	                    d.messageIDs = [];
	                }
	                if (m.messageIDs && m.messageIDs.length) {
	                    d.messageIDs = [];
	                    for (var j = 0; j < m.messageIDs.length; ++j) {
	                        d.messageIDs[j] = o.bytes === String ? $util.base64.encode(m.messageIDs[j], 0, m.messageIDs[j].length) : o.bytes === Array ? Array.prototype.slice.call(m.messageIDs[j]) : m.messageIDs[j];
	                    }
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlIWant to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlIWant
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlIWant.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlIWant;
	        })();

	        RPC.ControlGraft = (function() {

	            /**
	             * Properties of a ControlGraft.
	             * @memberof RPC
	             * @interface IControlGraft
	             * @property {string|null} [topicID] ControlGraft topicID
	             */

	            /**
	             * Constructs a new ControlGraft.
	             * @memberof RPC
	             * @classdesc Represents a ControlGraft.
	             * @implements IControlGraft
	             * @constructor
	             * @param {RPC.IControlGraft=} [p] Properties to set
	             */
	            function ControlGraft(p) {
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlGraft topicID.
	             * @member {string|null|undefined} topicID
	             * @memberof RPC.ControlGraft
	             * @instance
	             */
	            ControlGraft.prototype.topicID = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * ControlGraft _topicID.
	             * @member {"topicID"|undefined} _topicID
	             * @memberof RPC.ControlGraft
	             * @instance
	             */
	            Object.defineProperty(ControlGraft.prototype, "_topicID", {
	                get: $util.oneOfGetter($oneOfFields = ["topicID"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified ControlGraft message. Does not implicitly {@link RPC.ControlGraft.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlGraft
	             * @static
	             * @param {RPC.IControlGraft} m ControlGraft message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlGraft.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.topicID != null && Object.hasOwnProperty.call(m, "topicID"))
	                    w.uint32(10).string(m.topicID);
	                return w;
	            };

	            /**
	             * Decodes a ControlGraft message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlGraft
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlGraft} ControlGraft
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlGraft.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlGraft();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.topicID = r.string();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlGraft message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlGraft
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlGraft} ControlGraft
	             */
	            ControlGraft.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlGraft)
	                    return d;
	                var m = new $root.RPC.ControlGraft();
	                if (d.topicID != null) {
	                    m.topicID = String(d.topicID);
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlGraft message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlGraft
	             * @static
	             * @param {RPC.ControlGraft} m ControlGraft
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlGraft.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (m.topicID != null && m.hasOwnProperty("topicID")) {
	                    d.topicID = m.topicID;
	                    if (o.oneofs)
	                        d._topicID = "topicID";
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlGraft to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlGraft
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlGraft.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlGraft;
	        })();

	        RPC.ControlPrune = (function() {

	            /**
	             * Properties of a ControlPrune.
	             * @memberof RPC
	             * @interface IControlPrune
	             * @property {string|null} [topicID] ControlPrune topicID
	             * @property {Array.<RPC.IPeerInfo>|null} [peers] ControlPrune peers
	             * @property {number|null} [backoff] ControlPrune backoff
	             */

	            /**
	             * Constructs a new ControlPrune.
	             * @memberof RPC
	             * @classdesc Represents a ControlPrune.
	             * @implements IControlPrune
	             * @constructor
	             * @param {RPC.IControlPrune=} [p] Properties to set
	             */
	            function ControlPrune(p) {
	                this.peers = [];
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlPrune topicID.
	             * @member {string|null|undefined} topicID
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            ControlPrune.prototype.topicID = null;

	            /**
	             * ControlPrune peers.
	             * @member {Array.<RPC.IPeerInfo>} peers
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            ControlPrune.prototype.peers = $util.emptyArray;

	            /**
	             * ControlPrune backoff.
	             * @member {number|null|undefined} backoff
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            ControlPrune.prototype.backoff = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * ControlPrune _topicID.
	             * @member {"topicID"|undefined} _topicID
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            Object.defineProperty(ControlPrune.prototype, "_topicID", {
	                get: $util.oneOfGetter($oneOfFields = ["topicID"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * ControlPrune _backoff.
	             * @member {"backoff"|undefined} _backoff
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            Object.defineProperty(ControlPrune.prototype, "_backoff", {
	                get: $util.oneOfGetter($oneOfFields = ["backoff"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified ControlPrune message. Does not implicitly {@link RPC.ControlPrune.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlPrune
	             * @static
	             * @param {RPC.IControlPrune} m ControlPrune message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlPrune.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.topicID != null && Object.hasOwnProperty.call(m, "topicID"))
	                    w.uint32(10).string(m.topicID);
	                if (m.peers != null && m.peers.length) {
	                    for (var i = 0; i < m.peers.length; ++i)
	                        $root.RPC.PeerInfo.encode(m.peers[i], w.uint32(18).fork()).ldelim();
	                }
	                if (m.backoff != null && Object.hasOwnProperty.call(m, "backoff"))
	                    w.uint32(24).uint64(m.backoff);
	                return w;
	            };

	            /**
	             * Decodes a ControlPrune message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlPrune
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlPrune} ControlPrune
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlPrune.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlPrune();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.topicID = r.string();
	                        break;
	                    case 2:
	                        if (!(m.peers && m.peers.length))
	                            m.peers = [];
	                        m.peers.push($root.RPC.PeerInfo.decode(r, r.uint32()));
	                        break;
	                    case 3:
	                        m.backoff = r.uint64();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlPrune message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlPrune
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlPrune} ControlPrune
	             */
	            ControlPrune.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlPrune)
	                    return d;
	                var m = new $root.RPC.ControlPrune();
	                if (d.topicID != null) {
	                    m.topicID = String(d.topicID);
	                }
	                if (d.peers) {
	                    if (!Array.isArray(d.peers))
	                        throw TypeError(".RPC.ControlPrune.peers: array expected");
	                    m.peers = [];
	                    for (var i = 0; i < d.peers.length; ++i) {
	                        if (typeof d.peers[i] !== "object")
	                            throw TypeError(".RPC.ControlPrune.peers: object expected");
	                        m.peers[i] = $root.RPC.PeerInfo.fromObject(d.peers[i]);
	                    }
	                }
	                if (d.backoff != null) {
	                    if ($util.Long)
	                        (m.backoff = $util.Long.fromValue(d.backoff)).unsigned = true;
	                    else if (typeof d.backoff === "string")
	                        m.backoff = parseInt(d.backoff, 10);
	                    else if (typeof d.backoff === "number")
	                        m.backoff = d.backoff;
	                    else if (typeof d.backoff === "object")
	                        m.backoff = new $util.LongBits(d.backoff.low >>> 0, d.backoff.high >>> 0).toNumber(true);
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlPrune message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlPrune
	             * @static
	             * @param {RPC.ControlPrune} m ControlPrune
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlPrune.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.arrays || o.defaults) {
	                    d.peers = [];
	                }
	                if (m.topicID != null && m.hasOwnProperty("topicID")) {
	                    d.topicID = m.topicID;
	                    if (o.oneofs)
	                        d._topicID = "topicID";
	                }
	                if (m.peers && m.peers.length) {
	                    d.peers = [];
	                    for (var j = 0; j < m.peers.length; ++j) {
	                        d.peers[j] = $root.RPC.PeerInfo.toObject(m.peers[j], o);
	                    }
	                }
	                if (m.backoff != null && m.hasOwnProperty("backoff")) {
	                    if (typeof m.backoff === "number")
	                        d.backoff = o.longs === String ? String(m.backoff) : m.backoff;
	                    else
	                        d.backoff = o.longs === String ? $util.Long.prototype.toString.call(m.backoff) : o.longs === Number ? new $util.LongBits(m.backoff.low >>> 0, m.backoff.high >>> 0).toNumber(true) : m.backoff;
	                    if (o.oneofs)
	                        d._backoff = "backoff";
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlPrune to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlPrune
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlPrune.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlPrune;
	        })();

	        RPC.PeerInfo = (function() {

	            /**
	             * Properties of a PeerInfo.
	             * @memberof RPC
	             * @interface IPeerInfo
	             * @property {Uint8Array|null} [peerID] PeerInfo peerID
	             * @property {Uint8Array|null} [signedPeerRecord] PeerInfo signedPeerRecord
	             */

	            /**
	             * Constructs a new PeerInfo.
	             * @memberof RPC
	             * @classdesc Represents a PeerInfo.
	             * @implements IPeerInfo
	             * @constructor
	             * @param {RPC.IPeerInfo=} [p] Properties to set
	             */
	            function PeerInfo(p) {
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * PeerInfo peerID.
	             * @member {Uint8Array|null|undefined} peerID
	             * @memberof RPC.PeerInfo
	             * @instance
	             */
	            PeerInfo.prototype.peerID = null;

	            /**
	             * PeerInfo signedPeerRecord.
	             * @member {Uint8Array|null|undefined} signedPeerRecord
	             * @memberof RPC.PeerInfo
	             * @instance
	             */
	            PeerInfo.prototype.signedPeerRecord = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * PeerInfo _peerID.
	             * @member {"peerID"|undefined} _peerID
	             * @memberof RPC.PeerInfo
	             * @instance
	             */
	            Object.defineProperty(PeerInfo.prototype, "_peerID", {
	                get: $util.oneOfGetter($oneOfFields = ["peerID"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * PeerInfo _signedPeerRecord.
	             * @member {"signedPeerRecord"|undefined} _signedPeerRecord
	             * @memberof RPC.PeerInfo
	             * @instance
	             */
	            Object.defineProperty(PeerInfo.prototype, "_signedPeerRecord", {
	                get: $util.oneOfGetter($oneOfFields = ["signedPeerRecord"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified PeerInfo message. Does not implicitly {@link RPC.PeerInfo.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.PeerInfo
	             * @static
	             * @param {RPC.IPeerInfo} m PeerInfo message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            PeerInfo.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.peerID != null && Object.hasOwnProperty.call(m, "peerID"))
	                    w.uint32(10).bytes(m.peerID);
	                if (m.signedPeerRecord != null && Object.hasOwnProperty.call(m, "signedPeerRecord"))
	                    w.uint32(18).bytes(m.signedPeerRecord);
	                return w;
	            };

	            /**
	             * Decodes a PeerInfo message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.PeerInfo
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.PeerInfo} PeerInfo
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            PeerInfo.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.PeerInfo();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.peerID = r.bytes();
	                        break;
	                    case 2:
	                        m.signedPeerRecord = r.bytes();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a PeerInfo message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.PeerInfo
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.PeerInfo} PeerInfo
	             */
	            PeerInfo.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.PeerInfo)
	                    return d;
	                var m = new $root.RPC.PeerInfo();
	                if (d.peerID != null) {
	                    if (typeof d.peerID === "string")
	                        $util.base64.decode(d.peerID, m.peerID = $util.newBuffer($util.base64.length(d.peerID)), 0);
	                    else if (d.peerID.length)
	                        m.peerID = d.peerID;
	                }
	                if (d.signedPeerRecord != null) {
	                    if (typeof d.signedPeerRecord === "string")
	                        $util.base64.decode(d.signedPeerRecord, m.signedPeerRecord = $util.newBuffer($util.base64.length(d.signedPeerRecord)), 0);
	                    else if (d.signedPeerRecord.length)
	                        m.signedPeerRecord = d.signedPeerRecord;
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a PeerInfo message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.PeerInfo
	             * @static
	             * @param {RPC.PeerInfo} m PeerInfo
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            PeerInfo.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (m.peerID != null && m.hasOwnProperty("peerID")) {
	                    d.peerID = o.bytes === String ? $util.base64.encode(m.peerID, 0, m.peerID.length) : o.bytes === Array ? Array.prototype.slice.call(m.peerID) : m.peerID;
	                    if (o.oneofs)
	                        d._peerID = "peerID";
	                }
	                if (m.signedPeerRecord != null && m.hasOwnProperty("signedPeerRecord")) {
	                    d.signedPeerRecord = o.bytes === String ? $util.base64.encode(m.signedPeerRecord, 0, m.signedPeerRecord.length) : o.bytes === Array ? Array.prototype.slice.call(m.signedPeerRecord) : m.signedPeerRecord;
	                    if (o.oneofs)
	                        d._signedPeerRecord = "signedPeerRecord";
	                }
	                return d;
	            };

	            /**
	             * Converts this PeerInfo to JSON.
	             * @function toJSON
	             * @memberof RPC.PeerInfo
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            PeerInfo.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return PeerInfo;
	        })();

	        return RPC;
	    })();

	    return $root;
	});
} (rpc$1));

var cjs = rpcExports;

const {RPC} = cjs;

const second = 1000;
const minute$1 = 60 * second;
// Protocol identifiers
const FloodsubID = '/floodsub/1.0.0';
/**
 * The protocol ID for version 1.0.0 of the Gossipsub protocol
 * It is advertised along with GossipsubIDv11 for backwards compatability
 */
const GossipsubIDv10 = '/meshsub/1.0.0';
/**
 * The protocol ID for version 1.1.0 of the Gossipsub protocol
 * See the spec for details about how v1.1.0 compares to v1.0.0:
 * https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md
 */
const GossipsubIDv11 = '/meshsub/1.1.0';
// Overlay parameters
/**
 * GossipsubD sets the optimal degree for a Gossipsub topic mesh. For example, if GossipsubD == 6,
 * each peer will want to have about six peers in their mesh for each topic they're subscribed to.
 * GossipsubD should be set somewhere between GossipsubDlo and GossipsubDhi.
 */
const GossipsubD = 6;
/**
 * GossipsubDlo sets the lower bound on the number of peers we keep in a Gossipsub topic mesh.
 * If we have fewer than GossipsubDlo peers, we will attempt to graft some more into the mesh at
 * the next heartbeat.
 */
const GossipsubDlo = 4;
/**
 * GossipsubDhi sets the upper bound on the number of peers we keep in a Gossipsub topic mesh.
 * If we have more than GossipsubDhi peers, we will select some to prune from the mesh at the next heartbeat.
 */
const GossipsubDhi = 12;
/**
 * GossipsubDscore affects how peers are selected when pruning a mesh due to over subscription.
 * At least GossipsubDscore of the retained peers will be high-scoring, while the remainder are
 * chosen randomly.
 */
const GossipsubDscore = 4;
/**
 * GossipsubDout sets the quota for the number of outbound connections to maintain in a topic mesh.
 * When the mesh is pruned due to over subscription, we make sure that we have outbound connections
 * to at least GossipsubDout of the survivor peers. This prevents sybil attackers from overwhelming
 * our mesh with incoming connections.
 *
 * GossipsubDout must be set below GossipsubDlo, and must not exceed GossipsubD / 2.
 */
const GossipsubDout = 2;
// Gossip parameters
/**
 * GossipsubHistoryLength controls the size of the message cache used for gossip.
 * The message cache will remember messages for GossipsubHistoryLength heartbeats.
 */
const GossipsubHistoryLength = 5;
/**
 * GossipsubHistoryGossip controls how many cached message ids we will advertise in
 * IHAVE gossip messages. When asked for our seen message IDs, we will return
 * only those from the most recent GossipsubHistoryGossip heartbeats. The slack between
 * GossipsubHistoryGossip and GossipsubHistoryLength allows us to avoid advertising messages
 * that will be expired by the time they're requested.
 *
 * GossipsubHistoryGossip must be less than or equal to GossipsubHistoryLength to
 * avoid a runtime panic.
 */
const GossipsubHistoryGossip = 3;
/**
 * GossipsubDlazy affects how many peers we will emit gossip to at each heartbeat.
 * We will send gossip to at least GossipsubDlazy peers outside our mesh. The actual
 * number may be more, depending on GossipsubGossipFactor and how many peers we're
 * connected to.
 */
const GossipsubDlazy = 6;
/**
 * GossipsubGossipFactor affects how many peers we will emit gossip to at each heartbeat.
 * We will send gossip to GossipsubGossipFactor * (total number of non-mesh peers), or
 * GossipsubDlazy, whichever is greater.
 */
const GossipsubGossipFactor = 0.25;
/**
 * GossipsubGossipRetransmission controls how many times we will allow a peer to request
 * the same message id through IWANT gossip before we start ignoring them. This is designed
 * to prevent peers from spamming us with requests and wasting our resources.
 */
const GossipsubGossipRetransmission = 3;
// Heartbeat interval
/**
 * GossipsubHeartbeatInitialDelay is the short delay before the heartbeat timer begins
 * after the router is initialized.
 */
const GossipsubHeartbeatInitialDelay = 100;
/**
 * GossipsubHeartbeatInterval controls the time between heartbeats.
 */
const GossipsubHeartbeatInterval = second;
/**
 * GossipsubFanoutTTL controls how long we keep track of the fanout state. If it's been
 * GossipsubFanoutTTL since we've published to a topic that we're not subscribed to,
 * we'll delete the fanout map for that topic.
 */
const GossipsubFanoutTTL = minute$1;
/**
 * GossipsubPrunePeers controls the number of peers to include in prune Peer eXchange.
 * When we prune a peer that's eligible for PX (has a good score, etc), we will try to
 * send them signed peer records for up to GossipsubPrunePeers other peers that we
 * know of.
 */
const GossipsubPrunePeers = 16;
/**
 * GossipsubPruneBackoff controls the backoff time for pruned peers. This is how long
 * a peer must wait before attempting to graft into our mesh again after being pruned.
 * When pruning a peer, we send them our value of GossipsubPruneBackoff so they know
 * the minimum time to wait. Peers running older versions may not send a backoff time,
 * so if we receive a prune message without one, we will wait at least GossipsubPruneBackoff
 * before attempting to re-graft.
 */
const GossipsubPruneBackoff = minute$1;
/**
 * GossipsubPruneBackoffTicks is the number of heartbeat ticks for attempting to prune expired
 * backoff timers.
 */
const GossipsubPruneBackoffTicks = 15;
/**
 * GossipsubDirectConnectTicks is the number of heartbeat ticks for attempting to reconnect direct peers
 * that are not currently connected.
 */
const GossipsubDirectConnectTicks = 300;
/**
 * GossipsubDirectConnectInitialDelay is the initial delay before opening connections to direct peers
 */
const GossipsubDirectConnectInitialDelay = second;
/**
 * GossipsubOpportunisticGraftTicks is the number of heartbeat ticks for attempting to improve the mesh
 * with opportunistic grafting. Every GossipsubOpportunisticGraftTicks we will attempt to select some
 * high-scoring mesh peers to replace lower-scoring ones, if the median score of our mesh peers falls
 * below a threshold
 */
const GossipsubOpportunisticGraftTicks = 60;
/**
 * GossipsubOpportunisticGraftPeers is the number of peers to opportunistically graft.
 */
const GossipsubOpportunisticGraftPeers = 2;
/**
 * If a GRAFT comes before GossipsubGraftFloodThreshold has elapsed since the last PRUNE,
 * then there is an extra score penalty applied to the peer through P7.
 */
const GossipsubGraftFloodThreshold = 10 * second;
/**
 * GossipsubMaxIHaveLength is the maximum number of messages to include in an IHAVE message.
 * Also controls the maximum number of IHAVE ids we will accept and request with IWANT from a
 * peer within a heartbeat, to protect from IHAVE floods. You should adjust this value from the
 * default if your system is pushing more than 5000 messages in GossipsubHistoryGossip heartbeats;
 * with the defaults this is 1666 messages/s.
 */
const GossipsubMaxIHaveLength = 5000;
/**
 * GossipsubMaxIHaveMessages is the maximum number of IHAVE messages to accept from a peer within a heartbeat.
 */
const GossipsubMaxIHaveMessages = 10;
/**
 * Time to wait for a message requested through IWANT following an IHAVE advertisement.
 * If the message is not received within this window, a broken promise is declared and
 * the router may apply bahavioural penalties.
 */
const GossipsubIWantFollowupTime = 3 * second;
/**
 * Time in milliseconds to keep message ids in the seen cache
 */
const GossipsubSeenTTL = 2 * minute$1;
const TimeCacheDuration = 120 * 1000;
const ERR_TOPIC_VALIDATOR_REJECT = 'ERR_TOPIC_VALIDATOR_REJECT';
const ERR_TOPIC_VALIDATOR_IGNORE = 'ERR_TOPIC_VALIDATOR_IGNORE';
/**
 * If peer score is better than this, we accept messages from this peer
 * within ACCEPT_FROM_WHITELIST_DURATION_MS from the last time computing score.
 **/
const ACCEPT_FROM_WHITELIST_THRESHOLD_SCORE = 0;
/**
 * If peer score >= ACCEPT_FROM_WHITELIST_THRESHOLD_SCORE, accept up to this
 * number of messages from that peer.
 */
const ACCEPT_FROM_WHITELIST_MAX_MESSAGES = 128;
/**
 * If peer score >= ACCEPT_FROM_WHITELIST_THRESHOLD_SCORE, accept messages from
 * this peer up to this time duration.
 */
const ACCEPT_FROM_WHITELIST_DURATION_MS = 1000;
/**
 * The default MeshMessageDeliveriesWindow to be used in metrics.
 */
const DEFAULT_METRIC_MESH_MESSAGE_DELIVERIES_WINDOWS = 1000;

/**
 * Pseudo-randomly shuffles an array
 *
 * Mutates the input array
 */
function shuffle(arr) {
    if (arr.length <= 1) {
        return arr;
    }
    const randInt = () => {
        return Math.floor(Math.random() * Math.floor(arr.length));
    };
    for (let i = 0; i < arr.length; i++) {
        const j = randInt();
        const tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
    return arr;
}

/**
 * Browser friendly function to convert Uint8Array message id to base64 string.
 */
function messageIdToString(msgId) {
    return toString$7(msgId, 'base64');
}

/**
 * On the producing side:
 * * Build messages with the signature, key (from may be enough for certain inlineable public key types), from and seqno fields.
 *
 * On the consuming side:
 * * Enforce the fields to be present, reject otherwise.
 * * Propagate only if the fields are valid and signature can be verified, reject otherwise.
 */
const StrictSign = 'StrictSign';
/**
 * On the producing side:
 * * Build messages without the signature, key, from and seqno fields.
 * * The corresponding protobuf key-value pairs are absent from the marshalled message, not just empty.
 *
 * On the consuming side:
 * * Enforce the fields to be absent, reject otherwise.
 * * Propagate only if the fields are absent, reject otherwise.
 * * A message_id function will not be able to use the above fields, and should instead rely on the data field. A commonplace strategy is to calculate a hash.
 */
const StrictNoSign = 'StrictNoSign';
var TopicValidatorResult;
(function (TopicValidatorResult) {
    /**
     * The message is considered valid, and it should be delivered and forwarded to the network
     */
    TopicValidatorResult["Accept"] = "accept";
    /**
     * The message is neither delivered nor forwarded to the network
     */
    TopicValidatorResult["Ignore"] = "ignore";
    /**
     * The message is considered invalid, and it should be rejected
     */
    TopicValidatorResult["Reject"] = "reject";
})(TopicValidatorResult || (TopicValidatorResult = {}));

var SignaturePolicy;
(function (SignaturePolicy) {
    /**
     * On the producing side:
     * - Build messages with the signature, key (from may be enough for certain inlineable public key types), from and seqno fields.
     *
     * On the consuming side:
     * - Enforce the fields to be present, reject otherwise.
     * - Propagate only if the fields are valid and signature can be verified, reject otherwise.
     */
    SignaturePolicy["StrictSign"] = "StrictSign";
    /**
     * On the producing side:
     * - Build messages without the signature, key, from and seqno fields.
     * - The corresponding protobuf key-value pairs are absent from the marshalled message, not just empty.
     *
     * On the consuming side:
     * - Enforce the fields to be absent, reject otherwise.
     * - Propagate only if the fields are absent, reject otherwise.
     * - A message_id function will not be able to use the above fields, and should instead rely on the data field. A commonplace strategy is to calculate a hash.
     */
    SignaturePolicy["StrictNoSign"] = "StrictNoSign";
})(SignaturePolicy || (SignaturePolicy = {}));
var PublishConfigType;
(function (PublishConfigType) {
    PublishConfigType[PublishConfigType["Signing"] = 0] = "Signing";
    PublishConfigType[PublishConfigType["Anonymous"] = 1] = "Anonymous";
})(PublishConfigType || (PublishConfigType = {}));
var RejectReason;
(function (RejectReason) {
    /**
     * The message failed the configured validation during decoding.
     * SelfOrigin is considered a ValidationError
     */
    RejectReason["Error"] = "error";
    /**
     * Custom validator fn reported status IGNORE.
     */
    RejectReason["Ignore"] = "ignore";
    /**
     * Custom validator fn reported status REJECT.
     */
    RejectReason["Reject"] = "reject";
    /**
     * The peer that sent the message OR the source from field is blacklisted.
     * Causes messages to be ignored, not penalized, neither do score record creation.
     */
    RejectReason["Blacklisted"] = "blacklisted";
})(RejectReason || (RejectReason = {}));
var ValidateError;
(function (ValidateError) {
    /// The message has an invalid signature,
    ValidateError["InvalidSignature"] = "invalid_signature";
    /// The sequence number was the incorrect size
    ValidateError["InvalidSeqno"] = "invalid_seqno";
    /// The PeerId was invalid
    ValidateError["InvalidPeerId"] = "invalid_peerid";
    /// Signature existed when validation has been sent to
    /// [`crate::behaviour::MessageAuthenticity::Anonymous`].
    ValidateError["SignaturePresent"] = "signature_present";
    /// Sequence number existed when validation has been sent to
    /// [`crate::behaviour::MessageAuthenticity::Anonymous`].
    ValidateError["SeqnoPresent"] = "seqno_present";
    /// Message source existed when validation has been sent to
    /// [`crate::behaviour::MessageAuthenticity::Anonymous`].
    ValidateError["FromPresent"] = "from_present";
    /// The data transformation failed.
    ValidateError["TransformFailed"] = "transform_failed";
})(ValidateError || (ValidateError = {}));
var MessageStatus;
(function (MessageStatus) {
    MessageStatus["duplicate"] = "duplicate";
    MessageStatus["invalid"] = "invalid";
    MessageStatus["valid"] = "valid";
})(MessageStatus || (MessageStatus = {}));
/**
 * Typesafe conversion of MessageAcceptance -> RejectReason. TS ensures all values covered
 */
function rejectReasonFromAcceptance(acceptance) {
    switch (acceptance) {
        case TopicValidatorResult.Ignore:
            return RejectReason.Ignore;
        case TopicValidatorResult.Reject:
            return RejectReason.Reject;
    }
}

/**
 * Prepare a PublishConfig object from a PeerId.
 */
async function getPublishConfigFromPeerId(signaturePolicy, peerId) {
    switch (signaturePolicy) {
        case StrictSign: {
            if (!peerId) {
                throw Error('Must provide PeerId');
            }
            if (peerId.privateKey == null) {
                throw Error('Cannot sign message, no private key present');
            }
            if (peerId.publicKey == null) {
                throw Error('Cannot sign message, no public key present');
            }
            // Transform privateKey once at initialization time instead of once per message
            const privateKey = await unmarshalPrivateKey(peerId.privateKey);
            return {
                type: PublishConfigType.Signing,
                author: peerId,
                key: peerId.publicKey,
                privateKey
            };
        }
        case StrictNoSign:
            return {
                type: PublishConfigType.Anonymous
            };
        default:
            throw new Error(`Unknown signature policy "${signaturePolicy}"`);
    }
}

const ERR_INVALID_PEER_SCORE_PARAMS = 'ERR_INVALID_PEER_SCORE_PARAMS';

const defaultPeerScoreParams = {
    topics: {},
    topicScoreCap: 10.0,
    appSpecificScore: () => 0.0,
    appSpecificWeight: 10.0,
    IPColocationFactorWeight: -5.0,
    IPColocationFactorThreshold: 10.0,
    IPColocationFactorWhitelist: new Set(),
    behaviourPenaltyWeight: -10.0,
    behaviourPenaltyThreshold: 0.0,
    behaviourPenaltyDecay: 0.2,
    decayInterval: 1000.0,
    decayToZero: 0.1,
    retainScore: 3600 * 1000
};
const defaultTopicScoreParams = {
    topicWeight: 0.5,
    timeInMeshWeight: 1,
    timeInMeshQuantum: 1,
    timeInMeshCap: 3600,
    firstMessageDeliveriesWeight: 1,
    firstMessageDeliveriesDecay: 0.5,
    firstMessageDeliveriesCap: 2000,
    meshMessageDeliveriesWeight: -1,
    meshMessageDeliveriesDecay: 0.5,
    meshMessageDeliveriesCap: 100,
    meshMessageDeliveriesThreshold: 20,
    meshMessageDeliveriesWindow: 10,
    meshMessageDeliveriesActivation: 5000,
    meshFailurePenaltyWeight: -1,
    meshFailurePenaltyDecay: 0.5,
    invalidMessageDeliveriesWeight: -1,
    invalidMessageDeliveriesDecay: 0.3
};
function createPeerScoreParams(p = {}) {
    return {
        ...defaultPeerScoreParams,
        ...p,
        topics: p.topics
            ? Object.entries(p.topics).reduce((topics, [topic, topicScoreParams]) => {
                topics[topic] = createTopicScoreParams(topicScoreParams);
                return topics;
            }, {})
            : {}
    };
}
function createTopicScoreParams(p = {}) {
    return {
        ...defaultTopicScoreParams,
        ...p
    };
}
// peer score parameter validation
function validatePeerScoreParams(p) {
    for (const [topic, params] of Object.entries(p.topics)) {
        try {
            validateTopicScoreParams(params);
        }
        catch (e) {
            throw new CodeError(`invalid score parameters for topic ${topic}: ${e.message}`, ERR_INVALID_PEER_SCORE_PARAMS);
        }
    }
    // check that the topic score is 0 or something positive
    if (p.topicScoreCap < 0) {
        throw new CodeError('invalid topic score cap; must be positive (or 0 for no cap)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check that we have an app specific score; the weight can be anything (but expected positive)
    if (p.appSpecificScore === null || p.appSpecificScore === undefined) {
        throw new CodeError('missing application specific score function', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check the IP colocation factor
    if (p.IPColocationFactorWeight > 0) {
        throw new CodeError('invalid IPColocationFactorWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.IPColocationFactorWeight !== 0 && p.IPColocationFactorThreshold < 1) {
        throw new CodeError('invalid IPColocationFactorThreshold; must be at least 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check the behaviour penalty
    if (p.behaviourPenaltyWeight > 0) {
        throw new CodeError('invalid BehaviourPenaltyWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.behaviourPenaltyWeight !== 0 && (p.behaviourPenaltyDecay <= 0 || p.behaviourPenaltyDecay >= 1)) {
        throw new CodeError('invalid BehaviourPenaltyDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check the decay parameters
    if (p.decayInterval < 1000) {
        throw new CodeError('invalid DecayInterval; must be at least 1s', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.decayToZero <= 0 || p.decayToZero >= 1) {
        throw new CodeError('invalid DecayToZero; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // no need to check the score retention; a value of 0 means that we don't retain scores
}
function validateTopicScoreParams(p) {
    // make sure we have a sane topic weight
    if (p.topicWeight < 0) {
        throw new CodeError('invalid topic weight; must be >= 0', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P1
    if (p.timeInMeshQuantum === 0) {
        throw new CodeError('invalid TimeInMeshQuantum; must be non zero', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.timeInMeshWeight < 0) {
        throw new CodeError('invalid TimeInMeshWeight; must be positive (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.timeInMeshWeight !== 0 && p.timeInMeshQuantum <= 0) {
        throw new CodeError('invalid TimeInMeshQuantum; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.timeInMeshWeight !== 0 && p.timeInMeshCap <= 0) {
        throw new CodeError('invalid TimeInMeshCap; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P2
    if (p.firstMessageDeliveriesWeight < 0) {
        throw new CodeError('invallid FirstMessageDeliveriesWeight; must be positive (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.firstMessageDeliveriesWeight !== 0 &&
        (p.firstMessageDeliveriesDecay <= 0 || p.firstMessageDeliveriesDecay >= 1)) {
        throw new CodeError('invalid FirstMessageDeliveriesDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.firstMessageDeliveriesWeight !== 0 && p.firstMessageDeliveriesCap <= 0) {
        throw new CodeError('invalid FirstMessageDeliveriesCap; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P3
    if (p.meshMessageDeliveriesWeight > 0) {
        throw new CodeError('invalid MeshMessageDeliveriesWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWeight !== 0 && (p.meshMessageDeliveriesDecay <= 0 || p.meshMessageDeliveriesDecay >= 1)) {
        throw new CodeError('invalid MeshMessageDeliveriesDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWeight !== 0 && p.meshMessageDeliveriesCap <= 0) {
        throw new CodeError('invalid MeshMessageDeliveriesCap; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWeight !== 0 && p.meshMessageDeliveriesThreshold <= 0) {
        throw new CodeError('invalid MeshMessageDeliveriesThreshold; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWindow < 0) {
        throw new CodeError('invalid MeshMessageDeliveriesWindow; must be non-negative', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWeight !== 0 && p.meshMessageDeliveriesActivation < 1000) {
        throw new CodeError('invalid MeshMessageDeliveriesActivation; must be at least 1s', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P3b
    if (p.meshFailurePenaltyWeight > 0) {
        throw new CodeError('invalid MeshFailurePenaltyWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshFailurePenaltyWeight !== 0 && (p.meshFailurePenaltyDecay <= 0 || p.meshFailurePenaltyDecay >= 1)) {
        throw new CodeError('invalid MeshFailurePenaltyDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P4
    if (p.invalidMessageDeliveriesWeight > 0) {
        throw new CodeError('invalid InvalidMessageDeliveriesWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.invalidMessageDeliveriesDecay <= 0 || p.invalidMessageDeliveriesDecay >= 1) {
        throw new CodeError('invalid InvalidMessageDeliveriesDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
}

const defaultPeerScoreThresholds = {
    gossipThreshold: -10,
    publishThreshold: -50,
    graylistThreshold: -80,
    acceptPXThreshold: 10,
    opportunisticGraftThreshold: 20
};
function createPeerScoreThresholds(p = {}) {
    return {
        ...defaultPeerScoreThresholds,
        ...p
    };
}

function computeScore(peer, pstats, params, peerIPs) {
    let score = 0;
    // topic stores
    Object.entries(pstats.topics).forEach(([topic, tstats]) => {
        // the topic parameters
        const topicParams = params.topics[topic];
        if (topicParams === undefined) {
            // we are not scoring this topic
            return;
        }
        let topicScore = 0;
        // P1: time in Mesh
        if (tstats.inMesh) {
            let p1 = tstats.meshTime / topicParams.timeInMeshQuantum;
            if (p1 > topicParams.timeInMeshCap) {
                p1 = topicParams.timeInMeshCap;
            }
            topicScore += p1 * topicParams.timeInMeshWeight;
        }
        // P2: first message deliveries
        let p2 = tstats.firstMessageDeliveries;
        if (p2 > topicParams.firstMessageDeliveriesCap) {
            p2 = topicParams.firstMessageDeliveriesCap;
        }
        topicScore += p2 * topicParams.firstMessageDeliveriesWeight;
        // P3: mesh message deliveries
        if (tstats.meshMessageDeliveriesActive &&
            tstats.meshMessageDeliveries < topicParams.meshMessageDeliveriesThreshold) {
            const deficit = topicParams.meshMessageDeliveriesThreshold - tstats.meshMessageDeliveries;
            const p3 = deficit * deficit;
            topicScore += p3 * topicParams.meshMessageDeliveriesWeight;
        }
        // P3b:
        // NOTE: the weight of P3b is negative (validated in validateTopicScoreParams) so this detracts
        const p3b = tstats.meshFailurePenalty;
        topicScore += p3b * topicParams.meshFailurePenaltyWeight;
        // P4: invalid messages
        // NOTE: the weight of P4 is negative (validated in validateTopicScoreParams) so this detracts
        const p4 = tstats.invalidMessageDeliveries * tstats.invalidMessageDeliveries;
        topicScore += p4 * topicParams.invalidMessageDeliveriesWeight;
        // update score, mixing with topic weight
        score += topicScore * topicParams.topicWeight;
    });
    // apply the topic score cap, if any
    if (params.topicScoreCap > 0 && score > params.topicScoreCap) {
        score = params.topicScoreCap;
    }
    // P5: application-specific score
    const p5 = params.appSpecificScore(peer);
    score += p5 * params.appSpecificWeight;
    // P6: IP colocation factor
    pstats.knownIPs.forEach((ip) => {
        if (params.IPColocationFactorWhitelist.has(ip)) {
            return;
        }
        // P6 has a cliff (IPColocationFactorThreshold)
        // It's only applied if at least that many peers are connected to us from that source IP addr.
        // It is quadratic, and the weight is negative (validated in validatePeerScoreParams)
        const peersInIP = peerIPs.get(ip);
        const numPeersInIP = peersInIP ? peersInIP.size : 0;
        if (numPeersInIP > params.IPColocationFactorThreshold) {
            const surplus = numPeersInIP - params.IPColocationFactorThreshold;
            const p6 = surplus * surplus;
            score += p6 * params.IPColocationFactorWeight;
        }
    });
    // P7: behavioural pattern penalty
    if (pstats.behaviourPenalty > params.behaviourPenaltyThreshold) {
        const excess = pstats.behaviourPenalty - params.behaviourPenaltyThreshold;
        const p7 = excess * excess;
        score += p7 * params.behaviourPenaltyWeight;
    }
    return score;
}

/**
 * Custom implementation of a double ended queue.
 */
function Denque(array, options) {
  var options = options || {};

  this._head = 0;
  this._tail = 0;
  this._capacity = options.capacity;
  this._capacityMask = 0x3;
  this._list = new Array(4);
  if (Array.isArray(array)) {
    this._fromArray(array);
  }
}

/**
 * -------------
 *  PUBLIC API
 * -------------
 */

/**
 * Returns the item at the specified index from the list.
 * 0 is the first element, 1 is the second, and so on...
 * Elements at negative values are that many from the end: -1 is one before the end
 * (the last element), -2 is two before the end (one before last), etc.
 * @param index
 * @returns {*}
 */
Denque.prototype.peekAt = function peekAt(index) {
  var i = index;
  // expect a number or return undefined
  if ((i !== (i | 0))) {
    return void 0;
  }
  var len = this.size();
  if (i >= len || i < -len) return undefined;
  if (i < 0) i += len;
  i = (this._head + i) & this._capacityMask;
  return this._list[i];
};

/**
 * Alias for peekAt()
 * @param i
 * @returns {*}
 */
Denque.prototype.get = function get(i) {
  return this.peekAt(i);
};

/**
 * Returns the first item in the list without removing it.
 * @returns {*}
 */
Denque.prototype.peek = function peek() {
  if (this._head === this._tail) return undefined;
  return this._list[this._head];
};

/**
 * Alias for peek()
 * @returns {*}
 */
Denque.prototype.peekFront = function peekFront() {
  return this.peek();
};

/**
 * Returns the item that is at the back of the queue without removing it.
 * Uses peekAt(-1)
 */
Denque.prototype.peekBack = function peekBack() {
  return this.peekAt(-1);
};

/**
 * Returns the current length of the queue
 * @return {Number}
 */
Object.defineProperty(Denque.prototype, 'length', {
  get: function length() {
    return this.size();
  }
});

/**
 * Return the number of items on the list, or 0 if empty.
 * @returns {number}
 */
Denque.prototype.size = function size() {
  if (this._head === this._tail) return 0;
  if (this._head < this._tail) return this._tail - this._head;
  else return this._capacityMask + 1 - (this._head - this._tail);
};

/**
 * Add an item at the beginning of the list.
 * @param item
 */
Denque.prototype.unshift = function unshift(item) {
  if (item === undefined) return this.size();
  var len = this._list.length;
  this._head = (this._head - 1 + len) & this._capacityMask;
  this._list[this._head] = item;
  if (this._tail === this._head) this._growArray();
  if (this._capacity && this.size() > this._capacity) this.pop();
  if (this._head < this._tail) return this._tail - this._head;
  else return this._capacityMask + 1 - (this._head - this._tail);
};

/**
 * Remove and return the first item on the list,
 * Returns undefined if the list is empty.
 * @returns {*}
 */
Denque.prototype.shift = function shift() {
  var head = this._head;
  if (head === this._tail) return undefined;
  var item = this._list[head];
  this._list[head] = undefined;
  this._head = (head + 1) & this._capacityMask;
  if (head < 2 && this._tail > 10000 && this._tail <= this._list.length >>> 2) this._shrinkArray();
  return item;
};

/**
 * Add an item to the bottom of the list.
 * @param item
 */
Denque.prototype.push = function push(item) {
  if (item === undefined) return this.size();
  var tail = this._tail;
  this._list[tail] = item;
  this._tail = (tail + 1) & this._capacityMask;
  if (this._tail === this._head) {
    this._growArray();
  }
  if (this._capacity && this.size() > this._capacity) {
    this.shift();
  }
  if (this._head < this._tail) return this._tail - this._head;
  else return this._capacityMask + 1 - (this._head - this._tail);
};

/**
 * Remove and return the last item on the list.
 * Returns undefined if the list is empty.
 * @returns {*}
 */
Denque.prototype.pop = function pop() {
  var tail = this._tail;
  if (tail === this._head) return undefined;
  var len = this._list.length;
  this._tail = (tail - 1 + len) & this._capacityMask;
  var item = this._list[this._tail];
  this._list[this._tail] = undefined;
  if (this._head < 2 && tail > 10000 && tail <= len >>> 2) this._shrinkArray();
  return item;
};

/**
 * Remove and return the item at the specified index from the list.
 * Returns undefined if the list is empty.
 * @param index
 * @returns {*}
 */
Denque.prototype.removeOne = function removeOne(index) {
  var i = index;
  // expect a number or return undefined
  if ((i !== (i | 0))) {
    return void 0;
  }
  if (this._head === this._tail) return void 0;
  var size = this.size();
  var len = this._list.length;
  if (i >= size || i < -size) return void 0;
  if (i < 0) i += size;
  i = (this._head + i) & this._capacityMask;
  var item = this._list[i];
  var k;
  if (index < size / 2) {
    for (k = index; k > 0; k--) {
      this._list[i] = this._list[i = (i - 1 + len) & this._capacityMask];
    }
    this._list[i] = void 0;
    this._head = (this._head + 1 + len) & this._capacityMask;
  } else {
    for (k = size - 1 - index; k > 0; k--) {
      this._list[i] = this._list[i = ( i + 1 + len) & this._capacityMask];
    }
    this._list[i] = void 0;
    this._tail = (this._tail - 1 + len) & this._capacityMask;
  }
  return item;
};

/**
 * Remove number of items from the specified index from the list.
 * Returns array of removed items.
 * Returns undefined if the list is empty.
 * @param index
 * @param count
 * @returns {array}
 */
Denque.prototype.remove = function remove(index, count) {
  var i = index;
  var removed;
  var del_count = count;
  // expect a number or return undefined
  if ((i !== (i | 0))) {
    return void 0;
  }
  if (this._head === this._tail) return void 0;
  var size = this.size();
  var len = this._list.length;
  if (i >= size || i < -size || count < 1) return void 0;
  if (i < 0) i += size;
  if (count === 1 || !count) {
    removed = new Array(1);
    removed[0] = this.removeOne(i);
    return removed;
  }
  if (i === 0 && i + count >= size) {
    removed = this.toArray();
    this.clear();
    return removed;
  }
  if (i + count > size) count = size - i;
  var k;
  removed = new Array(count);
  for (k = 0; k < count; k++) {
    removed[k] = this._list[(this._head + i + k) & this._capacityMask];
  }
  i = (this._head + i) & this._capacityMask;
  if (index + count === size) {
    this._tail = (this._tail - count + len) & this._capacityMask;
    for (k = count; k > 0; k--) {
      this._list[i = (i + 1 + len) & this._capacityMask] = void 0;
    }
    return removed;
  }
  if (index === 0) {
    this._head = (this._head + count + len) & this._capacityMask;
    for (k = count - 1; k > 0; k--) {
      this._list[i = (i + 1 + len) & this._capacityMask] = void 0;
    }
    return removed;
  }
  if (i < size / 2) {
    this._head = (this._head + index + count + len) & this._capacityMask;
    for (k = index; k > 0; k--) {
      this.unshift(this._list[i = (i - 1 + len) & this._capacityMask]);
    }
    i = (this._head - 1 + len) & this._capacityMask;
    while (del_count > 0) {
      this._list[i = (i - 1 + len) & this._capacityMask] = void 0;
      del_count--;
    }
    if (index < 0) this._tail = i;
  } else {
    this._tail = i;
    i = (i + count + len) & this._capacityMask;
    for (k = size - (count + index); k > 0; k--) {
      this.push(this._list[i++]);
    }
    i = this._tail;
    while (del_count > 0) {
      this._list[i = (i + 1 + len) & this._capacityMask] = void 0;
      del_count--;
    }
  }
  if (this._head < 2 && this._tail > 10000 && this._tail <= len >>> 2) this._shrinkArray();
  return removed;
};

/**
 * Native splice implementation.
 * Remove number of items from the specified index from the list and/or add new elements.
 * Returns array of removed items or empty array if count == 0.
 * Returns undefined if the list is empty.
 *
 * @param index
 * @param count
 * @param {...*} [elements]
 * @returns {array}
 */
Denque.prototype.splice = function splice(index, count) {
  var i = index;
  // expect a number or return undefined
  if ((i !== (i | 0))) {
    return void 0;
  }
  var size = this.size();
  if (i < 0) i += size;
  if (i > size) return void 0;
  if (arguments.length > 2) {
    var k;
    var temp;
    var removed;
    var arg_len = arguments.length;
    var len = this._list.length;
    var arguments_index = 2;
    if (!size || i < size / 2) {
      temp = new Array(i);
      for (k = 0; k < i; k++) {
        temp[k] = this._list[(this._head + k) & this._capacityMask];
      }
      if (count === 0) {
        removed = [];
        if (i > 0) {
          this._head = (this._head + i + len) & this._capacityMask;
        }
      } else {
        removed = this.remove(i, count);
        this._head = (this._head + i + len) & this._capacityMask;
      }
      while (arg_len > arguments_index) {
        this.unshift(arguments[--arg_len]);
      }
      for (k = i; k > 0; k--) {
        this.unshift(temp[k - 1]);
      }
    } else {
      temp = new Array(size - (i + count));
      var leng = temp.length;
      for (k = 0; k < leng; k++) {
        temp[k] = this._list[(this._head + i + count + k) & this._capacityMask];
      }
      if (count === 0) {
        removed = [];
        if (i != size) {
          this._tail = (this._head + i + len) & this._capacityMask;
        }
      } else {
        removed = this.remove(i, count);
        this._tail = (this._tail - leng + len) & this._capacityMask;
      }
      while (arguments_index < arg_len) {
        this.push(arguments[arguments_index++]);
      }
      for (k = 0; k < leng; k++) {
        this.push(temp[k]);
      }
    }
    return removed;
  } else {
    return this.remove(i, count);
  }
};

/**
 * Soft clear - does not reset capacity.
 */
Denque.prototype.clear = function clear() {
  this._head = 0;
  this._tail = 0;
};

/**
 * Returns true or false whether the list is empty.
 * @returns {boolean}
 */
Denque.prototype.isEmpty = function isEmpty() {
  return this._head === this._tail;
};

/**
 * Returns an array of all queue items.
 * @returns {Array}
 */
Denque.prototype.toArray = function toArray() {
  return this._copyArray(false);
};

/**
 * -------------
 *   INTERNALS
 * -------------
 */

/**
 * Fills the queue with items from an array
 * For use in the constructor
 * @param array
 * @private
 */
Denque.prototype._fromArray = function _fromArray(array) {
  for (var i = 0; i < array.length; i++) this.push(array[i]);
};

/**
 *
 * @param fullCopy
 * @returns {Array}
 * @private
 */
Denque.prototype._copyArray = function _copyArray(fullCopy) {
  var newArray = [];
  var list = this._list;
  var len = list.length;
  var i;
  if (fullCopy || this._head > this._tail) {
    for (i = this._head; i < len; i++) newArray.push(list[i]);
    for (i = 0; i < this._tail; i++) newArray.push(list[i]);
  } else {
    for (i = this._head; i < this._tail; i++) newArray.push(list[i]);
  }
  return newArray;
};

/**
 * Grows the internal list array.
 * @private
 */
Denque.prototype._growArray = function _growArray() {
  if (this._head) {
    // copy existing data, head to end, then beginning to tail.
    this._list = this._copyArray(true);
    this._head = 0;
  }

  // head is at 0 and array is now full, safe to extend
  this._tail = this._list.length;

  this._list.length <<= 1;
  this._capacityMask = (this._capacityMask << 1) | 1;
};

/**
 * Shrinks the internal list array.
 * @private
 */
Denque.prototype._shrinkArray = function _shrinkArray() {
  this._list.length >>>= 1;
  this._capacityMask >>>= 1;
};


var denque = Denque;

var DeliveryRecordStatus;
(function (DeliveryRecordStatus) {
    /**
     * we don't know (yet) if the message is valid
     */
    DeliveryRecordStatus[DeliveryRecordStatus["unknown"] = 0] = "unknown";
    /**
     * we know the message is valid
     */
    DeliveryRecordStatus[DeliveryRecordStatus["valid"] = 1] = "valid";
    /**
     * we know the message is invalid
     */
    DeliveryRecordStatus[DeliveryRecordStatus["invalid"] = 2] = "invalid";
    /**
     * we were instructed by the validator to ignore the message
     */
    DeliveryRecordStatus[DeliveryRecordStatus["ignored"] = 3] = "ignored";
})(DeliveryRecordStatus || (DeliveryRecordStatus = {}));
/**
 * Map of canonical message ID to DeliveryRecord
 *
 * Maintains an internal queue for efficient gc of old messages
 */
class MessageDeliveries {
    constructor() {
        this.records = new Map();
        this.queue = new denque();
    }
    ensureRecord(msgIdStr) {
        let drec = this.records.get(msgIdStr);
        if (drec) {
            return drec;
        }
        // record doesn't exist yet
        // create record
        drec = {
            status: DeliveryRecordStatus.unknown,
            firstSeen: Date.now(),
            validated: 0,
            peers: new Set()
        };
        this.records.set(msgIdStr, drec);
        // and add msgId to the queue
        const entry = {
            msgId: msgIdStr,
            expire: Date.now() + TimeCacheDuration
        };
        this.queue.push(entry);
        return drec;
    }
    gc() {
        const now = Date.now();
        // queue is sorted by expiry time
        // remove expired messages, remove from queue until first un-expired message found
        let head = this.queue.peekFront();
        while (head && head.expire < now) {
            this.records.delete(head.msgId);
            this.queue.shift();
            head = this.queue.peekFront();
        }
    }
    clear() {
        this.records.clear();
        this.queue.clear();
    }
}

/**
 * Exclude up to `ineed` items from a set if item meets condition `cond`
 */
function removeItemsFromSet(superSet, ineed, cond = () => true) {
    const subset = new Set();
    if (ineed <= 0)
        return subset;
    for (const id of superSet) {
        if (subset.size >= ineed)
            break;
        if (cond(id)) {
            subset.add(id);
            superSet.delete(id);
        }
    }
    return subset;
}
/**
 * Exclude up to `ineed` items from a set
 */
function removeFirstNItemsFromSet(superSet, ineed) {
    return removeItemsFromSet(superSet, ineed, () => true);
}
class MapDef extends Map {
    constructor(getDefault) {
        super();
        this.getDefault = getDefault;
    }
    getOrDefault(key) {
        let value = super.get(key);
        if (value === undefined) {
            value = this.getDefault();
            this.set(key, value);
        }
        return value;
    }
}

const log$I = logger$2('libp2p:gossipsub:score');
class PeerScore {
    constructor(params, metrics, opts) {
        this.params = params;
        this.metrics = metrics;
        /**
         * Per-peer stats for score calculation
         */
        this.peerStats = new Map();
        /**
         * IP colocation tracking; maps IP => set of peers.
         */
        this.peerIPs = new MapDef(() => new Set());
        /**
         * Cache score up to decayInterval if topic stats are unchanged.
         */
        this.scoreCache = new Map();
        /**
         * Recent message delivery timing/participants
         */
        this.deliveryRecords = new MessageDeliveries();
        validatePeerScoreParams(params);
        this.scoreCacheValidityMs = opts.scoreCacheValidityMs;
        this.computeScore = opts.computeScore ?? computeScore;
    }
    get size() {
        return this.peerStats.size;
    }
    /**
     * Start PeerScore instance
     */
    start() {
        if (this._backgroundInterval) {
            log$I('Peer score already running');
            return;
        }
        this._backgroundInterval = setInterval(() => this.background(), this.params.decayInterval);
        log$I('started');
    }
    /**
     * Stop PeerScore instance
     */
    stop() {
        if (!this._backgroundInterval) {
            log$I('Peer score already stopped');
            return;
        }
        clearInterval(this._backgroundInterval);
        delete this._backgroundInterval;
        this.peerIPs.clear();
        this.peerStats.clear();
        this.deliveryRecords.clear();
        log$I('stopped');
    }
    /**
     * Periodic maintenance
     */
    background() {
        this.refreshScores();
        this.deliveryRecords.gc();
    }
    dumpPeerScoreStats() {
        return Object.fromEntries(Array.from(this.peerStats.entries()).map(([peer, stats]) => [peer, stats]));
    }
    /**
     * Decays scores, and purges score records for disconnected peers once their expiry has elapsed.
     */
    refreshScores() {
        const now = Date.now();
        const decayToZero = this.params.decayToZero;
        this.peerStats.forEach((pstats, id) => {
            if (!pstats.connected) {
                // has the retention period expired?
                if (now > pstats.expire) {
                    // yes, throw it away (but clean up the IP tracking first)
                    this.removeIPsForPeer(id, pstats.knownIPs);
                    this.peerStats.delete(id);
                    this.scoreCache.delete(id);
                }
                // we don't decay retained scores, as the peer is not active.
                // this way the peer cannot reset a negative score by simply disconnecting and reconnecting,
                // unless the retention period has elapsed.
                // similarly, a well behaved peer does not lose its score by getting disconnected.
                return;
            }
            Object.entries(pstats.topics).forEach(([topic, tstats]) => {
                const tparams = this.params.topics[topic];
                if (tparams === undefined) {
                    // we are not scoring this topic
                    // should be unreachable, we only add scored topics to pstats
                    return;
                }
                // decay counters
                tstats.firstMessageDeliveries *= tparams.firstMessageDeliveriesDecay;
                if (tstats.firstMessageDeliveries < decayToZero) {
                    tstats.firstMessageDeliveries = 0;
                }
                tstats.meshMessageDeliveries *= tparams.meshMessageDeliveriesDecay;
                if (tstats.meshMessageDeliveries < decayToZero) {
                    tstats.meshMessageDeliveries = 0;
                }
                tstats.meshFailurePenalty *= tparams.meshFailurePenaltyDecay;
                if (tstats.meshFailurePenalty < decayToZero) {
                    tstats.meshFailurePenalty = 0;
                }
                tstats.invalidMessageDeliveries *= tparams.invalidMessageDeliveriesDecay;
                if (tstats.invalidMessageDeliveries < decayToZero) {
                    tstats.invalidMessageDeliveries = 0;
                }
                // update mesh time and activate mesh message delivery parameter if need be
                if (tstats.inMesh) {
                    tstats.meshTime = now - tstats.graftTime;
                    if (tstats.meshTime > tparams.meshMessageDeliveriesActivation) {
                        tstats.meshMessageDeliveriesActive = true;
                    }
                }
            });
            // decay P7 counter
            pstats.behaviourPenalty *= this.params.behaviourPenaltyDecay;
            if (pstats.behaviourPenalty < decayToZero) {
                pstats.behaviourPenalty = 0;
            }
        });
    }
    /**
     * Return the score for a peer
     */
    score(id) {
        this.metrics?.scoreFnCalls.inc();
        const pstats = this.peerStats.get(id);
        if (!pstats) {
            return 0;
        }
        const now = Date.now();
        const cacheEntry = this.scoreCache.get(id);
        // Found cached score within validity period
        if (cacheEntry && cacheEntry.cacheUntil > now) {
            return cacheEntry.score;
        }
        this.metrics?.scoreFnRuns.inc();
        const score = this.computeScore(id, pstats, this.params, this.peerIPs);
        const cacheUntil = now + this.scoreCacheValidityMs;
        if (cacheEntry) {
            this.metrics?.scoreCachedDelta.observe(Math.abs(score - cacheEntry.score));
            cacheEntry.score = score;
            cacheEntry.cacheUntil = cacheUntil;
        }
        else {
            this.scoreCache.set(id, { score, cacheUntil });
        }
        return score;
    }
    /**
     * Apply a behavioural penalty to a peer
     */
    addPenalty(id, penalty, penaltyLabel) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            pstats.behaviourPenalty += penalty;
            this.metrics?.onScorePenalty(penaltyLabel);
        }
    }
    addPeer(id) {
        // create peer stats (not including topic stats for each topic to be scored)
        // topic stats will be added as needed
        const pstats = {
            connected: true,
            expire: 0,
            topics: {},
            knownIPs: new Set(),
            behaviourPenalty: 0
        };
        this.peerStats.set(id, pstats);
    }
    /** Adds a new IP to a peer, if the peer is not known the update is ignored */
    addIP(id, ip) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            pstats.knownIPs.add(ip);
        }
        this.peerIPs.getOrDefault(ip).add(id);
    }
    /** Remove peer association with IP */
    removeIP(id, ip) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            pstats.knownIPs.delete(ip);
        }
        const peersWithIP = this.peerIPs.get(ip);
        if (peersWithIP) {
            peersWithIP.delete(id);
            if (peersWithIP.size === 0) {
                this.peerIPs.delete(ip);
            }
        }
    }
    removePeer(id) {
        const pstats = this.peerStats.get(id);
        if (!pstats) {
            return;
        }
        // decide whether to retain the score; this currently only retains non-positive scores
        // to dissuade attacks on the score function.
        if (this.score(id) > 0) {
            this.removeIPsForPeer(id, pstats.knownIPs);
            this.peerStats.delete(id);
            return;
        }
        // furthermore, when we decide to retain the score, the firstMessageDelivery counters are
        // reset to 0 and mesh delivery penalties applied.
        Object.entries(pstats.topics).forEach(([topic, tstats]) => {
            tstats.firstMessageDeliveries = 0;
            const threshold = this.params.topics[topic].meshMessageDeliveriesThreshold;
            if (tstats.inMesh && tstats.meshMessageDeliveriesActive && tstats.meshMessageDeliveries < threshold) {
                const deficit = threshold - tstats.meshMessageDeliveries;
                tstats.meshFailurePenalty += deficit * deficit;
            }
            tstats.inMesh = false;
            tstats.meshMessageDeliveriesActive = false;
        });
        pstats.connected = false;
        pstats.expire = Date.now() + this.params.retainScore;
    }
    /** Handles scoring functionality as a peer GRAFTs to a topic. */
    graft(id, topic) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats) {
                // if we are scoring the topic, update the mesh status.
                tstats.inMesh = true;
                tstats.graftTime = Date.now();
                tstats.meshTime = 0;
                tstats.meshMessageDeliveriesActive = false;
            }
        }
    }
    /** Handles scoring functionality as a peer PRUNEs from a topic. */
    prune(id, topic) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats) {
                // sticky mesh delivery rate failure penalty
                const threshold = this.params.topics[topic].meshMessageDeliveriesThreshold;
                if (tstats.meshMessageDeliveriesActive && tstats.meshMessageDeliveries < threshold) {
                    const deficit = threshold - tstats.meshMessageDeliveries;
                    tstats.meshFailurePenalty += deficit * deficit;
                }
                tstats.meshMessageDeliveriesActive = false;
                tstats.inMesh = false;
                // TODO: Consider clearing score cache on important penalties
                // this.scoreCache.delete(id)
            }
        }
    }
    validateMessage(msgIdStr) {
        this.deliveryRecords.ensureRecord(msgIdStr);
    }
    deliverMessage(from, msgIdStr, topic) {
        this.markFirstMessageDelivery(from, topic);
        const drec = this.deliveryRecords.ensureRecord(msgIdStr);
        const now = Date.now();
        // defensive check that this is the first delivery trace -- delivery status should be unknown
        if (drec.status !== DeliveryRecordStatus.unknown) {
            log$I('unexpected delivery: message from %s was first seen %s ago and has delivery status %s', from, now - drec.firstSeen, DeliveryRecordStatus[drec.status]);
            return;
        }
        // mark the message as valid and reward mesh peers that have already forwarded it to us
        drec.status = DeliveryRecordStatus.valid;
        drec.validated = now;
        drec.peers.forEach((p) => {
            // this check is to make sure a peer can't send us a message twice and get a double count
            // if it is a first delivery.
            if (p !== from.toString()) {
                this.markDuplicateMessageDelivery(p, topic);
            }
        });
    }
    /**
     * Similar to `rejectMessage` except does not require the message id or reason for an invalid message.
     */
    rejectInvalidMessage(from, topic) {
        this.markInvalidMessageDelivery(from, topic);
    }
    rejectMessage(from, msgIdStr, topic, reason) {
        switch (reason) {
            // these messages are not tracked, but the peer is penalized as they are invalid
            case RejectReason.Error:
                this.markInvalidMessageDelivery(from, topic);
                return;
            // we ignore those messages, so do nothing.
            case RejectReason.Blacklisted:
                return;
            // the rest are handled after record creation
        }
        const drec = this.deliveryRecords.ensureRecord(msgIdStr);
        // defensive check that this is the first rejection -- delivery status should be unknown
        if (drec.status !== DeliveryRecordStatus.unknown) {
            log$I('unexpected rejection: message from %s was first seen %s ago and has delivery status %d', from, Date.now() - drec.firstSeen, DeliveryRecordStatus[drec.status]);
            return;
        }
        if (reason === RejectReason.Ignore) {
            // we were explicitly instructed by the validator to ignore the message but not penalize the peer
            drec.status = DeliveryRecordStatus.ignored;
            drec.peers.clear();
            return;
        }
        // mark the message as invalid and penalize peers that have already forwarded it.
        drec.status = DeliveryRecordStatus.invalid;
        this.markInvalidMessageDelivery(from, topic);
        drec.peers.forEach((p) => {
            this.markInvalidMessageDelivery(p, topic);
        });
        // release the delivery time tracking map to free some memory early
        drec.peers.clear();
    }
    duplicateMessage(from, msgIdStr, topic) {
        const drec = this.deliveryRecords.ensureRecord(msgIdStr);
        if (drec.peers.has(from)) {
            // we have already seen this duplicate
            return;
        }
        switch (drec.status) {
            case DeliveryRecordStatus.unknown:
                // the message is being validated; track the peer delivery and wait for
                // the Deliver/Reject/Ignore notification.
                drec.peers.add(from);
                break;
            case DeliveryRecordStatus.valid:
                // mark the peer delivery time to only count a duplicate delivery once.
                drec.peers.add(from);
                this.markDuplicateMessageDelivery(from, topic, drec.validated);
                break;
            case DeliveryRecordStatus.invalid:
                // we no longer track delivery time
                this.markInvalidMessageDelivery(from, topic);
                break;
            case DeliveryRecordStatus.ignored:
                // the message was ignored; do nothing (we don't know if it was valid)
                break;
        }
    }
    /**
     * Increments the "invalid message deliveries" counter for all scored topics the message is published in.
     */
    markInvalidMessageDelivery(from, topic) {
        const pstats = this.peerStats.get(from);
        if (pstats) {
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats) {
                tstats.invalidMessageDeliveries += 1;
            }
        }
    }
    /**
     * Increments the "first message deliveries" counter for all scored topics the message is published in,
     * as well as the "mesh message deliveries" counter, if the peer is in the mesh for the topic.
     * Messages already known (with the seenCache) are counted with markDuplicateMessageDelivery()
     */
    markFirstMessageDelivery(from, topic) {
        const pstats = this.peerStats.get(from);
        if (pstats) {
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats) {
                let cap = this.params.topics[topic].firstMessageDeliveriesCap;
                tstats.firstMessageDeliveries = Math.min(cap, tstats.firstMessageDeliveries + 1);
                if (tstats.inMesh) {
                    cap = this.params.topics[topic].meshMessageDeliveriesCap;
                    tstats.meshMessageDeliveries = Math.min(cap, tstats.meshMessageDeliveries + 1);
                }
            }
        }
    }
    /**
     * Increments the "mesh message deliveries" counter for messages we've seen before,
     * as long the message was received within the P3 window.
     */
    markDuplicateMessageDelivery(from, topic, validatedTime) {
        const pstats = this.peerStats.get(from);
        if (pstats) {
            const now = validatedTime !== undefined ? Date.now() : 0;
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats && tstats.inMesh) {
                const tparams = this.params.topics[topic];
                // check against the mesh delivery window -- if the validated time is passed as 0, then
                // the message was received before we finished validation and thus falls within the mesh
                // delivery window.
                if (validatedTime !== undefined) {
                    const deliveryDelayMs = now - validatedTime;
                    const isLateDelivery = deliveryDelayMs > tparams.meshMessageDeliveriesWindow;
                    this.metrics?.onDuplicateMsgDelivery(topic, deliveryDelayMs, isLateDelivery);
                    if (isLateDelivery) {
                        return;
                    }
                }
                const cap = tparams.meshMessageDeliveriesCap;
                tstats.meshMessageDeliveries = Math.min(cap, tstats.meshMessageDeliveries + 1);
            }
        }
    }
    /**
     * Removes an IP list from the tracking list for a peer.
     */
    removeIPsForPeer(id, ipsToRemove) {
        for (const ipToRemove of ipsToRemove) {
            const peerSet = this.peerIPs.get(ipToRemove);
            if (peerSet) {
                peerSet.delete(id);
                if (peerSet.size === 0) {
                    this.peerIPs.delete(ipToRemove);
                }
            }
        }
    }
    /**
     * Returns topic stats if they exist, otherwise if the supplied parameters score the
     * topic, inserts the default stats and returns a reference to those. If neither apply, returns None.
     */
    getPtopicStats(pstats, topic) {
        let topicStats = pstats.topics[topic];
        if (topicStats !== undefined) {
            return topicStats;
        }
        if (this.params.topics[topic] !== undefined) {
            topicStats = {
                inMesh: false,
                graftTime: 0,
                meshTime: 0,
                firstMessageDeliveries: 0,
                meshMessageDeliveries: 0,
                meshMessageDeliveriesActive: false,
                meshFailurePenalty: 0,
                invalidMessageDeliveries: 0
            };
            pstats.topics[topic] = topicStats;
            return topicStats;
        }
        return null;
    }
}

/**
 * IWantTracer is an internal tracer that tracks IWANT requests in order to penalize
 * peers who don't follow up on IWANT requests after an IHAVE advertisement.
 * The tracking of promises is probabilistic to avoid using too much memory.
 *
 * Note: Do not confuse these 'promises' with JS Promise objects.
 * These 'promises' are merely expectations of a peer's behavior.
 */
class IWantTracer {
    constructor(gossipsubIWantFollowupMs, msgIdToStrFn, metrics) {
        this.gossipsubIWantFollowupMs = gossipsubIWantFollowupMs;
        this.msgIdToStrFn = msgIdToStrFn;
        this.metrics = metrics;
        /**
         * Promises to deliver a message
         * Map per message id, per peer, promise expiration time
         */
        this.promises = new Map();
        /**
         * First request time by msgId. Used for metrics to track expire times.
         * Necessary to know if peers are actually breaking promises or simply sending them a bit later
         */
        this.requestMsByMsg = new Map();
        this.requestMsByMsgExpire = 10 * gossipsubIWantFollowupMs;
    }
    get size() {
        return this.promises.size;
    }
    get requestMsByMsgSize() {
        return this.requestMsByMsg.size;
    }
    /**
     * Track a promise to deliver a message from a list of msgIds we are requesting
     */
    addPromise(from, msgIds) {
        // pick msgId randomly from the list
        const ix = Math.floor(Math.random() * msgIds.length);
        const msgId = msgIds[ix];
        const msgIdStr = this.msgIdToStrFn(msgId);
        let expireByPeer = this.promises.get(msgIdStr);
        if (!expireByPeer) {
            expireByPeer = new Map();
            this.promises.set(msgIdStr, expireByPeer);
        }
        const now = Date.now();
        // If a promise for this message id and peer already exists we don't update the expiry
        if (!expireByPeer.has(from)) {
            expireByPeer.set(from, now + this.gossipsubIWantFollowupMs);
            if (this.metrics) {
                this.metrics.iwantPromiseStarted.inc(1);
                if (!this.requestMsByMsg.has(msgIdStr)) {
                    this.requestMsByMsg.set(msgIdStr, now);
                }
            }
        }
    }
    /**
     * Returns the number of broken promises for each peer who didn't follow up on an IWANT request.
     *
     * This should be called not too often relative to the expire times, since it iterates over the whole data.
     */
    getBrokenPromises() {
        const now = Date.now();
        const result = new Map();
        let brokenPromises = 0;
        this.promises.forEach((expireByPeer, msgId) => {
            expireByPeer.forEach((expire, p) => {
                // the promise has been broken
                if (expire < now) {
                    // add 1 to result
                    result.set(p, (result.get(p) ?? 0) + 1);
                    // delete from tracked promises
                    expireByPeer.delete(p);
                    // for metrics
                    brokenPromises++;
                }
            });
            // clean up empty promises for a msgId
            if (!expireByPeer.size) {
                this.promises.delete(msgId);
            }
        });
        this.metrics?.iwantPromiseBroken.inc(brokenPromises);
        return result;
    }
    /**
     * Someone delivered a message, stop tracking promises for it
     */
    deliverMessage(msgIdStr, isDuplicate = false) {
        this.trackMessage(msgIdStr);
        const expireByPeer = this.promises.get(msgIdStr);
        // Expired promise, check requestMsByMsg
        if (expireByPeer) {
            this.promises.delete(msgIdStr);
            if (this.metrics) {
                this.metrics.iwantPromiseResolved.inc(1);
                if (isDuplicate)
                    this.metrics.iwantPromiseResolvedFromDuplicate.inc(1);
                this.metrics.iwantPromiseResolvedPeers.inc(expireByPeer.size);
            }
        }
    }
    /**
     * A message got rejected, so we can stop tracking promises and let the score penalty apply from invalid message delivery,
     * unless its an obviously invalid message.
     */
    rejectMessage(msgIdStr, reason) {
        this.trackMessage(msgIdStr);
        // A message got rejected, so we can stop tracking promises and let the score penalty apply.
        // With the expection of obvious invalid messages
        switch (reason) {
            case RejectReason.Error:
                return;
        }
        this.promises.delete(msgIdStr);
    }
    clear() {
        this.promises.clear();
    }
    prune() {
        const maxMs = Date.now() - this.requestMsByMsgExpire;
        let count = 0;
        for (const [k, v] of this.requestMsByMsg.entries()) {
            if (v < maxMs) {
                // messages that stay too long in the requestMsByMsg map, delete
                this.requestMsByMsg.delete(k);
                count++;
            }
            else {
                // recent messages, keep them
                // sort by insertion order
                break;
            }
        }
        this.metrics?.iwantMessagePruned.inc(count);
    }
    trackMessage(msgIdStr) {
        if (this.metrics) {
            const requestMs = this.requestMsByMsg.get(msgIdStr);
            if (requestMs !== undefined) {
                this.metrics.iwantPromiseDeliveryTime.observe((Date.now() - requestMs) / 1000);
                this.requestMsByMsg.delete(msgIdStr);
            }
        }
    }
}

/**
 * This is similar to https://github.com/daviddias/time-cache/blob/master/src/index.js
 * for our own need, we don't use lodash throttle to improve performance.
 * This gives 4x - 5x performance gain compared to npm TimeCache
 */
class SimpleTimeCache {
    constructor(opts) {
        this.entries = new Map();
        this.validityMs = opts.validityMs;
        // allow negative validityMs so that this does not cache anything, spec test compliance.spec.js
        // sends duplicate messages and expect peer to receive all. Application likely uses positive validityMs
    }
    get size() {
        return this.entries.size;
    }
    /** Returns true if there was a key collision and the entry is dropped */
    put(key, value) {
        if (this.entries.has(key)) {
            // Key collisions break insertion order in the entries cache, which break prune logic.
            // prune relies on each iterated entry to have strictly ascending validUntilMs, else it
            // won't prune expired entries and SimpleTimeCache will grow unexpectedly.
            // As of Oct 2022 NodeJS v16, inserting the same key twice with different value does not
            // change the key position in the iterator stream. A unit test asserts this behaviour.
            return true;
        }
        this.entries.set(key, { value, validUntilMs: Date.now() + this.validityMs });
        return false;
    }
    prune() {
        const now = Date.now();
        for (const [k, v] of this.entries.entries()) {
            if (v.validUntilMs < now) {
                this.entries.delete(k);
            }
            else {
                // Entries are inserted with strictly ascending validUntilMs.
                // Stop early to save iterations
                break;
            }
        }
    }
    has(key) {
        return this.entries.has(key);
    }
    get(key) {
        const value = this.entries.get(key);
        return value && value.validUntilMs >= Date.now() ? value.value : undefined;
    }
    clear() {
        this.entries.clear();
    }
}

var MessageSource;
(function (MessageSource) {
    MessageSource["forward"] = "forward";
    MessageSource["publish"] = "publish";
})(MessageSource || (MessageSource = {}));
var InclusionReason;
(function (InclusionReason) {
    /** Peer was a fanaout peer. */
    InclusionReason["Fanout"] = "fanout";
    /** Included from random selection. */
    InclusionReason["Random"] = "random";
    /** Peer subscribed. */
    InclusionReason["Subscribed"] = "subscribed";
    /** On heartbeat, peer was included to fill the outbound quota. */
    InclusionReason["Outbound"] = "outbound";
    /** On heartbeat, not enough peers in mesh */
    InclusionReason["NotEnough"] = "not_enough";
    /** On heartbeat opportunistic grafting due to low mesh score */
    InclusionReason["Opportunistic"] = "opportunistic";
})(InclusionReason || (InclusionReason = {}));
/// Reasons why a peer was removed from the mesh.
var ChurnReason;
(function (ChurnReason) {
    /// Peer disconnected.
    ChurnReason["Dc"] = "disconnected";
    /// Peer had a bad score.
    ChurnReason["BadScore"] = "bad_score";
    /// Peer sent a PRUNE.
    ChurnReason["Prune"] = "prune";
    /// Peer unsubscribed.
    ChurnReason["Unsub"] = "unsubscribed";
    /// Too many peers.
    ChurnReason["Excess"] = "excess";
})(ChurnReason || (ChurnReason = {}));
/// Kinds of reasons a peer's score has been penalized
var ScorePenalty;
(function (ScorePenalty) {
    /// A peer grafted before waiting the back-off time.
    ScorePenalty["GraftBackoff"] = "graft_backoff";
    /// A Peer did not respond to an IWANT request in time.
    ScorePenalty["BrokenPromise"] = "broken_promise";
    /// A Peer did not send enough messages as expected.
    ScorePenalty["MessageDeficit"] = "message_deficit";
    /// Too many peers under one IP address.
    ScorePenalty["IPColocation"] = "IP_colocation";
})(ScorePenalty || (ScorePenalty = {}));
var IHaveIgnoreReason;
(function (IHaveIgnoreReason) {
    IHaveIgnoreReason["LowScore"] = "low_score";
    IHaveIgnoreReason["MaxIhave"] = "max_ihave";
    IHaveIgnoreReason["MaxIasked"] = "max_iasked";
})(IHaveIgnoreReason || (IHaveIgnoreReason = {}));
var ScoreThreshold;
(function (ScoreThreshold) {
    ScoreThreshold["graylist"] = "graylist";
    ScoreThreshold["publish"] = "publish";
    ScoreThreshold["gossip"] = "gossip";
    ScoreThreshold["mesh"] = "mesh";
})(ScoreThreshold || (ScoreThreshold = {}));
/**
 * A collection of metrics used throughout the Gossipsub behaviour.
 */
// eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types
function getMetrics(register, topicStrToLabel, opts) {
    // Using function style instead of class to prevent having to re-declare all MetricsPrometheus types.
    return {
        /* Metrics for static config */
        protocolsEnabled: register.gauge({
            name: 'gossipsub_protocol',
            help: 'Status of enabled protocols',
            labelNames: ['protocol']
        }),
        /* Metrics per known topic */
        /** Status of our subscription to this topic. This metric allows analyzing other topic metrics
         *  filtered by our current subscription status.
         *  = rust-libp2p `topic_subscription_status` */
        topicSubscriptionStatus: register.gauge({
            name: 'gossipsub_topic_subscription_status',
            help: 'Status of our subscription to this topic',
            labelNames: ['topicStr']
        }),
        /** Number of peers subscribed to each topic. This allows us to analyze a topic's behaviour
         * regardless of our subscription status. */
        topicPeersCount: register.gauge({
            name: 'gossipsub_topic_peer_count',
            help: 'Number of peers subscribed to each topic',
            labelNames: ['topicStr']
        }),
        /* Metrics regarding mesh state */
        /** Number of peers in our mesh. This metric should be updated with the count of peers for a
         *  topic in the mesh regardless of inclusion and churn events.
         *  = rust-libp2p `mesh_peer_counts` */
        meshPeerCounts: register.gauge({
            name: 'gossipsub_mesh_peer_count',
            help: 'Number of peers in our mesh',
            labelNames: ['topicStr']
        }),
        /** Number of times we include peers in a topic mesh for different reasons.
         *  = rust-libp2p `mesh_peer_inclusion_events` */
        meshPeerInclusionEvents: register.gauge({
            name: 'gossipsub_mesh_peer_inclusion_events_total',
            help: 'Number of times we include peers in a topic mesh for different reasons',
            labelNames: ['topic', 'reason']
        }),
        /** Number of times we remove peers in a topic mesh for different reasons.
         *  = rust-libp2p `mesh_peer_churn_events` */
        meshPeerChurnEvents: register.gauge({
            name: 'gossipsub_peer_churn_events_total',
            help: 'Number of times we remove peers in a topic mesh for different reasons',
            labelNames: ['topic', 'reason']
        }),
        /* General Metrics */
        /** Gossipsub supports floodsub, gossipsub v1.0 and gossipsub v1.1. Peers are classified based
         *  on which protocol they support. This metric keeps track of the number of peers that are
         *  connected of each type. */
        peersPerProtocol: register.gauge({
            name: 'gossipsub_peers_per_protocol_count',
            help: 'Peers connected for each topic',
            labelNames: ['protocol']
        }),
        /** The time it takes to complete one iteration of the heartbeat. */
        heartbeatDuration: register.histogram({
            name: 'gossipsub_heartbeat_duration_seconds',
            help: 'The time it takes to complete one iteration of the heartbeat',
            // Should take <10ms, over 1s it's a huge issue that needs debugging, since a heartbeat will be cancelled
            buckets: [0.01, 0.1, 1]
        }),
        /** Heartbeat run took longer than heartbeat interval so next is skipped */
        heartbeatSkipped: register.gauge({
            name: 'gossipsub_heartbeat_skipped',
            help: 'Heartbeat run took longer than heartbeat interval so next is skipped'
        }),
        /** Message validation results for each topic.
         *  Invalid == Reject?
         *  = rust-libp2p `invalid_messages`, `accepted_messages`, `ignored_messages`, `rejected_messages` */
        asyncValidationResult: register.gauge({
            name: 'gossipsub_async_validation_result_total',
            help: 'Message validation result for each topic',
            labelNames: ['topic', 'acceptance']
        }),
        /** When the user validates a message, it tries to re propagate it to its mesh peers. If the
         *  message expires from the memcache before it can be validated, we count this a cache miss
         *  and it is an indicator that the memcache size should be increased.
         *  = rust-libp2p `mcache_misses` */
        asyncValidationMcacheHit: register.gauge({
            name: 'gossipsub_async_validation_mcache_hit_total',
            help: 'Async validation result reported by the user layer',
            labelNames: ['hit']
        }),
        // RPC outgoing. Track byte length + data structure sizes
        rpcRecvBytes: register.gauge({ name: 'gossipsub_rpc_recv_bytes_total', help: 'RPC recv' }),
        rpcRecvCount: register.gauge({ name: 'gossipsub_rpc_recv_count_total', help: 'RPC recv' }),
        rpcRecvSubscription: register.gauge({ name: 'gossipsub_rpc_recv_subscription_total', help: 'RPC recv' }),
        rpcRecvMessage: register.gauge({ name: 'gossipsub_rpc_recv_message_total', help: 'RPC recv' }),
        rpcRecvControl: register.gauge({ name: 'gossipsub_rpc_recv_control_total', help: 'RPC recv' }),
        rpcRecvIHave: register.gauge({ name: 'gossipsub_rpc_recv_ihave_total', help: 'RPC recv' }),
        rpcRecvIWant: register.gauge({ name: 'gossipsub_rpc_recv_iwant_total', help: 'RPC recv' }),
        rpcRecvGraft: register.gauge({ name: 'gossipsub_rpc_recv_graft_total', help: 'RPC recv' }),
        rpcRecvPrune: register.gauge({ name: 'gossipsub_rpc_recv_prune_total', help: 'RPC recv' }),
        /** Total count of RPC dropped because acceptFrom() == false */
        rpcRecvNotAccepted: register.gauge({
            name: 'gossipsub_rpc_rcv_not_accepted_total',
            help: 'Total count of RPC dropped because acceptFrom() == false'
        }),
        // RPC incoming. Track byte length + data structure sizes
        rpcSentBytes: register.gauge({ name: 'gossipsub_rpc_sent_bytes_total', help: 'RPC sent' }),
        rpcSentCount: register.gauge({ name: 'gossipsub_rpc_sent_count_total', help: 'RPC sent' }),
        rpcSentSubscription: register.gauge({ name: 'gossipsub_rpc_sent_subscription_total', help: 'RPC sent' }),
        rpcSentMessage: register.gauge({ name: 'gossipsub_rpc_sent_message_total', help: 'RPC sent' }),
        rpcSentControl: register.gauge({ name: 'gossipsub_rpc_sent_control_total', help: 'RPC sent' }),
        rpcSentIHave: register.gauge({ name: 'gossipsub_rpc_sent_ihave_total', help: 'RPC sent' }),
        rpcSentIWant: register.gauge({ name: 'gossipsub_rpc_sent_iwant_total', help: 'RPC sent' }),
        rpcSentGraft: register.gauge({ name: 'gossipsub_rpc_sent_graft_total', help: 'RPC sent' }),
        rpcSentPrune: register.gauge({ name: 'gossipsub_rpc_sent_prune_total', help: 'RPC sent' }),
        // publish message. Track peers sent to and bytes
        /** Total count of msg published by topic */
        msgPublishCount: register.gauge({
            name: 'gossipsub_msg_publish_count_total',
            help: 'Total count of msg published by topic',
            labelNames: ['topic']
        }),
        /** Total count of peers that we publish a msg to */
        msgPublishPeers: register.gauge({
            name: 'gossipsub_msg_publish_peers_total',
            help: 'Total count of peers that we publish a msg to',
            labelNames: ['topic']
        }),
        /** Total count of peers (by group) that we publish a msg to */
        // NOTE: Do not use 'group' label since it's a generic already used by Prometheus to group instances
        msgPublishPeersByGroup: register.gauge({
            name: 'gossipsub_msg_publish_peers_by_group',
            help: 'Total count of peers (by group) that we publish a msg to',
            labelNames: ['topic', 'peerGroup']
        }),
        /** Total count of msg publish data.length bytes */
        msgPublishBytes: register.gauge({
            name: 'gossipsub_msg_publish_bytes_total',
            help: 'Total count of msg publish data.length bytes',
            labelNames: ['topic']
        }),
        /** Total count of msg forwarded by topic */
        msgForwardCount: register.gauge({
            name: 'gossipsub_msg_forward_count_total',
            help: 'Total count of msg forwarded by topic',
            labelNames: ['topic']
        }),
        /** Total count of peers that we forward a msg to */
        msgForwardPeers: register.gauge({
            name: 'gossipsub_msg_forward_peers_total',
            help: 'Total count of peers that we forward a msg to',
            labelNames: ['topic']
        }),
        /** Total count of recv msgs before any validation */
        msgReceivedPreValidation: register.gauge({
            name: 'gossipsub_msg_received_prevalidation_total',
            help: 'Total count of recv msgs before any validation',
            labelNames: ['topic']
        }),
        /** Tracks distribution of recv msgs by duplicate, invalid, valid */
        msgReceivedStatus: register.gauge({
            name: 'gossipsub_msg_received_status_total',
            help: 'Tracks distribution of recv msgs by duplicate, invalid, valid',
            labelNames: ['topic', 'status']
        }),
        /** Tracks specific reason of invalid */
        msgReceivedInvalid: register.gauge({
            name: 'gossipsub_msg_received_invalid_total',
            help: 'Tracks specific reason of invalid',
            labelNames: ['topic', 'error']
        }),
        /** Track duplicate message delivery time */
        duplicateMsgDeliveryDelay: register.histogram({
            name: 'gossisub_duplicate_msg_delivery_delay_seconds',
            help: 'Time since the 1st duplicated message validated',
            labelNames: ['topic'],
            buckets: [
                0.25 * opts.maxMeshMessageDeliveriesWindowSec,
                0.5 * opts.maxMeshMessageDeliveriesWindowSec,
                1 * opts.maxMeshMessageDeliveriesWindowSec,
                2 * opts.maxMeshMessageDeliveriesWindowSec,
                4 * opts.maxMeshMessageDeliveriesWindowSec
            ]
        }),
        /** Total count of late msg delivery total by topic */
        duplicateMsgLateDelivery: register.gauge({
            name: 'gossisub_duplicate_msg_late_delivery_total',
            help: 'Total count of late duplicate message delivery by topic, which triggers P3 penalty',
            labelNames: ['topic']
        }),
        duplicateMsgIgnored: register.gauge({
            name: 'gossisub_ignored_published_duplicate_msgs_total',
            help: 'Total count of published duplicate message ignored by topic',
            labelNames: ['topic']
        }),
        /* Metrics related to scoring */
        /** Total times score() is called */
        scoreFnCalls: register.gauge({
            name: 'gossipsub_score_fn_calls_total',
            help: 'Total times score() is called'
        }),
        /** Total times score() call actually computed computeScore(), no cache */
        scoreFnRuns: register.gauge({
            name: 'gossipsub_score_fn_runs_total',
            help: 'Total times score() call actually computed computeScore(), no cache'
        }),
        scoreCachedDelta: register.histogram({
            name: 'gossipsub_score_cache_delta',
            help: 'Delta of score between cached values that expired',
            buckets: [10, 100, 1000]
        }),
        /** Current count of peers by score threshold */
        peersByScoreThreshold: register.gauge({
            name: 'gossipsub_peers_by_score_threshold_count',
            help: 'Current count of peers by score threshold',
            labelNames: ['threshold']
        }),
        score: register.avgMinMax({
            name: 'gossipsub_score',
            help: 'Avg min max of gossip scores',
            labelNames: ['topic', 'p']
        }),
        /** Separate score weights */
        scoreWeights: register.avgMinMax({
            name: 'gossipsub_score_weights',
            help: 'Separate score weights',
            labelNames: ['topic', 'p']
        }),
        /** Histogram of the scores for each mesh topic. */
        // TODO: Not implemented
        scorePerMesh: register.avgMinMax({
            name: 'gossipsub_score_per_mesh',
            help: 'Histogram of the scores for each mesh topic',
            labelNames: ['topic']
        }),
        /** A counter of the kind of penalties being applied to peers. */
        // TODO: Not fully implemented
        scoringPenalties: register.gauge({
            name: 'gossipsub_scoring_penalties_total',
            help: 'A counter of the kind of penalties being applied to peers',
            labelNames: ['penalty']
        }),
        behaviourPenalty: register.histogram({
            name: 'gossipsub_peer_stat_behaviour_penalty',
            help: 'Current peer stat behaviour_penalty at each scrape',
            buckets: [
                0.25 * opts.behaviourPenaltyThreshold,
                0.5 * opts.behaviourPenaltyThreshold,
                1 * opts.behaviourPenaltyThreshold,
                2 * opts.behaviourPenaltyThreshold,
                4 * opts.behaviourPenaltyThreshold
            ]
        }),
        // TODO:
        // - iasked per peer (on heartbeat)
        // - when promise is resolved, track messages from promises
        /** Total received IHAVE messages that we ignore for some reason */
        ihaveRcvIgnored: register.gauge({
            name: 'gossipsub_ihave_rcv_ignored_total',
            help: 'Total received IHAVE messages that we ignore for some reason',
            labelNames: ['reason']
        }),
        /** Total received IHAVE messages by topic */
        ihaveRcvMsgids: register.gauge({
            name: 'gossipsub_ihave_rcv_msgids_total',
            help: 'Total received IHAVE messages by topic',
            labelNames: ['topic']
        }),
        /** Total messages per topic we don't have. Not actual requests.
         *  The number of times we have decided that an IWANT control message is required for this
         *  topic. A very high metric might indicate an underperforming network.
         *  = rust-libp2p `topic_iwant_msgs` */
        ihaveRcvNotSeenMsgids: register.gauge({
            name: 'gossipsub_ihave_rcv_not_seen_msgids_total',
            help: 'Total messages per topic we do not have, not actual requests',
            labelNames: ['topic']
        }),
        /** Total received IWANT messages by topic */
        iwantRcvMsgids: register.gauge({
            name: 'gossipsub_iwant_rcv_msgids_total',
            help: 'Total received IWANT messages by topic',
            labelNames: ['topic']
        }),
        /** Total requested messageIDs that we don't have */
        iwantRcvDonthaveMsgids: register.gauge({
            name: 'gossipsub_iwant_rcv_dont_have_msgids_total',
            help: 'Total requested messageIDs that we do not have'
        }),
        iwantPromiseStarted: register.gauge({
            name: 'gossipsub_iwant_promise_sent_total',
            help: 'Total count of started IWANT promises'
        }),
        /** Total count of resolved IWANT promises */
        iwantPromiseResolved: register.gauge({
            name: 'gossipsub_iwant_promise_resolved_total',
            help: 'Total count of resolved IWANT promises'
        }),
        /** Total count of resolved IWANT promises from duplicate messages */
        iwantPromiseResolvedFromDuplicate: register.gauge({
            name: 'gossipsub_iwant_promise_resolved_from_duplicate_total',
            help: 'Total count of resolved IWANT promises from duplicate messages'
        }),
        /** Total count of peers we have asked IWANT promises that are resolved */
        iwantPromiseResolvedPeers: register.gauge({
            name: 'gossipsub_iwant_promise_resolved_peers',
            help: 'Total count of peers we have asked IWANT promises that are resolved'
        }),
        iwantPromiseBroken: register.gauge({
            name: 'gossipsub_iwant_promise_broken',
            help: 'Total count of broken IWANT promises'
        }),
        iwantMessagePruned: register.gauge({
            name: 'gossipsub_iwant_message_pruned',
            help: 'Total count of pruned IWANT messages'
        }),
        /** Histogram of delivery time of resolved IWANT promises */
        iwantPromiseDeliveryTime: register.histogram({
            name: 'gossipsub_iwant_promise_delivery_seconds',
            help: 'Histogram of delivery time of resolved IWANT promises',
            buckets: [
                0.5 * opts.gossipPromiseExpireSec,
                1 * opts.gossipPromiseExpireSec,
                2 * opts.gossipPromiseExpireSec,
                4 * opts.gossipPromiseExpireSec
            ]
        }),
        /* Data structure sizes */
        /** Unbounded cache sizes */
        cacheSize: register.gauge({
            name: 'gossipsub_cache_size',
            help: 'Unbounded cache sizes',
            labelNames: ['cache']
        }),
        /** Current mcache msg count */
        mcacheSize: register.gauge({
            name: 'gossipsub_mcache_size',
            help: 'Current mcache msg count'
        }),
        mcacheNotValidatedCount: register.gauge({
            name: 'gossipsub_mcache_not_validated_count',
            help: 'Current mcache msg count not validated'
        }),
        fastMsgIdCacheCollision: register.gauge({
            name: 'gossipsub_fastmsgid_cache_collision_total',
            help: 'Total count of key collisions on fastmsgid cache put'
        }),
        newConnectionCount: register.gauge({
            name: 'gossipsub_new_connection_total',
            help: 'Total new connection by status',
            labelNames: ['status']
        }),
        topicStrToLabel: topicStrToLabel,
        toTopic(topicStr) {
            return this.topicStrToLabel.get(topicStr) ?? topicStr;
        },
        /** We joined a topic */
        onJoin(topicStr) {
            this.topicSubscriptionStatus.set({ topicStr }, 1);
            this.meshPeerCounts.set({ topicStr }, 0); // Reset count
        },
        /** We left a topic */
        onLeave(topicStr) {
            this.topicSubscriptionStatus.set({ topicStr }, 0);
            this.meshPeerCounts.set({ topicStr }, 0); // Reset count
        },
        /** Register the inclusion of peers in our mesh due to some reason. */
        onAddToMesh(topicStr, reason, count) {
            const topic = this.toTopic(topicStr);
            this.meshPeerInclusionEvents.inc({ topic, reason }, count);
        },
        /** Register the removal of peers in our mesh due to some reason */
        // - remove_peer_from_mesh()
        // - heartbeat() Churn::BadScore
        // - heartbeat() Churn::Excess
        // - on_disconnect() Churn::Ds
        onRemoveFromMesh(topicStr, reason, count) {
            const topic = this.toTopic(topicStr);
            this.meshPeerChurnEvents.inc({ topic, reason }, count);
        },
        onReportValidationMcacheHit(hit) {
            this.asyncValidationMcacheHit.inc({ hit: hit ? 'hit' : 'miss' });
        },
        onReportValidation(topicStr, acceptance) {
            const topic = this.toTopic(topicStr);
            this.asyncValidationResult.inc({ topic: topic, acceptance });
        },
        /**
         * - in handle_graft() Penalty::GraftBackoff
         * - in apply_iwant_penalties() Penalty::BrokenPromise
         * - in metric_score() P3 Penalty::MessageDeficit
         * - in metric_score() P6 Penalty::IPColocation
         */
        onScorePenalty(penalty) {
            // Can this be labeled by topic too?
            this.scoringPenalties.inc({ penalty }, 1);
        },
        onIhaveRcv(topicStr, ihave, idonthave) {
            const topic = this.toTopic(topicStr);
            this.ihaveRcvMsgids.inc({ topic }, ihave);
            this.ihaveRcvNotSeenMsgids.inc({ topic }, idonthave);
        },
        onIwantRcv(iwantByTopic, iwantDonthave) {
            for (const [topicStr, iwant] of iwantByTopic) {
                const topic = this.toTopic(topicStr);
                this.iwantRcvMsgids.inc({ topic }, iwant);
            }
            this.iwantRcvDonthaveMsgids.inc(iwantDonthave);
        },
        onForwardMsg(topicStr, tosendCount) {
            const topic = this.toTopic(topicStr);
            this.msgForwardCount.inc({ topic }, 1);
            this.msgForwardPeers.inc({ topic }, tosendCount);
        },
        onPublishMsg(topicStr, tosendGroupCount, tosendCount, dataLen) {
            const topic = this.toTopic(topicStr);
            this.msgPublishCount.inc({ topic }, 1);
            this.msgPublishBytes.inc({ topic }, tosendCount * dataLen);
            this.msgPublishPeers.inc({ topic }, tosendCount);
            this.msgPublishPeersByGroup.inc({ topic, peerGroup: 'direct' }, tosendGroupCount.direct);
            this.msgPublishPeersByGroup.inc({ topic, peerGroup: 'floodsub' }, tosendGroupCount.floodsub);
            this.msgPublishPeersByGroup.inc({ topic, peerGroup: 'mesh' }, tosendGroupCount.mesh);
            this.msgPublishPeersByGroup.inc({ topic, peerGroup: 'fanout' }, tosendGroupCount.fanout);
        },
        onMsgRecvPreValidation(topicStr) {
            const topic = this.toTopic(topicStr);
            this.msgReceivedPreValidation.inc({ topic }, 1);
        },
        onMsgRecvResult(topicStr, status) {
            const topic = this.toTopic(topicStr);
            this.msgReceivedStatus.inc({ topic, status });
        },
        onMsgRecvInvalid(topicStr, reason) {
            const topic = this.toTopic(topicStr);
            const error = reason.reason === RejectReason.Error ? reason.error : reason.reason;
            this.msgReceivedInvalid.inc({ topic, error }, 1);
        },
        onDuplicateMsgDelivery(topicStr, deliveryDelayMs, isLateDelivery) {
            this.duplicateMsgDeliveryDelay.observe(deliveryDelayMs / 1000);
            if (isLateDelivery) {
                const topic = this.toTopic(topicStr);
                this.duplicateMsgLateDelivery.inc({ topic }, 1);
            }
        },
        onPublishDuplicateMsg(topicStr) {
            const topic = this.toTopic(topicStr);
            this.duplicateMsgIgnored.inc({ topic }, 1);
        },
        onRpcRecv(rpc, rpcBytes) {
            this.rpcRecvBytes.inc(rpcBytes);
            this.rpcRecvCount.inc(1);
            if (rpc.subscriptions)
                this.rpcRecvSubscription.inc(rpc.subscriptions.length);
            if (rpc.messages)
                this.rpcRecvMessage.inc(rpc.messages.length);
            if (rpc.control) {
                this.rpcRecvControl.inc(1);
                if (rpc.control.ihave)
                    this.rpcRecvIHave.inc(rpc.control.ihave.length);
                if (rpc.control.iwant)
                    this.rpcRecvIWant.inc(rpc.control.iwant.length);
                if (rpc.control.graft)
                    this.rpcRecvGraft.inc(rpc.control.graft.length);
                if (rpc.control.prune)
                    this.rpcRecvPrune.inc(rpc.control.prune.length);
            }
        },
        onRpcSent(rpc, rpcBytes) {
            this.rpcSentBytes.inc(rpcBytes);
            this.rpcSentCount.inc(1);
            if (rpc.subscriptions)
                this.rpcSentSubscription.inc(rpc.subscriptions.length);
            if (rpc.messages)
                this.rpcSentMessage.inc(rpc.messages.length);
            if (rpc.control) {
                const ihave = rpc.control.ihave?.length ?? 0;
                const iwant = rpc.control.iwant?.length ?? 0;
                const graft = rpc.control.graft?.length ?? 0;
                const prune = rpc.control.prune?.length ?? 0;
                if (ihave > 0)
                    this.rpcSentIHave.inc(ihave);
                if (iwant > 0)
                    this.rpcSentIWant.inc(iwant);
                if (graft > 0)
                    this.rpcSentGraft.inc(graft);
                if (prune > 0)
                    this.rpcSentPrune.inc(prune);
                if (ihave > 0 || iwant > 0 || graft > 0 || prune > 0)
                    this.rpcSentControl.inc(1);
            }
        },
        registerScores(scores, scoreThresholds) {
            let graylist = 0;
            let publish = 0;
            let gossip = 0;
            let mesh = 0;
            for (const score of scores) {
                if (score >= scoreThresholds.graylistThreshold)
                    graylist++;
                if (score >= scoreThresholds.publishThreshold)
                    publish++;
                if (score >= scoreThresholds.gossipThreshold)
                    gossip++;
                if (score >= 0)
                    mesh++;
            }
            this.peersByScoreThreshold.set({ threshold: ScoreThreshold.graylist }, graylist);
            this.peersByScoreThreshold.set({ threshold: ScoreThreshold.publish }, publish);
            this.peersByScoreThreshold.set({ threshold: ScoreThreshold.gossip }, gossip);
            this.peersByScoreThreshold.set({ threshold: ScoreThreshold.mesh }, mesh);
            // Register full score too
            this.score.set(scores);
        },
        registerScoreWeights(sw) {
            for (const [topic, wsTopic] of sw.byTopic) {
                this.scoreWeights.set({ topic, p: 'p1' }, wsTopic.p1w);
                this.scoreWeights.set({ topic, p: 'p2' }, wsTopic.p2w);
                this.scoreWeights.set({ topic, p: 'p3' }, wsTopic.p3w);
                this.scoreWeights.set({ topic, p: 'p3b' }, wsTopic.p3bw);
                this.scoreWeights.set({ topic, p: 'p4' }, wsTopic.p4w);
            }
            this.scoreWeights.set({ p: 'p5' }, sw.p5w);
            this.scoreWeights.set({ p: 'p6' }, sw.p6w);
            this.scoreWeights.set({ p: 'p7' }, sw.p7w);
        },
        registerScorePerMesh(mesh, scoreByPeer) {
            const peersPerTopicLabel = new Map();
            mesh.forEach((peers, topicStr) => {
                // Aggregate by known topicLabel or throw to 'unknown'. This prevent too high cardinality
                const topicLabel = this.topicStrToLabel.get(topicStr) ?? 'unknown';
                let peersInMesh = peersPerTopicLabel.get(topicLabel);
                if (!peersInMesh) {
                    peersInMesh = new Set();
                    peersPerTopicLabel.set(topicLabel, peersInMesh);
                }
                peers.forEach((p) => peersInMesh?.add(p));
            });
            for (const [topic, peers] of peersPerTopicLabel) {
                const meshScores = [];
                peers.forEach((peer) => {
                    meshScores.push(scoreByPeer.get(peer) ?? 0);
                });
                this.scorePerMesh.set({ topic }, meshScores);
            }
        }
    };
}

// @ts-expect-error types are missing
/**
 * Maps an IPFS hash name to its node-forge equivalent.
 *
 * See https://github.com/multiformats/multihash/blob/master/hashtable.csv
 *
 * @private
 */
const hashName = {
    sha1: 'sha1',
    'sha2-256': 'sha256',
    'sha2-512': 'sha512'
};
/**
 * Computes the Password-Based Key Derivation Function 2.
 */
function pbkdf2(password, salt, iterations, keySize, hash) {
    if (hash !== 'sha1' && hash !== 'sha2-256' && hash !== 'sha2-512') {
        const types = Object.keys(hashName).join(' / ');
        throw new CodeError(`Hash '${hash}' is unknown or not supported. Must be ${types}`, 'ERR_UNSUPPORTED_HASH_TYPE');
    }
    const hasher = hashName[hash];
    const dek = pbkdf2$1(password, salt, iterations, keySize, hasher);
    return utilExports.encode64(dek, null);
}

const SignPrefix = fromString$2('libp2p-pubsub:');
async function buildRawMessage(publishConfig, topic, originalData, transformedData) {
    switch (publishConfig.type) {
        case PublishConfigType.Signing: {
            const rpcMsg = {
                from: publishConfig.author.toBytes(),
                data: transformedData,
                seqno: randomBytes(8),
                topic,
                signature: undefined,
                key: undefined // Exclude key field for signing
            };
            // Get the message in bytes, and prepend with the pubsub prefix
            // the signature is over the bytes "libp2p-pubsub:<protobuf-message>"
            const bytes = concat([SignPrefix, RPC.Message.encode(rpcMsg).finish()]);
            rpcMsg.signature = await publishConfig.privateKey.sign(bytes);
            rpcMsg.key = publishConfig.key;
            const msg = {
                type: 'signed',
                from: publishConfig.author,
                data: originalData,
                sequenceNumber: BigInt(`0x${toString$7(rpcMsg.seqno, 'base16')}`),
                topic,
                signature: rpcMsg.signature,
                key: rpcMsg.key
            };
            return {
                raw: rpcMsg,
                msg: msg
            };
        }
        case PublishConfigType.Anonymous: {
            return {
                raw: {
                    from: undefined,
                    data: transformedData,
                    seqno: undefined,
                    topic,
                    signature: undefined,
                    key: undefined
                },
                msg: {
                    type: 'unsigned',
                    data: originalData,
                    topic
                }
            };
        }
    }
}
async function validateToRawMessage(signaturePolicy, msg) {
    // If strict-sign, verify all
    // If anonymous (no-sign), ensure no preven
    switch (signaturePolicy) {
        case StrictNoSign:
            if (msg.signature != null)
                return { valid: false, error: ValidateError.SignaturePresent };
            if (msg.seqno != null)
                return { valid: false, error: ValidateError.SeqnoPresent };
            if (msg.key != null)
                return { valid: false, error: ValidateError.FromPresent };
            return { valid: true, message: { type: 'unsigned', topic: msg.topic, data: msg.data ?? new Uint8Array(0) } };
        case StrictSign: {
            // Verify seqno
            if (msg.seqno == null)
                return { valid: false, error: ValidateError.InvalidSeqno };
            if (msg.seqno.length !== 8) {
                return { valid: false, error: ValidateError.InvalidSeqno };
            }
            if (msg.signature == null)
                return { valid: false, error: ValidateError.InvalidSignature };
            if (msg.from == null)
                return { valid: false, error: ValidateError.InvalidPeerId };
            let fromPeerId;
            try {
                // TODO: Fix PeerId types
                fromPeerId = peerIdFromBytes(msg.from);
            }
            catch (e) {
                return { valid: false, error: ValidateError.InvalidPeerId };
            }
            // - check from defined
            // - transform source to PeerId
            // - parse signature
            // - get .key, else from source
            // - check key == source if present
            // - verify sig
            let publicKey;
            if (msg.key) {
                publicKey = unmarshalPublicKey(msg.key);
                // TODO: Should `fromPeerId.pubKey` be optional?
                if (fromPeerId.publicKey !== undefined && !equals$2(publicKey.bytes, fromPeerId.publicKey)) {
                    return { valid: false, error: ValidateError.InvalidPeerId };
                }
            }
            else {
                if (fromPeerId.publicKey == null) {
                    return { valid: false, error: ValidateError.InvalidPeerId };
                }
                publicKey = unmarshalPublicKey(fromPeerId.publicKey);
            }
            const rpcMsgPreSign = {
                from: msg.from,
                data: msg.data,
                seqno: msg.seqno,
                topic: msg.topic,
                signature: undefined,
                key: undefined // Exclude key field for signing
            };
            // Get the message in bytes, and prepend with the pubsub prefix
            // the signature is over the bytes "libp2p-pubsub:<protobuf-message>"
            const bytes = concat([SignPrefix, RPC.Message.encode(rpcMsgPreSign).finish()]);
            if (!(await publicKey.verify(bytes, msg.signature))) {
                return { valid: false, error: ValidateError.InvalidSignature };
            }
            return {
                valid: true,
                message: {
                    type: 'signed',
                    from: fromPeerId,
                    data: msg.data ?? new Uint8Array(0),
                    sequenceNumber: BigInt(`0x${toString$7(msg.seqno, 'base16')}`),
                    topic: msg.topic,
                    signature: msg.signature,
                    key: msg.key ?? marshalPublicKey(publicKey)
                }
            };
        }
    }
}

/**
 * Generate a message id, based on the `key` and `seqno`
 */
const msgId = (key, seqno) => {
    const seqnoBytes = fromString$2(seqno.toString(16).padStart(16, '0'), 'base16');
    const msgId = new Uint8Array(key.length + seqnoBytes.length);
    msgId.set(key, 0);
    msgId.set(seqnoBytes, key.length);
    return msgId;
};

/**
 * Generate a message id, based on the `key` and `seqno`
 */
function msgIdFnStrictSign(msg) {
    if (msg.type !== 'signed') {
        throw new Error('expected signed message type');
    }
    // Should never happen
    if (msg.sequenceNumber == null)
        throw Error('missing seqno field');
    // TODO: Should use .from here or key?
    return msgId(msg.from.toBytes(), msg.sequenceNumber);
}
/**
 * Generate a message id, based on message `data`
 */
async function msgIdFnStrictNoSign(msg) {
    return await sha256.encode(msg.data);
}

function computeScoreWeights(peer, pstats, params, peerIPs, topicStrToLabel) {
    let score = 0;
    const byTopic = new Map();
    // topic stores
    Object.entries(pstats.topics).forEach(([topic, tstats]) => {
        // the topic parameters
        // Aggregate by known topicLabel or throw to 'unknown'. This prevent too high cardinality
        const topicLabel = topicStrToLabel.get(topic) ?? 'unknown';
        const topicParams = params.topics[topic];
        if (topicParams === undefined) {
            // we are not scoring this topic
            return;
        }
        let topicScores = byTopic.get(topicLabel);
        if (!topicScores) {
            topicScores = {
                p1w: 0,
                p2w: 0,
                p3w: 0,
                p3bw: 0,
                p4w: 0
            };
            byTopic.set(topicLabel, topicScores);
        }
        let p1w = 0;
        let p2w = 0;
        let p3w = 0;
        let p3bw = 0;
        let p4w = 0;
        // P1: time in Mesh
        if (tstats.inMesh) {
            const p1 = Math.max(tstats.meshTime / topicParams.timeInMeshQuantum, topicParams.timeInMeshCap);
            p1w += p1 * topicParams.timeInMeshWeight;
        }
        // P2: first message deliveries
        let p2 = tstats.firstMessageDeliveries;
        if (p2 > topicParams.firstMessageDeliveriesCap) {
            p2 = topicParams.firstMessageDeliveriesCap;
        }
        p2w += p2 * topicParams.firstMessageDeliveriesWeight;
        // P3: mesh message deliveries
        if (tstats.meshMessageDeliveriesActive &&
            tstats.meshMessageDeliveries < topicParams.meshMessageDeliveriesThreshold) {
            const deficit = topicParams.meshMessageDeliveriesThreshold - tstats.meshMessageDeliveries;
            const p3 = deficit * deficit;
            p3w += p3 * topicParams.meshMessageDeliveriesWeight;
        }
        // P3b:
        // NOTE: the weight of P3b is negative (validated in validateTopicScoreParams) so this detracts
        const p3b = tstats.meshFailurePenalty;
        p3bw += p3b * topicParams.meshFailurePenaltyWeight;
        // P4: invalid messages
        // NOTE: the weight of P4 is negative (validated in validateTopicScoreParams) so this detracts
        const p4 = tstats.invalidMessageDeliveries * tstats.invalidMessageDeliveries;
        p4w += p4 * topicParams.invalidMessageDeliveriesWeight;
        // update score, mixing with topic weight
        score += (p1w + p2w + p3w + p3bw + p4w) * topicParams.topicWeight;
        topicScores.p1w += p1w;
        topicScores.p2w += p2w;
        topicScores.p3w += p3w;
        topicScores.p3bw += p3bw;
        topicScores.p4w += p4w;
    });
    // apply the topic score cap, if any
    if (params.topicScoreCap > 0 && score > params.topicScoreCap) {
        score = params.topicScoreCap;
        // Proportionally apply cap to all individual contributions
        const capF = params.topicScoreCap / score;
        for (const ws of byTopic.values()) {
            ws.p1w *= capF;
            ws.p2w *= capF;
            ws.p3w *= capF;
            ws.p3bw *= capF;
            ws.p4w *= capF;
        }
    }
    let p5w = 0;
    let p6w = 0;
    let p7w = 0;
    // P5: application-specific score
    const p5 = params.appSpecificScore(peer);
    p5w += p5 * params.appSpecificWeight;
    // P6: IP colocation factor
    pstats.knownIPs.forEach((ip) => {
        if (params.IPColocationFactorWhitelist.has(ip)) {
            return;
        }
        // P6 has a cliff (IPColocationFactorThreshold)
        // It's only applied if at least that many peers are connected to us from that source IP addr.
        // It is quadratic, and the weight is negative (validated in validatePeerScoreParams)
        const peersInIP = peerIPs.get(ip);
        const numPeersInIP = peersInIP ? peersInIP.size : 0;
        if (numPeersInIP > params.IPColocationFactorThreshold) {
            const surplus = numPeersInIP - params.IPColocationFactorThreshold;
            const p6 = surplus * surplus;
            p6w += p6 * params.IPColocationFactorWeight;
        }
    });
    // P7: behavioural pattern penalty
    const p7 = pstats.behaviourPenalty * pstats.behaviourPenalty;
    p7w += p7 * params.behaviourPenaltyWeight;
    score += p5w + p6w + p7w;
    return {
        byTopic,
        p5w,
        p6w,
        p7w,
        score
    };
}
function computeAllPeersScoreWeights(peerIdStrs, peerStats, params, peerIPs, topicStrToLabel) {
    const sw = {
        byTopic: new Map(),
        p5w: [],
        p6w: [],
        p7w: [],
        score: []
    };
    for (const peerIdStr of peerIdStrs) {
        const pstats = peerStats.get(peerIdStr);
        if (pstats) {
            const swPeer = computeScoreWeights(peerIdStr, pstats, params, peerIPs, topicStrToLabel);
            for (const [topic, swPeerTopic] of swPeer.byTopic) {
                let swTopic = sw.byTopic.get(topic);
                if (!swTopic) {
                    swTopic = {
                        p1w: [],
                        p2w: [],
                        p3w: [],
                        p3bw: [],
                        p4w: []
                    };
                    sw.byTopic.set(topic, swTopic);
                }
                swTopic.p1w.push(swPeerTopic.p1w);
                swTopic.p2w.push(swPeerTopic.p2w);
                swTopic.p3w.push(swPeerTopic.p3w);
                swTopic.p3bw.push(swPeerTopic.p3bw);
                swTopic.p4w.push(swPeerTopic.p4w);
            }
            sw.p5w.push(swPeer.p5w);
            sw.p6w.push(swPeer.p6w);
            sw.p7w.push(swPeer.p7w);
            sw.score.push(swPeer.score);
        }
        else {
            sw.p5w.push(0);
            sw.p6w.push(0);
            sw.p7w.push(0);
            sw.score.push(0);
        }
    }
    return sw;
}

class OutboundStream {
    constructor(rawStream, errCallback, opts) {
        this.rawStream = rawStream;
        this.pushable = pushable({ objectMode: false });
        this.closeController = new AbortController();
        this.maxBufferSize = opts.maxBufferSize ?? Infinity;
        pipe(abortableSource(this.pushable, this.closeController.signal, { returnOnAbort: true }), encode$b(), this.rawStream).catch(errCallback);
    }
    get protocol() {
        // TODO remove this non-nullish assertion after https://github.com/libp2p/js-libp2p-interfaces/pull/265 is incorporated
        return this.rawStream.stat.protocol;
    }
    push(data) {
        if (this.pushable.readableLength > this.maxBufferSize) {
            throw Error(`OutboundStream buffer full, size > ${this.maxBufferSize}`);
        }
        this.pushable.push(data);
    }
    close() {
        this.closeController.abort();
        // similar to pushable.end() but clear the internal buffer
        this.pushable.return();
        this.rawStream.close();
    }
}
class InboundStream {
    constructor(rawStream, opts = {}) {
        this.rawStream = rawStream;
        this.closeController = new AbortController();
        this.source = abortableSource(pipe(this.rawStream, decode$a(opts)), this.closeController.signal, {
            returnOnAbort: true
        });
    }
    close() {
        this.closeController.abort();
        this.rawStream.close();
    }
}

const defaultDecodeRpcLimits = {
    maxSubscriptions: Infinity,
    maxMessages: Infinity,
    maxIhaveMessageIDs: Infinity,
    maxIwantMessageIDs: Infinity,
    maxControlMessages: Infinity,
    maxPeerInfos: Infinity
};
/**
 * Copied code from src/message/rpc.cjs but with decode limits to prevent OOM attacks
 */
function decodeRpc(bytes, opts) {
    // Mutate to use the option as stateful counter. Must limit the total count of messageIDs across all IWANT, IHAVE
    // else one count put 100 messageIDs into each 100 IWANT and "get around" the limit
    opts = { ...opts };
    const r = protobuf.Reader.create(bytes);
    const l = bytes.length;
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                if (!(m.subscriptions && m.subscriptions.length))
                    m.subscriptions = [];
                if (m.subscriptions.length < opts.maxSubscriptions)
                    m.subscriptions.push(decodeSubOpts(r, r.uint32()));
                else
                    r.skipType(t & 7);
                break;
            case 2:
                if (!(m.messages && m.messages.length))
                    m.messages = [];
                if (m.messages.length < opts.maxMessages)
                    m.messages.push(decodeMessage$2(r, r.uint32()));
                else
                    r.skipType(t & 7);
                break;
            case 3:
                m.control = decodeControlMessage(r, r.uint32(), opts);
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeSubOpts(r, l) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.subscribe = r.bool();
                break;
            case 2:
                m.topic = r.string();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeMessage$2(r, l) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.from = r.bytes();
                break;
            case 2:
                m.data = r.bytes();
                break;
            case 3:
                m.seqno = r.bytes();
                break;
            case 4:
                m.topic = r.string();
                break;
            case 5:
                m.signature = r.bytes();
                break;
            case 6:
                m.key = r.bytes();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    if (!m.topic)
        throw Error("missing required 'topic'");
    return m;
}
function decodeControlMessage(r, l, opts) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                if (!(m.ihave && m.ihave.length))
                    m.ihave = [];
                if (m.ihave.length < opts.maxControlMessages)
                    m.ihave.push(decodeControlIHave(r, r.uint32(), opts));
                else
                    r.skipType(t & 7);
                break;
            case 2:
                if (!(m.iwant && m.iwant.length))
                    m.iwant = [];
                if (m.iwant.length < opts.maxControlMessages)
                    m.iwant.push(decodeControlIWant(r, r.uint32(), opts));
                else
                    r.skipType(t & 7);
                break;
            case 3:
                if (!(m.graft && m.graft.length))
                    m.graft = [];
                if (m.graft.length < opts.maxControlMessages)
                    m.graft.push(decodeControlGraft(r, r.uint32()));
                else
                    r.skipType(t & 7);
                break;
            case 4:
                if (!(m.prune && m.prune.length))
                    m.prune = [];
                if (m.prune.length < opts.maxControlMessages)
                    m.prune.push(decodeControlPrune(r, r.uint32(), opts));
                else
                    r.skipType(t & 7);
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeControlIHave(r, l, opts) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.topicID = r.string();
                break;
            case 2:
                if (!(m.messageIDs && m.messageIDs.length))
                    m.messageIDs = [];
                if (opts.maxIhaveMessageIDs-- > 0)
                    m.messageIDs.push(r.bytes());
                else
                    r.skipType(t & 7);
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeControlIWant(r, l, opts) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                if (!(m.messageIDs && m.messageIDs.length))
                    m.messageIDs = [];
                if (opts.maxIwantMessageIDs-- > 0)
                    m.messageIDs.push(r.bytes());
                else
                    r.skipType(t & 7);
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeControlGraft(r, l) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.topicID = r.string();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeControlPrune(r, l, opts) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.topicID = r.string();
                break;
            case 2:
                if (!(m.peers && m.peers.length))
                    m.peers = [];
                if (opts.maxPeerInfos-- > 0)
                    m.peers.push(decodePeerInfo(r, r.uint32()));
                else
                    r.skipType(t & 7);
                break;
            case 3:
                m.backoff = r.uint64();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodePeerInfo(r, l) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.peerID = r.bytes();
                break;
            case 2:
                m.signedPeerRecord = r.bytes();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}

// Protocols https://github.com/multiformats/multiaddr/blob/master/protocols.csv
// code  size  name
// 4     32    ip4
// 41    128   ip6
var Protocol;
(function (Protocol) {
    Protocol[Protocol["ip4"] = 4] = "ip4";
    Protocol[Protocol["ip6"] = 41] = "ip6";
})(Protocol || (Protocol = {}));
function multiaddrToIPStr(multiaddr) {
    for (const tuple of multiaddr.tuples()) {
        switch (tuple[0]) {
            case Protocol.ip4:
            case Protocol.ip6:
                return convertToString$1(tuple[0], tuple[1]);
        }
    }
    return null;
}

var GossipStatusCode;
(function (GossipStatusCode) {
    GossipStatusCode[GossipStatusCode["started"] = 0] = "started";
    GossipStatusCode[GossipStatusCode["stopped"] = 1] = "stopped";
})(GossipStatusCode || (GossipStatusCode = {}));
class GossipSub extends EventEmitter$1 {
    constructor(components, options = {}) {
        super();
        this.multicodecs = [GossipsubIDv11, GossipsubIDv10];
        // State
        this.peers = new Set();
        this.streamsInbound = new Map();
        this.streamsOutbound = new Map();
        /** Ensures outbound streams are created sequentially */
        this.outboundInflightQueue = pushable({ objectMode: true });
        /** Direct peers */
        this.direct = new Set();
        /** Floodsub peers */
        this.floodsubPeers = new Set();
        /**
         * Map of peer id and AcceptRequestWhileListEntry
         */
        this.acceptFromWhitelist = new Map();
        /**
         * Map of topics to which peers are subscribed to
         */
        this.topics = new Map();
        /**
         * List of our subscriptions
         */
        this.subscriptions = new Set();
        /**
         * Map of topic meshes
         * topic => peer id set
         */
        this.mesh = new Map();
        /**
         * Map of topics to set of peers. These mesh peers are the ones to which we are publishing without a topic membership
         * topic => peer id set
         */
        this.fanout = new Map();
        /**
         * Map of last publish time for fanout topics
         * topic => last publish time
         */
        this.fanoutLastpub = new Map();
        /**
         * Map of pending messages to gossip
         * peer id => control messages
         */
        this.gossip = new Map();
        /**
         * Map of control messages
         * peer id => control message
         */
        this.control = new Map();
        /**
         * Number of IHAVEs received from peer in the last heartbeat
         */
        this.peerhave = new Map();
        /** Number of messages we have asked from peer in the last heartbeat */
        this.iasked = new Map();
        /** Prune backoff map */
        this.backoff = new Map();
        /**
         * Connection direction cache, marks peers with outbound connections
         * peer id => direction
         */
        this.outbound = new Map();
        /**
         * Custom validator function per topic.
         * Must return or resolve quickly (< 100ms) to prevent causing penalties for late messages.
         * If you need to apply validation that may require longer times use `asyncValidation` option and callback the
         * validation result through `Gossipsub.reportValidationResult`
         */
        this.topicValidators = new Map();
        /**
         * Number of heartbeats since the beginning of time
         * This allows us to amortize some resource cleanup -- eg: backoff cleanup
         */
        this.heartbeatTicks = 0;
        this.directPeerInitial = null;
        this.status = { code: GossipStatusCode.stopped };
        this.heartbeatTimer = null;
        this.runHeartbeat = () => {
            const timer = this.metrics?.heartbeatDuration.startTimer();
            this.heartbeat()
                .catch((err) => {
                this.log('Error running heartbeat', err);
            })
                .finally(() => {
                if (timer != null) {
                    timer();
                }
                // Schedule the next run if still in started status
                if (this.status.code === GossipStatusCode.started) {
                    // Clear previous timeout before overwriting `status.heartbeatTimeout`, it should be completed tho.
                    clearTimeout(this.status.heartbeatTimeout);
                    // NodeJS setInterval function is innexact, calls drift by a few miliseconds on each call.
                    // To run the heartbeat precisely setTimeout() must be used recomputing the delay on every loop.
                    let msToNextHeartbeat = this.opts.heartbeatInterval - ((Date.now() - this.status.hearbeatStartMs) % this.opts.heartbeatInterval);
                    // If too close to next heartbeat, skip one
                    if (msToNextHeartbeat < this.opts.heartbeatInterval * 0.25) {
                        msToNextHeartbeat += this.opts.heartbeatInterval;
                        this.metrics?.heartbeatSkipped.inc();
                    }
                    this.status.heartbeatTimeout = setTimeout(this.runHeartbeat, msToNextHeartbeat);
                }
            });
        };
        const opts = {
            fallbackToFloodsub: true,
            floodPublish: true,
            doPX: false,
            directPeers: [],
            D: GossipsubD,
            Dlo: GossipsubDlo,
            Dhi: GossipsubDhi,
            Dscore: GossipsubDscore,
            Dout: GossipsubDout,
            Dlazy: GossipsubDlazy,
            heartbeatInterval: GossipsubHeartbeatInterval,
            fanoutTTL: GossipsubFanoutTTL,
            mcacheLength: GossipsubHistoryLength,
            mcacheGossip: GossipsubHistoryGossip,
            seenTTL: GossipsubSeenTTL,
            gossipsubIWantFollowupMs: GossipsubIWantFollowupTime,
            prunePeers: GossipsubPrunePeers,
            pruneBackoff: GossipsubPruneBackoff,
            graftFloodThreshold: GossipsubGraftFloodThreshold,
            opportunisticGraftPeers: GossipsubOpportunisticGraftPeers,
            opportunisticGraftTicks: GossipsubOpportunisticGraftTicks,
            directConnectTicks: GossipsubDirectConnectTicks,
            ...options,
            scoreParams: createPeerScoreParams(options.scoreParams),
            scoreThresholds: createPeerScoreThresholds(options.scoreThresholds)
        };
        this.components = components;
        this.decodeRpcLimits = opts.decodeRpcLimits ?? defaultDecodeRpcLimits;
        this.globalSignaturePolicy = opts.globalSignaturePolicy ?? StrictSign;
        // Also wants to get notified of peers connected using floodsub
        if (opts.fallbackToFloodsub) {
            this.multicodecs.push(FloodsubID);
        }
        // From pubsub
        this.log = logger$2(opts.debugName ?? 'libp2p:gossipsub');
        // Gossipsub
        this.opts = opts;
        this.direct = new Set(opts.directPeers.map((p) => p.id.toString()));
        this.seenCache = new SimpleTimeCache({ validityMs: opts.seenTTL });
        this.publishedMessageIds = new SimpleTimeCache({ validityMs: opts.seenTTL });
        if (options.msgIdFn) {
            // Use custom function
            this.msgIdFn = options.msgIdFn;
        }
        else {
            switch (this.globalSignaturePolicy) {
                case StrictSign:
                    this.msgIdFn = msgIdFnStrictSign;
                    break;
                case StrictNoSign:
                    this.msgIdFn = msgIdFnStrictNoSign;
                    break;
            }
        }
        if (options.fastMsgIdFn) {
            this.fastMsgIdFn = options.fastMsgIdFn;
            this.fastMsgIdCache = new SimpleTimeCache({ validityMs: opts.seenTTL });
        }
        // By default, gossipsub only provide a browser friendly function to convert Uint8Array message id to string.
        this.msgIdToStrFn = options.msgIdToStrFn ?? messageIdToString;
        this.mcache = options.messageCache || new MessageCache(opts.mcacheGossip, opts.mcacheLength, this.msgIdToStrFn);
        if (options.dataTransform) {
            this.dataTransform = options.dataTransform;
        }
        if (options.metricsRegister) {
            if (!options.metricsTopicStrToLabel) {
                throw Error('Must set metricsTopicStrToLabel with metrics');
            }
            // in theory, each topic has its own meshMessageDeliveriesWindow param
            // however in lodestar, we configure it mostly the same so just pick the max of positive ones
            // (some topics have meshMessageDeliveriesWindow as 0)
            const maxMeshMessageDeliveriesWindowMs = Math.max(...Object.values(opts.scoreParams.topics).map((topicParam) => topicParam.meshMessageDeliveriesWindow), DEFAULT_METRIC_MESH_MESSAGE_DELIVERIES_WINDOWS);
            const metrics = getMetrics(options.metricsRegister, options.metricsTopicStrToLabel, {
                gossipPromiseExpireSec: this.opts.gossipsubIWantFollowupMs / 1000,
                behaviourPenaltyThreshold: opts.scoreParams.behaviourPenaltyThreshold,
                maxMeshMessageDeliveriesWindowSec: maxMeshMessageDeliveriesWindowMs / 1000
            });
            metrics.mcacheSize.addCollect(() => this.onScrapeMetrics(metrics));
            for (const protocol of this.multicodecs) {
                metrics.protocolsEnabled.set({ protocol }, 1);
            }
            this.metrics = metrics;
        }
        else {
            this.metrics = null;
        }
        this.gossipTracer = new IWantTracer(this.opts.gossipsubIWantFollowupMs, this.msgIdToStrFn, this.metrics);
        /**
         * libp2p
         */
        this.score = new PeerScore(this.opts.scoreParams, this.metrics, {
            scoreCacheValidityMs: opts.heartbeatInterval
        });
        this.maxInboundStreams = options.maxInboundStreams;
        this.maxOutboundStreams = options.maxOutboundStreams;
        this.allowedTopics = opts.allowedTopics ? new Set(opts.allowedTopics) : null;
    }
    getPeers() {
        return [...this.peers.keys()].map((str) => peerIdFromString(str));
    }
    isStarted() {
        return this.status.code === GossipStatusCode.started;
    }
    // LIFECYCLE METHODS
    /**
     * Mounts the gossipsub protocol onto the libp2p node and sends our
     * our subscriptions to every peer connected
     */
    async start() {
        // From pubsub
        if (this.isStarted()) {
            return;
        }
        this.log('starting');
        this.publishConfig = await getPublishConfigFromPeerId(this.globalSignaturePolicy, this.components.peerId);
        // Create the outbound inflight queue
        // This ensures that outbound stream creation happens sequentially
        this.outboundInflightQueue = pushable({ objectMode: true });
        pipe(this.outboundInflightQueue, async (source) => {
            for await (const { peerId, connection } of source) {
                await this.createOutboundStream(peerId, connection);
            }
        }).catch((e) => this.log.error('outbound inflight queue error', e));
        // set direct peer addresses in the address book
        await Promise.all(this.opts.directPeers.map(async (p) => {
            await this.components.peerStore.addressBook.add(p.id, p.addrs);
        }));
        const registrar = this.components.registrar;
        // Incoming streams
        // Called after a peer dials us
        await Promise.all(this.multicodecs.map((multicodec) => registrar.handle(multicodec, this.onIncomingStream.bind(this), {
            maxInboundStreams: this.maxInboundStreams,
            maxOutboundStreams: this.maxOutboundStreams
        })));
        // # How does Gossipsub interact with libp2p? Rough guide from Mar 2022
        //
        // ## Setup:
        // Gossipsub requests libp2p to callback, TBD
        //
        // `this.libp2p.handle()` registers a handler for `/meshsub/1.1.0` and other Gossipsub protocols
        // The handler callback is registered in libp2p Upgrader.protocols map.
        //
        // Upgrader receives an inbound connection from some transport and (`Upgrader.upgradeInbound`):
        // - Adds encryption (NOISE in our case)
        // - Multiplex stream
        // - Create a muxer and register that for each new stream call Upgrader.protocols handler
        //
        // ## Topology
        // - new instance of Topology (unlinked to libp2p) with handlers
        // - registar.register(topology)
        // register protocol with topology
        // Topology callbacks called on connection manager changes
        const topology = createTopology({
            onConnect: this.onPeerConnected.bind(this),
            onDisconnect: this.onPeerDisconnected.bind(this)
        });
        const registrarTopologyIds = await Promise.all(this.multicodecs.map((multicodec) => registrar.register(multicodec, topology)));
        // Schedule to start heartbeat after `GossipsubHeartbeatInitialDelay`
        const heartbeatTimeout = setTimeout(this.runHeartbeat, GossipsubHeartbeatInitialDelay);
        // Then, run heartbeat every `heartbeatInterval` offset by `GossipsubHeartbeatInitialDelay`
        this.status = {
            code: GossipStatusCode.started,
            registrarTopologyIds,
            heartbeatTimeout: heartbeatTimeout,
            hearbeatStartMs: Date.now() + GossipsubHeartbeatInitialDelay
        };
        this.score.start();
        // connect to direct peers
        this.directPeerInitial = setTimeout(() => {
            Promise.resolve()
                .then(async () => {
                await Promise.all(Array.from(this.direct).map(async (id) => await this.connect(id)));
            })
                .catch((err) => {
                this.log(err);
            });
        }, GossipsubDirectConnectInitialDelay);
        this.log('started');
    }
    /**
     * Unmounts the gossipsub protocol and shuts down every connection
     */
    async stop() {
        this.log('stopping');
        // From pubsub
        if (this.status.code !== GossipStatusCode.started) {
            return;
        }
        const { registrarTopologyIds } = this.status;
        this.status = { code: GossipStatusCode.stopped };
        // unregister protocol and handlers
        const registrar = this.components.registrar;
        registrarTopologyIds.forEach((id) => registrar.unregister(id));
        this.outboundInflightQueue.end();
        for (const outboundStream of this.streamsOutbound.values()) {
            outboundStream.close();
        }
        this.streamsOutbound.clear();
        for (const inboundStream of this.streamsInbound.values()) {
            inboundStream.close();
        }
        this.streamsInbound.clear();
        this.peers.clear();
        this.subscriptions.clear();
        // Gossipsub
        if (this.heartbeatTimer) {
            this.heartbeatTimer.cancel();
            this.heartbeatTimer = null;
        }
        this.score.stop();
        this.mesh.clear();
        this.fanout.clear();
        this.fanoutLastpub.clear();
        this.gossip.clear();
        this.control.clear();
        this.peerhave.clear();
        this.iasked.clear();
        this.backoff.clear();
        this.outbound.clear();
        this.gossipTracer.clear();
        this.seenCache.clear();
        if (this.fastMsgIdCache)
            this.fastMsgIdCache.clear();
        if (this.directPeerInitial)
            clearTimeout(this.directPeerInitial);
        this.log('stopped');
    }
    /** FOR DEBUG ONLY - Dump peer stats for all peers. Data is cloned, safe to mutate */
    dumpPeerScoreStats() {
        return this.score.dumpPeerScoreStats();
    }
    /**
     * On an inbound stream opened
     */
    onIncomingStream({ stream, connection }) {
        if (!this.isStarted()) {
            return;
        }
        const peerId = connection.remotePeer;
        // add peer to router
        this.addPeer(peerId, connection.stat.direction, connection.remoteAddr);
        // create inbound stream
        this.createInboundStream(peerId, stream);
        // attempt to create outbound stream
        this.outboundInflightQueue.push({ peerId, connection });
    }
    /**
     * Registrar notifies an established connection with pubsub protocol
     */
    onPeerConnected(peerId, connection) {
        this.metrics?.newConnectionCount.inc({ status: connection.stat.status });
        // libp2p may emit a closed connection and never issue peer:disconnect event
        // see https://github.com/ChainSafe/js-libp2p-gossipsub/issues/398
        if (!this.isStarted() || connection.stat.status !== 'OPEN') {
            return;
        }
        this.addPeer(peerId, connection.stat.direction, connection.remoteAddr);
        this.outboundInflightQueue.push({ peerId, connection });
    }
    /**
     * Registrar notifies a closing connection with pubsub protocol
     */
    onPeerDisconnected(peerId) {
        this.log('connection ended %p', peerId);
        this.removePeer(peerId);
    }
    async createOutboundStream(peerId, connection) {
        if (!this.isStarted()) {
            return;
        }
        const id = peerId.toString();
        if (!this.peers.has(id)) {
            return;
        }
        // TODO make this behavior more robust
        // This behavior is different than for inbound streams
        // If an outbound stream already exists, don't create a new stream
        if (this.streamsOutbound.has(id)) {
            return;
        }
        try {
            const stream = new OutboundStream(await connection.newStream(this.multicodecs), (e) => this.log.error('outbound pipe error', e), { maxBufferSize: this.opts.maxOutboundBufferSize });
            this.log('create outbound stream %p', peerId);
            this.streamsOutbound.set(id, stream);
            const protocol = stream.protocol;
            if (protocol === FloodsubID) {
                this.floodsubPeers.add(id);
            }
            this.metrics?.peersPerProtocol.inc({ protocol }, 1);
            // Immediately send own subscriptions via the newly attached stream
            if (this.subscriptions.size > 0) {
                this.log('send subscriptions to', id);
                this.sendSubscriptions(id, Array.from(this.subscriptions), true);
            }
        }
        catch (e) {
            this.log.error('createOutboundStream error', e);
        }
    }
    async createInboundStream(peerId, stream) {
        if (!this.isStarted()) {
            return;
        }
        const id = peerId.toString();
        if (!this.peers.has(id)) {
            return;
        }
        // TODO make this behavior more robust
        // This behavior is different than for outbound streams
        // If a peer initiates a new inbound connection
        // we assume that one is the new canonical inbound stream
        const priorInboundStream = this.streamsInbound.get(id);
        if (priorInboundStream !== undefined) {
            this.log('replacing existing inbound steam %s', id);
            priorInboundStream.close();
        }
        this.log('create inbound stream %s', id);
        const inboundStream = new InboundStream(stream, { maxDataLength: this.opts.maxInboundDataLength });
        this.streamsInbound.set(id, inboundStream);
        this.pipePeerReadStream(peerId, inboundStream.source).catch((err) => this.log(err));
    }
    /**
     * Add a peer to the router
     */
    addPeer(peerId, direction, addr) {
        const id = peerId.toString();
        if (!this.peers.has(id)) {
            this.log('new peer %p', peerId);
            this.peers.add(id);
            // Add to peer scoring
            this.score.addPeer(id);
            const currentIP = multiaddrToIPStr(addr);
            if (currentIP !== null) {
                this.score.addIP(id, currentIP);
            }
            else {
                this.log('Added peer has no IP in current address %s %s', id, addr.toString());
            }
            // track the connection direction. Don't allow to unset outbound
            if (!this.outbound.has(id)) {
                this.outbound.set(id, direction === 'outbound');
            }
        }
    }
    /**
     * Removes a peer from the router
     */
    removePeer(peerId) {
        const id = peerId.toString();
        if (!this.peers.has(id)) {
            return;
        }
        // delete peer
        this.log('delete peer %p', peerId);
        this.peers.delete(id);
        const outboundStream = this.streamsOutbound.get(id);
        const inboundStream = this.streamsInbound.get(id);
        if (outboundStream) {
            this.metrics?.peersPerProtocol.inc({ protocol: outboundStream.protocol }, -1);
        }
        // close streams
        outboundStream?.close();
        inboundStream?.close();
        // remove streams
        this.streamsOutbound.delete(id);
        this.streamsInbound.delete(id);
        // remove peer from topics map
        for (const peers of this.topics.values()) {
            peers.delete(id);
        }
        // Remove this peer from the mesh
        for (const [topicStr, peers] of this.mesh) {
            if (peers.delete(id) === true) {
                this.metrics?.onRemoveFromMesh(topicStr, ChurnReason.Dc, 1);
            }
        }
        // Remove this peer from the fanout
        for (const peers of this.fanout.values()) {
            peers.delete(id);
        }
        // Remove from floodsubPeers
        this.floodsubPeers.delete(id);
        // Remove from gossip mapping
        this.gossip.delete(id);
        // Remove from control mapping
        this.control.delete(id);
        // Remove from backoff mapping
        this.outbound.delete(id);
        // Remove from peer scoring
        this.score.removePeer(id);
        this.acceptFromWhitelist.delete(id);
    }
    // API METHODS
    get started() {
        return this.status.code === GossipStatusCode.started;
    }
    /**
     * Get a the peer-ids in a topic mesh
     */
    getMeshPeers(topic) {
        const peersInTopic = this.mesh.get(topic);
        return peersInTopic ? Array.from(peersInTopic) : [];
    }
    /**
     * Get a list of the peer-ids that are subscribed to one topic.
     */
    getSubscribers(topic) {
        const peersInTopic = this.topics.get(topic);
        return (peersInTopic ? Array.from(peersInTopic) : []).map((str) => peerIdFromString(str));
    }
    /**
     * Get the list of topics which the peer is subscribed to.
     */
    getTopics() {
        return Array.from(this.subscriptions);
    }
    // TODO: Reviewing Pubsub API
    // MESSAGE METHODS
    /**
     * Responsible for processing each RPC message received by other peers.
     */
    async pipePeerReadStream(peerId, stream) {
        try {
            await pipe(stream, async (source) => {
                for await (const data of source) {
                    try {
                        // TODO: Check max gossip message size, before decodeRpc()
                        const rpcBytes = data.subarray();
                        // Note: This function may throw, it must be wrapped in a try {} catch {} to prevent closing the stream.
                        // TODO: What should we do if the entire RPC is invalid?
                        const rpc = decodeRpc(rpcBytes, this.decodeRpcLimits);
                        this.metrics?.onRpcRecv(rpc, rpcBytes.length);
                        // Since processRpc may be overridden entirely in unsafe ways,
                        // the simplest/safest option here is to wrap in a function and capture all errors
                        // to prevent a top-level unhandled exception
                        // This processing of rpc messages should happen without awaiting full validation/execution of prior messages
                        if (this.opts.awaitRpcHandler) {
                            await this.handleReceivedRpc(peerId, rpc);
                        }
                        else {
                            this.handleReceivedRpc(peerId, rpc).catch((err) => this.log(err));
                        }
                    }
                    catch (e) {
                        this.log(e);
                    }
                }
            });
        }
        catch (err) {
            this.handlePeerReadStreamError(err, peerId);
        }
    }
    /**
     * Handle error when read stream pipe throws, less of the functional use but more
     * to for testing purposes to spy on the error handling
     * */
    handlePeerReadStreamError(err, peerId) {
        this.log.error(err);
        this.onPeerDisconnected(peerId);
    }
    /**
     * Handles an rpc request from a peer
     */
    async handleReceivedRpc(from, rpc) {
        // Check if peer is graylisted in which case we ignore the event
        if (!this.acceptFrom(from.toString())) {
            this.log('received message from unacceptable peer %p', from);
            this.metrics?.rpcRecvNotAccepted.inc();
            return;
        }
        this.log('rpc from %p', from);
        // Handle received subscriptions
        if (rpc.subscriptions && rpc.subscriptions.length > 0) {
            // update peer subscriptions
            const subscriptions = [];
            rpc.subscriptions.forEach((subOpt) => {
                const topic = subOpt.topic;
                const subscribe = subOpt.subscribe === true;
                if (topic != null) {
                    if (this.allowedTopics && !this.allowedTopics.has(topic)) {
                        // Not allowed: subscription data-structures are not bounded by topic count
                        // TODO: Should apply behaviour penalties?
                        return;
                    }
                    this.handleReceivedSubscription(from, topic, subscribe);
                    subscriptions.push({ topic, subscribe });
                }
            });
            this.dispatchEvent(new CustomEvent('subscription-change', {
                detail: { peerId: from, subscriptions }
            }));
        }
        // Handle messages
        // TODO: (up to limit)
        if (rpc.messages) {
            for (const message of rpc.messages) {
                if (this.allowedTopics && !this.allowedTopics.has(message.topic)) {
                    // Not allowed: message cache data-structures are not bounded by topic count
                    // TODO: Should apply behaviour penalties?
                    continue;
                }
                const handleReceivedMessagePromise = this.handleReceivedMessage(from, message)
                    // Should never throw, but handle just in case
                    .catch((err) => this.log(err));
                if (this.opts.awaitRpcMessageHandler) {
                    await handleReceivedMessagePromise;
                }
            }
        }
        // Handle control messages
        if (rpc.control) {
            await this.handleControlMessage(from.toString(), rpc.control);
        }
    }
    /**
     * Handles a subscription change from a peer
     */
    handleReceivedSubscription(from, topic, subscribe) {
        this.log('subscription update from %p topic %s', from, topic);
        let topicSet = this.topics.get(topic);
        if (topicSet == null) {
            topicSet = new Set();
            this.topics.set(topic, topicSet);
        }
        if (subscribe) {
            // subscribe peer to new topic
            topicSet.add(from.toString());
        }
        else {
            // unsubscribe from existing topic
            topicSet.delete(from.toString());
        }
        // TODO: rust-libp2p has A LOT more logic here
    }
    /**
     * Handles a newly received message from an RPC.
     * May forward to all peers in the mesh.
     */
    async handleReceivedMessage(from, rpcMsg) {
        this.metrics?.onMsgRecvPreValidation(rpcMsg.topic);
        const validationResult = await this.validateReceivedMessage(from, rpcMsg);
        this.metrics?.onMsgRecvResult(rpcMsg.topic, validationResult.code);
        switch (validationResult.code) {
            case MessageStatus.duplicate:
                // Report the duplicate
                this.score.duplicateMessage(from.toString(), validationResult.msgIdStr, rpcMsg.topic);
                // due to the collision of fastMsgIdFn, 2 different messages may end up the same fastMsgId
                // so we need to also mark the duplicate message as delivered or the promise is not resolved
                // and peer gets penalized. See https://github.com/ChainSafe/js-libp2p-gossipsub/pull/385
                this.gossipTracer.deliverMessage(validationResult.msgIdStr, true);
                this.mcache.observeDuplicate(validationResult.msgIdStr, from.toString());
                return;
            case MessageStatus.invalid:
                // invalid messages received
                // metrics.register_invalid_message(&raw_message.topic)
                // Tell peer_score about reject
                // Reject the original source, and any duplicates we've seen from other peers.
                if (validationResult.msgIdStr) {
                    const msgIdStr = validationResult.msgIdStr;
                    this.score.rejectMessage(from.toString(), msgIdStr, rpcMsg.topic, validationResult.reason);
                    this.gossipTracer.rejectMessage(msgIdStr, validationResult.reason);
                }
                else {
                    this.score.rejectInvalidMessage(from.toString(), rpcMsg.topic);
                }
                this.metrics?.onMsgRecvInvalid(rpcMsg.topic, validationResult);
                return;
            case MessageStatus.valid:
                // Tells score that message arrived (but is maybe not fully validated yet).
                // Consider the message as delivered for gossip promises.
                this.score.validateMessage(validationResult.messageId.msgIdStr);
                this.gossipTracer.deliverMessage(validationResult.messageId.msgIdStr);
                // Add the message to our memcache
                // if no validation is required, mark the message as validated
                this.mcache.put(validationResult.messageId, rpcMsg, !this.opts.asyncValidation);
                // Dispatch the message to the user if we are subscribed to the topic
                if (this.subscriptions.has(rpcMsg.topic)) {
                    const isFromSelf = this.components.peerId.equals(from);
                    if (!isFromSelf || this.opts.emitSelf) {
                        super.dispatchEvent(new CustomEvent('gossipsub:message', {
                            detail: {
                                propagationSource: from,
                                msgId: validationResult.messageId.msgIdStr,
                                msg: validationResult.msg
                            }
                        }));
                        // TODO: Add option to switch between emit per topic or all messages in one
                        super.dispatchEvent(new CustomEvent('message', { detail: validationResult.msg }));
                    }
                }
                // Forward the message to mesh peers, if no validation is required
                // If asyncValidation is ON, expect the app layer to call reportMessageValidationResult(), then forward
                if (!this.opts.asyncValidation) {
                    // TODO: in rust-libp2p
                    // .forward_msg(&msg_id, raw_message, Some(propagation_source))
                    this.forwardMessage(validationResult.messageId.msgIdStr, rpcMsg, from.toString());
                }
        }
    }
    /**
     * Handles a newly received message from an RPC.
     * May forward to all peers in the mesh.
     */
    async validateReceivedMessage(propagationSource, rpcMsg) {
        // Fast message ID stuff
        const fastMsgIdStr = this.fastMsgIdFn?.(rpcMsg);
        const msgIdCached = fastMsgIdStr !== undefined ? this.fastMsgIdCache?.get(fastMsgIdStr) : undefined;
        if (msgIdCached) {
            // This message has been seen previously. Ignore it
            return { code: MessageStatus.duplicate, msgIdStr: msgIdCached };
        }
        // Perform basic validation on message and convert to RawGossipsubMessage for fastMsgIdFn()
        const validationResult = await validateToRawMessage(this.globalSignaturePolicy, rpcMsg);
        if (!validationResult.valid) {
            return { code: MessageStatus.invalid, reason: RejectReason.Error, error: validationResult.error };
        }
        const msg = validationResult.message;
        // Try and perform the data transform to the message. If it fails, consider it invalid.
        try {
            if (this.dataTransform) {
                msg.data = this.dataTransform.inboundTransform(rpcMsg.topic, msg.data);
            }
        }
        catch (e) {
            this.log('Invalid message, transform failed', e);
            return { code: MessageStatus.invalid, reason: RejectReason.Error, error: ValidateError.TransformFailed };
        }
        // TODO: Check if message is from a blacklisted source or propagation origin
        // - Reject any message from a blacklisted peer
        // - Also reject any message that originated from a blacklisted peer
        // - reject messages claiming to be from ourselves but not locally published
        // Calculate the message id on the transformed data.
        const msgId = await this.msgIdFn(msg);
        const msgIdStr = this.msgIdToStrFn(msgId);
        const messageId = { msgId, msgIdStr };
        // Add the message to the duplicate caches
        if (fastMsgIdStr !== undefined && this.fastMsgIdCache) {
            const collision = this.fastMsgIdCache.put(fastMsgIdStr, msgIdStr);
            if (collision) {
                this.metrics?.fastMsgIdCacheCollision.inc();
            }
        }
        if (this.seenCache.has(msgIdStr)) {
            return { code: MessageStatus.duplicate, msgIdStr };
        }
        else {
            this.seenCache.put(msgIdStr);
        }
        // (Optional) Provide custom validation here with dynamic validators per topic
        // NOTE: This custom topicValidator() must resolve fast (< 100ms) to allow scores
        // to not penalize peers for long validation times.
        const topicValidator = this.topicValidators.get(rpcMsg.topic);
        if (topicValidator != null) {
            let acceptance;
            // Use try {} catch {} in case topicValidator() is synchronous
            try {
                acceptance = await topicValidator(propagationSource, msg);
            }
            catch (e) {
                const errCode = e.code;
                if (errCode === ERR_TOPIC_VALIDATOR_IGNORE)
                    acceptance = TopicValidatorResult.Ignore;
                if (errCode === ERR_TOPIC_VALIDATOR_REJECT)
                    acceptance = TopicValidatorResult.Reject;
                else
                    acceptance = TopicValidatorResult.Ignore;
            }
            if (acceptance !== TopicValidatorResult.Accept) {
                return { code: MessageStatus.invalid, reason: rejectReasonFromAcceptance(acceptance), msgIdStr };
            }
        }
        return { code: MessageStatus.valid, messageId, msg };
    }
    /**
     * Return score of a peer.
     */
    getScore(peerId) {
        return this.score.score(peerId);
    }
    /**
     * Send an rpc object to a peer with subscriptions
     */
    sendSubscriptions(toPeer, topics, subscribe) {
        this.sendRpc(toPeer, {
            subscriptions: topics.map((topic) => ({ topic, subscribe }))
        });
    }
    /**
     * Handles an rpc control message from a peer
     */
    async handleControlMessage(id, controlMsg) {
        if (controlMsg === undefined) {
            return;
        }
        const iwant = controlMsg.ihave ? this.handleIHave(id, controlMsg.ihave) : [];
        const ihave = controlMsg.iwant ? this.handleIWant(id, controlMsg.iwant) : [];
        const prune = controlMsg.graft ? await this.handleGraft(id, controlMsg.graft) : [];
        controlMsg.prune && (await this.handlePrune(id, controlMsg.prune));
        if (!iwant.length && !ihave.length && !prune.length) {
            return;
        }
        this.sendRpc(id, { messages: ihave, control: { iwant, prune } });
    }
    /**
     * Whether to accept a message from a peer
     */
    acceptFrom(id) {
        if (this.direct.has(id)) {
            return true;
        }
        const now = Date.now();
        const entry = this.acceptFromWhitelist.get(id);
        if (entry && entry.messagesAccepted < ACCEPT_FROM_WHITELIST_MAX_MESSAGES && entry.acceptUntil >= now) {
            entry.messagesAccepted += 1;
            return true;
        }
        const score = this.score.score(id);
        if (score >= ACCEPT_FROM_WHITELIST_THRESHOLD_SCORE) {
            // peer is unlikely to be able to drop its score to `graylistThreshold`
            // after 128 messages or 1s
            this.acceptFromWhitelist.set(id, {
                messagesAccepted: 0,
                acceptUntil: now + ACCEPT_FROM_WHITELIST_DURATION_MS
            });
        }
        else {
            this.acceptFromWhitelist.delete(id);
        }
        return score >= this.opts.scoreThresholds.graylistThreshold;
    }
    /**
     * Handles IHAVE messages
     */
    handleIHave(id, ihave) {
        if (!ihave.length) {
            return [];
        }
        // we ignore IHAVE gossip from any peer whose score is below the gossips threshold
        const score = this.score.score(id);
        if (score < this.opts.scoreThresholds.gossipThreshold) {
            this.log('IHAVE: ignoring peer %s with score below threshold [ score = %d ]', id, score);
            this.metrics?.ihaveRcvIgnored.inc({ reason: IHaveIgnoreReason.LowScore });
            return [];
        }
        // IHAVE flood protection
        const peerhave = (this.peerhave.get(id) ?? 0) + 1;
        this.peerhave.set(id, peerhave);
        if (peerhave > GossipsubMaxIHaveMessages) {
            this.log('IHAVE: peer %s has advertised too many times (%d) within this heartbeat interval; ignoring', id, peerhave);
            this.metrics?.ihaveRcvIgnored.inc({ reason: IHaveIgnoreReason.MaxIhave });
            return [];
        }
        const iasked = this.iasked.get(id) ?? 0;
        if (iasked >= GossipsubMaxIHaveLength) {
            this.log('IHAVE: peer %s has already advertised too many messages (%d); ignoring', id, iasked);
            this.metrics?.ihaveRcvIgnored.inc({ reason: IHaveIgnoreReason.MaxIasked });
            return [];
        }
        // string msgId => msgId
        const iwant = new Map();
        ihave.forEach(({ topicID, messageIDs }) => {
            if (!topicID || !messageIDs || !this.mesh.has(topicID)) {
                return;
            }
            let idonthave = 0;
            messageIDs.forEach((msgId) => {
                const msgIdStr = this.msgIdToStrFn(msgId);
                if (!this.seenCache.has(msgIdStr)) {
                    iwant.set(msgIdStr, msgId);
                    idonthave++;
                }
            });
            this.metrics?.onIhaveRcv(topicID, messageIDs.length, idonthave);
        });
        if (!iwant.size) {
            return [];
        }
        let iask = iwant.size;
        if (iask + iasked > GossipsubMaxIHaveLength) {
            iask = GossipsubMaxIHaveLength - iasked;
        }
        this.log('IHAVE: Asking for %d out of %d messages from %s', iask, iwant.size, id);
        let iwantList = Array.from(iwant.values());
        // ask in random order
        shuffle(iwantList);
        // truncate to the messages we are actually asking for and update the iasked counter
        iwantList = iwantList.slice(0, iask);
        this.iasked.set(id, iasked + iask);
        this.gossipTracer.addPromise(id, iwantList);
        return [
            {
                messageIDs: iwantList
            }
        ];
    }
    /**
     * Handles IWANT messages
     * Returns messages to send back to peer
     */
    handleIWant(id, iwant) {
        if (!iwant.length) {
            return [];
        }
        // we don't respond to IWANT requests from any per whose score is below the gossip threshold
        const score = this.score.score(id);
        if (score < this.opts.scoreThresholds.gossipThreshold) {
            this.log('IWANT: ignoring peer %s with score below threshold [score = %d]', id, score);
            return [];
        }
        const ihave = new Map();
        const iwantByTopic = new Map();
        let iwantDonthave = 0;
        iwant.forEach(({ messageIDs }) => {
            messageIDs &&
                messageIDs.forEach((msgId) => {
                    const msgIdStr = this.msgIdToStrFn(msgId);
                    const entry = this.mcache.getWithIWantCount(msgIdStr, id);
                    if (entry == null) {
                        iwantDonthave++;
                        return;
                    }
                    iwantByTopic.set(entry.msg.topic, 1 + (iwantByTopic.get(entry.msg.topic) ?? 0));
                    if (entry.count > GossipsubGossipRetransmission) {
                        this.log('IWANT: Peer %s has asked for message %s too many times: ignoring request', id, msgId);
                        return;
                    }
                    ihave.set(msgIdStr, entry.msg);
                });
        });
        this.metrics?.onIwantRcv(iwantByTopic, iwantDonthave);
        if (!ihave.size) {
            this.log('IWANT: Could not provide any wanted messages to %s', id);
            return [];
        }
        this.log('IWANT: Sending %d messages to %s', ihave.size, id);
        return Array.from(ihave.values());
    }
    /**
     * Handles Graft messages
     */
    async handleGraft(id, graft) {
        const prune = [];
        const score = this.score.score(id);
        const now = Date.now();
        let doPX = this.opts.doPX;
        graft.forEach(({ topicID }) => {
            if (!topicID) {
                return;
            }
            const peersInMesh = this.mesh.get(topicID);
            if (!peersInMesh) {
                // don't do PX when there is an unknown topic to avoid leaking our peers
                doPX = false;
                // spam hardening: ignore GRAFTs for unknown topics
                return;
            }
            // check if peer is already in the mesh; if so do nothing
            if (peersInMesh.has(id)) {
                return;
            }
            // we don't GRAFT to/from direct peers; complain loudly if this happens
            if (this.direct.has(id)) {
                this.log('GRAFT: ignoring request from direct peer %s', id);
                // this is possibly a bug from a non-reciprical configuration; send a PRUNE
                prune.push(topicID);
                // but don't px
                doPX = false;
                return;
            }
            // make sure we are not backing off that peer
            const expire = this.backoff.get(topicID)?.get(id);
            if (typeof expire === 'number' && now < expire) {
                this.log('GRAFT: ignoring backed off peer %s', id);
                // add behavioral penalty
                this.score.addPenalty(id, 1, ScorePenalty.GraftBackoff);
                // no PX
                doPX = false;
                // check the flood cutoff -- is the GRAFT coming too fast?
                const floodCutoff = expire + this.opts.graftFloodThreshold - this.opts.pruneBackoff;
                if (now < floodCutoff) {
                    // extra penalty
                    this.score.addPenalty(id, 1, ScorePenalty.GraftBackoff);
                }
                // refresh the backoff
                this.addBackoff(id, topicID);
                prune.push(topicID);
                return;
            }
            // check the score
            if (score < 0) {
                // we don't GRAFT peers with negative score
                this.log('GRAFT: ignoring peer %s with negative score: score=%d, topic=%s', id, score, topicID);
                // we do send them PRUNE however, because it's a matter of protocol correctness
                prune.push(topicID);
                // but we won't PX to them
                doPX = false;
                // add/refresh backoff so that we don't reGRAFT too early even if the score decays
                this.addBackoff(id, topicID);
                return;
            }
            // check the number of mesh peers; if it is at (or over) Dhi, we only accept grafts
            // from peers with outbound connections; this is a defensive check to restrict potential
            // mesh takeover attacks combined with love bombing
            if (peersInMesh.size >= this.opts.Dhi && !this.outbound.get(id)) {
                prune.push(topicID);
                this.addBackoff(id, topicID);
                return;
            }
            this.log('GRAFT: Add mesh link from %s in %s', id, topicID);
            this.score.graft(id, topicID);
            peersInMesh.add(id);
            this.metrics?.onAddToMesh(topicID, InclusionReason.Subscribed, 1);
        });
        if (!prune.length) {
            return [];
        }
        return await Promise.all(prune.map((topic) => this.makePrune(id, topic, doPX)));
    }
    /**
     * Handles Prune messages
     */
    async handlePrune(id, prune) {
        const score = this.score.score(id);
        for (const { topicID, backoff, peers } of prune) {
            if (topicID == null) {
                continue;
            }
            const peersInMesh = this.mesh.get(topicID);
            if (!peersInMesh) {
                return;
            }
            this.log('PRUNE: Remove mesh link to %s in %s', id, topicID);
            this.score.prune(id, topicID);
            if (peersInMesh.has(id)) {
                peersInMesh.delete(id);
                this.metrics?.onRemoveFromMesh(topicID, ChurnReason.Unsub, 1);
            }
            // is there a backoff specified by the peer? if so obey it
            if (typeof backoff === 'number' && backoff > 0) {
                this.doAddBackoff(id, topicID, backoff * 1000);
            }
            else {
                this.addBackoff(id, topicID);
            }
            // PX
            if (peers && peers.length) {
                // we ignore PX from peers with insufficient scores
                if (score < this.opts.scoreThresholds.acceptPXThreshold) {
                    this.log('PRUNE: ignoring PX from peer %s with insufficient score [score = %d, topic = %s]', id, score, topicID);
                    continue;
                }
                await this.pxConnect(peers);
            }
        }
    }
    /**
     * Add standard backoff log for a peer in a topic
     */
    addBackoff(id, topic) {
        this.doAddBackoff(id, topic, this.opts.pruneBackoff);
    }
    /**
     * Add backoff expiry interval for a peer in a topic
     *
     * @param id
     * @param topic
     * @param interval - backoff duration in milliseconds
     */
    doAddBackoff(id, topic, interval) {
        let backoff = this.backoff.get(topic);
        if (!backoff) {
            backoff = new Map();
            this.backoff.set(topic, backoff);
        }
        const expire = Date.now() + interval;
        const existingExpire = backoff.get(id) ?? 0;
        if (existingExpire < expire) {
            backoff.set(id, expire);
        }
    }
    /**
     * Apply penalties from broken IHAVE/IWANT promises
     */
    applyIwantPenalties() {
        this.gossipTracer.getBrokenPromises().forEach((count, p) => {
            this.log("peer %s didn't follow up in %d IWANT requests; adding penalty", p, count);
            this.score.addPenalty(p, count, ScorePenalty.BrokenPromise);
        });
    }
    /**
     * Clear expired backoff expiries
     */
    clearBackoff() {
        // we only clear once every GossipsubPruneBackoffTicks ticks to avoid iterating over the maps too much
        if (this.heartbeatTicks % GossipsubPruneBackoffTicks !== 0) {
            return;
        }
        const now = Date.now();
        this.backoff.forEach((backoff, topic) => {
            backoff.forEach((expire, id) => {
                if (expire < now) {
                    backoff.delete(id);
                }
            });
            if (backoff.size === 0) {
                this.backoff.delete(topic);
            }
        });
    }
    /**
     * Maybe reconnect to direct peers
     */
    async directConnect() {
        const toconnect = [];
        this.direct.forEach((id) => {
            if (!this.streamsOutbound.has(id)) {
                toconnect.push(id);
            }
        });
        await Promise.all(toconnect.map(async (id) => await this.connect(id)));
    }
    /**
     * Maybe attempt connection given signed peer records
     */
    async pxConnect(peers) {
        if (peers.length > this.opts.prunePeers) {
            shuffle(peers);
            peers = peers.slice(0, this.opts.prunePeers);
        }
        const toconnect = [];
        await Promise.all(peers.map(async (pi) => {
            if (!pi.peerID) {
                return;
            }
            const p = peerIdFromBytes(pi.peerID).toString();
            if (this.peers.has(p)) {
                return;
            }
            if (!pi.signedPeerRecord) {
                toconnect.push(p);
                return;
            }
            // The peer sent us a signed record
            // This is not a record from the peer who sent the record, but another peer who is connected with it
            // Ensure that it is valid
            try {
                const envelope = await RecordEnvelope.openAndCertify(pi.signedPeerRecord, 'libp2p-peer-record');
                const eid = envelope.peerId;
                if (!envelope.peerId.equals(p)) {
                    this.log("bogus peer record obtained through px: peer ID %p doesn't match expected peer %p", eid, p);
                    return;
                }
                if (!(await this.components.peerStore.addressBook.consumePeerRecord(envelope))) {
                    this.log('bogus peer record obtained through px: could not add peer record to address book');
                    return;
                }
                toconnect.push(p);
            }
            catch (e) {
                this.log('bogus peer record obtained through px: invalid signature or not a peer record');
            }
        }));
        if (!toconnect.length) {
            return;
        }
        await Promise.all(toconnect.map(async (id) => await this.connect(id)));
    }
    /**
     * Connect to a peer using the gossipsub protocol
     */
    async connect(id) {
        this.log('Initiating connection with %s', id);
        const peerId = peerIdFromString(id);
        const connection = await this.components.connectionManager.openConnection(peerId);
        for (const multicodec of this.multicodecs) {
            for (const topology of this.components.registrar.getTopologies(multicodec)) {
                topology.onConnect(peerId, connection);
            }
        }
    }
    /**
     * Subscribes to a topic
     */
    subscribe(topic) {
        if (this.status.code !== GossipStatusCode.started) {
            throw new Error('Pubsub has not started');
        }
        if (!this.subscriptions.has(topic)) {
            this.subscriptions.add(topic);
            for (const peerId of this.peers.keys()) {
                this.sendSubscriptions(peerId, [topic], true);
            }
        }
        this.join(topic);
    }
    /**
     * Unsubscribe to a topic
     */
    unsubscribe(topic) {
        if (this.status.code !== GossipStatusCode.started) {
            throw new Error('Pubsub is not started');
        }
        const wasSubscribed = this.subscriptions.delete(topic);
        this.log('unsubscribe from %s - am subscribed %s', topic, wasSubscribed);
        if (wasSubscribed) {
            for (const peerId of this.peers.keys()) {
                this.sendSubscriptions(peerId, [topic], false);
            }
        }
        this.leave(topic);
    }
    /**
     * Join topic
     */
    join(topic) {
        if (this.status.code !== GossipStatusCode.started) {
            throw new Error('Gossipsub has not started');
        }
        // if we are already in the mesh, return
        if (this.mesh.has(topic)) {
            return;
        }
        this.log('JOIN %s', topic);
        this.metrics?.onJoin(topic);
        const toAdd = new Set();
        // check if we have mesh_n peers in fanout[topic] and add them to the mesh if we do,
        // removing the fanout entry.
        const fanoutPeers = this.fanout.get(topic);
        if (fanoutPeers) {
            // Remove fanout entry and the last published time
            this.fanout.delete(topic);
            this.fanoutLastpub.delete(topic);
            // remove explicit peers, peers with negative scores, and backoffed peers
            fanoutPeers.forEach((id) => {
                // TODO:rust-libp2p checks `self.backoffs.is_backoff_with_slack()`
                if (!this.direct.has(id) && this.score.score(id) >= 0) {
                    toAdd.add(id);
                }
            });
            this.metrics?.onAddToMesh(topic, InclusionReason.Fanout, toAdd.size);
        }
        // check if we need to get more peers, which we randomly select
        if (toAdd.size < this.opts.D) {
            const fanoutCount = toAdd.size;
            const newPeers = this.getRandomGossipPeers(topic, this.opts.D, (id) => 
            // filter direct peers and peers with negative score
            !toAdd.has(id) && !this.direct.has(id) && this.score.score(id) >= 0);
            newPeers.forEach((peer) => {
                toAdd.add(peer);
            });
            this.metrics?.onAddToMesh(topic, InclusionReason.Random, toAdd.size - fanoutCount);
        }
        this.mesh.set(topic, toAdd);
        toAdd.forEach((id) => {
            this.log('JOIN: Add mesh link to %s in %s', id, topic);
            this.sendGraft(id, topic);
            // rust-libp2p
            // - peer_score.graft()
            // - Self::control_pool_add()
            // - peer_added_to_mesh()
        });
    }
    /**
     * Leave topic
     */
    leave(topic) {
        if (this.status.code !== GossipStatusCode.started) {
            throw new Error('Gossipsub has not started');
        }
        this.log('LEAVE %s', topic);
        this.metrics?.onLeave(topic);
        // Send PRUNE to mesh peers
        const meshPeers = this.mesh.get(topic);
        if (meshPeers) {
            Promise.all(Array.from(meshPeers).map(async (id) => {
                this.log('LEAVE: Remove mesh link to %s in %s', id, topic);
                return await this.sendPrune(id, topic);
            })).catch((err) => {
                this.log('Error sending prunes to mesh peers', err);
            });
            this.mesh.delete(topic);
        }
    }
    selectPeersToForward(topic, propagationSource, excludePeers) {
        const tosend = new Set();
        // Add explicit peers
        const peersInTopic = this.topics.get(topic);
        if (peersInTopic) {
            this.direct.forEach((peer) => {
                if (peersInTopic.has(peer) && propagationSource !== peer && !excludePeers?.has(peer)) {
                    tosend.add(peer);
                }
            });
            // As of Mar 2022, spec + golang-libp2p include this while rust-libp2p does not
            // rust-libp2p: https://github.com/libp2p/rust-libp2p/blob/6cc3b4ec52c922bfcf562a29b5805c3150e37c75/protocols/gossipsub/src/behaviour.rs#L2693
            // spec: https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/gossipsub-v1.0.md?plain=1#L361
            this.floodsubPeers.forEach((peer) => {
                if (peersInTopic.has(peer) &&
                    propagationSource !== peer &&
                    !excludePeers?.has(peer) &&
                    this.score.score(peer) >= this.opts.scoreThresholds.publishThreshold) {
                    tosend.add(peer);
                }
            });
        }
        // add mesh peers
        const meshPeers = this.mesh.get(topic);
        if (meshPeers && meshPeers.size > 0) {
            meshPeers.forEach((peer) => {
                if (propagationSource !== peer && !excludePeers?.has(peer)) {
                    tosend.add(peer);
                }
            });
        }
        return tosend;
    }
    selectPeersToPublish(topic) {
        const tosend = new Set();
        const tosendCount = {
            direct: 0,
            floodsub: 0,
            mesh: 0,
            fanout: 0
        };
        const peersInTopic = this.topics.get(topic);
        if (peersInTopic) {
            // flood-publish behavior
            // send to direct peers and _all_ peers meeting the publishThreshold
            if (this.opts.floodPublish) {
                peersInTopic.forEach((id) => {
                    if (this.direct.has(id)) {
                        tosend.add(id);
                        tosendCount.direct++;
                    }
                    else if (this.score.score(id) >= this.opts.scoreThresholds.publishThreshold) {
                        tosend.add(id);
                        tosendCount.floodsub++;
                    }
                });
            }
            else {
                // non-flood-publish behavior
                // send to direct peers, subscribed floodsub peers
                // and some mesh peers above publishThreshold
                // direct peers (if subscribed)
                this.direct.forEach((id) => {
                    if (peersInTopic.has(id)) {
                        tosend.add(id);
                        tosendCount.direct++;
                    }
                });
                // floodsub peers
                // Note: if there are no floodsub peers, we save a loop through peersInTopic Map
                this.floodsubPeers.forEach((id) => {
                    if (peersInTopic.has(id) && this.score.score(id) >= this.opts.scoreThresholds.publishThreshold) {
                        tosend.add(id);
                        tosendCount.floodsub++;
                    }
                });
                // Gossipsub peers handling
                const meshPeers = this.mesh.get(topic);
                if (meshPeers && meshPeers.size > 0) {
                    meshPeers.forEach((peer) => {
                        tosend.add(peer);
                        tosendCount.mesh++;
                    });
                }
                // We are not in the mesh for topic, use fanout peers
                else {
                    const fanoutPeers = this.fanout.get(topic);
                    if (fanoutPeers && fanoutPeers.size > 0) {
                        fanoutPeers.forEach((peer) => {
                            tosend.add(peer);
                            tosendCount.fanout++;
                        });
                    }
                    // We have no fanout peers, select mesh_n of them and add them to the fanout
                    else {
                        // If we are not in the fanout, then pick peers in topic above the publishThreshold
                        const newFanoutPeers = this.getRandomGossipPeers(topic, this.opts.D, (id) => {
                            return this.score.score(id) >= this.opts.scoreThresholds.publishThreshold;
                        });
                        if (newFanoutPeers.size > 0) {
                            // eslint-disable-line max-depth
                            this.fanout.set(topic, newFanoutPeers);
                            newFanoutPeers.forEach((peer) => {
                                // eslint-disable-line max-depth
                                tosend.add(peer);
                                tosendCount.fanout++;
                            });
                        }
                    }
                    // We are publishing to fanout peers - update the time we published
                    this.fanoutLastpub.set(topic, Date.now());
                }
            }
        }
        return { tosend, tosendCount };
    }
    /**
     * Forwards a message from our peers.
     *
     * For messages published by us (the app layer), this class uses `publish`
     */
    forwardMessage(msgIdStr, rawMsg, propagationSource, excludePeers) {
        // message is fully validated inform peer_score
        if (propagationSource) {
            this.score.deliverMessage(propagationSource, msgIdStr, rawMsg.topic);
        }
        const tosend = this.selectPeersToForward(rawMsg.topic, propagationSource, excludePeers);
        // Note: Don't throw if tosend is empty, we can have a mesh with a single peer
        // forward the message to peers
        tosend.forEach((id) => {
            // sendRpc may mutate RPC message on piggyback, create a new message for each peer
            this.sendRpc(id, { messages: [rawMsg] });
        });
        this.metrics?.onForwardMsg(rawMsg.topic, tosend.size);
    }
    /**
     * App layer publishes a message to peers, return number of peers this message is published to
     * Note: `async` due to crypto only if `StrictSign`, otherwise it's a sync fn.
     *
     * For messages not from us, this class uses `forwardMessage`.
     */
    async publish(topic, data, opts) {
        const transformedData = this.dataTransform ? this.dataTransform.outboundTransform(topic, data) : data;
        if (this.publishConfig == null) {
            throw Error('PublishError.Uninitialized');
        }
        // Prepare raw message with user's publishConfig
        const { raw: rawMsg, msg } = await buildRawMessage(this.publishConfig, topic, data, transformedData);
        // calculate the message id from the un-transformed data
        const msgId = await this.msgIdFn(msg);
        const msgIdStr = this.msgIdToStrFn(msgId);
        // Current publish opt takes precedence global opts, while preserving false value
        const ignoreDuplicatePublishError = opts?.ignoreDuplicatePublishError ?? this.opts.ignoreDuplicatePublishError;
        if (this.seenCache.has(msgIdStr)) {
            // This message has already been seen. We don't re-publish messages that have already
            // been published on the network.
            if (ignoreDuplicatePublishError) {
                this.metrics?.onPublishDuplicateMsg(topic);
                return { recipients: [] };
            }
            throw Error('PublishError.Duplicate');
        }
        const { tosend, tosendCount } = this.selectPeersToPublish(topic);
        const willSendToSelf = this.opts.emitSelf === true && this.subscriptions.has(topic);
        // Current publish opt takes precedence global opts, while preserving false value
        const allowPublishToZeroPeers = opts?.allowPublishToZeroPeers ?? this.opts.allowPublishToZeroPeers;
        if (tosend.size === 0 && !allowPublishToZeroPeers && !willSendToSelf) {
            throw Error('PublishError.InsufficientPeers');
        }
        // If the message isn't a duplicate and we have sent it to some peers add it to the
        // duplicate cache and memcache.
        this.seenCache.put(msgIdStr);
        // all published messages are valid
        this.mcache.put({ msgId, msgIdStr }, rawMsg, true);
        // If the message is anonymous or has a random author add it to the published message ids cache.
        this.publishedMessageIds.put(msgIdStr);
        // Send to set of peers aggregated from direct, mesh, fanout
        for (const id of tosend) {
            // sendRpc may mutate RPC message on piggyback, create a new message for each peer
            const sent = this.sendRpc(id, { messages: [rawMsg] });
            // did not actually send the message
            if (!sent) {
                tosend.delete(id);
            }
        }
        this.metrics?.onPublishMsg(topic, tosendCount, tosend.size, rawMsg.data != null ? rawMsg.data.length : 0);
        // Dispatch the message to the user if we are subscribed to the topic
        if (willSendToSelf) {
            tosend.add(this.components.peerId.toString());
            super.dispatchEvent(new CustomEvent('gossipsub:message', {
                detail: {
                    propagationSource: this.components.peerId,
                    msgId: msgIdStr,
                    msg
                }
            }));
            // TODO: Add option to switch between emit per topic or all messages in one
            super.dispatchEvent(new CustomEvent('message', { detail: msg }));
        }
        return {
            recipients: Array.from(tosend.values()).map((str) => peerIdFromString(str))
        };
    }
    /**
     * This function should be called when `asyncValidation` is `true` after
     * the message got validated by the caller. Messages are stored in the `mcache` and
     * validation is expected to be fast enough that the messages should still exist in the cache.
     * There are three possible validation outcomes and the outcome is given in acceptance.
     *
     * If acceptance = `MessageAcceptance.Accept` the message will get propagated to the
     * network. The `propagation_source` parameter indicates who the message was received by and
     * will not be forwarded back to that peer.
     *
     * If acceptance = `MessageAcceptance.Reject` the message will be deleted from the memcache
     * and the P penalty will be applied to the `propagationSource`.
     *
     * If acceptance = `MessageAcceptance.Ignore` the message will be deleted from the memcache
     * but no P penalty will be applied.
     *
     * This function will return true if the message was found in the cache and false if was not
     * in the cache anymore.
     *
     * This should only be called once per message.
     */
    reportMessageValidationResult(msgId, propagationSource, acceptance) {
        if (acceptance === TopicValidatorResult.Accept) {
            const cacheEntry = this.mcache.validate(msgId);
            this.metrics?.onReportValidationMcacheHit(cacheEntry !== null);
            if (cacheEntry != null) {
                const { message: rawMsg, originatingPeers } = cacheEntry;
                // message is fully validated inform peer_score
                this.score.deliverMessage(propagationSource.toString(), msgId, rawMsg.topic);
                this.forwardMessage(msgId, cacheEntry.message, propagationSource.toString(), originatingPeers);
                this.metrics?.onReportValidation(rawMsg.topic, acceptance);
            }
            // else, Message not in cache. Ignoring forwarding
        }
        // Not valid
        else {
            const cacheEntry = this.mcache.remove(msgId);
            this.metrics?.onReportValidationMcacheHit(cacheEntry !== null);
            if (cacheEntry) {
                const rejectReason = rejectReasonFromAcceptance(acceptance);
                const { message: rawMsg, originatingPeers } = cacheEntry;
                // Tell peer_score about reject
                // Reject the original source, and any duplicates we've seen from other peers.
                this.score.rejectMessage(propagationSource.toString(), msgId, rawMsg.topic, rejectReason);
                for (const peer of originatingPeers) {
                    this.score.rejectMessage(peer, msgId, rawMsg.topic, rejectReason);
                }
                this.metrics?.onReportValidation(rawMsg.topic, acceptance);
            }
            // else, Message not in cache. Ignoring forwarding
        }
    }
    /**
     * Sends a GRAFT message to a peer
     */
    sendGraft(id, topic) {
        const graft = [
            {
                topicID: topic
            }
        ];
        this.sendRpc(id, { control: { graft } });
    }
    /**
     * Sends a PRUNE message to a peer
     */
    async sendPrune(id, topic) {
        const prune = [await this.makePrune(id, topic, this.opts.doPX)];
        this.sendRpc(id, { control: { prune } });
    }
    /**
     * Send an rpc object to a peer
     */
    sendRpc(id, rpc) {
        const outboundStream = this.streamsOutbound.get(id);
        if (!outboundStream) {
            this.log(`Cannot send RPC to ${id} as there is no open stream to it available`);
            return false;
        }
        // piggyback control message retries
        const ctrl = this.control.get(id);
        if (ctrl) {
            this.piggybackControl(id, rpc, ctrl);
            this.control.delete(id);
        }
        // piggyback gossip
        const ihave = this.gossip.get(id);
        if (ihave) {
            this.piggybackGossip(id, rpc, ihave);
            this.gossip.delete(id);
        }
        const rpcBytes = RPC.encode(rpc).finish();
        try {
            outboundStream.push(rpcBytes);
        }
        catch (e) {
            this.log.error(`Cannot send rpc to ${id}`, e);
            // if the peer had control messages or gossip, re-attach
            if (ctrl) {
                this.control.set(id, ctrl);
            }
            if (ihave) {
                this.gossip.set(id, ihave);
            }
            return false;
        }
        this.metrics?.onRpcSent(rpc, rpcBytes.length);
        return true;
    }
    /** Mutates `outRpc` adding graft and prune control messages */
    piggybackControl(id, outRpc, ctrl) {
        if (ctrl.graft) {
            if (!outRpc.control)
                outRpc.control = {};
            if (!outRpc.control.graft)
                outRpc.control.graft = [];
            for (const graft of ctrl.graft) {
                if (graft.topicID && this.mesh.get(graft.topicID)?.has(id)) {
                    outRpc.control.graft.push(graft);
                }
            }
        }
        if (ctrl.prune) {
            if (!outRpc.control)
                outRpc.control = {};
            if (!outRpc.control.prune)
                outRpc.control.prune = [];
            for (const prune of ctrl.prune) {
                if (prune.topicID && !this.mesh.get(prune.topicID)?.has(id)) {
                    outRpc.control.prune.push(prune);
                }
            }
        }
    }
    /** Mutates `outRpc` adding ihave control messages */
    piggybackGossip(id, outRpc, ihave) {
        if (!outRpc.control)
            outRpc.control = {};
        outRpc.control.ihave = ihave;
    }
    /**
     * Send graft and prune messages
     *
     * @param tograft - peer id => topic[]
     * @param toprune - peer id => topic[]
     */
    async sendGraftPrune(tograft, toprune, noPX) {
        const doPX = this.opts.doPX;
        for (const [id, topics] of tograft) {
            const graft = topics.map((topicID) => ({ topicID }));
            let prune = [];
            // If a peer also has prunes, process them now
            const pruning = toprune.get(id);
            if (pruning) {
                prune = await Promise.all(pruning.map(async (topicID) => await this.makePrune(id, topicID, doPX && !(noPX.get(id) ?? false))));
                toprune.delete(id);
            }
            this.sendRpc(id, { control: { graft, prune } });
        }
        for (const [id, topics] of toprune) {
            const prune = await Promise.all(topics.map(async (topicID) => await this.makePrune(id, topicID, doPX && !(noPX.get(id) ?? false))));
            this.sendRpc(id, { control: { prune } });
        }
    }
    /**
     * Emits gossip - Send IHAVE messages to a random set of gossip peers
     */
    emitGossip(peersToGossipByTopic) {
        const gossipIDsByTopic = this.mcache.getGossipIDs(new Set(peersToGossipByTopic.keys()));
        for (const [topic, peersToGossip] of peersToGossipByTopic) {
            this.doEmitGossip(topic, peersToGossip, gossipIDsByTopic.get(topic) ?? []);
        }
    }
    /**
     * Send gossip messages to GossipFactor peers above threshold with a minimum of D_lazy
     * Peers are randomly selected from the heartbeat which exclude mesh + fanout peers
     * We also exclude direct peers, as there is no reason to emit gossip to them
     * @param topic
     * @param candidateToGossip - peers to gossip
     * @param messageIDs - message ids to gossip
     */
    doEmitGossip(topic, candidateToGossip, messageIDs) {
        if (!messageIDs.length) {
            return;
        }
        // shuffle to emit in random order
        shuffle(messageIDs);
        // if we are emitting more than GossipsubMaxIHaveLength ids, truncate the list
        if (messageIDs.length > GossipsubMaxIHaveLength) {
            // we do the truncation (with shuffling) per peer below
            this.log('too many messages for gossip; will truncate IHAVE list (%d messages)', messageIDs.length);
        }
        if (!candidateToGossip.size)
            return;
        let target = this.opts.Dlazy;
        const factor = GossipsubGossipFactor * candidateToGossip.size;
        let peersToGossip = candidateToGossip;
        if (factor > target) {
            target = factor;
        }
        if (target > peersToGossip.size) {
            target = peersToGossip.size;
        }
        else {
            // only shuffle if needed
            peersToGossip = shuffle(Array.from(peersToGossip)).slice(0, target);
        }
        // Emit the IHAVE gossip to the selected peers up to the target
        peersToGossip.forEach((id) => {
            let peerMessageIDs = messageIDs;
            if (messageIDs.length > GossipsubMaxIHaveLength) {
                // shuffle and slice message IDs per peer so that we emit a different set for each peer
                // we have enough reduncancy in the system that this will significantly increase the message
                // coverage when we do truncate
                peerMessageIDs = shuffle(peerMessageIDs.slice()).slice(0, GossipsubMaxIHaveLength);
            }
            this.pushGossip(id, {
                topicID: topic,
                messageIDs: peerMessageIDs
            });
        });
    }
    /**
     * Flush gossip and control messages
     */
    flush() {
        // send gossip first, which will also piggyback control
        for (const [peer, ihave] of this.gossip.entries()) {
            this.gossip.delete(peer);
            this.sendRpc(peer, { control: { ihave } });
        }
        // send the remaining control messages
        for (const [peer, control] of this.control.entries()) {
            this.control.delete(peer);
            this.sendRpc(peer, { control: { graft: control.graft, prune: control.prune } });
        }
    }
    /**
     * Adds new IHAVE messages to pending gossip
     */
    pushGossip(id, controlIHaveMsgs) {
        this.log('Add gossip to %s', id);
        const gossip = this.gossip.get(id) || [];
        this.gossip.set(id, gossip.concat(controlIHaveMsgs));
    }
    /**
     * Make a PRUNE control message for a peer in a topic
     */
    async makePrune(id, topic, doPX) {
        this.score.prune(id, topic);
        if (this.streamsOutbound.get(id).protocol === GossipsubIDv10) {
            // Gossipsub v1.0 -- no backoff, the peer won't be able to parse it anyway
            return {
                topicID: topic,
                peers: []
            };
        }
        // backoff is measured in seconds
        // GossipsubPruneBackoff is measured in milliseconds
        // The protobuf has it as a uint64
        const backoff = this.opts.pruneBackoff / 1000;
        if (!doPX) {
            return {
                topicID: topic,
                peers: [],
                backoff: backoff
            };
        }
        // select peers for Peer eXchange
        const peers = this.getRandomGossipPeers(topic, this.opts.prunePeers, (xid) => {
            return xid !== id && this.score.score(xid) >= 0;
        });
        const px = await Promise.all(Array.from(peers).map(async (peerId) => {
            // see if we have a signed record to send back; if we don't, just send
            // the peer ID and let the pruned peer find them in the DHT -- we can't trust
            // unsigned address records through PX anyways
            // Finding signed records in the DHT is not supported at the time of writing in js-libp2p
            const id = peerIdFromString(peerId);
            return {
                peerID: id.toBytes(),
                signedPeerRecord: await this.components.peerStore.addressBook.getRawEnvelope(id)
            };
        }));
        return {
            topicID: topic,
            peers: px,
            backoff: backoff
        };
    }
    /**
     * Maintains the mesh and fanout maps in gossipsub.
     */
    async heartbeat() {
        const { D, Dlo, Dhi, Dscore, Dout, fanoutTTL } = this.opts;
        this.heartbeatTicks++;
        // cache scores throught the heartbeat
        const scores = new Map();
        const getScore = (id) => {
            let s = scores.get(id);
            if (s === undefined) {
                s = this.score.score(id);
                scores.set(id, s);
            }
            return s;
        };
        // peer id => topic[]
        const tograft = new Map();
        // peer id => topic[]
        const toprune = new Map();
        // peer id => don't px
        const noPX = new Map();
        // clean up expired backoffs
        this.clearBackoff();
        // clean up peerhave/iasked counters
        this.peerhave.clear();
        this.metrics?.cacheSize.set({ cache: 'iasked' }, this.iasked.size);
        this.iasked.clear();
        // apply IWANT request penalties
        this.applyIwantPenalties();
        // ensure direct peers are connected
        if (this.heartbeatTicks % this.opts.directConnectTicks === 0) {
            // we only do this every few ticks to allow pending connections to complete and account for restarts/downtime
            await this.directConnect();
        }
        // EXTRA: Prune caches
        this.fastMsgIdCache?.prune();
        this.seenCache.prune();
        this.gossipTracer.prune();
        this.publishedMessageIds.prune();
        /**
         * Instead of calling getRandomGossipPeers multiple times to:
         *   + get more mesh peers
         *   + more outbound peers
         *   + oppportunistic grafting
         *   + emitGossip
         *
         * We want to loop through the topic peers only a single time and prepare gossip peers for all topics to improve the performance
         */
        const peersToGossipByTopic = new Map();
        // maintain the mesh for topics we have joined
        this.mesh.forEach((peers, topic) => {
            const peersInTopic = this.topics.get(topic);
            const candidateMeshPeers = new Set();
            const peersToGossip = new Set();
            peersToGossipByTopic.set(topic, peersToGossip);
            if (peersInTopic) {
                const shuffledPeers = shuffle(Array.from(peersInTopic));
                const backoff = this.backoff.get(topic);
                for (const id of shuffledPeers) {
                    const peerStreams = this.streamsOutbound.get(id);
                    if (peerStreams &&
                        this.multicodecs.includes(peerStreams.protocol) &&
                        !peers.has(id) &&
                        !this.direct.has(id)) {
                        const score = getScore(id);
                        if ((!backoff || !backoff.has(id)) && score >= 0)
                            candidateMeshPeers.add(id);
                        // instead of having to find gossip peers after heartbeat which require another loop
                        // we prepare peers to gossip in a topic within heartbeat to improve performance
                        if (score >= this.opts.scoreThresholds.gossipThreshold)
                            peersToGossip.add(id);
                    }
                }
            }
            // prune/graft helper functions (defined per topic)
            const prunePeer = (id, reason) => {
                this.log('HEARTBEAT: Remove mesh link to %s in %s', id, topic);
                // no need to update peer score here as we do it in makePrune
                // add prune backoff record
                this.addBackoff(id, topic);
                // remove peer from mesh
                peers.delete(id);
                // after pruning a peer from mesh, we want to gossip topic to it if its score meet the gossip threshold
                if (getScore(id) >= this.opts.scoreThresholds.gossipThreshold)
                    peersToGossip.add(id);
                this.metrics?.onRemoveFromMesh(topic, reason, 1);
                // add to toprune
                const topics = toprune.get(id);
                if (!topics) {
                    toprune.set(id, [topic]);
                }
                else {
                    topics.push(topic);
                }
            };
            const graftPeer = (id, reason) => {
                this.log('HEARTBEAT: Add mesh link to %s in %s', id, topic);
                // update peer score
                this.score.graft(id, topic);
                // add peer to mesh
                peers.add(id);
                // when we add a new mesh peer, we don't want to gossip messages to it
                peersToGossip.delete(id);
                this.metrics?.onAddToMesh(topic, reason, 1);
                // add to tograft
                const topics = tograft.get(id);
                if (!topics) {
                    tograft.set(id, [topic]);
                }
                else {
                    topics.push(topic);
                }
            };
            // drop all peers with negative score, without PX
            peers.forEach((id) => {
                const score = getScore(id);
                // Record the score
                if (score < 0) {
                    this.log('HEARTBEAT: Prune peer %s with negative score: score=%d, topic=%s', id, score, topic);
                    prunePeer(id, ChurnReason.BadScore);
                    noPX.set(id, true);
                }
            });
            // do we have enough peers?
            if (peers.size < Dlo) {
                const ineed = D - peers.size;
                // slice up to first `ineed` items and remove them from candidateMeshPeers
                // same to `const newMeshPeers = candidateMeshPeers.slice(0, ineed)`
                const newMeshPeers = removeFirstNItemsFromSet(candidateMeshPeers, ineed);
                newMeshPeers.forEach((p) => {
                    graftPeer(p, InclusionReason.NotEnough);
                });
            }
            // do we have to many peers?
            if (peers.size > Dhi) {
                let peersArray = Array.from(peers);
                // sort by score
                peersArray.sort((a, b) => getScore(b) - getScore(a));
                // We keep the first D_score peers by score and the remaining up to D randomly
                // under the constraint that we keep D_out peers in the mesh (if we have that many)
                peersArray = peersArray.slice(0, Dscore).concat(shuffle(peersArray.slice(Dscore)));
                // count the outbound peers we are keeping
                let outbound = 0;
                peersArray.slice(0, D).forEach((p) => {
                    if (this.outbound.get(p)) {
                        outbound++;
                    }
                });
                // if it's less than D_out, bubble up some outbound peers from the random selection
                if (outbound < Dout) {
                    const rotate = (i) => {
                        // rotate the peersArray to the right and put the ith peer in the front
                        const p = peersArray[i];
                        for (let j = i; j > 0; j--) {
                            peersArray[j] = peersArray[j - 1];
                        }
                        peersArray[0] = p;
                    };
                    // first bubble up all outbound peers already in the selection to the front
                    if (outbound > 0) {
                        let ihave = outbound;
                        for (let i = 1; i < D && ihave > 0; i++) {
                            if (this.outbound.get(peersArray[i])) {
                                rotate(i);
                                ihave--;
                            }
                        }
                    }
                    // now bubble up enough outbound peers outside the selection to the front
                    let ineed = D - outbound;
                    for (let i = D; i < peersArray.length && ineed > 0; i++) {
                        if (this.outbound.get(peersArray[i])) {
                            rotate(i);
                            ineed--;
                        }
                    }
                }
                // prune the excess peers
                peersArray.slice(D).forEach((p) => {
                    prunePeer(p, ChurnReason.Excess);
                });
            }
            // do we have enough outbound peers?
            if (peers.size >= Dlo) {
                // count the outbound peers we have
                let outbound = 0;
                peers.forEach((p) => {
                    if (this.outbound.get(p)) {
                        outbound++;
                    }
                });
                // if it's less than D_out, select some peers with outbound connections and graft them
                if (outbound < Dout) {
                    const ineed = Dout - outbound;
                    const newMeshPeers = removeItemsFromSet(candidateMeshPeers, ineed, (id) => this.outbound.get(id) === true);
                    newMeshPeers.forEach((p) => {
                        graftPeer(p, InclusionReason.Outbound);
                    });
                }
            }
            // should we try to improve the mesh with opportunistic grafting?
            if (this.heartbeatTicks % this.opts.opportunisticGraftTicks === 0 && peers.size > 1) {
                // Opportunistic grafting works as follows: we check the median score of peers in the
                // mesh; if this score is below the opportunisticGraftThreshold, we select a few peers at
                // random with score over the median.
                // The intention is to (slowly) improve an underperforming mesh by introducing good
                // scoring peers that may have been gossiping at us. This allows us to get out of sticky
                // situations where we are stuck with poor peers and also recover from churn of good peers.
                // now compute the median peer score in the mesh
                const peersList = Array.from(peers).sort((a, b) => getScore(a) - getScore(b));
                const medianIndex = Math.floor(peers.size / 2);
                const medianScore = getScore(peersList[medianIndex]);
                // if the median score is below the threshold, select a better peer (if any) and GRAFT
                if (medianScore < this.opts.scoreThresholds.opportunisticGraftThreshold) {
                    const ineed = this.opts.opportunisticGraftPeers;
                    const newMeshPeers = removeItemsFromSet(candidateMeshPeers, ineed, (id) => getScore(id) > medianScore);
                    for (const id of newMeshPeers) {
                        this.log('HEARTBEAT: Opportunistically graft peer %s on topic %s', id, topic);
                        graftPeer(id, InclusionReason.Opportunistic);
                    }
                }
            }
        });
        // expire fanout for topics we haven't published to in a while
        const now = Date.now();
        this.fanoutLastpub.forEach((lastpb, topic) => {
            if (lastpb + fanoutTTL < now) {
                this.fanout.delete(topic);
                this.fanoutLastpub.delete(topic);
            }
        });
        // maintain our fanout for topics we are publishing but we have not joined
        this.fanout.forEach((fanoutPeers, topic) => {
            // checks whether our peers are still in the topic and have a score above the publish threshold
            const topicPeers = this.topics.get(topic);
            fanoutPeers.forEach((id) => {
                if (!topicPeers.has(id) || getScore(id) < this.opts.scoreThresholds.publishThreshold) {
                    fanoutPeers.delete(id);
                }
            });
            const peersInTopic = this.topics.get(topic);
            const candidateFanoutPeers = [];
            // the fanout map contains topics to which we are not subscribed.
            const peersToGossip = new Set();
            peersToGossipByTopic.set(topic, peersToGossip);
            if (peersInTopic) {
                const shuffledPeers = shuffle(Array.from(peersInTopic));
                for (const id of shuffledPeers) {
                    const peerStreams = this.streamsOutbound.get(id);
                    if (peerStreams &&
                        this.multicodecs.includes(peerStreams.protocol) &&
                        !fanoutPeers.has(id) &&
                        !this.direct.has(id)) {
                        const score = getScore(id);
                        if (score >= this.opts.scoreThresholds.publishThreshold)
                            candidateFanoutPeers.push(id);
                        // instead of having to find gossip peers after heartbeat which require another loop
                        // we prepare peers to gossip in a topic within heartbeat to improve performance
                        if (score >= this.opts.scoreThresholds.gossipThreshold)
                            peersToGossip.add(id);
                    }
                }
            }
            // do we need more peers?
            if (fanoutPeers.size < D) {
                const ineed = D - fanoutPeers.size;
                candidateFanoutPeers.slice(0, ineed).forEach((id) => {
                    fanoutPeers.add(id);
                    peersToGossip?.delete(id);
                });
            }
        });
        this.emitGossip(peersToGossipByTopic);
        // send coalesced GRAFT/PRUNE messages (will piggyback gossip)
        await this.sendGraftPrune(tograft, toprune, noPX);
        // flush pending gossip that wasn't piggybacked above
        this.flush();
        // advance the message history window
        this.mcache.shift();
        this.dispatchEvent(new CustomEvent('gossipsub:heartbeat'));
    }
    /**
     * Given a topic, returns up to count peers subscribed to that topic
     * that pass an optional filter function
     *
     * @param topic
     * @param count
     * @param filter - a function to filter acceptable peers
     */
    getRandomGossipPeers(topic, count, filter = () => true) {
        const peersInTopic = this.topics.get(topic);
        if (!peersInTopic) {
            return new Set();
        }
        // Adds all peers using our protocol
        // that also pass the filter function
        let peers = [];
        peersInTopic.forEach((id) => {
            const peerStreams = this.streamsOutbound.get(id);
            if (!peerStreams) {
                return;
            }
            if (this.multicodecs.includes(peerStreams.protocol) && filter(id)) {
                peers.push(id);
            }
        });
        // Pseudo-randomly shuffles peers
        peers = shuffle(peers);
        if (count > 0 && peers.length > count) {
            peers = peers.slice(0, count);
        }
        return new Set(peers);
    }
    onScrapeMetrics(metrics) {
        /* Data structure sizes */
        metrics.mcacheSize.set(this.mcache.size);
        metrics.mcacheNotValidatedCount.set(this.mcache.notValidatedCount);
        // Arbitrary size
        metrics.cacheSize.set({ cache: 'direct' }, this.direct.size);
        metrics.cacheSize.set({ cache: 'seenCache' }, this.seenCache.size);
        metrics.cacheSize.set({ cache: 'fastMsgIdCache' }, this.fastMsgIdCache?.size ?? 0);
        metrics.cacheSize.set({ cache: 'publishedMessageIds' }, this.publishedMessageIds.size);
        metrics.cacheSize.set({ cache: 'mcache' }, this.mcache.size);
        metrics.cacheSize.set({ cache: 'score' }, this.score.size);
        metrics.cacheSize.set({ cache: 'gossipTracer.promises' }, this.gossipTracer.size);
        metrics.cacheSize.set({ cache: 'gossipTracer.requests' }, this.gossipTracer.requestMsByMsgSize);
        // Bounded by topic
        metrics.cacheSize.set({ cache: 'topics' }, this.topics.size);
        metrics.cacheSize.set({ cache: 'subscriptions' }, this.subscriptions.size);
        metrics.cacheSize.set({ cache: 'mesh' }, this.mesh.size);
        metrics.cacheSize.set({ cache: 'fanout' }, this.fanout.size);
        // Bounded by peer
        metrics.cacheSize.set({ cache: 'peers' }, this.peers.size);
        metrics.cacheSize.set({ cache: 'streamsOutbound' }, this.streamsOutbound.size);
        metrics.cacheSize.set({ cache: 'streamsInbound' }, this.streamsInbound.size);
        metrics.cacheSize.set({ cache: 'acceptFromWhitelist' }, this.acceptFromWhitelist.size);
        metrics.cacheSize.set({ cache: 'gossip' }, this.gossip.size);
        metrics.cacheSize.set({ cache: 'control' }, this.control.size);
        metrics.cacheSize.set({ cache: 'peerhave' }, this.peerhave.size);
        metrics.cacheSize.set({ cache: 'outbound' }, this.outbound.size);
        // 2D nested data structure
        let backoffSize = 0;
        for (const backoff of this.backoff.values()) {
            backoffSize += backoff.size;
        }
        metrics.cacheSize.set({ cache: 'backoff' }, backoffSize);
        // Peer counts
        for (const [topicStr, peers] of this.topics) {
            metrics.topicPeersCount.set({ topicStr }, peers.size);
        }
        for (const [topicStr, peers] of this.mesh) {
            metrics.meshPeerCounts.set({ topicStr }, peers.size);
        }
        // Peer scores
        const scores = [];
        const scoreByPeer = new Map();
        metrics.behaviourPenalty.reset();
        for (const peerIdStr of this.peers.keys()) {
            const score = this.score.score(peerIdStr);
            scores.push(score);
            scoreByPeer.set(peerIdStr, score);
            metrics.behaviourPenalty.observe(this.score.peerStats.get(peerIdStr)?.behaviourPenalty ?? 0);
        }
        metrics.registerScores(scores, this.opts.scoreThresholds);
        // Breakdown score per mesh topicLabel
        metrics.registerScorePerMesh(this.mesh, scoreByPeer);
        // Breakdown on each score weight
        const sw = computeAllPeersScoreWeights(this.peers.keys(), this.score.peerStats, this.score.params, this.score.peerIPs, metrics.topicStrToLabel);
        metrics.registerScoreWeights(sw);
    }
}
GossipSub.multicodec = GossipsubIDv11;

const log$H = debug("waku:relay");
function messageValidator(peer, message) {
    const startTime = performance.now();
    log$H(`validating message from ${peer} received on ${message.topic}`);
    let result = TopicValidatorResult.Accept;
    try {
        const protoMessage = WakuMessage$3.decode(message.data);
        if (!protoMessage.contentTopic ||
            !protoMessage.contentTopic.length ||
            !protoMessage.payload ||
            !protoMessage.payload.length) {
            result = TopicValidatorResult.Reject;
        }
    }
    catch (e) {
        result = TopicValidatorResult.Reject;
    }
    const endTime = performance.now();
    log$H(`Validation time (must be <100ms): ${endTime - startTime}ms`);
    return result;
}

const log$G = debug("waku:relay");
/**
 * Implements the [Waku v2 Relay protocol](https://rfc.vac.dev/spec/11/).
 * Throws if libp2p.pubsub does not support Waku Relay
 */
let Relay$1 = class Relay {
    constructor(libp2p, options) {
        if (!this.isRelayPubSub(libp2p.pubsub)) {
            throw Error(`Failed to initialize Relay. libp2p.pubsub does not support ${Relay.multicodec}`);
        }
        this.gossipSub = libp2p.pubsub;
        this.pubSubTopic = options?.pubSubTopic ?? DefaultPubSubTopic;
        if (this.gossipSub.isStarted()) {
            this.gossipSubSubscribe(this.pubSubTopic);
        }
        this.observers = new Map();
        // TODO: User might want to decide what decoder should be used (e.g. for RLN)
        this.defaultDecoder = new TopicOnlyDecoder();
    }
    /**
     * Mounts the gossipsub protocol onto the libp2p node
     * and subscribes to the default topic.
     *
     * @override
     * @returns {void}
     */
    async start() {
        if (this.gossipSub.isStarted()) {
            throw Error("GossipSub already started.");
        }
        await this.gossipSub.start();
        this.gossipSubSubscribe(this.pubSubTopic);
    }
    /**
     * Send Waku message.
     */
    async send(encoder, message) {
        const msg = await encoder.toWire(message);
        if (!msg) {
            log$G("Failed to encode message, aborting publish");
            return { recipients: [] };
        }
        return this.gossipSub.publish(this.pubSubTopic, msg);
    }
    /**
     * Add an observer and associated Decoder to process incoming messages on a given content topic.
     *
     * @returns Function to delete the observer
     */
    subscribe(decoders, callback) {
        const contentTopicToObservers = Array.isArray(decoders)
            ? toObservers(decoders, callback)
            : toObservers([decoders], callback);
        for (const contentTopic of contentTopicToObservers.keys()) {
            const currObservers = this.observers.get(contentTopic) || new Set();
            const newObservers = contentTopicToObservers.get(contentTopic) || new Set();
            this.observers.set(contentTopic, union(currObservers, newObservers));
        }
        return () => {
            for (const contentTopic of contentTopicToObservers.keys()) {
                const currentObservers = this.observers.get(contentTopic) || new Set();
                const observersToRemove = contentTopicToObservers.get(contentTopic) || new Set();
                const nextObservers = leftMinusJoin(currentObservers, observersToRemove);
                if (nextObservers.size) {
                    this.observers.set(contentTopic, nextObservers);
                }
                else {
                    this.observers.delete(contentTopic);
                }
            }
        };
    }
    getActiveSubscriptions() {
        const map = new Map();
        map.set(this.pubSubTopic, this.observers.keys());
        return map;
    }
    getMeshPeers(topic) {
        return this.gossipSub.getMeshPeers(topic ?? this.pubSubTopic);
    }
    async processIncomingMessage(pubSubTopic, bytes) {
        const topicOnlyMsg = await this.defaultDecoder.fromWireToProtoObj(bytes);
        if (!topicOnlyMsg || !topicOnlyMsg.contentTopic) {
            log$G("Message does not have a content topic, skipping");
            return;
        }
        const observers = this.observers.get(topicOnlyMsg.contentTopic);
        if (!observers) {
            return;
        }
        await Promise.all(Array.from(observers).map(async ({ decoder, callback }) => {
            const protoMsg = await decoder.fromWireToProtoObj(bytes);
            if (!protoMsg) {
                log$G("Internal error: message previously decoded failed on 2nd pass.");
                return;
            }
            const msg = await decoder.fromProtoObj(pubSubTopic, protoMsg);
            if (msg) {
                callback(msg);
            }
            else {
                log$G("Failed to decode messages on", topicOnlyMsg.contentTopic);
            }
        }));
    }
    /**
     * Subscribe to a pubsub topic and start emitting Waku messages to observers.
     *
     * @override
     */
    gossipSubSubscribe(pubSubTopic) {
        this.gossipSub.addEventListener("gossipsub:message", async (event) => {
            if (event.detail.msg.topic !== pubSubTopic)
                return;
            log$G(`Message received on ${pubSubTopic}`);
            this.processIncomingMessage(event.detail.msg.topic, event.detail.msg.data).catch((e) => log$G("Failed to process incoming message", e));
        });
        this.gossipSub.topicValidators.set(pubSubTopic, messageValidator);
        this.gossipSub.subscribe(pubSubTopic);
    }
    isRelayPubSub(pubsub) {
        return pubsub?.multicodecs?.includes(Relay.multicodec) || false;
    }
};
Relay$1.multicodec = RelayCodecs[0];
function wakuRelay(init = {}) {
    return (libp2p) => new Relay$1(libp2p, init);
}
function wakuGossipSub(init = {}) {
    return (components) => {
        init = {
            ...init,
            // Ensure that no signature is included nor expected in the messages.
            globalSignaturePolicy: SignaturePolicy.StrictNoSign,
            fallbackToFloodsub: false,
        };
        const pubsub = new GossipSub(components, init);
        pubsub.multicodecs = RelayCodecs;
        return pubsub;
    };
}
function toObservers(decoders, callback) {
    const contentTopicToDecoders = Array.from(groupByContentTopic(decoders).entries());
    const contentTopicToObserversEntries = contentTopicToDecoders.map(([contentTopic, decoders]) => [
        contentTopic,
        new Set(decoders.map((decoder) => ({
            decoder,
            callback,
        }))),
    ]);
    return new Map(contentTopicToObserversEntries);
}
function union(left, right) {
    for (const val of right.values()) {
        left.add(val);
    }
    return left;
}
function leftMinusJoin(left, right) {
    for (const val of right.values()) {
        if (left.has(val)) {
            left.delete(val);
        }
    }
    return left;
}

function number(n) {
    if (!Number.isSafeInteger(n) || n < 0)
        throw new Error(`Wrong positive integer: ${n}`);
}
function bool(b) {
    if (typeof b !== 'boolean')
        throw new Error(`Expected boolean, not ${b}`);
}
function bytes(b, ...lengths) {
    if (!(b instanceof Uint8Array))
        throw new TypeError('Expected Uint8Array');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new TypeError(`Expected Uint8Array of length ${lengths}, not of length=${b.length}`);
}
function hash(hash) {
    if (typeof hash !== 'function' || typeof hash.create !== 'function')
        throw new Error('Hash should be wrapped by utils.wrapConstructor');
    number(hash.outputLen);
    number(hash.blockLen);
}
function exists(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
function output(out, instance) {
    bytes(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error(`digestInto() expects output buffer of length at least ${min}`);
    }
}
const assert = {
    number,
    bool,
    bytes,
    hash,
    exists,
    output,
};

/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Cast array to view
const createView = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
// The rotate right (circular right shift) operation for uint32
const rotr = (word, shift) => (word << (32 - shift)) | (word >>> shift);
// big-endian hardware is rare. Just in case someone still decides to run hashes:
// early-throw an error because we don't support BE yet.
const isLE = new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;
if (!isLE)
    throw new Error('Non little-endian hardware is not supported');
Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, '0'));
function utf8ToBytes$1(str) {
    if (typeof str !== 'string') {
        throw new TypeError(`utf8ToBytes expected string, got ${typeof str}`);
    }
    return new TextEncoder().encode(str);
}
function toBytes$1(data) {
    if (typeof data === 'string')
        data = utf8ToBytes$1(data);
    if (!(data instanceof Uint8Array))
        throw new TypeError(`Expected input type is Uint8Array (got ${typeof data})`);
    return data;
}
// For runtime check if class implements interface
class Hash {
    // Safe version that clones internal state
    clone() {
        return this._cloneInto();
    }
}
function wrapConstructor(hashConstructor) {
    const hashC = (message) => hashConstructor().update(toBytes$1(message)).digest();
    const tmp = hashConstructor();
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = () => hashConstructor();
    return hashC;
}

// Polyfill for Safari 14
function setBigUint64(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = isLE ? 4 : 0;
    const l = isLE ? 0 : 4;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}
// Base SHA2 class (RFC 6234)
class SHA2 extends Hash {
    constructor(blockLen, outputLen, padOffset, isLE) {
        super();
        this.blockLen = blockLen;
        this.outputLen = outputLen;
        this.padOffset = padOffset;
        this.isLE = isLE;
        this.finished = false;
        this.length = 0;
        this.pos = 0;
        this.destroyed = false;
        this.buffer = new Uint8Array(blockLen);
        this.view = createView(this.buffer);
    }
    update(data) {
        assert.exists(this);
        const { view, buffer, blockLen } = this;
        data = toBytes$1(data);
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input, cast it to view and process
            if (take === blockLen) {
                const dataView = createView(data);
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(dataView, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(view, 0);
                this.pos = 0;
            }
        }
        this.length += data.length;
        this.roundClean();
        return this;
    }
    digestInto(out) {
        assert.exists(this);
        assert.output(out, this);
        this.finished = true;
        // Padding
        // We can avoid allocation of buffer for padding completely if it
        // was previously not allocated here. But it won't change performance.
        const { buffer, view, blockLen, isLE } = this;
        let { pos } = this;
        // append the bit '1' to the message
        buffer[pos++] = 0b10000000;
        this.buffer.subarray(pos).fill(0);
        // we have less than padOffset left in buffer, so we cannot put length in current block, need process it and pad again
        if (this.padOffset > blockLen - pos) {
            this.process(view, 0);
            pos = 0;
        }
        // Pad until full block byte with zeros
        for (let i = pos; i < blockLen; i++)
            buffer[i] = 0;
        // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that
        // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.
        // So we just write lowest 64 bits of that value.
        setBigUint64(view, blockLen - 8, BigInt(this.length * 8), isLE);
        this.process(view, 0);
        const oview = createView(out);
        const len = this.outputLen;
        // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT
        if (len % 4)
            throw new Error('_sha2: outputLen should be aligned to 32bit');
        const outLen = len / 4;
        const state = this.get();
        if (outLen > state.length)
            throw new Error('_sha2: outputLen bigger than state');
        for (let i = 0; i < outLen; i++)
            oview.setUint32(4 * i, state[i], isLE);
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
    _cloneInto(to) {
        to || (to = new this.constructor());
        to.set(...this.get());
        const { blockLen, buffer, length, finished, destroyed, pos } = this;
        to.length = length;
        to.pos = pos;
        to.finished = finished;
        to.destroyed = destroyed;
        if (length % blockLen)
            to.buffer.set(buffer);
        return to;
    }
}

// Choice: a ? b : c
const Chi = (a, b, c) => (a & b) ^ (~a & c);
// Majority function, true if any two inpust is true
const Maj = (a, b, c) => (a & b) ^ (a & c) ^ (b & c);
// Round constants:
// first 32 bits of the fractional parts of the cube roots of the first 64 primes 2..311)
// prettier-ignore
const SHA256_K = new Uint32Array([
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
]);
// Initial state (first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19):
// prettier-ignore
const IV = new Uint32Array([
    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
]);
// Temporary buffer, not used to store anything between runs
// Named this way because it matches specification.
const SHA256_W = new Uint32Array(64);
class SHA256 extends SHA2 {
    constructor() {
        super(64, 32, 8, false);
        // We cannot use array here since array allows indexing by variable
        // which means optimizer/compiler cannot use registers.
        this.A = IV[0] | 0;
        this.B = IV[1] | 0;
        this.C = IV[2] | 0;
        this.D = IV[3] | 0;
        this.E = IV[4] | 0;
        this.F = IV[5] | 0;
        this.G = IV[6] | 0;
        this.H = IV[7] | 0;
    }
    get() {
        const { A, B, C, D, E, F, G, H } = this;
        return [A, B, C, D, E, F, G, H];
    }
    // prettier-ignore
    set(A, B, C, D, E, F, G, H) {
        this.A = A | 0;
        this.B = B | 0;
        this.C = C | 0;
        this.D = D | 0;
        this.E = E | 0;
        this.F = F | 0;
        this.G = G | 0;
        this.H = H | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4)
            SHA256_W[i] = view.getUint32(offset, false);
        for (let i = 16; i < 64; i++) {
            const W15 = SHA256_W[i - 15];
            const W2 = SHA256_W[i - 2];
            const s0 = rotr(W15, 7) ^ rotr(W15, 18) ^ (W15 >>> 3);
            const s1 = rotr(W2, 17) ^ rotr(W2, 19) ^ (W2 >>> 10);
            SHA256_W[i] = (s1 + SHA256_W[i - 7] + s0 + SHA256_W[i - 16]) | 0;
        }
        // Compression function main loop, 64 rounds
        let { A, B, C, D, E, F, G, H } = this;
        for (let i = 0; i < 64; i++) {
            const sigma1 = rotr(E, 6) ^ rotr(E, 11) ^ rotr(E, 25);
            const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;
            const sigma0 = rotr(A, 2) ^ rotr(A, 13) ^ rotr(A, 22);
            const T2 = (sigma0 + Maj(A, B, C)) | 0;
            H = G;
            G = F;
            F = E;
            E = (D + T1) | 0;
            D = C;
            C = B;
            B = A;
            A = (T1 + T2) | 0;
        }
        // Add the compressed chunk to the current hash value
        A = (A + this.A) | 0;
        B = (B + this.B) | 0;
        C = (C + this.C) | 0;
        D = (D + this.D) | 0;
        E = (E + this.E) | 0;
        F = (F + this.F) | 0;
        G = (G + this.G) | 0;
        H = (H + this.H) | 0;
        this.set(A, B, C, D, E, F, G, H);
    }
    roundClean() {
        SHA256_W.fill(0);
    }
    destroy() {
        this.set(0, 0, 0, 0, 0, 0, 0, 0);
        this.buffer.fill(0);
    }
}
// Constants from https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf
class SHA224 extends SHA256 {
    constructor() {
        super();
        this.A = 0xc1059ed8 | 0;
        this.B = 0x367cd507 | 0;
        this.C = 0x3070dd17 | 0;
        this.D = 0xf70e5939 | 0;
        this.E = 0xffc00b31 | 0;
        this.F = 0x68581511 | 0;
        this.G = 0x64f98fa7 | 0;
        this.H = 0xbefa4fa4 | 0;
        this.outputLen = 28;
    }
}
/**
 * SHA2-256 hash function
 * @param message - data that would be hashed
 */
wrapConstructor(() => new SHA256());
wrapConstructor(() => new SHA224());

function isDefined(value) {
    return Boolean(value);
}

/**
 * Convert input to a byte array.
 *
 * Handles both `0x` prefixed and non-prefixed strings.
 */
function hexToBytes(hex) {
    if (typeof hex === "string") {
        const _hex = hex.replace(/^0x/i, "");
        return fromString$2(_hex.toLowerCase(), "base16");
    }
    return hex;
}
/**
 * Convert byte array to hex string (no `0x` prefix).
 */
const bytesToHex = (bytes) => toString$7(bytes, "base16");
/**
 * Decode byte array to utf-8 string.
 */
const bytesToUtf8 = (b) => toString$7(b, "utf8");
/**
 * Encode utf-8 string to byte array.
 */
const utf8ToBytes = (s) => fromString$2(s, "utf8");

const OneMillion = BigInt(1000000);
var PageDirection;
(function (PageDirection) {
    PageDirection["BACKWARD"] = "backward";
    PageDirection["FORWARD"] = "forward";
})(PageDirection || (PageDirection = {}));
class HistoryRpc {
    constructor(proto) {
        this.proto = proto;
    }
    get query() {
        return this.proto.query;
    }
    get response() {
        return this.proto.response;
    }
    /**
     * Create History Query.
     */
    static createQuery(params) {
        const contentFilters = params.contentTopics.map((contentTopic) => {
            return { contentTopic };
        });
        const direction = directionToProto(params.pageDirection);
        const pagingInfo = {
            pageSize: BigInt(params.pageSize),
            cursor: params.cursor,
            direction,
        };
        let startTime, endTime;
        if (params.startTime) {
            // milliseconds 10^-3 to nanoseconds 10^-9
            startTime = BigInt(params.startTime.valueOf()) * OneMillion;
        }
        if (params.endTime) {
            // milliseconds 10^-3 to nanoseconds 10^-9
            endTime = BigInt(params.endTime.valueOf()) * OneMillion;
        }
        return new HistoryRpc({
            requestId: v4$2(),
            query: {
                pubsubTopic: params.pubSubTopic,
                contentFilters,
                pagingInfo,
                startTime,
                endTime,
            },
            response: undefined,
        });
    }
    decode(bytes) {
        const res = HistoryRpc$1.decode(bytes);
        return new HistoryRpc(res);
    }
    encode() {
        return HistoryRpc$1.encode(this.proto);
    }
}
function directionToProto(pageDirection) {
    switch (pageDirection) {
        case PageDirection.BACKWARD:
            return PagingInfo.Direction.BACKWARD;
        case PageDirection.FORWARD:
            return PagingInfo.Direction.FORWARD;
        default:
            return PagingInfo.Direction.BACKWARD;
    }
}

var HistoryError = HistoryResponse.HistoryError;
const log$F = debug("waku:store");
const StoreCodec = "/vac/waku/store/2.0.0-beta4";
const DefaultPageSize = 10;
/**
 * Implements the [Waku v2 Store protocol](https://rfc.vac.dev/spec/13/).
 *
 * The Waku Store protocol can be used to retrieved historical messages.
 */
class Store extends BaseProtocol {
    constructor(libp2p, options) {
        super(StoreCodec, libp2p.peerStore, libp2p.getConnections.bind(libp2p));
        this.libp2p = libp2p;
        this.options = options ?? {};
    }
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     *
     * The callback function takes a `WakuMessage` in input,
     * messages are processed in order:
     * - oldest to latest if `options.pageDirection` == { @link PageDirection.FORWARD }
     * - latest to oldest if `options.pageDirection` == { @link PageDirection.BACKWARD }
     *
     * The ordering may affect performance.
     * The ordering depends on the behavior of the remote store node.
     * If strong ordering is needed, you may need to handle this at application level
     * and set your own timestamps too (the WakuMessage timestamps are not certified).
     *
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     */
    async queryOrderedCallback(decoders, callback, options) {
        let abort = false;
        for await (const promises of this.queryGenerator(decoders, options)) {
            if (abort)
                break;
            const messagesOrUndef = await Promise.all(promises);
            let messages = messagesOrUndef.filter(isDefined);
            // Messages in pages are ordered from oldest (first) to most recent (last).
            // https://github.com/vacp2p/rfc/issues/533
            if (typeof options?.pageDirection === "undefined" ||
                options?.pageDirection === PageDirection.BACKWARD) {
                messages = messages.reverse();
            }
            await Promise.all(messages.map(async (msg) => {
                if (msg && !abort) {
                    abort = Boolean(await callback(msg));
                }
            }));
        }
    }
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     *
     * The callback function takes a `Promise<WakuMessage>` in input,
     * useful if messages needs to be decrypted and performance matters.
     *
     * The order of the messages passed to the callback is as follows:
     * - within a page, messages are expected to be ordered from oldest to most recent
     * - pages direction depends on { @link QueryOptions.pageDirection }
     *
     * Do note that the resolution of the `Promise<WakuMessage | undefined` may
     * break the order as it may rely on the browser decryption API, which in turn,
     * may have a different speed depending on the type of decryption.
     *
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     */
    async queryCallbackOnPromise(decoders, callback, options) {
        let abort = false;
        let promises = [];
        for await (const page of this.queryGenerator(decoders, options)) {
            const _promises = page.map(async (msg) => {
                if (!abort) {
                    abort = Boolean(await callback(msg));
                }
            });
            promises = promises.concat(_promises);
        }
        await Promise.all(promises);
    }
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     *
     * This is a generator, useful if you want most control on how messages
     * are processed.
     *
     * The order of the messages returned by the remote Waku node SHOULD BE
     * as follows:
     * - within a page, messages SHOULD be ordered from oldest to most recent
     * - pages direction depends on { @link QueryOptions.pageDirection }
     *
     * However, there is no way to guarantee the behavior of the remote node.
     *
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     */
    async *queryGenerator(decoders, options) {
        const { pubSubTopic = DefaultPubSubTopic } = this.options;
        let startTime, endTime;
        if (options?.timeFilter) {
            startTime = options.timeFilter.startTime;
            endTime = options.timeFilter.endTime;
        }
        const decodersAsMap = new Map();
        decoders.forEach((dec) => {
            if (decodersAsMap.has(dec.contentTopic)) {
                throw new Error("API does not support different decoder per content topic");
            }
            decodersAsMap.set(dec.contentTopic, dec);
        });
        const contentTopics = decoders.map((dec) => dec.contentTopic);
        const queryOpts = Object.assign({
            pubSubTopic: pubSubTopic,
            pageDirection: PageDirection.BACKWARD,
            pageSize: DefaultPageSize,
        }, options, { contentTopics, startTime, endTime });
        log$F("Querying history with the following options", {
            ...options,
            peerId: options?.peerId?.toString(),
        });
        const peer = await this.getPeer(options?.peerId);
        for await (const messages of paginate(this.newStream.bind(this, peer), queryOpts, decodersAsMap, options?.cursor)) {
            yield messages;
        }
    }
}
async function* paginate(streamFactory, queryOpts, decoders, cursor) {
    if (queryOpts.contentTopics.toString() !==
        Array.from(decoders.keys()).toString()) {
        throw new Error("Internal error, the decoders should match the query's content topics");
    }
    let currentCursor = cursor;
    while (true) {
        queryOpts.cursor = currentCursor;
        const historyRpcQuery = HistoryRpc.createQuery(queryOpts);
        log$F("Querying store peer", `for (${queryOpts.pubSubTopic})`, queryOpts.contentTopics);
        const stream = await streamFactory();
        const res = await pipe([historyRpcQuery.encode()], encode$b(), stream, decode$a(), async (source) => await all(source));
        const bytes = new Uint8ArrayList();
        res.forEach((chunk) => {
            bytes.append(chunk);
        });
        const reply = historyRpcQuery.decode(bytes);
        if (!reply.response) {
            log$F("Stopping pagination due to store `response` field missing");
            break;
        }
        const response = reply.response;
        if (response.error && response.error !== HistoryError.NONE) {
            throw "History response contains an Error: " + response.error;
        }
        if (!response.messages || !response.messages.length) {
            log$F("Stopping pagination due to store `response.messages` field missing or empty");
            break;
        }
        log$F(`${response.messages.length} messages retrieved from store`);
        yield response.messages.map((protoMsg) => {
            const contentTopic = protoMsg.contentTopic;
            if (typeof contentTopic !== "undefined") {
                const decoder = decoders.get(contentTopic);
                if (decoder) {
                    return decoder.fromProtoObj(queryOpts.pubSubTopic, toProtoMessage(protoMsg));
                }
            }
            return Promise.resolve(undefined);
        });
        const nextCursor = response.pagingInfo?.cursor;
        if (typeof nextCursor === "undefined") {
            // If the server does not return cursor then there is an issue,
            // Need to abort, or we end up in an infinite loop
            log$F("Stopping pagination due to `response.pagingInfo.cursor` missing from store response");
            break;
        }
        currentCursor = nextCursor;
        const responsePageSize = response.pagingInfo?.pageSize;
        const queryPageSize = historyRpcQuery.query?.pagingInfo?.pageSize;
        if (
        // Response page size smaller than query, meaning this is the last page
        responsePageSize &&
            queryPageSize &&
            responsePageSize < queryPageSize) {
            break;
        }
    }
}
function wakuStore(init = {}) {
    return (libp2p) => new Store(libp2p, init);
}

debug("waku:wait-for-remote-peer");

const symbol$2 = Symbol.for('@libp2p/peer-discovery');

// Maximum encoded size of an ENR
const ERR_INVALID_ID = "Invalid record id";
// The maximum length of byte size of a multiaddr to encode in the `multiaddr` field
// The size is a big endian 16-bit unsigned integer
const MULTIADDR_LENGTH_SIZE = 2;

var sha3Exports = {};
var sha3$1 = {
  get exports(){ return sha3Exports; },
  set exports(v){ sha3Exports = v; },
};

/**
 * [js-sha3]{@link https://github.com/emn178/js-sha3}
 *
 * @version 0.8.0
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2015-2018
 * @license MIT
 */

(function (module) {
	/*jslint bitwise: true */
	(function () {

	  var INPUT_ERROR = 'input is invalid type';
	  var FINALIZE_ERROR = 'finalize already called';
	  var WINDOW = typeof window === 'object';
	  var root = WINDOW ? window : {};
	  if (root.JS_SHA3_NO_WINDOW) {
	    WINDOW = false;
	  }
	  var WEB_WORKER = !WINDOW && typeof self === 'object';
	  var NODE_JS = !root.JS_SHA3_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
	  if (NODE_JS) {
	    root = commonjsGlobal;
	  } else if (WEB_WORKER) {
	    root = self;
	  }
	  var COMMON_JS = !root.JS_SHA3_NO_COMMON_JS && 'object' === 'object' && module.exports;
	  var ARRAY_BUFFER = !root.JS_SHA3_NO_ARRAY_BUFFER && typeof ArrayBuffer !== 'undefined';
	  var HEX_CHARS = '0123456789abcdef'.split('');
	  var SHAKE_PADDING = [31, 7936, 2031616, 520093696];
	  var CSHAKE_PADDING = [4, 1024, 262144, 67108864];
	  var KECCAK_PADDING = [1, 256, 65536, 16777216];
	  var PADDING = [6, 1536, 393216, 100663296];
	  var SHIFT = [0, 8, 16, 24];
	  var RC = [1, 0, 32898, 0, 32906, 2147483648, 2147516416, 2147483648, 32907, 0, 2147483649,
	    0, 2147516545, 2147483648, 32777, 2147483648, 138, 0, 136, 0, 2147516425, 0,
	    2147483658, 0, 2147516555, 0, 139, 2147483648, 32905, 2147483648, 32771,
	    2147483648, 32770, 2147483648, 128, 2147483648, 32778, 0, 2147483658, 2147483648,
	    2147516545, 2147483648, 32896, 2147483648, 2147483649, 0, 2147516424, 2147483648];
	  var BITS = [224, 256, 384, 512];
	  var SHAKE_BITS = [128, 256];
	  var OUTPUT_TYPES = ['hex', 'buffer', 'arrayBuffer', 'array', 'digest'];
	  var CSHAKE_BYTEPAD = {
	    '128': 168,
	    '256': 136
	  };

	  if (root.JS_SHA3_NO_NODE_JS || !Array.isArray) {
	    Array.isArray = function (obj) {
	      return Object.prototype.toString.call(obj) === '[object Array]';
	    };
	  }

	  if (ARRAY_BUFFER && (root.JS_SHA3_NO_ARRAY_BUFFER_IS_VIEW || !ArrayBuffer.isView)) {
	    ArrayBuffer.isView = function (obj) {
	      return typeof obj === 'object' && obj.buffer && obj.buffer.constructor === ArrayBuffer;
	    };
	  }

	  var createOutputMethod = function (bits, padding, outputType) {
	    return function (message) {
	      return new Keccak(bits, padding, bits).update(message)[outputType]();
	    };
	  };

	  var createShakeOutputMethod = function (bits, padding, outputType) {
	    return function (message, outputBits) {
	      return new Keccak(bits, padding, outputBits).update(message)[outputType]();
	    };
	  };

	  var createCshakeOutputMethod = function (bits, padding, outputType) {
	    return function (message, outputBits, n, s) {
	      return methods['cshake' + bits].update(message, outputBits, n, s)[outputType]();
	    };
	  };

	  var createKmacOutputMethod = function (bits, padding, outputType) {
	    return function (key, message, outputBits, s) {
	      return methods['kmac' + bits].update(key, message, outputBits, s)[outputType]();
	    };
	  };

	  var createOutputMethods = function (method, createMethod, bits, padding) {
	    for (var i = 0; i < OUTPUT_TYPES.length; ++i) {
	      var type = OUTPUT_TYPES[i];
	      method[type] = createMethod(bits, padding, type);
	    }
	    return method;
	  };

	  var createMethod = function (bits, padding) {
	    var method = createOutputMethod(bits, padding, 'hex');
	    method.create = function () {
	      return new Keccak(bits, padding, bits);
	    };
	    method.update = function (message) {
	      return method.create().update(message);
	    };
	    return createOutputMethods(method, createOutputMethod, bits, padding);
	  };

	  var createShakeMethod = function (bits, padding) {
	    var method = createShakeOutputMethod(bits, padding, 'hex');
	    method.create = function (outputBits) {
	      return new Keccak(bits, padding, outputBits);
	    };
	    method.update = function (message, outputBits) {
	      return method.create(outputBits).update(message);
	    };
	    return createOutputMethods(method, createShakeOutputMethod, bits, padding);
	  };

	  var createCshakeMethod = function (bits, padding) {
	    var w = CSHAKE_BYTEPAD[bits];
	    var method = createCshakeOutputMethod(bits, padding, 'hex');
	    method.create = function (outputBits, n, s) {
	      if (!n && !s) {
	        return methods['shake' + bits].create(outputBits);
	      } else {
	        return new Keccak(bits, padding, outputBits).bytepad([n, s], w);
	      }
	    };
	    method.update = function (message, outputBits, n, s) {
	      return method.create(outputBits, n, s).update(message);
	    };
	    return createOutputMethods(method, createCshakeOutputMethod, bits, padding);
	  };

	  var createKmacMethod = function (bits, padding) {
	    var w = CSHAKE_BYTEPAD[bits];
	    var method = createKmacOutputMethod(bits, padding, 'hex');
	    method.create = function (key, outputBits, s) {
	      return new Kmac(bits, padding, outputBits).bytepad(['KMAC', s], w).bytepad([key], w);
	    };
	    method.update = function (key, message, outputBits, s) {
	      return method.create(key, outputBits, s).update(message);
	    };
	    return createOutputMethods(method, createKmacOutputMethod, bits, padding);
	  };

	  var algorithms = [
	    { name: 'keccak', padding: KECCAK_PADDING, bits: BITS, createMethod: createMethod },
	    { name: 'sha3', padding: PADDING, bits: BITS, createMethod: createMethod },
	    { name: 'shake', padding: SHAKE_PADDING, bits: SHAKE_BITS, createMethod: createShakeMethod },
	    { name: 'cshake', padding: CSHAKE_PADDING, bits: SHAKE_BITS, createMethod: createCshakeMethod },
	    { name: 'kmac', padding: CSHAKE_PADDING, bits: SHAKE_BITS, createMethod: createKmacMethod }
	  ];

	  var methods = {}, methodNames = [];

	  for (var i = 0; i < algorithms.length; ++i) {
	    var algorithm = algorithms[i];
	    var bits = algorithm.bits;
	    for (var j = 0; j < bits.length; ++j) {
	      var methodName = algorithm.name + '_' + bits[j];
	      methodNames.push(methodName);
	      methods[methodName] = algorithm.createMethod(bits[j], algorithm.padding);
	      if (algorithm.name !== 'sha3') {
	        var newMethodName = algorithm.name + bits[j];
	        methodNames.push(newMethodName);
	        methods[newMethodName] = methods[methodName];
	      }
	    }
	  }

	  function Keccak(bits, padding, outputBits) {
	    this.blocks = [];
	    this.s = [];
	    this.padding = padding;
	    this.outputBits = outputBits;
	    this.reset = true;
	    this.finalized = false;
	    this.block = 0;
	    this.start = 0;
	    this.blockCount = (1600 - (bits << 1)) >> 5;
	    this.byteCount = this.blockCount << 2;
	    this.outputBlocks = outputBits >> 5;
	    this.extraBytes = (outputBits & 31) >> 3;

	    for (var i = 0; i < 50; ++i) {
	      this.s[i] = 0;
	    }
	  }

	  Keccak.prototype.update = function (message) {
	    if (this.finalized) {
	      throw new Error(FINALIZE_ERROR);
	    }
	    var notString, type = typeof message;
	    if (type !== 'string') {
	      if (type === 'object') {
	        if (message === null) {
	          throw new Error(INPUT_ERROR);
	        } else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
	          message = new Uint8Array(message);
	        } else if (!Array.isArray(message)) {
	          if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) {
	            throw new Error(INPUT_ERROR);
	          }
	        }
	      } else {
	        throw new Error(INPUT_ERROR);
	      }
	      notString = true;
	    }
	    var blocks = this.blocks, byteCount = this.byteCount, length = message.length,
	      blockCount = this.blockCount, index = 0, s = this.s, i, code;

	    while (index < length) {
	      if (this.reset) {
	        this.reset = false;
	        blocks[0] = this.block;
	        for (i = 1; i < blockCount + 1; ++i) {
	          blocks[i] = 0;
	        }
	      }
	      if (notString) {
	        for (i = this.start; index < length && i < byteCount; ++index) {
	          blocks[i >> 2] |= message[index] << SHIFT[i++ & 3];
	        }
	      } else {
	        for (i = this.start; index < length && i < byteCount; ++index) {
	          code = message.charCodeAt(index);
	          if (code < 0x80) {
	            blocks[i >> 2] |= code << SHIFT[i++ & 3];
	          } else if (code < 0x800) {
	            blocks[i >> 2] |= (0xc0 | (code >> 6)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          } else if (code < 0xd800 || code >= 0xe000) {
	            blocks[i >> 2] |= (0xe0 | (code >> 12)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          } else {
	            code = 0x10000 + (((code & 0x3ff) << 10) | (message.charCodeAt(++index) & 0x3ff));
	            blocks[i >> 2] |= (0xf0 | (code >> 18)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 12) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          }
	        }
	      }
	      this.lastByteIndex = i;
	      if (i >= byteCount) {
	        this.start = i - byteCount;
	        this.block = blocks[blockCount];
	        for (i = 0; i < blockCount; ++i) {
	          s[i] ^= blocks[i];
	        }
	        f(s);
	        this.reset = true;
	      } else {
	        this.start = i;
	      }
	    }
	    return this;
	  };

	  Keccak.prototype.encode = function (x, right) {
	    var o = x & 255, n = 1;
	    var bytes = [o];
	    x = x >> 8;
	    o = x & 255;
	    while (o > 0) {
	      bytes.unshift(o);
	      x = x >> 8;
	      o = x & 255;
	      ++n;
	    }
	    if (right) {
	      bytes.push(n);
	    } else {
	      bytes.unshift(n);
	    }
	    this.update(bytes);
	    return bytes.length;
	  };

	  Keccak.prototype.encodeString = function (str) {
	    var notString, type = typeof str;
	    if (type !== 'string') {
	      if (type === 'object') {
	        if (str === null) {
	          throw new Error(INPUT_ERROR);
	        } else if (ARRAY_BUFFER && str.constructor === ArrayBuffer) {
	          str = new Uint8Array(str);
	        } else if (!Array.isArray(str)) {
	          if (!ARRAY_BUFFER || !ArrayBuffer.isView(str)) {
	            throw new Error(INPUT_ERROR);
	          }
	        }
	      } else {
	        throw new Error(INPUT_ERROR);
	      }
	      notString = true;
	    }
	    var bytes = 0, length = str.length;
	    if (notString) {
	      bytes = length;
	    } else {
	      for (var i = 0; i < str.length; ++i) {
	        var code = str.charCodeAt(i);
	        if (code < 0x80) {
	          bytes += 1;
	        } else if (code < 0x800) {
	          bytes += 2;
	        } else if (code < 0xd800 || code >= 0xe000) {
	          bytes += 3;
	        } else {
	          code = 0x10000 + (((code & 0x3ff) << 10) | (str.charCodeAt(++i) & 0x3ff));
	          bytes += 4;
	        }
	      }
	    }
	    bytes += this.encode(bytes * 8);
	    this.update(str);
	    return bytes;
	  };

	  Keccak.prototype.bytepad = function (strs, w) {
	    var bytes = this.encode(w);
	    for (var i = 0; i < strs.length; ++i) {
	      bytes += this.encodeString(strs[i]);
	    }
	    var paddingBytes = w - bytes % w;
	    var zeros = [];
	    zeros.length = paddingBytes;
	    this.update(zeros);
	    return this;
	  };

	  Keccak.prototype.finalize = function () {
	    if (this.finalized) {
	      return;
	    }
	    this.finalized = true;
	    var blocks = this.blocks, i = this.lastByteIndex, blockCount = this.blockCount, s = this.s;
	    blocks[i >> 2] |= this.padding[i & 3];
	    if (this.lastByteIndex === this.byteCount) {
	      blocks[0] = blocks[blockCount];
	      for (i = 1; i < blockCount + 1; ++i) {
	        blocks[i] = 0;
	      }
	    }
	    blocks[blockCount - 1] |= 0x80000000;
	    for (i = 0; i < blockCount; ++i) {
	      s[i] ^= blocks[i];
	    }
	    f(s);
	  };

	  Keccak.prototype.toString = Keccak.prototype.hex = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var hex = '', block;
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        block = s[i];
	        hex += HEX_CHARS[(block >> 4) & 0x0F] + HEX_CHARS[block & 0x0F] +
	          HEX_CHARS[(block >> 12) & 0x0F] + HEX_CHARS[(block >> 8) & 0x0F] +
	          HEX_CHARS[(block >> 20) & 0x0F] + HEX_CHARS[(block >> 16) & 0x0F] +
	          HEX_CHARS[(block >> 28) & 0x0F] + HEX_CHARS[(block >> 24) & 0x0F];
	      }
	      if (j % blockCount === 0) {
	        f(s);
	        i = 0;
	      }
	    }
	    if (extraBytes) {
	      block = s[i];
	      hex += HEX_CHARS[(block >> 4) & 0x0F] + HEX_CHARS[block & 0x0F];
	      if (extraBytes > 1) {
	        hex += HEX_CHARS[(block >> 12) & 0x0F] + HEX_CHARS[(block >> 8) & 0x0F];
	      }
	      if (extraBytes > 2) {
	        hex += HEX_CHARS[(block >> 20) & 0x0F] + HEX_CHARS[(block >> 16) & 0x0F];
	      }
	    }
	    return hex;
	  };

	  Keccak.prototype.arrayBuffer = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var bytes = this.outputBits >> 3;
	    var buffer;
	    if (extraBytes) {
	      buffer = new ArrayBuffer((outputBlocks + 1) << 2);
	    } else {
	      buffer = new ArrayBuffer(bytes);
	    }
	    var array = new Uint32Array(buffer);
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        array[j] = s[i];
	      }
	      if (j % blockCount === 0) {
	        f(s);
	      }
	    }
	    if (extraBytes) {
	      array[i] = s[i];
	      buffer = buffer.slice(0, bytes);
	    }
	    return buffer;
	  };

	  Keccak.prototype.buffer = Keccak.prototype.arrayBuffer;

	  Keccak.prototype.digest = Keccak.prototype.array = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var array = [], offset, block;
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        offset = j << 2;
	        block = s[i];
	        array[offset] = block & 0xFF;
	        array[offset + 1] = (block >> 8) & 0xFF;
	        array[offset + 2] = (block >> 16) & 0xFF;
	        array[offset + 3] = (block >> 24) & 0xFF;
	      }
	      if (j % blockCount === 0) {
	        f(s);
	      }
	    }
	    if (extraBytes) {
	      offset = j << 2;
	      block = s[i];
	      array[offset] = block & 0xFF;
	      if (extraBytes > 1) {
	        array[offset + 1] = (block >> 8) & 0xFF;
	      }
	      if (extraBytes > 2) {
	        array[offset + 2] = (block >> 16) & 0xFF;
	      }
	    }
	    return array;
	  };

	  function Kmac(bits, padding, outputBits) {
	    Keccak.call(this, bits, padding, outputBits);
	  }

	  Kmac.prototype = new Keccak();

	  Kmac.prototype.finalize = function () {
	    this.encode(this.outputBits, true);
	    return Keccak.prototype.finalize.call(this);
	  };

	  var f = function (s) {
	    var h, l, n, c0, c1, c2, c3, c4, c5, c6, c7, c8, c9,
	      b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, b10, b11, b12, b13, b14, b15, b16, b17,
	      b18, b19, b20, b21, b22, b23, b24, b25, b26, b27, b28, b29, b30, b31, b32, b33,
	      b34, b35, b36, b37, b38, b39, b40, b41, b42, b43, b44, b45, b46, b47, b48, b49;
	    for (n = 0; n < 48; n += 2) {
	      c0 = s[0] ^ s[10] ^ s[20] ^ s[30] ^ s[40];
	      c1 = s[1] ^ s[11] ^ s[21] ^ s[31] ^ s[41];
	      c2 = s[2] ^ s[12] ^ s[22] ^ s[32] ^ s[42];
	      c3 = s[3] ^ s[13] ^ s[23] ^ s[33] ^ s[43];
	      c4 = s[4] ^ s[14] ^ s[24] ^ s[34] ^ s[44];
	      c5 = s[5] ^ s[15] ^ s[25] ^ s[35] ^ s[45];
	      c6 = s[6] ^ s[16] ^ s[26] ^ s[36] ^ s[46];
	      c7 = s[7] ^ s[17] ^ s[27] ^ s[37] ^ s[47];
	      c8 = s[8] ^ s[18] ^ s[28] ^ s[38] ^ s[48];
	      c9 = s[9] ^ s[19] ^ s[29] ^ s[39] ^ s[49];

	      h = c8 ^ ((c2 << 1) | (c3 >>> 31));
	      l = c9 ^ ((c3 << 1) | (c2 >>> 31));
	      s[0] ^= h;
	      s[1] ^= l;
	      s[10] ^= h;
	      s[11] ^= l;
	      s[20] ^= h;
	      s[21] ^= l;
	      s[30] ^= h;
	      s[31] ^= l;
	      s[40] ^= h;
	      s[41] ^= l;
	      h = c0 ^ ((c4 << 1) | (c5 >>> 31));
	      l = c1 ^ ((c5 << 1) | (c4 >>> 31));
	      s[2] ^= h;
	      s[3] ^= l;
	      s[12] ^= h;
	      s[13] ^= l;
	      s[22] ^= h;
	      s[23] ^= l;
	      s[32] ^= h;
	      s[33] ^= l;
	      s[42] ^= h;
	      s[43] ^= l;
	      h = c2 ^ ((c6 << 1) | (c7 >>> 31));
	      l = c3 ^ ((c7 << 1) | (c6 >>> 31));
	      s[4] ^= h;
	      s[5] ^= l;
	      s[14] ^= h;
	      s[15] ^= l;
	      s[24] ^= h;
	      s[25] ^= l;
	      s[34] ^= h;
	      s[35] ^= l;
	      s[44] ^= h;
	      s[45] ^= l;
	      h = c4 ^ ((c8 << 1) | (c9 >>> 31));
	      l = c5 ^ ((c9 << 1) | (c8 >>> 31));
	      s[6] ^= h;
	      s[7] ^= l;
	      s[16] ^= h;
	      s[17] ^= l;
	      s[26] ^= h;
	      s[27] ^= l;
	      s[36] ^= h;
	      s[37] ^= l;
	      s[46] ^= h;
	      s[47] ^= l;
	      h = c6 ^ ((c0 << 1) | (c1 >>> 31));
	      l = c7 ^ ((c1 << 1) | (c0 >>> 31));
	      s[8] ^= h;
	      s[9] ^= l;
	      s[18] ^= h;
	      s[19] ^= l;
	      s[28] ^= h;
	      s[29] ^= l;
	      s[38] ^= h;
	      s[39] ^= l;
	      s[48] ^= h;
	      s[49] ^= l;

	      b0 = s[0];
	      b1 = s[1];
	      b32 = (s[11] << 4) | (s[10] >>> 28);
	      b33 = (s[10] << 4) | (s[11] >>> 28);
	      b14 = (s[20] << 3) | (s[21] >>> 29);
	      b15 = (s[21] << 3) | (s[20] >>> 29);
	      b46 = (s[31] << 9) | (s[30] >>> 23);
	      b47 = (s[30] << 9) | (s[31] >>> 23);
	      b28 = (s[40] << 18) | (s[41] >>> 14);
	      b29 = (s[41] << 18) | (s[40] >>> 14);
	      b20 = (s[2] << 1) | (s[3] >>> 31);
	      b21 = (s[3] << 1) | (s[2] >>> 31);
	      b2 = (s[13] << 12) | (s[12] >>> 20);
	      b3 = (s[12] << 12) | (s[13] >>> 20);
	      b34 = (s[22] << 10) | (s[23] >>> 22);
	      b35 = (s[23] << 10) | (s[22] >>> 22);
	      b16 = (s[33] << 13) | (s[32] >>> 19);
	      b17 = (s[32] << 13) | (s[33] >>> 19);
	      b48 = (s[42] << 2) | (s[43] >>> 30);
	      b49 = (s[43] << 2) | (s[42] >>> 30);
	      b40 = (s[5] << 30) | (s[4] >>> 2);
	      b41 = (s[4] << 30) | (s[5] >>> 2);
	      b22 = (s[14] << 6) | (s[15] >>> 26);
	      b23 = (s[15] << 6) | (s[14] >>> 26);
	      b4 = (s[25] << 11) | (s[24] >>> 21);
	      b5 = (s[24] << 11) | (s[25] >>> 21);
	      b36 = (s[34] << 15) | (s[35] >>> 17);
	      b37 = (s[35] << 15) | (s[34] >>> 17);
	      b18 = (s[45] << 29) | (s[44] >>> 3);
	      b19 = (s[44] << 29) | (s[45] >>> 3);
	      b10 = (s[6] << 28) | (s[7] >>> 4);
	      b11 = (s[7] << 28) | (s[6] >>> 4);
	      b42 = (s[17] << 23) | (s[16] >>> 9);
	      b43 = (s[16] << 23) | (s[17] >>> 9);
	      b24 = (s[26] << 25) | (s[27] >>> 7);
	      b25 = (s[27] << 25) | (s[26] >>> 7);
	      b6 = (s[36] << 21) | (s[37] >>> 11);
	      b7 = (s[37] << 21) | (s[36] >>> 11);
	      b38 = (s[47] << 24) | (s[46] >>> 8);
	      b39 = (s[46] << 24) | (s[47] >>> 8);
	      b30 = (s[8] << 27) | (s[9] >>> 5);
	      b31 = (s[9] << 27) | (s[8] >>> 5);
	      b12 = (s[18] << 20) | (s[19] >>> 12);
	      b13 = (s[19] << 20) | (s[18] >>> 12);
	      b44 = (s[29] << 7) | (s[28] >>> 25);
	      b45 = (s[28] << 7) | (s[29] >>> 25);
	      b26 = (s[38] << 8) | (s[39] >>> 24);
	      b27 = (s[39] << 8) | (s[38] >>> 24);
	      b8 = (s[48] << 14) | (s[49] >>> 18);
	      b9 = (s[49] << 14) | (s[48] >>> 18);

	      s[0] = b0 ^ (~b2 & b4);
	      s[1] = b1 ^ (~b3 & b5);
	      s[10] = b10 ^ (~b12 & b14);
	      s[11] = b11 ^ (~b13 & b15);
	      s[20] = b20 ^ (~b22 & b24);
	      s[21] = b21 ^ (~b23 & b25);
	      s[30] = b30 ^ (~b32 & b34);
	      s[31] = b31 ^ (~b33 & b35);
	      s[40] = b40 ^ (~b42 & b44);
	      s[41] = b41 ^ (~b43 & b45);
	      s[2] = b2 ^ (~b4 & b6);
	      s[3] = b3 ^ (~b5 & b7);
	      s[12] = b12 ^ (~b14 & b16);
	      s[13] = b13 ^ (~b15 & b17);
	      s[22] = b22 ^ (~b24 & b26);
	      s[23] = b23 ^ (~b25 & b27);
	      s[32] = b32 ^ (~b34 & b36);
	      s[33] = b33 ^ (~b35 & b37);
	      s[42] = b42 ^ (~b44 & b46);
	      s[43] = b43 ^ (~b45 & b47);
	      s[4] = b4 ^ (~b6 & b8);
	      s[5] = b5 ^ (~b7 & b9);
	      s[14] = b14 ^ (~b16 & b18);
	      s[15] = b15 ^ (~b17 & b19);
	      s[24] = b24 ^ (~b26 & b28);
	      s[25] = b25 ^ (~b27 & b29);
	      s[34] = b34 ^ (~b36 & b38);
	      s[35] = b35 ^ (~b37 & b39);
	      s[44] = b44 ^ (~b46 & b48);
	      s[45] = b45 ^ (~b47 & b49);
	      s[6] = b6 ^ (~b8 & b0);
	      s[7] = b7 ^ (~b9 & b1);
	      s[16] = b16 ^ (~b18 & b10);
	      s[17] = b17 ^ (~b19 & b11);
	      s[26] = b26 ^ (~b28 & b20);
	      s[27] = b27 ^ (~b29 & b21);
	      s[36] = b36 ^ (~b38 & b30);
	      s[37] = b37 ^ (~b39 & b31);
	      s[46] = b46 ^ (~b48 & b40);
	      s[47] = b47 ^ (~b49 & b41);
	      s[8] = b8 ^ (~b0 & b2);
	      s[9] = b9 ^ (~b1 & b3);
	      s[18] = b18 ^ (~b10 & b12);
	      s[19] = b19 ^ (~b11 & b13);
	      s[28] = b28 ^ (~b20 & b22);
	      s[29] = b29 ^ (~b21 & b23);
	      s[38] = b38 ^ (~b30 & b32);
	      s[39] = b39 ^ (~b31 & b33);
	      s[48] = b48 ^ (~b40 & b42);
	      s[49] = b49 ^ (~b41 & b43);

	      s[0] ^= RC[n];
	      s[1] ^= RC[n + 1];
	    }
	  };

	  if (COMMON_JS) {
	    module.exports = methods;
	  } else {
	    for (i = 0; i < methodNames.length; ++i) {
	      root[methodNames[i]] = methods[methodNames[i]];
	    }
	  }
	})();
} (sha3$1));

var sha3 = sha3Exports;

function keccak256(input) {
    return new Uint8Array(sha3.keccak256.arrayBuffer(input));
}
/**
 * Verify an ECDSA signature.
 */
function verifySignature(signature, message, publicKey) {
    try {
        const _signature = Signature$1.fromCompact(signature.slice(0, 64));
        return verify$1(_signature, message, publicKey);
    }
    catch {
        return false;
    }
}

const isV4 = isIPv4;
const isV6 = isIPv6;
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const toBytes = function (ip) {
    let offset = 0;
    ip = ip.toString().trim();
    if (isV4(ip)) {
        const bytes = new Uint8Array(offset + 4);
        ip.split(/\./g).forEach((byte) => {
            bytes[offset++] = parseInt(byte, 10) & 0xff;
        });
        return bytes;
    }
    if (isV6(ip)) {
        const sections = ip.split(':', 8);
        let i;
        for (i = 0; i < sections.length; i++) {
            const isv4 = isV4(sections[i]);
            let v4Buffer;
            if (isv4) {
                v4Buffer = toBytes(sections[i]);
                sections[i] = toString$7(v4Buffer.slice(0, 2), 'base16');
            }
            if (v4Buffer != null && ++i < 8) {
                sections.splice(i, 0, toString$7(v4Buffer.slice(2, 4), 'base16'));
            }
        }
        if (sections[0] === '') {
            while (sections.length < 8)
                sections.unshift('0');
        }
        else if (sections[sections.length - 1] === '') {
            while (sections.length < 8)
                sections.push('0');
        }
        else if (sections.length < 8) {
            for (i = 0; i < sections.length && sections[i] !== ''; i++)
                ;
            const argv = [i, 1];
            for (i = 9 - sections.length; i > 0; i--) {
                argv.push('0');
            }
            sections.splice.apply(sections, argv);
        }
        const bytes = new Uint8Array(offset + 16);
        for (i = 0; i < sections.length; i++) {
            const word = parseInt(sections[i], 16);
            bytes[offset++] = (word >> 8) & 0xff;
            bytes[offset++] = word & 0xff;
        }
        return bytes;
    }
    throw new Error('invalid ip address');
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L63
const toString$5 = function (buf, offset = 0, length) {
    offset = ~~offset;
    length = length ?? (buf.length - offset);
    const view = new DataView(buf.buffer);
    if (length === 4) {
        const result = [];
        // IPv4
        for (let i = 0; i < length; i++) {
            result.push(buf[offset + i]);
        }
        return result.join('.');
    }
    if (length === 16) {
        const result = [];
        // IPv6
        for (let i = 0; i < length; i += 2) {
            result.push(view.getUint16(offset + i).toString(16));
        }
        return result.join(':')
            .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')
            .replace(/:{3,4}/, '::');
    }
    return '';
};

const V = -1;
const names = {};
const codes$2 = {};
const table = [
    [4, 32, 'ip4'],
    [6, 16, 'tcp'],
    [33, 16, 'dccp'],
    [41, 128, 'ip6'],
    [42, V, 'ip6zone'],
    [43, 8, 'ipcidr'],
    [53, V, 'dns', true],
    [54, V, 'dns4', true],
    [55, V, 'dns6', true],
    [56, V, 'dnsaddr', true],
    [132, 16, 'sctp'],
    [273, 16, 'udp'],
    [275, 0, 'p2p-webrtc-star'],
    [276, 0, 'p2p-webrtc-direct'],
    [277, 0, 'p2p-stardust'],
    [280, 0, 'webrtc-direct'],
    [281, 0, 'webrtc'],
    [290, 0, 'p2p-circuit'],
    [301, 0, 'udt'],
    [302, 0, 'utp'],
    [400, V, 'unix', false, true],
    // `ipfs` is added before `p2p` for legacy support.
    // All text representations will default to `p2p`, but `ipfs` will
    // still be supported
    [421, V, 'ipfs'],
    // `p2p` is the preferred name for 421, and is now the default
    [421, V, 'p2p'],
    [443, 0, 'https'],
    [444, 96, 'onion'],
    [445, 296, 'onion3'],
    [446, V, 'garlic64'],
    [448, 0, 'tls'],
    [449, V, 'sni'],
    [460, 0, 'quic'],
    [461, 0, 'quic-v1'],
    [465, 0, 'webtransport'],
    [466, V, 'certhash'],
    [477, 0, 'ws'],
    [478, 0, 'wss'],
    [479, 0, 'p2p-websocket-star'],
    [480, 0, 'http'],
    [777, V, 'memory']
];
// populate tables
table.forEach(row => {
    const proto = createProtocol(...row);
    codes$2[proto.code] = proto;
    names[proto.name] = proto;
});
function createProtocol(code, size, name, resolvable, path) {
    return {
        code,
        size,
        name,
        resolvable: Boolean(resolvable),
        path: Boolean(path)
    };
}
/**
 * For the passed proto string or number, return a {@link Protocol}
 *
 * @example
 *
 * ```js
 * import { protocol } from '@multiformats/multiaddr'
 *
 * console.info(protocol(4))
 * // { code: 4, size: 32, name: 'ip4', resolvable: false, path: false }
 * ```
 */
function getProtocol(proto) {
    if (typeof proto === 'number') {
        if (codes$2[proto] != null) {
            return codes$2[proto];
        }
        throw new Error(`no protocol with code: ${proto}`);
    }
    else if (typeof proto === 'string') {
        if (names[proto] != null) {
            return names[proto];
        }
        throw new Error(`no protocol with name: ${proto}`);
    }
    throw new Error(`invalid protocol id type: ${typeof proto}`);
}

/**
 * @packageDocumentation
 *
 * Provides methods for converting
 */
/**
 * Convert [code,Uint8Array] to string
 */
function convertToString(proto, buf) {
    const protocol = getProtocol(proto);
    switch (protocol.code) {
        case 4: // ipv4
        case 41: // ipv6
            return bytes2ip(buf);
        case 42: // ipv6zone
            return bytes2str(buf);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return bytes2port(buf).toString();
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return bytes2str(buf);
        case 421: // ipfs
            return bytes2mh(buf);
        case 444: // onion
            return bytes2onion(buf);
        case 445: // onion3
            return bytes2onion(buf);
        case 466: // certhash
            return bytes2mb(buf);
        default:
            return toString$7(buf, 'base16'); // no clue. convert to hex
    }
}
function convertToBytes(proto, str) {
    const protocol = getProtocol(proto);
    switch (protocol.code) {
        case 4: // ipv4
            return ip2bytes(str);
        case 41: // ipv6
            return ip2bytes(str);
        case 42: // ipv6zone
            return str2bytes(str);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return port2bytes(parseInt(str, 10));
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return str2bytes(str);
        case 421: // ipfs
            return mh2bytes(str);
        case 444: // onion
            return onion2bytes(str);
        case 445: // onion3
            return onion32bytes(str);
        case 466: // certhash
            return mb2bytes(str);
        default:
            return fromString$2(str, 'base16'); // no clue. convert from hex
    }
}
const decoders = Object.values(bases).map((c) => c.decoder);
const anybaseDecoder = (function () {
    let acc = decoders[0].or(decoders[1]);
    decoders.slice(2).forEach((d) => (acc = acc.or(d)));
    return acc;
})();
function ip2bytes(ipString) {
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return toBytes(ipString);
}
function bytes2ip(ipBuff) {
    const ipString = toString$5(ipBuff, 0, ipBuff.length);
    if (ipString == null) {
        throw new Error('ipBuff is required');
    }
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return ipString;
}
function port2bytes(port) {
    const buf = new ArrayBuffer(2);
    const view = new DataView(buf);
    view.setUint16(0, port);
    return new Uint8Array(buf);
}
function bytes2port(buf) {
    const view = new DataView(buf.buffer);
    return view.getUint16(buf.byteOffset);
}
function str2bytes(str) {
    const buf = fromString$2(str);
    const size = Uint8Array.from(varint.encode(buf.length));
    return concat([size, buf], size.length + buf.length);
}
function bytes2str(buf) {
    const size = varint.decode(buf);
    buf = buf.slice(varint.decode.bytes);
    if (buf.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$7(buf);
}
function mh2bytes(hash) {
    let mh;
    if (hash[0] === 'Q' || hash[0] === '1') {
        mh = decode$5(base58btc.decode(`z${hash}`)).bytes;
    }
    else {
        mh = CID.parse(hash).multihash.bytes;
    }
    // the address is a varint prefixed multihash string representation
    const size = Uint8Array.from(varint.encode(mh.length));
    return concat([size, mh], size.length + mh.length);
}
function mb2bytes(mbstr) {
    const mb = anybaseDecoder.decode(mbstr);
    const size = Uint8Array.from(varint.encode(mb.length));
    return concat([size, mb], size.length + mb.length);
}
function bytes2mb(buf) {
    const size = varint.decode(buf);
    const hash = buf.slice(varint.decode.bytes);
    if (hash.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return 'u' + toString$7(hash, 'base64url');
}
/**
 * Converts bytes to bas58btc string
 */
function bytes2mh(buf) {
    const size = varint.decode(buf);
    const address = buf.slice(varint.decode.bytes);
    if (address.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$7(address, 'base58btc');
}
function onion2bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 16) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$1.decode('b' + addr[0]);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat([buf, portBuf], buf.length + portBuf.length);
}
function onion32bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 56) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion3 address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$1.decode(`b${addr[0]}`);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat([buf, portBuf], buf.length + portBuf.length);
}
function bytes2onion(buf) {
    const addrBytes = buf.slice(0, buf.length - 2);
    const portBytes = buf.slice(buf.length - 2);
    const addr = toString$7(addrBytes, 'base32');
    const port = bytes2port(portBytes);
    return `${addr}:${port}`;
}

/**
 * string -> [[str name, str addr]... ]
 */
function stringToStringTuples(str) {
    const tuples = [];
    const parts = str.split('/').slice(1); // skip first empty elem
    if (parts.length === 1 && parts[0] === '') {
        return [];
    }
    for (let p = 0; p < parts.length; p++) {
        const part = parts[p];
        const proto = getProtocol(part);
        if (proto.size === 0) {
            tuples.push([part]);
            // eslint-disable-next-line no-continue
            continue;
        }
        p++; // advance addr part
        if (p >= parts.length) {
            throw ParseError('invalid address: ' + str);
        }
        // if it's a path proto, take the rest
        if (proto.path === true) {
            tuples.push([
                part,
                // should we need to check each path part to see if it's a proto?
                // This would allow for other protocols to be added after a unix path,
                // however it would have issues if the path had a protocol name in the path
                cleanPath(parts.slice(p).join('/'))
            ]);
            break;
        }
        tuples.push([part, parts[p]]);
    }
    return tuples;
}
/**
 * [[str name, str addr]... ] -> string
 */
function stringTuplesToString(tuples) {
    const parts = [];
    tuples.map((tup) => {
        const proto = protoFromTuple(tup);
        parts.push(proto.name);
        if (tup.length > 1 && tup[1] != null) {
            parts.push(tup[1]);
        }
        return null;
    });
    return cleanPath(parts.join('/'));
}
/**
 * [[str name, str addr]... ] -> [[int code, Uint8Array]... ]
 */
function stringTuplesToTuples(tuples) {
    return tuples.map((tup) => {
        if (!Array.isArray(tup)) {
            tup = [tup];
        }
        const proto = protoFromTuple(tup);
        if (tup.length > 1) {
            return [proto.code, convertToBytes(proto.code, tup[1])];
        }
        return [proto.code];
    });
}
/**
 * Convert tuples to string tuples
 *
 * [[int code, Uint8Array]... ] -> [[int code, str addr]... ]
 */
function tuplesToStringTuples(tuples) {
    return tuples.map(tup => {
        const proto = protoFromTuple(tup);
        if (tup[1] != null) {
            return [proto.code, convertToString(proto.code, tup[1])];
        }
        return [proto.code];
    });
}
/**
 * [[int code, Uint8Array ]... ] -> Uint8Array
 */
function tuplesToBytes(tuples) {
    return fromBytes(concat(tuples.map((tup) => {
        const proto = protoFromTuple(tup);
        let buf = Uint8Array.from(varint.encode(proto.code));
        if (tup.length > 1 && tup[1] != null) {
            buf = concat([buf, tup[1]]); // add address buffer
        }
        return buf;
    })));
}
/**
 * For the passed address, return the serialized size
 */
function sizeForAddr(p, addr) {
    if (p.size > 0) {
        return p.size / 8;
    }
    else if (p.size === 0) {
        return 0;
    }
    else {
        const size = varint.decode(addr);
        return size + (varint.decode.bytes ?? 0);
    }
}
function bytesToTuples(buf) {
    const tuples = [];
    let i = 0;
    while (i < buf.length) {
        const code = varint.decode(buf, i);
        const n = varint.decode.bytes ?? 0;
        const p = getProtocol(code);
        const size = sizeForAddr(p, buf.slice(i + n));
        if (size === 0) {
            tuples.push([code]);
            i += n;
            // eslint-disable-next-line no-continue
            continue;
        }
        const addr = buf.slice(i + n, i + n + size);
        i += (size + n);
        if (i > buf.length) { // did not end _exactly_ at buffer.length
            throw ParseError('Invalid address Uint8Array: ' + toString$7(buf, 'base16'));
        }
        // ok, tuple seems good.
        tuples.push([code, addr]);
    }
    return tuples;
}
/**
 * Uint8Array -> String
 */
function bytesToString(buf) {
    const a = bytesToTuples(buf);
    const b = tuplesToStringTuples(a);
    return stringTuplesToString(b);
}
/**
 * String -> Uint8Array
 */
function stringToBytes(str) {
    str = cleanPath(str);
    const a = stringToStringTuples(str);
    const b = stringTuplesToTuples(a);
    return tuplesToBytes(b);
}
/**
 * String -> Uint8Array
 */
function fromString(str) {
    return stringToBytes(str);
}
/**
 * Uint8Array -> Uint8Array
 */
function fromBytes(buf) {
    const err = validateBytes(buf);
    if (err != null) {
        throw err;
    }
    return Uint8Array.from(buf); // copy
}
function validateBytes(buf) {
    try {
        bytesToTuples(buf); // try to parse. will throw if breaks
    }
    catch (err) {
        return err;
    }
}
function cleanPath(str) {
    return '/' + str.trim().split('/').filter((a) => a).join('/');
}
function ParseError(str) {
    return new Error('Error parsing address: ' + str);
}
function protoFromTuple(tup) {
    const proto = getProtocol(tup[0]);
    return proto;
}

/**
 * @packageDocumentation
 *
 * An implementation of a Multiaddr in JavaScript
 *
 * @example
 *
 * ```js
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const ma = multiaddr('/ip4/127.0.0.1/tcp/1234')
 * ```
 */
var __classPrivateFieldGet$2 = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var __classPrivateFieldSet$1 = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return (kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;
};
var _DefaultMultiaddr_string, _DefaultMultiaddr_tuples, _DefaultMultiaddr_stringTuples, _a;
const inspect = Symbol.for('nodejs.util.inspect.custom');
const DNS_CODES = [
    getProtocol('dns').code,
    getProtocol('dns4').code,
    getProtocol('dns6').code,
    getProtocol('dnsaddr').code
];
/**
 * All configured {@link Resolver}s
 */
const resolvers$1 = new Map();
const symbol$1 = Symbol.for('@multiformats/js-multiaddr/multiaddr');
/**
 * Check if object is a {@link Multiaddr} instance
 *
 * @example
 *
 * ```js
 * import { isMultiaddr, multiaddr } from '@multiformats/multiaddr'
 *
 * isMultiaddr(5)
 * // false
 * isMultiaddr(multiaddr('/ip4/127.0.0.1'))
 * // true
 * ```
 */
function isMultiaddr(value) {
    return Boolean(value?.[symbol$1]);
}
/**
 * Creates a {@link Multiaddr} from a {@link MultiaddrInput}
 */
class DefaultMultiaddr {
    constructor(addr) {
        _DefaultMultiaddr_string.set(this, void 0);
        _DefaultMultiaddr_tuples.set(this, void 0);
        _DefaultMultiaddr_stringTuples.set(this, void 0);
        this[_a] = true;
        // default
        if (addr == null) {
            addr = '';
        }
        if (addr instanceof Uint8Array) {
            this.bytes = fromBytes(addr);
        }
        else if (typeof addr === 'string') {
            if (addr.length > 0 && addr.charAt(0) !== '/') {
                throw new Error(`multiaddr "${addr}" must start with a "/"`);
            }
            this.bytes = fromString(addr);
        }
        else if (isMultiaddr(addr)) { // Multiaddr
            this.bytes = fromBytes(addr.bytes); // validate + copy buffer
        }
        else {
            throw new Error('addr must be a string, Buffer, or another Multiaddr');
        }
    }
    toString() {
        if (__classPrivateFieldGet$2(this, _DefaultMultiaddr_string, "f") == null) {
            __classPrivateFieldSet$1(this, _DefaultMultiaddr_string, bytesToString(this.bytes), "f");
        }
        return __classPrivateFieldGet$2(this, _DefaultMultiaddr_string, "f");
    }
    toJSON() {
        return this.toString();
    }
    toOptions() {
        let family;
        let transport;
        let host;
        let port;
        let zone = '';
        const tcp = getProtocol('tcp');
        const udp = getProtocol('udp');
        const ip4 = getProtocol('ip4');
        const ip6 = getProtocol('ip6');
        const dns6 = getProtocol('dns6');
        const ip6zone = getProtocol('ip6zone');
        for (const [code, value] of this.stringTuples()) {
            if (code === ip6zone.code) {
                zone = `%${value ?? ''}`;
            }
            // default to https when protocol & port are omitted from DNS addrs
            if (DNS_CODES.includes(code)) {
                transport = tcp.name;
                port = 443;
                host = `${value ?? ''}${zone}`;
                family = code === dns6.code ? 6 : 4;
            }
            if (code === tcp.code || code === udp.code) {
                transport = getProtocol(code).name;
                port = parseInt(value ?? '');
            }
            if (code === ip4.code || code === ip6.code) {
                transport = getProtocol(code).name;
                host = `${value ?? ''}${zone}`;
                family = code === ip6.code ? 6 : 4;
            }
        }
        if (family == null || transport == null || host == null || port == null) {
            throw new Error('multiaddr must have a valid format: "/{ip4, ip6, dns4, dns6, dnsaddr}/{address}/{tcp, udp}/{port}".');
        }
        const opts = {
            family,
            host,
            transport,
            port
        };
        return opts;
    }
    protos() {
        return this.protoCodes().map(code => Object.assign({}, getProtocol(code)));
    }
    protoCodes() {
        const codes = [];
        const buf = this.bytes;
        let i = 0;
        while (i < buf.length) {
            const code = varint.decode(buf, i);
            const n = varint.decode.bytes ?? 0;
            const p = getProtocol(code);
            const size = sizeForAddr(p, buf.slice(i + n));
            i += (size + n);
            codes.push(code);
        }
        return codes;
    }
    protoNames() {
        return this.protos().map(proto => proto.name);
    }
    tuples() {
        if (__classPrivateFieldGet$2(this, _DefaultMultiaddr_tuples, "f") == null) {
            __classPrivateFieldSet$1(this, _DefaultMultiaddr_tuples, bytesToTuples(this.bytes), "f");
        }
        return __classPrivateFieldGet$2(this, _DefaultMultiaddr_tuples, "f");
    }
    stringTuples() {
        if (__classPrivateFieldGet$2(this, _DefaultMultiaddr_stringTuples, "f") == null) {
            __classPrivateFieldSet$1(this, _DefaultMultiaddr_stringTuples, tuplesToStringTuples(this.tuples()), "f");
        }
        return __classPrivateFieldGet$2(this, _DefaultMultiaddr_stringTuples, "f");
    }
    encapsulate(addr) {
        addr = new DefaultMultiaddr(addr);
        return new DefaultMultiaddr(this.toString() + addr.toString());
    }
    decapsulate(addr) {
        const addrString = addr.toString();
        const s = this.toString();
        const i = s.lastIndexOf(addrString);
        if (i < 0) {
            throw new Error(`Address ${this.toString()} does not contain subaddress: ${addr.toString()}`);
        }
        return new DefaultMultiaddr(s.slice(0, i));
    }
    decapsulateCode(code) {
        const tuples = this.tuples();
        for (let i = tuples.length - 1; i >= 0; i--) {
            if (tuples[i][0] === code) {
                return new DefaultMultiaddr(tuplesToBytes(tuples.slice(0, i)));
            }
        }
        return this;
    }
    getPeerId() {
        try {
            const tuples = this.stringTuples().filter((tuple) => {
                if (tuple[0] === names.ipfs.code) {
                    return true;
                }
                return false;
            });
            // Get the last ipfs tuple ['ipfs', 'peerid string']
            const tuple = tuples.pop();
            if (tuple?.[1] != null) {
                const peerIdStr = tuple[1];
                // peer id is base58btc encoded string but not multibase encoded so add the `z`
                // prefix so we can validate that it is correctly encoded
                if (peerIdStr[0] === 'Q' || peerIdStr[0] === '1') {
                    return toString$7(base58btc.decode(`z${peerIdStr}`), 'base58btc');
                }
                // try to parse peer id as CID
                return toString$7(CID.parse(peerIdStr).multihash.bytes, 'base58btc');
            }
            return null;
        }
        catch (e) {
            return null;
        }
    }
    getPath() {
        let path = null;
        try {
            path = this.stringTuples().filter((tuple) => {
                const proto = getProtocol(tuple[0]);
                if (proto.path === true) {
                    return true;
                }
                return false;
            })[0][1];
            if (path == null) {
                path = null;
            }
        }
        catch {
            path = null;
        }
        return path;
    }
    equals(addr) {
        return equals$2(this.bytes, addr.bytes);
    }
    async resolve(options) {
        const resolvableProto = this.protos().find((p) => p.resolvable);
        // Multiaddr is not resolvable?
        if (resolvableProto == null) {
            return [this];
        }
        const resolver = resolvers$1.get(resolvableProto.name);
        if (resolver == null) {
            throw errCode(new Error(`no available resolver for ${resolvableProto.name}`), 'ERR_NO_AVAILABLE_RESOLVER');
        }
        const addresses = await resolver(this, options);
        return addresses.map((a) => new DefaultMultiaddr(a));
    }
    nodeAddress() {
        const options = this.toOptions();
        if (options.transport !== 'tcp' && options.transport !== 'udp') {
            throw new Error(`multiaddr must have a valid format - no protocol with name: "${options.transport}". Must have a valid transport protocol: "{tcp, udp}"`);
        }
        return {
            family: options.family,
            address: options.host,
            port: options.port
        };
    }
    isThinWaistAddress(addr) {
        const protos = (addr ?? this).protos();
        if (protos.length !== 2) {
            return false;
        }
        if (protos[0].code !== 4 && protos[0].code !== 41) {
            return false;
        }
        if (protos[1].code !== 6 && protos[1].code !== 273) {
            return false;
        }
        return true;
    }
    /**
     * Returns Multiaddr as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { multiaddr } from '@multiformats/multiaddr'
     *
     * console.info(multiaddr('/ip4/127.0.0.1/tcp/4001'))
     * // 'Multiaddr(/ip4/127.0.0.1/tcp/4001)'
     * ```
     */
    [(_DefaultMultiaddr_string = new WeakMap(), _DefaultMultiaddr_tuples = new WeakMap(), _DefaultMultiaddr_stringTuples = new WeakMap(), _a = symbol$1, inspect)]() {
        return `Multiaddr(${bytesToString(this.bytes)})`;
    }
}
/**
 * A function that takes a {@link MultiaddrInput} and returns a {@link Multiaddr}
 *
 * @example
 * ```js
 * import { multiaddr } from '@libp2p/multiaddr'
 *
 * multiaddr('/ip4/127.0.0.1/tcp/4001')
 * // Multiaddr(/ip4/127.0.0.1/tcp/4001)
 * ```
 *
 * @param {MultiaddrInput} [addr] - If String or Uint8Array, needs to adhere to the address format of a [multiaddr](https://github.com/multiformats/multiaddr#string-format)
 */
function multiaddr(addr) {
    return new DefaultMultiaddr(addr);
}

function multiaddrFromFields(ipFamily, protocol, ipBytes, protocolBytes) {
    let ma = multiaddr("/" + ipFamily + "/" + convertToString(ipFamily, ipBytes));
    ma = ma.encapsulate(multiaddr("/" + protocol + "/" + convertToString(protocol, protocolBytes)));
    return ma;
}

function locationMultiaddrFromEnrFields(enr, protocol) {
    switch (protocol) {
        case "udp":
            return (locationMultiaddrFromEnrFields(enr, "udp4") ||
                locationMultiaddrFromEnrFields(enr, "udp6"));
        case "tcp":
            return (locationMultiaddrFromEnrFields(enr, "tcp4") ||
                locationMultiaddrFromEnrFields(enr, "tcp6"));
    }
    const isIpv6 = protocol.endsWith("6");
    const ipVal = enr.get(isIpv6 ? "ip6" : "ip");
    if (!ipVal)
        return;
    const protoName = protocol.slice(0, 3);
    let protoVal;
    switch (protoName) {
        case "udp":
            protoVal = isIpv6 ? enr.get("udp6") : enr.get("udp");
            break;
        case "tcp":
            protoVal = isIpv6 ? enr.get("tcp6") : enr.get("tcp");
            break;
        default:
            return;
    }
    if (!protoVal)
        return;
    return multiaddrFromFields(isIpv6 ? "ip6" : "ip4", protoName, ipVal, protoVal);
}

function createPeerIdFromPublicKey(publicKey) {
    const _publicKey = new supportedKeys.secp256k1.Secp256k1PublicKey(publicKey);
    return peerIdFromKeys(_publicKey.bytes, undefined);
}

function decodeMultiaddrs(bytes) {
    const multiaddrs = [];
    let index = 0;
    while (index < bytes.length) {
        const sizeDataView = new DataView(bytes.buffer, index, MULTIADDR_LENGTH_SIZE);
        const size = sizeDataView.getUint16(0);
        index += MULTIADDR_LENGTH_SIZE;
        const multiaddrBytes = bytes.slice(index, index + size);
        index += size;
        multiaddrs.push(multiaddr(multiaddrBytes));
    }
    return multiaddrs;
}
function encodeMultiaddrs(multiaddrs) {
    const totalLength = multiaddrs.reduce((acc, ma) => acc + MULTIADDR_LENGTH_SIZE + ma.bytes.length, 0);
    const bytes = new Uint8Array(totalLength);
    const dataView = new DataView(bytes.buffer);
    let index = 0;
    multiaddrs.forEach((multiaddr) => {
        if (multiaddr.getPeerId())
            throw new Error("`multiaddr` field MUST not contain peer id");
        // Prepend the size of the next entry
        dataView.setUint16(index, multiaddr.bytes.length);
        index += MULTIADDR_LENGTH_SIZE;
        bytes.set(multiaddr.bytes, index);
        index += multiaddr.bytes.length;
    });
    return bytes;
}

function encodeWaku2(protocols) {
    let byte = 0;
    if (protocols.lightPush)
        byte += 1;
    byte = byte << 1;
    if (protocols.filter)
        byte += 1;
    byte = byte << 1;
    if (protocols.store)
        byte += 1;
    byte = byte << 1;
    if (protocols.relay)
        byte += 1;
    return byte;
}
function decodeWaku2(byte) {
    const waku2 = {
        relay: false,
        store: false,
        filter: false,
        lightPush: false,
    };
    if (byte % 2)
        waku2.relay = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.store = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.filter = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.lightPush = true;
    return waku2;
}

class RawEnr extends Map {
    constructor(kvs = {}, seq = BigInt(1), signature) {
        super(Object.entries(kvs));
        this.seq = seq;
        this.signature = signature;
    }
    set(k, v) {
        this.signature = undefined;
        this.seq++;
        return super.set(k, v);
    }
    get id() {
        const id = this.get("id");
        if (!id)
            throw new Error("id not found.");
        return bytesToUtf8(id);
    }
    get publicKey() {
        switch (this.id) {
            case "v4":
                return this.get("secp256k1");
            default:
                throw new Error(ERR_INVALID_ID);
        }
    }
    get ip() {
        return getStringValue(this, "ip", "ip4");
    }
    set ip(ip) {
        setStringValue(this, "ip", "ip4", ip);
    }
    get tcp() {
        return getNumberAsStringValue(this, "tcp", "tcp");
    }
    set tcp(port) {
        setNumberAsStringValue(this, "tcp", "tcp", port);
    }
    get udp() {
        return getNumberAsStringValue(this, "udp", "udp");
    }
    set udp(port) {
        setNumberAsStringValue(this, "udp", "udp", port);
    }
    get ip6() {
        return getStringValue(this, "ip6", "ip6");
    }
    set ip6(ip) {
        setStringValue(this, "ip6", "ip6", ip);
    }
    get tcp6() {
        return getNumberAsStringValue(this, "tcp6", "tcp");
    }
    set tcp6(port) {
        setNumberAsStringValue(this, "tcp6", "tcp", port);
    }
    get udp6() {
        return getNumberAsStringValue(this, "udp6", "udp");
    }
    set udp6(port) {
        setNumberAsStringValue(this, "udp6", "udp", port);
    }
    /**
     * Get the `multiaddrs` field from ENR.
     *
     * This field is used to store multiaddresses that cannot be stored with the current ENR pre-defined keys.
     * These can be a multiaddresses that include encapsulation (e.g. wss) or do not use `ip4` nor `ip6` for the host
     * address (e.g. `dns4`, `dnsaddr`, etc)..
     *
     * If the peer information only contains information that can be represented with the ENR pre-defined keys
     * (ip, tcp, etc) then the usage of { @link ENR.getLocationMultiaddr } should be preferred.
     *
     * The multiaddresses stored in this field are expected to be location multiaddresses, ie, peer id less.
     */
    get multiaddrs() {
        const raw = this.get("multiaddrs");
        if (raw)
            return decodeMultiaddrs(raw);
        return;
    }
    /**
     * Set the `multiaddrs` field on the ENR.
     *
     * This field is used to store multiaddresses that cannot be stored with the current ENR pre-defined keys.
     * These can be a multiaddresses that include encapsulation (e.g. wss) or do not use `ip4` nor `ip6` for the host
     * address (e.g. `dns4`, `dnsaddr`, etc)..
     *
     * If the peer information only contains information that can be represented with the ENR pre-defined keys
     * (ip, tcp, etc) then the usage of { @link ENR.setLocationMultiaddr } should be preferred.
     * The multiaddresses stored in this field must be location multiaddresses,
     * ie, without a peer id.
     */
    set multiaddrs(multiaddrs) {
        deleteUndefined(this, "multiaddrs", multiaddrs, encodeMultiaddrs);
    }
    /**
     * Get the `waku2` field from ENR.
     */
    get waku2() {
        const raw = this.get("waku2");
        if (raw)
            return decodeWaku2(raw[0]);
        return;
    }
    /**
     * Set the `waku2` field on the ENR.
     */
    set waku2(waku2) {
        deleteUndefined(this, "waku2", waku2, (w) => new Uint8Array([encodeWaku2(w)]));
    }
}
function getStringValue(map, key, proto) {
    const raw = map.get(key);
    if (!raw)
        return;
    return convertToString(proto, raw);
}
function getNumberAsStringValue(map, key, proto) {
    const raw = map.get(key);
    if (!raw)
        return;
    return Number(convertToString(proto, raw));
}
function setStringValue(map, key, proto, value) {
    deleteUndefined(map, key, value, convertToBytes.bind({}, proto));
}
function setNumberAsStringValue(map, key, proto, value) {
    setStringValue(map, key, proto, value?.toString(10));
}
function deleteUndefined(map, key, value, transform) {
    if (value !== undefined) {
        map.set(key, transform(value));
    }
    else {
        map.delete(key);
    }
}

async function sign(privKey, msg) {
    return sign$2(keccak256(msg), privKey, {
        der: false,
    });
}
function nodeId(pubKey) {
    const publicKey = Point$1.fromHex(pubKey);
    const uncompressedPubkey = publicKey.toRawBytes(false);
    return bytesToHex(keccak256(uncompressedPubkey.slice(1)));
}

const log$E = debug("waku:enr");
var TransportProtocol;
(function (TransportProtocol) {
    TransportProtocol["TCP"] = "tcp";
    TransportProtocol["UDP"] = "udp";
})(TransportProtocol || (TransportProtocol = {}));
var TransportProtocolPerIpVersion;
(function (TransportProtocolPerIpVersion) {
    TransportProtocolPerIpVersion["TCP4"] = "tcp4";
    TransportProtocolPerIpVersion["UDP4"] = "udp4";
    TransportProtocolPerIpVersion["TCP6"] = "tcp6";
    TransportProtocolPerIpVersion["UDP6"] = "udp6";
})(TransportProtocolPerIpVersion || (TransportProtocolPerIpVersion = {}));
class ENR extends RawEnr {
    constructor() {
        super(...arguments);
        this.getLocationMultiaddr = locationMultiaddrFromEnrFields.bind({}, this);
    }
    static async create(kvs = {}, seq = BigInt(1), signature) {
        const enr = new ENR(kvs, seq, signature);
        try {
            const publicKey = enr.publicKey;
            if (publicKey) {
                enr.peerId = await createPeerIdFromPublicKey(publicKey);
            }
        }
        catch (e) {
            log$E("Could not calculate peer id for ENR", e);
        }
        return enr;
    }
    get nodeId() {
        switch (this.id) {
            case "v4":
                return this.publicKey ? nodeId(this.publicKey) : undefined;
            default:
                throw new Error(ERR_INVALID_ID);
        }
    }
    setLocationMultiaddr(multiaddr) {
        const protoNames = multiaddr.protoNames();
        if (protoNames.length !== 2 &&
            protoNames[1] !== "udp" &&
            protoNames[1] !== "tcp") {
            throw new Error("Invalid multiaddr");
        }
        const tuples = multiaddr.tuples();
        if (!tuples[0][1] || !tuples[1][1]) {
            throw new Error("Invalid multiaddr");
        }
        // IPv4
        if (tuples[0][0] === 4) {
            this.set("ip", tuples[0][1]);
            this.set(protoNames[1], tuples[1][1]);
        }
        else {
            this.set("ip6", tuples[0][1]);
            this.set(protoNames[1] + "6", tuples[1][1]);
        }
    }
    getAllLocationMultiaddrs() {
        const multiaddrs = [];
        for (const protocol of Object.values(TransportProtocolPerIpVersion)) {
            const ma = this.getLocationMultiaddr(protocol);
            if (ma)
                multiaddrs.push(ma);
        }
        const _multiaddrs = this.multiaddrs ?? [];
        return multiaddrs.concat(_multiaddrs);
    }
    get peerInfo() {
        const id = this.peerId;
        if (!id)
            return;
        return {
            id,
            multiaddrs: this.getAllLocationMultiaddrs(),
            protocols: [],
        };
    }
    /**
     * Returns the full multiaddr from the ENR fields matching the provided
     * `protocol` parameter.
     * To return full multiaddrs from the `multiaddrs` ENR field,
     * use { @link ENR.getFullMultiaddrs }.
     *
     * @param protocol
     */
    getFullMultiaddr(protocol) {
        if (this.peerId) {
            const locationMultiaddr = this.getLocationMultiaddr(protocol);
            if (locationMultiaddr) {
                return locationMultiaddr.encapsulate(`/p2p/${this.peerId.toString()}`);
            }
        }
        return;
    }
    /**
     * Returns the full multiaddrs from the `multiaddrs` ENR field.
     */
    getFullMultiaddrs() {
        if (this.peerId && this.multiaddrs) {
            const peerId = this.peerId;
            return this.multiaddrs.map((ma) => {
                return ma.encapsulate(`/p2p/${peerId.toString()}`);
            });
        }
        return [];
    }
    verify(data, signature) {
        if (!this.get("id") || this.id !== "v4") {
            throw new Error(ERR_INVALID_ID);
        }
        if (!this.publicKey) {
            throw new Error("Failed to verify ENR: No public key");
        }
        return verifySignature(signature, keccak256(data), this.publicKey);
    }
    async sign(data, privateKey) {
        switch (this.id) {
            case "v4":
                this.signature = await sign(privateKey, data);
                break;
            default:
                throw new Error(ERR_INVALID_ID);
        }
        return this.signature;
    }
}
ENR.RECORD_PREFIX = "enr:";

const version$3 = "logger/5.7.0";

let _permanentCensorErrors = false;
let _censorErrors = false;
const LogLevels = { debug: 1, "default": 2, info: 2, warning: 3, error: 4, off: 5 };
let _logLevel = LogLevels["default"];
let _globalLogger = null;
function _checkNormalize() {
    try {
        const missing = [];
        // Make sure all forms of normalization are supported
        ["NFD", "NFC", "NFKD", "NFKC"].forEach((form) => {
            try {
                if ("test".normalize(form) !== "test") {
                    throw new Error("bad normalize");
                }
                ;
            }
            catch (error) {
                missing.push(form);
            }
        });
        if (missing.length) {
            throw new Error("missing " + missing.join(", "));
        }
        if (String.fromCharCode(0xe9).normalize("NFD") !== String.fromCharCode(0x65, 0x0301)) {
            throw new Error("broken implementation");
        }
    }
    catch (error) {
        return error.message;
    }
    return null;
}
const _normalizeError = _checkNormalize();
var LogLevel;
(function (LogLevel) {
    LogLevel["DEBUG"] = "DEBUG";
    LogLevel["INFO"] = "INFO";
    LogLevel["WARNING"] = "WARNING";
    LogLevel["ERROR"] = "ERROR";
    LogLevel["OFF"] = "OFF";
})(LogLevel || (LogLevel = {}));
var ErrorCode;
(function (ErrorCode) {
    ///////////////////
    // Generic Errors
    // Unknown Error
    ErrorCode["UNKNOWN_ERROR"] = "UNKNOWN_ERROR";
    // Not Implemented
    ErrorCode["NOT_IMPLEMENTED"] = "NOT_IMPLEMENTED";
    // Unsupported Operation
    //   - operation
    ErrorCode["UNSUPPORTED_OPERATION"] = "UNSUPPORTED_OPERATION";
    // Network Error (i.e. Ethereum Network, such as an invalid chain ID)
    //   - event ("noNetwork" is not re-thrown in provider.ready; otherwise thrown)
    ErrorCode["NETWORK_ERROR"] = "NETWORK_ERROR";
    // Some sort of bad response from the server
    ErrorCode["SERVER_ERROR"] = "SERVER_ERROR";
    // Timeout
    ErrorCode["TIMEOUT"] = "TIMEOUT";
    ///////////////////
    // Operational  Errors
    // Buffer Overrun
    ErrorCode["BUFFER_OVERRUN"] = "BUFFER_OVERRUN";
    // Numeric Fault
    //   - operation: the operation being executed
    //   - fault: the reason this faulted
    ErrorCode["NUMERIC_FAULT"] = "NUMERIC_FAULT";
    ///////////////////
    // Argument Errors
    // Missing new operator to an object
    //  - name: The name of the class
    ErrorCode["MISSING_NEW"] = "MISSING_NEW";
    // Invalid argument (e.g. value is incompatible with type) to a function:
    //   - argument: The argument name that was invalid
    //   - value: The value of the argument
    ErrorCode["INVALID_ARGUMENT"] = "INVALID_ARGUMENT";
    // Missing argument to a function:
    //   - count: The number of arguments received
    //   - expectedCount: The number of arguments expected
    ErrorCode["MISSING_ARGUMENT"] = "MISSING_ARGUMENT";
    // Too many arguments
    //   - count: The number of arguments received
    //   - expectedCount: The number of arguments expected
    ErrorCode["UNEXPECTED_ARGUMENT"] = "UNEXPECTED_ARGUMENT";
    ///////////////////
    // Blockchain Errors
    // Call exception
    //  - transaction: the transaction
    //  - address?: the contract address
    //  - args?: The arguments passed into the function
    //  - method?: The Solidity method signature
    //  - errorSignature?: The EIP848 error signature
    //  - errorArgs?: The EIP848 error parameters
    //  - reason: The reason (only for EIP848 "Error(string)")
    ErrorCode["CALL_EXCEPTION"] = "CALL_EXCEPTION";
    // Insufficient funds (< value + gasLimit * gasPrice)
    //   - transaction: the transaction attempted
    ErrorCode["INSUFFICIENT_FUNDS"] = "INSUFFICIENT_FUNDS";
    // Nonce has already been used
    //   - transaction: the transaction attempted
    ErrorCode["NONCE_EXPIRED"] = "NONCE_EXPIRED";
    // The replacement fee for the transaction is too low
    //   - transaction: the transaction attempted
    ErrorCode["REPLACEMENT_UNDERPRICED"] = "REPLACEMENT_UNDERPRICED";
    // The gas limit could not be estimated
    //   - transaction: the transaction passed to estimateGas
    ErrorCode["UNPREDICTABLE_GAS_LIMIT"] = "UNPREDICTABLE_GAS_LIMIT";
    // The transaction was replaced by one with a higher gas price
    //   - reason: "cancelled", "replaced" or "repriced"
    //   - cancelled: true if reason == "cancelled" or reason == "replaced")
    //   - hash: original transaction hash
    //   - replacement: the full TransactionsResponse for the replacement
    //   - receipt: the receipt of the replacement
    ErrorCode["TRANSACTION_REPLACED"] = "TRANSACTION_REPLACED";
    ///////////////////
    // Interaction Errors
    // The user rejected the action, such as signing a message or sending
    // a transaction
    ErrorCode["ACTION_REJECTED"] = "ACTION_REJECTED";
})(ErrorCode || (ErrorCode = {}));
const HEX = "0123456789abcdef";
class Logger {
    constructor(version) {
        Object.defineProperty(this, "version", {
            enumerable: true,
            value: version,
            writable: false
        });
    }
    _log(logLevel, args) {
        const level = logLevel.toLowerCase();
        if (LogLevels[level] == null) {
            this.throwArgumentError("invalid log level name", "logLevel", logLevel);
        }
        if (_logLevel > LogLevels[level]) {
            return;
        }
        console.log.apply(console, args);
    }
    debug(...args) {
        this._log(Logger.levels.DEBUG, args);
    }
    info(...args) {
        this._log(Logger.levels.INFO, args);
    }
    warn(...args) {
        this._log(Logger.levels.WARNING, args);
    }
    makeError(message, code, params) {
        // Errors are being censored
        if (_censorErrors) {
            return this.makeError("censored error", code, {});
        }
        if (!code) {
            code = Logger.errors.UNKNOWN_ERROR;
        }
        if (!params) {
            params = {};
        }
        const messageDetails = [];
        Object.keys(params).forEach((key) => {
            const value = params[key];
            try {
                if (value instanceof Uint8Array) {
                    let hex = "";
                    for (let i = 0; i < value.length; i++) {
                        hex += HEX[value[i] >> 4];
                        hex += HEX[value[i] & 0x0f];
                    }
                    messageDetails.push(key + "=Uint8Array(0x" + hex + ")");
                }
                else {
                    messageDetails.push(key + "=" + JSON.stringify(value));
                }
            }
            catch (error) {
                messageDetails.push(key + "=" + JSON.stringify(params[key].toString()));
            }
        });
        messageDetails.push(`code=${code}`);
        messageDetails.push(`version=${this.version}`);
        const reason = message;
        let url = "";
        switch (code) {
            case ErrorCode.NUMERIC_FAULT: {
                url = "NUMERIC_FAULT";
                const fault = message;
                switch (fault) {
                    case "overflow":
                    case "underflow":
                    case "division-by-zero":
                        url += "-" + fault;
                        break;
                    case "negative-power":
                    case "negative-width":
                        url += "-unsupported";
                        break;
                    case "unbound-bitwise-result":
                        url += "-unbound-result";
                        break;
                }
                break;
            }
            case ErrorCode.CALL_EXCEPTION:
            case ErrorCode.INSUFFICIENT_FUNDS:
            case ErrorCode.MISSING_NEW:
            case ErrorCode.NONCE_EXPIRED:
            case ErrorCode.REPLACEMENT_UNDERPRICED:
            case ErrorCode.TRANSACTION_REPLACED:
            case ErrorCode.UNPREDICTABLE_GAS_LIMIT:
                url = code;
                break;
        }
        if (url) {
            message += " [ See: https:/\/links.ethers.org/v5-errors-" + url + " ]";
        }
        if (messageDetails.length) {
            message += " (" + messageDetails.join(", ") + ")";
        }
        // @TODO: Any??
        const error = new Error(message);
        error.reason = reason;
        error.code = code;
        Object.keys(params).forEach(function (key) {
            error[key] = params[key];
        });
        return error;
    }
    throwError(message, code, params) {
        throw this.makeError(message, code, params);
    }
    throwArgumentError(message, name, value) {
        return this.throwError(message, Logger.errors.INVALID_ARGUMENT, {
            argument: name,
            value: value
        });
    }
    assert(condition, message, code, params) {
        if (!!condition) {
            return;
        }
        this.throwError(message, code, params);
    }
    assertArgument(condition, message, name, value) {
        if (!!condition) {
            return;
        }
        this.throwArgumentError(message, name, value);
    }
    checkNormalize(message) {
        if (_normalizeError) {
            this.throwError("platform missing String.prototype.normalize", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "String.prototype.normalize", form: _normalizeError
            });
        }
    }
    checkSafeUint53(value, message) {
        if (typeof (value) !== "number") {
            return;
        }
        if (message == null) {
            message = "value not safe";
        }
        if (value < 0 || value >= 0x1fffffffffffff) {
            this.throwError(message, Logger.errors.NUMERIC_FAULT, {
                operation: "checkSafeInteger",
                fault: "out-of-safe-range",
                value: value
            });
        }
        if (value % 1) {
            this.throwError(message, Logger.errors.NUMERIC_FAULT, {
                operation: "checkSafeInteger",
                fault: "non-integer",
                value: value
            });
        }
    }
    checkArgumentCount(count, expectedCount, message) {
        if (message) {
            message = ": " + message;
        }
        else {
            message = "";
        }
        if (count < expectedCount) {
            this.throwError("missing argument" + message, Logger.errors.MISSING_ARGUMENT, {
                count: count,
                expectedCount: expectedCount
            });
        }
        if (count > expectedCount) {
            this.throwError("too many arguments" + message, Logger.errors.UNEXPECTED_ARGUMENT, {
                count: count,
                expectedCount: expectedCount
            });
        }
    }
    checkNew(target, kind) {
        if (target === Object || target == null) {
            this.throwError("missing new", Logger.errors.MISSING_NEW, { name: kind.name });
        }
    }
    checkAbstract(target, kind) {
        if (target === kind) {
            this.throwError("cannot instantiate abstract class " + JSON.stringify(kind.name) + " directly; use a sub-class", Logger.errors.UNSUPPORTED_OPERATION, { name: target.name, operation: "new" });
        }
        else if (target === Object || target == null) {
            this.throwError("missing new", Logger.errors.MISSING_NEW, { name: kind.name });
        }
    }
    static globalLogger() {
        if (!_globalLogger) {
            _globalLogger = new Logger(version$3);
        }
        return _globalLogger;
    }
    static setCensorship(censorship, permanent) {
        if (!censorship && permanent) {
            this.globalLogger().throwError("cannot permanently disable censorship", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "setCensorship"
            });
        }
        if (_permanentCensorErrors) {
            if (!censorship) {
                return;
            }
            this.globalLogger().throwError("error censorship permanent", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "setCensorship"
            });
        }
        _censorErrors = !!censorship;
        _permanentCensorErrors = !!permanent;
    }
    static setLogLevel(logLevel) {
        const level = LogLevels[logLevel.toLowerCase()];
        if (level == null) {
            Logger.globalLogger().warn("invalid log level - " + logLevel);
            return;
        }
        _logLevel = level;
    }
    static from(version) {
        return new Logger(version);
    }
}
Logger.errors = ErrorCode;
Logger.levels = LogLevel;

const version$2 = "bytes/5.7.0";

const logger$1 = new Logger(version$2);
///////////////////////////////
function isHexable(value) {
    return !!(value.toHexString);
}
function addSlice(array) {
    if (array.slice) {
        return array;
    }
    array.slice = function () {
        const args = Array.prototype.slice.call(arguments);
        return addSlice(new Uint8Array(Array.prototype.slice.apply(array, args)));
    };
    return array;
}
function isBytesLike(value) {
    return ((isHexString(value) && !(value.length % 2)) || isBytes(value));
}
function isInteger(value) {
    return (typeof (value) === "number" && value == value && (value % 1) === 0);
}
function isBytes(value) {
    if (value == null) {
        return false;
    }
    if (value.constructor === Uint8Array) {
        return true;
    }
    if (typeof (value) === "string") {
        return false;
    }
    if (!isInteger(value.length) || value.length < 0) {
        return false;
    }
    for (let i = 0; i < value.length; i++) {
        const v = value[i];
        if (!isInteger(v) || v < 0 || v >= 256) {
            return false;
        }
    }
    return true;
}
function arrayify(value, options) {
    if (!options) {
        options = {};
    }
    if (typeof (value) === "number") {
        logger$1.checkSafeUint53(value, "invalid arrayify value");
        const result = [];
        while (value) {
            result.unshift(value & 0xff);
            value = parseInt(String(value / 256));
        }
        if (result.length === 0) {
            result.push(0);
        }
        return addSlice(new Uint8Array(result));
    }
    if (options.allowMissingPrefix && typeof (value) === "string" && value.substring(0, 2) !== "0x") {
        value = "0x" + value;
    }
    if (isHexable(value)) {
        value = value.toHexString();
    }
    if (isHexString(value)) {
        let hex = value.substring(2);
        if (hex.length % 2) {
            if (options.hexPad === "left") {
                hex = "0" + hex;
            }
            else if (options.hexPad === "right") {
                hex += "0";
            }
            else {
                logger$1.throwArgumentError("hex data is odd-length", "value", value);
            }
        }
        const result = [];
        for (let i = 0; i < hex.length; i += 2) {
            result.push(parseInt(hex.substring(i, i + 2), 16));
        }
        return addSlice(new Uint8Array(result));
    }
    if (isBytes(value)) {
        return addSlice(new Uint8Array(value));
    }
    return logger$1.throwArgumentError("invalid arrayify value", "value", value);
}
function isHexString(value, length) {
    if (typeof (value) !== "string" || !value.match(/^0x[0-9A-Fa-f]*$/)) {
        return false;
    }
    if (length && value.length !== 2 + 2 * length) {
        return false;
    }
    return true;
}
const HexCharacters = "0123456789abcdef";
function hexlify(value, options) {
    if (!options) {
        options = {};
    }
    if (typeof (value) === "number") {
        logger$1.checkSafeUint53(value, "invalid hexlify value");
        let hex = "";
        while (value) {
            hex = HexCharacters[value & 0xf] + hex;
            value = Math.floor(value / 16);
        }
        if (hex.length) {
            if (hex.length % 2) {
                hex = "0" + hex;
            }
            return "0x" + hex;
        }
        return "0x00";
    }
    if (typeof (value) === "bigint") {
        value = value.toString(16);
        if (value.length % 2) {
            return ("0x0" + value);
        }
        return "0x" + value;
    }
    if (options.allowMissingPrefix && typeof (value) === "string" && value.substring(0, 2) !== "0x") {
        value = "0x" + value;
    }
    if (isHexable(value)) {
        return value.toHexString();
    }
    if (isHexString(value)) {
        if (value.length % 2) {
            if (options.hexPad === "left") {
                value = "0x0" + value.substring(2);
            }
            else if (options.hexPad === "right") {
                value += "0";
            }
            else {
                logger$1.throwArgumentError("hex data is odd-length", "value", value);
            }
        }
        return value.toLowerCase();
    }
    if (isBytes(value)) {
        let result = "0x";
        for (let i = 0; i < value.length; i++) {
            let v = value[i];
            result += HexCharacters[(v & 0xf0) >> 4] + HexCharacters[v & 0x0f];
        }
        return result;
    }
    return logger$1.throwArgumentError("invalid hexlify value", "value", value);
}

const version$1 = "rlp/5.7.0";

const logger = new Logger(version$1);
function arrayifyInteger(value) {
    const result = [];
    while (value) {
        result.unshift(value & 0xff);
        value >>= 8;
    }
    return result;
}
function unarrayifyInteger(data, offset, length) {
    let result = 0;
    for (let i = 0; i < length; i++) {
        result = (result * 256) + data[offset + i];
    }
    return result;
}
function _encode(object) {
    if (Array.isArray(object)) {
        let payload = [];
        object.forEach(function (child) {
            payload = payload.concat(_encode(child));
        });
        if (payload.length <= 55) {
            payload.unshift(0xc0 + payload.length);
            return payload;
        }
        const length = arrayifyInteger(payload.length);
        length.unshift(0xf7 + length.length);
        return length.concat(payload);
    }
    if (!isBytesLike(object)) {
        logger.throwArgumentError("RLP object must be BytesLike", "object", object);
    }
    const data = Array.prototype.slice.call(arrayify(object));
    if (data.length === 1 && data[0] <= 0x7f) {
        return data;
    }
    else if (data.length <= 55) {
        data.unshift(0x80 + data.length);
        return data;
    }
    const length = arrayifyInteger(data.length);
    length.unshift(0xb7 + length.length);
    return length.concat(data);
}
function encode$4(object) {
    return hexlify(_encode(object));
}
function _decodeChildren(data, offset, childOffset, length) {
    const result = [];
    while (childOffset < offset + 1 + length) {
        const decoded = _decode(data, childOffset);
        result.push(decoded.result);
        childOffset += decoded.consumed;
        if (childOffset > offset + 1 + length) {
            logger.throwError("child data too short", Logger.errors.BUFFER_OVERRUN, {});
        }
    }
    return { consumed: (1 + length), result: result };
}
// returns { consumed: number, result: Object }
function _decode(data, offset) {
    if (data.length === 0) {
        logger.throwError("data too short", Logger.errors.BUFFER_OVERRUN, {});
    }
    // Array with extra length prefix
    if (data[offset] >= 0xf8) {
        const lengthLength = data[offset] - 0xf7;
        if (offset + 1 + lengthLength > data.length) {
            logger.throwError("data short segment too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const length = unarrayifyInteger(data, offset + 1, lengthLength);
        if (offset + 1 + lengthLength + length > data.length) {
            logger.throwError("data long segment too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        return _decodeChildren(data, offset, offset + 1 + lengthLength, lengthLength + length);
    }
    else if (data[offset] >= 0xc0) {
        const length = data[offset] - 0xc0;
        if (offset + 1 + length > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        return _decodeChildren(data, offset, offset + 1, length);
    }
    else if (data[offset] >= 0xb8) {
        const lengthLength = data[offset] - 0xb7;
        if (offset + 1 + lengthLength > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const length = unarrayifyInteger(data, offset + 1, lengthLength);
        if (offset + 1 + lengthLength + length > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const result = hexlify(data.slice(offset + 1 + lengthLength, offset + 1 + lengthLength + length));
        return { consumed: (1 + lengthLength + length), result: result };
    }
    else if (data[offset] >= 0x80) {
        const length = data[offset] - 0x80;
        if (offset + 1 + length > data.length) {
            logger.throwError("data too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const result = hexlify(data.slice(offset + 1, offset + 1 + length));
        return { consumed: (1 + length), result: result };
    }
    return { consumed: 1, result: hexlify(data[offset]) };
}
function decode$3(data) {
    const bytes = arrayify(data);
    const decoded = _decode(bytes, 0);
    if (decoded.consumed !== bytes.length) {
        logger.throwArgumentError("invalid rlp data", "data", data);
    }
    return decoded.result;
}

class EnrDecoder {
    static fromString(encoded) {
        if (!encoded.startsWith(ENR.RECORD_PREFIX)) {
            throw new Error(`"string encoded ENR must start with '${ENR.RECORD_PREFIX}'`);
        }
        return EnrDecoder.fromRLP(fromString$2(encoded.slice(4), "base64url"));
    }
    static fromRLP(encoded) {
        const decoded = decode$3(encoded).map(hexToBytes);
        return fromValues(decoded);
    }
}
async function fromValues(values) {
    const { signature, seq, kvs } = checkValues(values);
    const obj = {};
    for (let i = 0; i < kvs.length; i += 2) {
        try {
            obj[bytesToUtf8(kvs[i])] = kvs[i + 1];
        }
        catch (e) {
            browserExports.log("Failed to decode ENR key to UTF-8, skipping it", kvs[i], e);
        }
    }
    const _seq = decodeSeq(seq);
    const enr = await ENR.create(obj, _seq, signature);
    checkSignature(seq, kvs, enr, signature);
    return enr;
}
function decodeSeq(seq) {
    // If seq is an empty array, translate as value 0
    if (!seq.length)
        return BigInt(0);
    return BigInt("0x" + bytesToHex(seq));
}
function checkValues(values) {
    if (!Array.isArray(values)) {
        throw new Error("Decoded ENR must be an array");
    }
    if (values.length % 2 !== 0) {
        throw new Error("Decoded ENR must have an even number of elements");
    }
    const [signature, seq, ...kvs] = values;
    if (!signature || Array.isArray(signature)) {
        throw new Error("Decoded ENR invalid signature: must be a byte array");
    }
    if (!seq || Array.isArray(seq)) {
        throw new Error("Decoded ENR invalid sequence number: must be a byte array");
    }
    return { signature, seq, kvs };
}
function checkSignature(seq, kvs, enr, signature) {
    const rlpEncodedBytes = hexToBytes(encode$4([seq, ...kvs]));
    if (!enr.verify(rlpEncodedBytes, signature)) {
        throw new Error("Unable to verify ENR signature");
    }
}

const v4Regex$1 = /^(\d{1,3}\.){3,3}\d{1,3}$/;
const v4Size = 4;
const v6Regex$1 = /^(::)?(((\d{1,3}\.){3}(\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?$/i;
const v6Size = 16;

const v4$1 = {
  name: 'v4',
  size: v4Size,
  isFormat: ip => v4Regex$1.test(ip),
  encode (ip, buff, offset) {
    offset = ~~offset;
    buff = buff || new Uint8Array(offset + v4Size);
    const max = ip.length;
    let n = 0;
    for (let i = 0; i < max;) {
      const c = ip.charCodeAt(i++);
      if (c === 46) { // "."
        buff[offset++] = n;
        n = 0;
      } else {
        n = n * 10 + (c - 48);
      }
    }
    buff[offset] = n;
    return buff
  },
  decode (buff, offset) {
    offset = ~~offset;
    return `${buff[offset++]}.${buff[offset++]}.${buff[offset++]}.${buff[offset]}`
  }
};

const v6$1 = {
  name: 'v6',
  size: v6Size,
  isFormat: ip => ip.length > 0 && v6Regex$1.test(ip),
  encode (ip, buff, offset) {
    offset = ~~offset;
    let end = offset + v6Size;
    let fill = -1;
    let hexN = 0;
    let decN = 0;
    let prevColon = true;
    let useDec = false;
    buff = buff || new Uint8Array(offset + v6Size);
    // Note: This algorithm needs to check if the offset
    // could exceed the buffer boundaries as it supports
    // non-standard compliant encodings that may go beyond
    // the boundary limits. if (offset < end) checks should
    // not be necessary...
    for (let i = 0; i < ip.length; i++) {
      let c = ip.charCodeAt(i);
      if (c === 58) { // :
        if (prevColon) {
          if (fill !== -1) {
            // Not Standard! (standard doesn't allow multiple ::)
            // We need to treat
            if (offset < end) buff[offset] = 0;
            if (offset < end - 1) buff[offset + 1] = 0;
            offset += 2;
          } else if (offset < end) {
            // :: in the middle
            fill = offset;
          }
        } else {
          // : ends the previous number
          if (useDec === true) {
            // Non-standard! (ipv4 should be at end only)
            // A ipv4 address should not be found anywhere else but at
            // the end. This codec also support putting characters
            // after the ipv4 address..
            if (offset < end) buff[offset] = decN;
            offset++;
          } else {
            if (offset < end) buff[offset] = hexN >> 8;
            if (offset < end - 1) buff[offset + 1] = hexN & 0xff;
            offset += 2;
          }
          hexN = 0;
          decN = 0;
        }
        prevColon = true;
        useDec = false;
      } else if (c === 46) { // . indicates IPV4 notation
        if (offset < end) buff[offset] = decN;
        offset++;
        decN = 0;
        hexN = 0;
        prevColon = false;
        useDec = true;
      } else {
        prevColon = false;
        if (c >= 97) {
          c -= 87; // a-f ... 97~102 -87 => 10~15
        } else if (c >= 65) {
          c -= 55; // A-F ... 65~70 -55 => 10~15
        } else {
          c -= 48; // 0-9 ... starting from charCode 48
          decN = decN * 10 + c;
        }
        // We don't know yet if its a dec or hex number
        hexN = (hexN << 4) + c;
      }
    }
    if (prevColon === false) {
      // Commiting last number
      if (useDec === true) {
        if (offset < end) buff[offset] = decN;
        offset++;
      } else {
        if (offset < end) buff[offset] = hexN >> 8;
        if (offset < end - 1) buff[offset + 1] = hexN & 0xff;
        offset += 2;
      }
    } else if (fill === 0) {
      // Not Standard! (standard doesn't allow multiple ::)
      // This means that a : was found at the start AND end which means the
      // end needs to be treated as 0 entry...
      if (offset < end) buff[offset] = 0;
      if (offset < end - 1) buff[offset + 1] = 0;
      offset += 2;
    } else if (fill !== -1) {
      // Non-standard! (standard doens't allow multiple ::)
      // Here we find that there has been a :: somewhere in the middle
      // and the end. To treat the end with priority we need to move all
      // written data two bytes to the right.
      offset += 2;
      for (let i = Math.min(offset - 1, end - 1); i >= fill + 2; i--) {
        buff[i] = buff[i - 2];
      }
      buff[fill] = 0;
      buff[fill + 1] = 0;
      fill = offset;
    }
    if (fill !== offset && fill !== -1) {
      // Move the written numbers to the end while filling the everything
      // "fill" to the bytes with zeros.
      if (offset > end - 2) {
        // Non Standard support, when the cursor exceeds bounds.
        offset = end - 2;
      }
      while (end > fill) {
        buff[--end] = offset < end && offset > fill ? buff[--offset] : 0;
      }
    } else {
      // Fill the rest with zeros
      while (offset < end) {
        buff[offset++] = 0;
      }
    }
    return buff
  },
  decode (buff, offset) {
    offset = ~~offset;
    let result = '';
    for (let i = 0; i < v6Size; i += 2) {
      if (i !== 0) {
        result += ':';
      }
      result += (buff[offset + i] << 8 | buff[offset + i + 1]).toString(16);
    }
    return result
      .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')
      .replace(/:{3,4}/, '::')
  }
};
function sizeOf (ip) {
  if (v4$1.isFormat(ip)) return v4$1.size
  if (v6$1.isFormat(ip)) return v6$1.size
  throw Error(`Invalid ip address: ${ip}`)
}

function familyOf (string) {
  return sizeOf(string) === v4$1.size ? 1 : 2
}

function encode$3 (ip, buff, offset) {
  offset = ~~offset;
  const size = sizeOf(ip);
  if (typeof buff === 'function') {
    buff = buff(offset + size);
  }
  if (size === v4$1.size) {
    return v4$1.encode(ip, buff, offset)
  }
  return v6$1.encode(ip, buff, offset)
}

function decode$2 (buff, offset, length) {
  offset = ~~offset;
  length = length || (buff.length - offset);
  if (length === v4$1.size) {
    return v4$1.decode(buff, offset, length)
  }
  if (length === v6$1.size) {
    return v6$1.decode(buff, offset, length)
  }
  throw Error(`Invalid buffer size needs to be ${v4$1.size} for v4 or ${v6$1.size} for v6.`)
}

function toString$4 (type) {
  switch (type) {
    case 1: return 'A'
    case 10: return 'NULL'
    case 28: return 'AAAA'
    case 18: return 'AFSDB'
    case 42: return 'APL'
    case 257: return 'CAA'
    case 60: return 'CDNSKEY'
    case 59: return 'CDS'
    case 37: return 'CERT'
    case 5: return 'CNAME'
    case 49: return 'DHCID'
    case 32769: return 'DLV'
    case 39: return 'DNAME'
    case 48: return 'DNSKEY'
    case 43: return 'DS'
    case 55: return 'HIP'
    case 13: return 'HINFO'
    case 45: return 'IPSECKEY'
    case 25: return 'KEY'
    case 36: return 'KX'
    case 29: return 'LOC'
    case 15: return 'MX'
    case 35: return 'NAPTR'
    case 2: return 'NS'
    case 47: return 'NSEC'
    case 50: return 'NSEC3'
    case 51: return 'NSEC3PARAM'
    case 12: return 'PTR'
    case 46: return 'RRSIG'
    case 17: return 'RP'
    case 24: return 'SIG'
    case 6: return 'SOA'
    case 99: return 'SPF'
    case 33: return 'SRV'
    case 44: return 'SSHFP'
    case 32768: return 'TA'
    case 249: return 'TKEY'
    case 52: return 'TLSA'
    case 250: return 'TSIG'
    case 16: return 'TXT'
    case 252: return 'AXFR'
    case 251: return 'IXFR'
    case 41: return 'OPT'
    case 255: return 'ANY'
  }
  return 'UNKNOWN_' + type
}

function toType (name) {
  switch (name.toUpperCase()) {
    case 'A': return 1
    case 'NULL': return 10
    case 'AAAA': return 28
    case 'AFSDB': return 18
    case 'APL': return 42
    case 'CAA': return 257
    case 'CDNSKEY': return 60
    case 'CDS': return 59
    case 'CERT': return 37
    case 'CNAME': return 5
    case 'DHCID': return 49
    case 'DLV': return 32769
    case 'DNAME': return 39
    case 'DNSKEY': return 48
    case 'DS': return 43
    case 'HIP': return 55
    case 'HINFO': return 13
    case 'IPSECKEY': return 45
    case 'KEY': return 25
    case 'KX': return 36
    case 'LOC': return 29
    case 'MX': return 15
    case 'NAPTR': return 35
    case 'NS': return 2
    case 'NSEC': return 47
    case 'NSEC3': return 50
    case 'NSEC3PARAM': return 51
    case 'PTR': return 12
    case 'RRSIG': return 46
    case 'RP': return 17
    case 'SIG': return 24
    case 'SOA': return 6
    case 'SPF': return 99
    case 'SRV': return 33
    case 'SSHFP': return 44
    case 'TA': return 32768
    case 'TKEY': return 249
    case 'TLSA': return 52
    case 'TSIG': return 250
    case 'TXT': return 16
    case 'AXFR': return 252
    case 'IXFR': return 251
    case 'OPT': return 41
    case 'ANY': return 255
    case '*': return 255
  }
  if (name.toUpperCase().startsWith('UNKNOWN_')) return parseInt(name.slice(8))
  return 0
}

/*
 * Traditional DNS header RCODEs (4-bits) defined by IANA in
 * https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml
 */

function toString$3 (rcode) {
  switch (rcode) {
    case 0: return 'NOERROR'
    case 1: return 'FORMERR'
    case 2: return 'SERVFAIL'
    case 3: return 'NXDOMAIN'
    case 4: return 'NOTIMP'
    case 5: return 'REFUSED'
    case 6: return 'YXDOMAIN'
    case 7: return 'YXRRSET'
    case 8: return 'NXRRSET'
    case 9: return 'NOTAUTH'
    case 10: return 'NOTZONE'
    case 11: return 'RCODE_11'
    case 12: return 'RCODE_12'
    case 13: return 'RCODE_13'
    case 14: return 'RCODE_14'
    case 15: return 'RCODE_15'
  }
  return 'RCODE_' + rcode
}

/*
 * Traditional DNS header OPCODEs (4-bits) defined by IANA in
 * https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-5
 */

function toString$2 (opcode) {
  switch (opcode) {
    case 0: return 'QUERY'
    case 1: return 'IQUERY'
    case 2: return 'STATUS'
    case 3: return 'OPCODE_3'
    case 4: return 'NOTIFY'
    case 5: return 'UPDATE'
    case 6: return 'OPCODE_6'
    case 7: return 'OPCODE_7'
    case 8: return 'OPCODE_8'
    case 9: return 'OPCODE_9'
    case 10: return 'OPCODE_10'
    case 11: return 'OPCODE_11'
    case 12: return 'OPCODE_12'
    case 13: return 'OPCODE_13'
    case 14: return 'OPCODE_14'
    case 15: return 'OPCODE_15'
  }
  return 'OPCODE_' + opcode
}

function toString$1 (klass) {
  switch (klass) {
    case 1: return 'IN'
    case 2: return 'CS'
    case 3: return 'CH'
    case 4: return 'HS'
    case 255: return 'ANY'
  }
  return 'UNKNOWN_' + klass
}

function toClass (name) {
  switch (name.toUpperCase()) {
    case 'IN': return 1
    case 'CS': return 2
    case 'CH': return 3
    case 'HS': return 4
    case 'ANY': return 255
  }
  return 0
}

function toString (type) {
  switch (type) {
    // list at
    // https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-11
    case 1: return 'LLQ'
    case 2: return 'UL'
    case 3: return 'NSID'
    case 5: return 'DAU'
    case 6: return 'DHU'
    case 7: return 'N3U'
    case 8: return 'CLIENT_SUBNET'
    case 9: return 'EXPIRE'
    case 10: return 'COOKIE'
    case 11: return 'TCP_KEEPALIVE'
    case 12: return 'PADDING'
    case 13: return 'CHAIN'
    case 14: return 'KEY_TAG'
    case 26946: return 'DEVICEID'
  }
  if (type < 0) {
    return null
  }
  return `OPTION_${type}`
}

function toCode (name) {
  if (typeof name === 'number') {
    return name
  }
  if (!name) {
    return -1
  }
  switch (name.toUpperCase()) {
    case 'OPTION_0': return 0
    case 'LLQ': return 1
    case 'UL': return 2
    case 'NSID': return 3
    case 'OPTION_4': return 4
    case 'DAU': return 5
    case 'DHU': return 6
    case 'N3U': return 7
    case 'CLIENT_SUBNET': return 8
    case 'EXPIRE': return 9
    case 'COOKIE': return 10
    case 'TCP_KEEPALIVE': return 11
    case 'PADDING': return 12
    case 'CHAIN': return 13
    case 'KEY_TAG': return 14
    case 'DEVICEID': return 26946
    case 'OPTION_65535': return 65535
  }
  const m = name.match(/_(\d+)$/);
  if (m) {
    return parseInt(m[1], 10)
  }
  return -1
}

const SURROGATE_A = 0b1101100000000000;
const SURROGATE_B = 0b1101110000000000;

function encodingLength$1 (str) {
  let len = 0;
  const strLen = str.length;
  for (let i = 0; i < strLen; i += 1) {
    const code = str.charCodeAt(i);
    if (code <= 0x7F) {
      len += 1;
    } else if (code <= 0x07FF) {
      len += 2;
    } else if ((code & 0xF800) !== SURROGATE_A) {
      len += 3;
    } else {
      const next = i + 1;
      if (next === strLen || code >= SURROGATE_B) {
        len += 3;
      } else {
        const nextCode = str.charCodeAt(next);
        if ((nextCode & 0xFC00) !== SURROGATE_B) {
          len += 3;
        } else {
          i = next;
          len += 4;
        }
      }
    }
  }
  return len
}

function encode$2 (str, buf, offset) {
  const strLen = str.length;
  if (offset === undefined || offset === null) {
    offset = 0;
  }
  if (buf === undefined) {
    buf = new Uint8Array(encodingLength$1(str) + offset);
  }
  let off = offset;
  for (let i = 0; i < strLen; i += 1) {
    let code = str.charCodeAt(i);
    if (code <= 0x7F) {
      buf[off++] = code;
    } else if (code <= 0x07FF) {
      buf[off++] = 0b11000000 | ((code & 0b11111000000) >> 6);
      buf[off++] = 0b10000000 | (code & 0b00000111111);
    } else if ((code & 0xF800) !== SURROGATE_A) {
      buf[off++] = 0b11100000 | ((code & 0b1111000000000000) >> 12);
      buf[off++] = 0b10000000 | ((code & 0b0000111111000000) >> 6);
      buf[off++] = 0b10000000 | (code & 0b0000000000111111);
    } else {
      const next = i + 1;
      if (next === strLen || code >= SURROGATE_B) {
        // Incorrectly started surrogate pair
        buf[off++] = 0xef;
        buf[off++] = 0xbf;
        buf[off++] = 0xbd;
      } else {
        const nextCode = str.charCodeAt(next);
        if ((nextCode & 0xFC00) !== SURROGATE_B) {
          // Incorrect surrogate pair
          buf[off++] = 0xef;
          buf[off++] = 0xbf;
          buf[off++] = 0xbd;
        } else {
          i = next;
          code = 0b000010000000000000000 |
            ((code & 0b1111111111) << 10) |
            (nextCode & 0b1111111111);
          buf[off++] = 0b11110000 | ((code & 0b111000000000000000000) >> 18);
          buf[off++] = 0b10000000 | ((code & 0b000111111000000000000) >> 12);
          buf[off++] = 0b10000000 | ((code & 0b000000000111111000000) >> 6);
          buf[off++] = 0b10000000 | (code & 0b000000000000000111111);
        }
      }
    }
  }
  encode$2.bytes = off - offset;
  return buf
}
encode$2.bytes = 0;

function decode$1 (buf, start, end) {
  let result = '';
  if (start === undefined || start === null) {
    start = 0;
  }
  if (end === undefined || end === null) {
    end = buf.length;
  }
  for (let offset = start; offset < end;) {
    const code = buf[offset++];
    let num;
    if (code <= 128) {
      num = code;
    } else if (code > 191 && code < 224) {
      num = ((code & 0b11111) << 6) | (buf[offset++] & 0b111111);
    } else if (code > 239 && code < 365) {
      num = (
        ((code & 0b111) << 18) |
        ((buf[offset++] & 0b111111) << 12) |
        ((buf[offset++] & 0b111111) << 6) |
        (buf[offset++] & 0b111111)
      ) - 0x10000;
      const numA = SURROGATE_A | ((num >> 10) & 0b1111111111);
      result += String.fromCharCode(numA);
      num = SURROGATE_B | (num & 0b1111111111);
    } else {
      num = ((code & 0b1111) << 12) |
        ((buf[offset++] & 0b111111) << 6) |
        (buf[offset++] & 0b111111);
    }
    result += String.fromCharCode(num);
  }
  decode$1.bytes = end - start;
  return result
}
decode$1.bytes = 0;

const isU8Arr = input => input instanceof Uint8Array;

function bytelength (input) {
  return typeof input === 'string' ? encodingLength$1(input) : input.byteLength
}

function from (input) {
  if (input instanceof Uint8Array) {
    return input
  }
  if (Array.isArray(input)) {
    return new Uint8Array(input)
  }
  return encode$2(input)
}

function write$1 (arr, str, start) {
  if (typeof str !== 'string') {
    throw new Error('unknown input type')
  }
  encode$2(str, arr, start);
  return encode$2.bytes
}

const P_24 = Math.pow(2, 24);
const P_16 = Math.pow(2, 16);
const P_8 = Math.pow(2, 8);
const readUInt32BE = (buf, offset) => buf[offset] * P_24 +
  buf[offset + 1] * P_16 +
  buf[offset + 2] * P_8 +
  buf[offset + 3];

const readUInt16BE = (buf, offset) => (buf[offset] << 8) | buf[offset + 1];
const writeUInt32BE = (buf, value, offset) => {
  value = +value;
  buf[offset + 3] = value;
  value = value >>> 8;
  buf[offset + 2] = value;
  value = value >>> 8;
  buf[offset + 1] = value;
  value = value >>> 8;
  buf[offset] = value;
  return offset + 4
};
const writeUInt16BE = (buf, value, offset) => {
  buf[offset] = value >> 8;
  buf[offset + 1] = value & 0xFF;
  return offset + 2
};

function copy (source, target, targetStart, sourceStart, sourceEnd) {
  if (targetStart < 0) {
    sourceStart -= targetStart;
    targetStart = 0;
  }

  if (sourceStart < 0) {
    sourceStart = 0;
  }

  if (sourceEnd < 0) {
    return new Uint8Array(0)
  }

  if (targetStart >= target.length || sourceStart >= sourceEnd) {
    return 0
  }

  return _copyActual(source, target, targetStart, sourceStart, sourceEnd)
}

function _copyActual (source, target, targetStart, sourceStart, sourceEnd) {
  if (sourceEnd - sourceStart > target.length - targetStart) {
    sourceEnd = sourceStart + target.length - targetStart;
  }

  let nb = sourceEnd - sourceStart;
  const sourceLen = source.length - sourceStart;
  if (nb > sourceLen) {
    nb = sourceLen;
  }

  if (sourceStart !== 0 || sourceEnd < source.length) {
    source = new Uint8Array(source.buffer, source.byteOffset + sourceStart, nb);
  }

  target.set(source, targetStart);

  return nb
}

const QUERY_FLAG = 0;
const RESPONSE_FLAG = 1 << 15;
const FLUSH_MASK = 1 << 15;
const NOT_FLUSH_MASK = ~FLUSH_MASK;
const QU_MASK = 1 << 15;
const NOT_QU_MASK = ~QU_MASK;

function codec ({ bytes = 0, encode, decode, encodingLength }) {
  encode.bytes = bytes;
  decode.bytes = bytes;
  return {
    encode,
    decode,
    encodingLength: encodingLength || (() => bytes)
  }
}

const name$1 = codec({
  encode (str, buf, offset) {
    if (!buf) buf = new Uint8Array(name$1.encodingLength(str));
    if (!offset) offset = 0;
    const oldOffset = offset;

    // strip leading and trailing .
    const n = str.replace(/^\.|\.$/gm, '');
    if (n.length) {
      const list = n.split('.');

      for (let i = 0; i < list.length; i++) {
        const len = write$1(buf, list[i], offset + 1);
        buf[offset] = len;
        offset += len + 1;
      }
    }

    buf[offset++] = 0;

    name$1.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const list = [];
    let oldOffset = offset;
    let totalLength = 0;
    let consumedBytes = 0;
    let jumped = false;

    while (true) {
      if (offset >= buf.length) {
        throw new Error('Cannot decode name (buffer overflow)')
      }
      const len = buf[offset++];
      consumedBytes += jumped ? 0 : 1;

      if (len === 0) {
        break
      } else if ((len & 0xc0) === 0) {
        if (offset + len > buf.length) {
          throw new Error('Cannot decode name (buffer overflow)')
        }
        totalLength += len + 1;
        if (totalLength > 254) {
          throw new Error('Cannot decode name (name too long)')
        }
        list.push(decode$1(buf, offset, offset + len));
        offset += len;
        consumedBytes += jumped ? 0 : len;
      } else if ((len & 0xc0) === 0xc0) {
        if (offset + 1 > buf.length) {
          throw new Error('Cannot decode name (buffer overflow)')
        }
        const jumpOffset = readUInt16BE(buf, offset - 1) - 0xc000;
        if (jumpOffset >= oldOffset) {
          // Allow only pointers to prior data. RFC 1035, section 4.1.4 states:
          // "[...] an entire domain name or a list of labels at the end of a domain name
          // is replaced with a pointer to a prior occurance (sic) of the same name."
          throw new Error('Cannot decode name (bad pointer)')
        }
        offset = jumpOffset;
        oldOffset = jumpOffset;
        consumedBytes += jumped ? 0 : 1;
        jumped = true;
      } else {
        throw new Error('Cannot decode name (bad label)')
      }
    }

    name$1.decode.bytes = consumedBytes;
    return list.length === 0 ? '.' : list.join('.')
  },
  encodingLength (n) {
    if (n === '.' || n === '..') return 1
    return bytelength(n.replace(/^\.|\.$/gm, '')) + 2
  }
});

const string = codec({
  encode (s, buf, offset) {
    if (!buf) buf = new Uint8Array(string.encodingLength(s));
    if (!offset) offset = 0;

    const len = write$1(buf, s, offset + 1);
    buf[offset] = len;
    string.encode.bytes = len + 1;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = buf[offset];
    const s = decode$1(buf, offset + 1, offset + 1 + len);
    string.decode.bytes = len + 1;
    return s
  },
  encodingLength (s) {
    return bytelength(s) + 1
  }
});

const header = codec({
  bytes: 12,
  encode (h, buf, offset) {
    if (!buf) buf = new Uint8Array(header.encodingLength(h));
    if (!offset) offset = 0;

    const flags = (h.flags || 0) & 32767;
    const type = h.type === 'response' ? RESPONSE_FLAG : QUERY_FLAG;

    writeUInt16BE(buf, h.id || 0, offset);
    writeUInt16BE(buf, flags | type, offset + 2);
    writeUInt16BE(buf, h.questions.length, offset + 4);
    writeUInt16BE(buf, h.answers.length, offset + 6);
    writeUInt16BE(buf, h.authorities.length, offset + 8);
    writeUInt16BE(buf, h.additionals.length, offset + 10);

    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    if (buf.length < 12) throw new Error('Header must be 12 bytes')
    const flags = readUInt16BE(buf, offset + 2);

    return {
      id: readUInt16BE(buf, offset),
      type: flags & RESPONSE_FLAG ? 'response' : 'query',
      flags: flags & 32767,
      flag_qr: ((flags >> 15) & 0x1) === 1,
      opcode: toString$2((flags >> 11) & 0xf),
      flag_aa: ((flags >> 10) & 0x1) === 1,
      flag_tc: ((flags >> 9) & 0x1) === 1,
      flag_rd: ((flags >> 8) & 0x1) === 1,
      flag_ra: ((flags >> 7) & 0x1) === 1,
      flag_z: ((flags >> 6) & 0x1) === 1,
      flag_ad: ((flags >> 5) & 0x1) === 1,
      flag_cd: ((flags >> 4) & 0x1) === 1,
      rcode: toString$3(flags & 0xf),
      questions: new Array(readUInt16BE(buf, offset + 4)),
      answers: new Array(readUInt16BE(buf, offset + 6)),
      authorities: new Array(readUInt16BE(buf, offset + 8)),
      additionals: new Array(readUInt16BE(buf, offset + 10))
    }
  },
  encodingLength () {
    return 12
  }
});

const runknown = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(runknown.encodingLength(data));
    if (!offset) offset = 0;

    const dLen = data.length;
    writeUInt16BE(buf, dLen, offset);
    copy(data, buf, offset + 2, 0, dLen);

    runknown.encode.bytes = dLen + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    const data = buf.slice(offset + 2, offset + 2 + len);
    runknown.decode.bytes = len + 2;
    return data
  },
  encodingLength (data) {
    return data.length + 2
  }
});

const rns = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rns.encodingLength(data));
    if (!offset) offset = 0;

    name$1.encode(data, buf, offset + 2);
    writeUInt16BE(buf, name$1.encode.bytes, offset);
    rns.encode.bytes = name$1.encode.bytes + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    const dd = name$1.decode(buf, offset + 2);

    rns.decode.bytes = len + 2;
    return dd
  },
  encodingLength (data) {
    return name$1.encodingLength(data) + 2
  }
});

const rsoa = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rsoa.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    name$1.encode(data.mname, buf, offset);
    offset += name$1.encode.bytes;
    name$1.encode(data.rname, buf, offset);
    offset += name$1.encode.bytes;
    writeUInt32BE(buf, data.serial || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.refresh || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.retry || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.expire || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.minimum || 0, offset);
    offset += 4;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rsoa.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.mname = name$1.decode(buf, offset);
    offset += name$1.decode.bytes;
    data.rname = name$1.decode(buf, offset);
    offset += name$1.decode.bytes;
    data.serial = readUInt32BE(buf, offset);
    offset += 4;
    data.refresh = readUInt32BE(buf, offset);
    offset += 4;
    data.retry = readUInt32BE(buf, offset);
    offset += 4;
    data.expire = readUInt32BE(buf, offset);
    offset += 4;
    data.minimum = readUInt32BE(buf, offset);
    offset += 4;

    rsoa.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 22 + name$1.encodingLength(data.mname) + name$1.encodingLength(data.rname)
  }
});

const rtxt = codec({
  encode (data, buf, offset) {
    if (!Array.isArray(data)) data = [data];
    for (let i = 0; i < data.length; i++) {
      if (typeof data[i] === 'string') {
        data[i] = from(data[i]);
      }
      if (!isU8Arr(data[i])) {
        throw new Error('Must be a Buffer')
      }
    }

    if (!buf) buf = new Uint8Array(rtxt.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;

    data.forEach(function (d) {
      buf[offset++] = d.length;
      copy(d, buf, offset, 0, d.length);
      offset += d.length;
    });

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rtxt.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;
    let remaining = readUInt16BE(buf, offset);
    offset += 2;

    const data = [];
    while (remaining > 0) {
      const len = buf[offset++];
      --remaining;
      if (remaining < len) {
        throw new Error('Buffer overflow')
      }
      data.push(buf.slice(offset, offset + len));
      offset += len;
      remaining -= len;
    }

    rtxt.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    if (!Array.isArray(data)) data = [data];
    let length = 2;
    data.forEach(function (buf) {
      if (typeof buf === 'string') {
        length += bytelength(buf) + 1;
      } else {
        length += buf.length + 1;
      }
    });
    return length
  }
});

const rnull = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rnull.encodingLength(data));
    if (!offset) offset = 0;

    if (typeof data === 'string') data = from(data);
    if (!data) data = new Uint8Array(0);

    const oldOffset = offset;
    offset += 2;

    const len = data.length;
    copy(data, buf, offset, 0, len);
    offset += len;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rnull.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;
    const len = readUInt16BE(buf, offset);

    offset += 2;

    const data = buf.slice(offset, offset + len);
    offset += len;

    rnull.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    if (!data) return 2
    return (isU8Arr(data) ? data.length : bytelength(data)) + 2
  }
});

const rhinfo = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rhinfo.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    string.encode(data.cpu, buf, offset);
    offset += string.encode.bytes;
    string.encode(data.os, buf, offset);
    offset += string.encode.bytes;
    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rhinfo.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.cpu = string.decode(buf, offset);
    offset += string.decode.bytes;
    data.os = string.decode(buf, offset);
    offset += string.decode.bytes;
    rhinfo.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return string.encodingLength(data.cpu) + string.encodingLength(data.os) + 2
  }
});

const rptr = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rptr.encodingLength(data));
    if (!offset) offset = 0;

    name$1.encode(data, buf, offset + 2);
    writeUInt16BE(buf, name$1.encode.bytes, offset);
    rptr.encode.bytes = name$1.encode.bytes + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const data = name$1.decode(buf, offset + 2);
    rptr.decode.bytes = name$1.decode.bytes + 2;
    return data
  },
  encodingLength (data) {
    return name$1.encodingLength(data) + 2
  }
});

const rsrv = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rsrv.encodingLength(data));
    if (!offset) offset = 0;

    writeUInt16BE(buf, data.priority || 0, offset + 2);
    writeUInt16BE(buf, data.weight || 0, offset + 4);
    writeUInt16BE(buf, data.port || 0, offset + 6);
    name$1.encode(data.target, buf, offset + 8);

    const len = name$1.encode.bytes + 6;
    writeUInt16BE(buf, len, offset);

    rsrv.encode.bytes = len + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);

    const data = {};
    data.priority = readUInt16BE(buf, offset + 2);
    data.weight = readUInt16BE(buf, offset + 4);
    data.port = readUInt16BE(buf, offset + 6);
    data.target = name$1.decode(buf, offset + 8);

    rsrv.decode.bytes = len + 2;
    return data
  },
  encodingLength (data) {
    return 8 + name$1.encodingLength(data.target)
  }
});

const rcaa = codec({
  encode (data, buf, offset) {
    const len = rcaa.encodingLength(data);

    if (!buf) buf = new Uint8Array(rcaa.encodingLength(data));
    if (!offset) offset = 0;

    if (data.issuerCritical) {
      data.flags = rcaa.ISSUER_CRITICAL;
    }

    writeUInt16BE(buf, len - 2, offset);
    offset += 2;
    buf[offset] = data.flags || 0;
    offset += 1;
    string.encode(data.tag, buf, offset);
    offset += string.encode.bytes;
    write$1(buf, data.value, offset);
    offset += bytelength(data.value);

    rcaa.encode.bytes = len;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    offset += 2;

    const oldOffset = offset;
    const data = {};
    data.flags = buf[offset];
    offset += 1;
    data.tag = string.decode(buf, offset);
    offset += string.decode.bytes;
    data.value = decode$1(buf, offset, oldOffset + len);

    data.issuerCritical = !!(data.flags & rcaa.ISSUER_CRITICAL);

    rcaa.decode.bytes = len + 2;

    return data
  },
  encodingLength (data) {
    return string.encodingLength(data.tag) + string.encodingLength(data.value) + 2
  }
});

rcaa.ISSUER_CRITICAL = 1 << 7;

const rmx = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rmx.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    writeUInt16BE(buf, data.preference || 0, offset);
    offset += 2;
    name$1.encode(data.exchange, buf, offset);
    offset += name$1.encode.bytes;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rmx.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.preference = readUInt16BE(buf, offset);
    offset += 2;
    data.exchange = name$1.decode(buf, offset);
    offset += name$1.decode.bytes;

    rmx.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 4 + name$1.encodingLength(data.exchange)
  }
});

const ra = codec({
  encode (host, buf, offset) {
    if (!buf) buf = new Uint8Array(ra.encodingLength(host));
    if (!offset) offset = 0;

    writeUInt16BE(buf, 4, offset);
    offset += 2;
    v4$1.encode(host, buf, offset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    offset += 2;
    const host = v4$1.decode(buf, offset);
    return host
  },
  bytes: 6
});

const raaaa = codec({
  encode (host, buf, offset) {
    if (!buf) buf = new Uint8Array(raaaa.encodingLength(host));
    if (!offset) offset = 0;

    writeUInt16BE(buf, 16, offset);
    offset += 2;
    v6$1.encode(host, buf, offset);
    raaaa.encode.bytes = 18;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    offset += 2;
    const host = v6$1.decode(buf, offset);
    raaaa.decode.bytes = 18;
    return host
  },
  bytes: 18
});

const alloc = size => new Uint8Array(size);

const roption = codec({
  encode (option, buf, offset) {
    if (!buf) buf = new Uint8Array(roption.encodingLength(option));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const code = toCode(option.code);
    writeUInt16BE(buf, code, offset);
    offset += 2;
    if (option.data) {
      writeUInt16BE(buf, option.data.length, offset);
      offset += 2;
      copy(option.data, buf, offset);
      offset += option.data.length;
    } else {
      switch (code) {
        // case 3: NSID.  No encode makes sense.
        // case 5,6,7: Not implementable
        case 8: // ECS
          {
            // note: do IP math before calling
            const spl = option.sourcePrefixLength || 0;
            const fam = option.family || familyOf(option.ip);
            const ipBuf = encode$3(option.ip, alloc);
            const ipLen = Math.ceil(spl / 8);
            writeUInt16BE(buf, ipLen + 4, offset);
            offset += 2;
            writeUInt16BE(buf, fam, offset);
            offset += 2;
            buf[offset++] = spl;
            buf[offset++] = option.scopePrefixLength || 0;

            copy(ipBuf, buf, offset, 0, ipLen);
            offset += ipLen;
          }
          break
        // case 9: EXPIRE (experimental)
        // case 10: COOKIE.  No encode makes sense.
        case 11: // KEEP-ALIVE
          if (option.timeout) {
            writeUInt16BE(buf, 2, offset);
            offset += 2;
            writeUInt16BE(buf, option.timeout, offset);
            offset += 2;
          } else {
            writeUInt16BE(buf, 0, offset);
            offset += 2;
          }
          break
        case 12: // PADDING
          {
            const len = option.length || 0;
            writeUInt16BE(buf, len, offset);
            offset += 2;
            buf.fill(0, offset, offset + len);
            offset += len;
          }
          break
        // case 13:  CHAIN.  Experimental.
        case 14: // KEY-TAG
          {
            const tagsLen = option.tags.length * 2;
            writeUInt16BE(buf, tagsLen, offset);
            offset += 2;
            for (const tag of option.tags) {
              writeUInt16BE(buf, tag, offset);
              offset += 2;
            }
          }
          break
        default:
          throw new Error(`Unknown roption code: ${option.code}`)
      }
    }

    roption.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const option = {};
    option.code = readUInt16BE(buf, offset);
    option.type = toString(option.code);
    offset += 2;
    const len = readUInt16BE(buf, offset);
    offset += 2;
    option.data = buf.slice(offset, offset + len);
    switch (option.code) {
      // case 3: NSID.  No decode makes sense.
      case 8: // ECS
        option.family = readUInt16BE(buf, offset);
        offset += 2;
        option.sourcePrefixLength = buf[offset++];
        option.scopePrefixLength = buf[offset++];
        {
          const padded = new Uint8Array((option.family === 1) ? 4 : 16);
          copy(buf, padded, 0, offset, offset + len - 4);
          option.ip = decode$2(padded);
        }
        break
      // case 12: Padding.  No decode makes sense.
      case 11: // KEEP-ALIVE
        if (len > 0) {
          option.timeout = readUInt16BE(buf, offset);
          offset += 2;
        }
        break
      case 14:
        option.tags = [];
        for (let i = 0; i < len; i += 2) {
          option.tags.push(readUInt16BE(buf, offset));
          offset += 2;
        }
      // don't worry about default.  caller will use data if desired
    }

    roption.decode.bytes = len + 4;
    return option
  },
  encodingLength (option) {
    if (option.data) {
      return option.data.length + 4
    }
    const code = toCode(option.code);
    switch (code) {
      case 8: // ECS
      {
        const spl = option.sourcePrefixLength || 0;
        return Math.ceil(spl / 8) + 8
      }
      case 11: // KEEP-ALIVE
        return (typeof option.timeout === 'number') ? 6 : 4
      case 12: // PADDING
        return option.length + 4
      case 14: // KEY-TAG
        return 4 + (option.tags.length * 2)
    }
    throw new Error(`Unknown roption code: ${option.code}`)
  }
});

const ropt = codec({
  encode (options, buf, offset) {
    if (!buf) buf = new Uint8Array(ropt.encodingLength(options));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const rdlen = encodingLengthList(options, roption);
    writeUInt16BE(buf, rdlen, offset);
    offset = encodeList(options, roption, buf, offset + 2);

    ropt.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const options = [];
    let rdlen = readUInt16BE(buf, offset);
    offset += 2;
    let o = 0;
    while (rdlen > 0) {
      options[o++] = roption.decode(buf, offset);
      offset += roption.decode.bytes;
      rdlen -= roption.decode.bytes;
    }
    ropt.decode.bytes = offset - oldOffset;
    return options
  },
  encodingLength (options) {
    return 2 + encodingLengthList(options || [], roption)
  }
});

const rdnskey = codec({
  encode (key, buf, offset) {
    if (!buf) buf = new Uint8Array(rdnskey.encodingLength(key));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const keydata = key.key;
    if (!isU8Arr(keydata)) {
      throw new Error('Key must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, key.flags, offset);
    offset += 2;
    buf[offset] = rdnskey.PROTOCOL_DNSSEC;
    offset += 1;
    buf[offset] = key.algorithm;
    offset += 1;
    copy(keydata, buf, offset, 0, keydata.length);
    offset += keydata.length;

    rdnskey.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rdnskey.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const key = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    key.flags = readUInt16BE(buf, offset);
    offset += 2;
    if (buf[offset] !== rdnskey.PROTOCOL_DNSSEC) {
      throw new Error('Protocol must be 3')
    }
    offset += 1;
    key.algorithm = buf[offset];
    offset += 1;
    key.key = buf.slice(offset, oldOffset + length + 2);
    offset += key.key.length;
    rdnskey.decode.bytes = offset - oldOffset;
    return key
  },
  encodingLength (key) {
    return 6 + bytelength(key.key)
  }
});

rdnskey.PROTOCOL_DNSSEC = 3;
rdnskey.ZONE_KEY = 0x80;
rdnskey.SECURE_ENTRYPOINT = 0x8000;

const rrrsig = codec({
  encode (sig, buf, offset) {
    if (!buf) buf = new Uint8Array(rrrsig.encodingLength(sig));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const signature = sig.signature;
    if (!isU8Arr(signature)) {
      throw new Error('Signature must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, toType(sig.typeCovered), offset);
    offset += 2;
    buf[offset] = sig.algorithm;
    offset += 1;
    buf[offset] = sig.labels;
    offset += 1;
    writeUInt32BE(buf, sig.originalTTL, offset);
    offset += 4;
    writeUInt32BE(buf, sig.expiration, offset);
    offset += 4;
    writeUInt32BE(buf, sig.inception, offset);
    offset += 4;
    writeUInt16BE(buf, sig.keyTag, offset);
    offset += 2;
    name$1.encode(sig.signersName, buf, offset);
    offset += name$1.encode.bytes;
    copy(signature, buf, offset, 0, signature.length);
    offset += signature.length;

    rrrsig.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rrrsig.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const sig = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    sig.typeCovered = toString$4(readUInt16BE(buf, offset));
    offset += 2;
    sig.algorithm = buf[offset];
    offset += 1;
    sig.labels = buf[offset];
    offset += 1;
    sig.originalTTL = readUInt32BE(buf, offset);
    offset += 4;
    sig.expiration = readUInt32BE(buf, offset);
    offset += 4;
    sig.inception = readUInt32BE(buf, offset);
    offset += 4;
    sig.keyTag = readUInt16BE(buf, offset);
    offset += 2;
    sig.signersName = name$1.decode(buf, offset);
    offset += name$1.decode.bytes;
    sig.signature = buf.slice(offset, oldOffset + length + 2);
    offset += sig.signature.length;
    rrrsig.decode.bytes = offset - oldOffset;
    return sig
  },
  encodingLength (sig) {
    return 20 +
      name$1.encodingLength(sig.signersName) +
      bytelength(sig.signature)
  }
});
const rrp = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rrp.encodingLength(data));
    if (!offset) offset = 0;
    const oldOffset = offset;

    offset += 2; // Leave space for length
    name$1.encode(data.mbox || '.', buf, offset);
    offset += name$1.encode.bytes;
    name$1.encode(data.txt || '.', buf, offset);
    offset += name$1.encode.bytes;
    rrp.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rrp.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.mbox = name$1.decode(buf, offset) || '.';
    offset += name$1.decode.bytes;
    data.txt = name$1.decode(buf, offset) || '.';
    offset += name$1.decode.bytes;
    rrp.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 2 + name$1.encodingLength(data.mbox || '.') + name$1.encodingLength(data.txt || '.')
  }
});

const typebitmap = codec({
  encode (typelist, buf, offset) {
    if (!buf) buf = new Uint8Array(typebitmap.encodingLength(typelist));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const typesByWindow = [];
    for (let i = 0; i < typelist.length; i++) {
      const typeid = toType(typelist[i]);
      if (typesByWindow[typeid >> 8] === undefined) {
        typesByWindow[typeid >> 8] = [];
      }
      typesByWindow[typeid >> 8][(typeid >> 3) & 0x1F] |= 1 << (7 - (typeid & 0x7));
    }

    for (let i = 0; i < typesByWindow.length; i++) {
      if (typesByWindow[i] !== undefined) {
        const windowBuf = from(typesByWindow[i]);
        buf[offset] = i;
        offset += 1;
        buf[offset] = windowBuf.length;
        offset += 1;
        copy(windowBuf, buf, offset, 0, windowBuf.length);
        offset += windowBuf.length;
      }
    }

    typebitmap.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset, length) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const typelist = [];
    while (offset - oldOffset < length) {
      const window = buf[offset];
      offset += 1;
      const windowLength = buf[offset];
      offset += 1;
      for (let i = 0; i < windowLength; i++) {
        const b = buf[offset + i];
        for (let j = 0; j < 8; j++) {
          if (b & (1 << (7 - j))) {
            const typeid = toString$4((window << 8) | (i << 3) | j);
            typelist.push(typeid);
          }
        }
      }
      offset += windowLength;
    }

    typebitmap.decode.bytes = offset - oldOffset;
    return typelist
  },
  encodingLength (typelist) {
    const extents = [];
    for (let i = 0; i < typelist.length; i++) {
      const typeid = toType(typelist[i]);
      extents[typeid >> 8] = Math.max(extents[typeid >> 8] || 0, typeid & 0xFF);
    }

    let len = 0;
    for (let i = 0; i < extents.length; i++) {
      if (extents[i] !== undefined) {
        len += 2 + Math.ceil((extents[i] + 1) / 8);
      }
    }

    return len
  }
});

const rnsec = codec({
  encode (record, buf, offset) {
    if (!buf) buf = new Uint8Array(rnsec.encodingLength(record));
    if (!offset) offset = 0;
    const oldOffset = offset;

    offset += 2; // Leave space for length
    name$1.encode(record.nextDomain, buf, offset);
    offset += name$1.encode.bytes;
    typebitmap.encode(record.rrtypes, buf, offset);
    offset += typebitmap.encode.bytes;

    rnsec.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rnsec.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const record = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    record.nextDomain = name$1.decode(buf, offset);
    offset += name$1.decode.bytes;
    record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset));
    offset += typebitmap.decode.bytes;

    rnsec.decode.bytes = offset - oldOffset;
    return record
  },
  encodingLength (record) {
    return 2 +
      name$1.encodingLength(record.nextDomain) +
      typebitmap.encodingLength(record.rrtypes)
  }
});

const rnsec3 = codec({
  encode (record, buf, offset) {
    if (!buf) buf = new Uint8Array(rnsec3.encodingLength(record));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const salt = record.salt;
    if (!isU8Arr(salt)) {
      throw new Error('salt must be a Buffer')
    }

    const nextDomain = record.nextDomain;
    if (!isU8Arr(nextDomain)) {
      throw new Error('nextDomain must be a Buffer')
    }

    offset += 2; // Leave space for length
    buf[offset] = record.algorithm;
    offset += 1;
    buf[offset] = record.flags;
    offset += 1;
    writeUInt16BE(buf, record.iterations, offset);
    offset += 2;
    buf[offset] = salt.length;
    offset += 1;
    copy(salt, buf, offset, 0, salt.length);
    offset += salt.length;
    buf[offset] = nextDomain.length;
    offset += 1;
    copy(nextDomain, buf, offset, 0, nextDomain.length);
    offset += nextDomain.length;
    typebitmap.encode(record.rrtypes, buf, offset);
    offset += typebitmap.encode.bytes;

    rnsec3.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rnsec3.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const record = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    record.algorithm = buf[offset];
    offset += 1;
    record.flags = buf[offset];
    offset += 1;
    record.iterations = readUInt16BE(buf, offset);
    offset += 2;
    const saltLength = buf[offset];
    offset += 1;
    record.salt = buf.slice(offset, offset + saltLength);
    offset += saltLength;
    const hashLength = buf[offset];
    offset += 1;
    record.nextDomain = buf.slice(offset, offset + hashLength);
    offset += hashLength;
    record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset));
    offset += typebitmap.decode.bytes;

    rnsec3.decode.bytes = offset - oldOffset;
    return record
  },
  encodingLength (record) {
    return 8 +
      record.salt.length +
      record.nextDomain.length +
      typebitmap.encodingLength(record.rrtypes)
  }
});

const rds = codec({
  encode (digest, buf, offset) {
    if (!buf) buf = new Uint8Array(rds.encodingLength(digest));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const digestdata = digest.digest;
    if (!isU8Arr(digestdata)) {
      throw new Error('Digest must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, digest.keyTag, offset);
    offset += 2;
    buf[offset] = digest.algorithm;
    offset += 1;
    buf[offset] = digest.digestType;
    offset += 1;
    copy(digestdata, buf, offset, 0, digestdata.length);
    offset += digestdata.length;

    rds.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rds.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const digest = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    digest.keyTag = readUInt16BE(buf, offset);
    offset += 2;
    digest.algorithm = buf[offset];
    offset += 1;
    digest.digestType = buf[offset];
    offset += 1;
    digest.digest = buf.slice(offset, oldOffset + length + 2);
    offset += digest.digest.length;
    rds.decode.bytes = offset - oldOffset;
    return digest
  },
  encodingLength (digest) {
    return 6 + bytelength(digest.digest)
  }
});

function renc (type) {
  switch (type.toUpperCase()) {
    case 'A': return ra
    case 'PTR': return rptr
    case 'CNAME': return rptr
    case 'DNAME': return rptr
    case 'TXT': return rtxt
    case 'NULL': return rnull
    case 'AAAA': return raaaa
    case 'SRV': return rsrv
    case 'HINFO': return rhinfo
    case 'CAA': return rcaa
    case 'NS': return rns
    case 'SOA': return rsoa
    case 'MX': return rmx
    case 'OPT': return ropt
    case 'DNSKEY': return rdnskey
    case 'RRSIG': return rrrsig
    case 'RP': return rrp
    case 'NSEC': return rnsec
    case 'NSEC3': return rnsec3
    case 'DS': return rds
  }
  return runknown
}

const answer = codec({
  encode (a, buf, offset) {
    if (!buf) buf = new Uint8Array(answer.encodingLength(a));
    if (!offset) offset = 0;

    const oldOffset = offset;

    name$1.encode(a.name, buf, offset);
    offset += name$1.encode.bytes;

    writeUInt16BE(buf, toType(a.type), offset);

    if (a.type.toUpperCase() === 'OPT') {
      if (a.name !== '.') {
        throw new Error('OPT name must be root.')
      }
      writeUInt16BE(buf, a.udpPayloadSize || 4096, offset + 2);
      buf[offset + 4] = a.extendedRcode || 0;
      buf[offset + 5] = a.ednsVersion || 0;
      writeUInt16BE(buf, a.flags || 0, offset + 6);

      offset += 8;
      ropt.encode(a.options || [], buf, offset);
      offset += ropt.encode.bytes;
    } else {
      let klass = toClass(a.class === undefined ? 'IN' : a.class);
      if (a.flush) klass |= FLUSH_MASK; // the 1st bit of the class is the flush bit
      writeUInt16BE(buf, klass, offset + 2);
      writeUInt32BE(buf, a.ttl || 0, offset + 4);

      offset += 8;
      const enc = renc(a.type);
      enc.encode(a.data, buf, offset);
      offset += enc.encode.bytes;
    }

    answer.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const a = {};
    const oldOffset = offset;

    a.name = name$1.decode(buf, offset);
    offset += name$1.decode.bytes;
    a.type = toString$4(readUInt16BE(buf, offset));
    if (a.type === 'OPT') {
      a.udpPayloadSize = readUInt16BE(buf, offset + 2);
      a.extendedRcode = buf[offset + 4];
      a.ednsVersion = buf[offset + 5];
      a.flags = readUInt16BE(buf, offset + 6);
      a.flag_do = ((a.flags >> 15) & 0x1) === 1;
      a.options = ropt.decode(buf, offset + 8);
      offset += 8 + ropt.decode.bytes;
    } else {
      const klass = readUInt16BE(buf, offset + 2);
      a.ttl = readUInt32BE(buf, offset + 4);

      a.class = toString$1(klass & NOT_FLUSH_MASK);
      a.flush = !!(klass & FLUSH_MASK);

      const enc = renc(a.type);
      a.data = enc.decode(buf, offset + 8);
      offset += 8 + enc.decode.bytes;
    }

    answer.decode.bytes = offset - oldOffset;
    return a
  },
  encodingLength (a) {
    const data = (a.data !== null && a.data !== undefined) ? a.data : a.options;
    return name$1.encodingLength(a.name) + 8 + renc(a.type).encodingLength(data)
  }
});

const question = codec({
  encode (q, buf, offset) {
    if (!buf) buf = new Uint8Array(question.encodingLength(q));
    if (!offset) offset = 0;

    const oldOffset = offset;

    name$1.encode(q.name, buf, offset);
    offset += name$1.encode.bytes;

    writeUInt16BE(buf, toType(q.type), offset);
    offset += 2;

    writeUInt16BE(buf, toClass(q.class === undefined ? 'IN' : q.class), offset);
    offset += 2;

    question.encode.bytes = offset - oldOffset;
    return q
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;
    const q = {};

    q.name = name$1.decode(buf, offset);
    offset += name$1.decode.bytes;

    q.type = toString$4(readUInt16BE(buf, offset));
    offset += 2;

    q.class = toString$1(readUInt16BE(buf, offset));
    offset += 2;

    const qu = !!(q.class & QU_MASK);
    if (qu) q.class &= NOT_QU_MASK;

    question.decode.bytes = offset - oldOffset;
    return q
  },
  encodingLength (q) {
    return name$1.encodingLength(q.name) + 4
  }
});
const RECURSION_DESIRED = 1 << 8;

const packet = {
  encode: function (result, buf, offset) {
    const allocing = !buf;

    if (allocing) buf = new Uint8Array(encodingLength(result));
    if (!offset) offset = 0;

    const oldOffset = offset;

    if (!result.questions) result.questions = [];
    if (!result.answers) result.answers = [];
    if (!result.authorities) result.authorities = [];
    if (!result.additionals) result.additionals = [];

    header.encode(result, buf, offset);
    offset += header.encode.bytes;

    offset = encodeList(result.questions, question, buf, offset);
    offset = encodeList(result.answers, answer, buf, offset);
    offset = encodeList(result.authorities, answer, buf, offset);
    offset = encodeList(result.additionals, answer, buf, offset);

    packet.encode.bytes = offset - oldOffset;

    // just a quick sanity check
    if (allocing && encode$1.bytes !== buf.length) {
      return buf.slice(0, encode$1.bytes)
    }

    return buf
  },
  decode: function (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;
    const result = header.decode(buf, offset);
    offset += header.decode.bytes;

    offset = decodeList(result.questions, question, buf, offset);
    offset = decodeList(result.answers, answer, buf, offset);
    offset = decodeList(result.authorities, answer, buf, offset);
    offset = decodeList(result.additionals, answer, buf, offset);

    packet.decode.bytes = offset - oldOffset;

    return result
  },
  encodingLength: function (result) {
    return header.encodingLength(result) +
      encodingLengthList(result.questions || [], question) +
      encodingLengthList(result.answers || [], answer) +
      encodingLengthList(result.authorities || [], answer) +
      encodingLengthList(result.additionals || [], answer)
  }
};
packet.encode.bytes = 0;
packet.decode.bytes = 0;

const encode$1 = packet.encode;
const decode = packet.decode;
const encodingLength = packet.encodingLength;

function encodingLengthList (list, enc) {
  let len = 0;
  for (let i = 0; i < list.length; i++) len += enc.encodingLength(list[i]);
  return len
}

function encodeList (list, enc, buf, offset) {
  for (let i = 0; i < list.length; i++) {
    enc.encode(list[i], buf, offset);
    offset += enc.encode.bytes;
  }
  return offset
}

function decodeList (list, enc, buf, offset) {
  for (let i = 0; i < list.length; i++) {
    list[i] = enc.decode(buf, offset);
    offset += enc.decode.bytes;
  }
  return offset
}

const PREFERS_PADDING = 1;
const PREFERS_NO_PADDING = 2;

function make (name, charset, padding, paddingMode) {
  if (charset.length !== 64) {
    throw new Error(`Charset needs to be 64 characters long! (${charset.length})`)
  }
  const byCharCode = new Uint8Array(256);
  const byNum = new Uint8Array(64);
  for (let i = 0; i < 64; i += 1) {
    const code = charset.charCodeAt(i);
    if (code > 255) {
      throw new Error(`Character #${i} in charset [code=${code}, char=${charset.charAt(i)}] is too high! (max=255)`)
    }
    if (byCharCode[code] !== 0) {
      throw new Error(`Character [code=${code}, char=${charset.charAt(i)}] is more than once in the charset!`)
    }
    byCharCode[code] = i;
    byNum[i] = code;
  }
  const padCode = padding.charCodeAt(0);
  const codec = {
    name,
    encodingLength (str) {
      const strLen = str.length;
      const len = strLen * 0.75 | 0;
      if (str.charCodeAt(strLen - 1) === padCode) {
        if (str.charCodeAt(strLen - 2) === padCode) {
          return len - 2
        }
        return len - 1
      }
      return len
    },
    encode (str, buffer, offset) {
      if (buffer === null || buffer === undefined) {
        buffer = new Uint8Array(codec.encodingLength(str));
      }
      if (offset === null || offset === undefined) {
        offset = 0;
      }

      let strLen = str.length;
      if (str.charCodeAt(strLen - 1) === padCode) {
        if (str.charCodeAt(strLen - 2) === padCode) {
          strLen -= 2;
        } else {
          strLen -= 1;
        }
      }

      const padding = strLen % 4;
      const safeLen = strLen - padding;

      let off = offset;
      let i = 0;
      while (i < safeLen) {
        const code =
          (byCharCode[str.charCodeAt(i)] << 18) |
          (byCharCode[str.charCodeAt(i + 1)] << 12) |
          (byCharCode[str.charCodeAt(i + 2)] << 6) |
          byCharCode[str.charCodeAt(i + 3)];
        buffer[off++] = code >> 16;
        buffer[off++] = code >> 8;
        buffer[off++] = code;
        i += 4;
      }

      if (padding === 3) {
        const code =
          (byCharCode[str.charCodeAt(i)] << 10) |
          (byCharCode[str.charCodeAt(i + 1)] << 4) |
          (byCharCode[str.charCodeAt(i + 2)] >> 2);
        buffer[off++] = code >> 8;
        buffer[off++] = code;
      } else if (padding === 2) {
        buffer[off++] = (byCharCode[str.charCodeAt(i)] << 2) |
          (byCharCode[str.charCodeAt(i + 1)] >> 4);
      }

      codec.encode.bytes = off - offset;
      return buffer
    },
    decode (buffer, start, end) {
      if (start === null || start === undefined) {
        start = 0;
      }
      if (end === null || end === undefined) {
        end = buffer.length;
      }

      const length = end - start;
      const pad = length % 3;
      const safeEnd = start + length - pad;
      const codes = [];
      for (let off = start; off < safeEnd; off += 3) {
        const num = (buffer[off] << 16) | ((buffer[off + 1] << 8)) | buffer[off + 2];
        codes.push(
          byNum[num >> 18 & 0x3F],
          byNum[num >> 12 & 0x3F],
          byNum[num >> 6 & 0x3F],
          byNum[num & 0x3F]
        );
      }

      if (pad === 2) {
        const num = (buffer[end - 2] << 8) + buffer[end - 1];
        codes.push(
          byNum[num >> 10],
          byNum[(num >> 4) & 0x3F],
          byNum[(num << 2) & 0x3F]
        );
        if (paddingMode === PREFERS_PADDING) {
          codes.push(padCode);
        }
      } else if (pad === 1) {
        const num = buffer[end - 1];
        codes.push(
          byNum[num >> 2],
          byNum[(num << 4) & 0x3F]
        );
        if (paddingMode === PREFERS_PADDING) {
          codes.push(padCode, padCode);
        }
      }

      codec.decode.bytes = length;
      return String.fromCharCode.apply(String, codes)
    }
  };
  return codec
}

make('base64', 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/', '=', PREFERS_PADDING);
// https://datatracker.ietf.org/doc/html/rfc4648#section-5
const base64URL = make('base64-url', 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_', '=', PREFERS_NO_PADDING);

let AbortError$2 = typeof global !== 'undefined' ? global.AbortError : typeof window !== 'undefined' ? window.AbortError : null;
if (!AbortError$2) {
  AbortError$2 = class AbortError extends Error {
    constructor (message = 'Request aborted.') {
      super(message);
    }
  };
}
AbortError$2.prototype.name = 'AbortError';
AbortError$2.prototype.code = 'ABORT_ERR';

const URL$1 = (typeof globalThis !== 'undefined' && globalThis.URL) || require('url').URL;

class HTTPStatusError extends Error {
  constructor (uri, code, method) {
    super('status=' + code + ' while requesting ' + uri + ' [' + method + ']');
    this.uri = uri;
    this.status = code;
    this.method = method;
  }

  toJSON () {
    return {
      code: this.code,
      uri: this.uri,
      status: this.status,
      method: this.method,
      endpoint: this.endpoint
    }
  }
}
HTTPStatusError.prototype.name = 'HTTPStatusError';
HTTPStatusError.prototype.code = 'HTTP_STATUS';

class ResponseError extends Error {
  constructor (message, cause) {
    super(message);
    this.cause = cause;
  }

  toJSON () {
    return {
      message: this.message,
      endpoint: this.endpoint,
      code: this.code,
      cause: reduceError(this.cause)
    }
  }
}
ResponseError.prototype.name = 'ResponseError';
ResponseError.prototype.code = 'RESPONSE_ERR';

let TimeoutError$1 = class TimeoutError extends Error {
  constructor (timeout) {
    super('Timeout (t=' + timeout + ').');
    this.timeout = timeout;
  }

  toJSON () {
    return {
      code: this.code,
      endpoint: this.endpoint,
      timeout: this.timeout
    }
  }
};
TimeoutError$1.prototype.name = 'TimeoutError';
TimeoutError$1.prototype.code = 'ETIMEOUT';

const v4Regex = /^((\d{1,3}\.){3,3}\d{1,3})(:(\d{2,5}))?$/;
const v6Regex = /^((::)?(((\d{1,3}\.){3}(\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?)(:(\d{2,5}))?$/i;

function reduceError (err) {
  if (typeof err === 'string') {
    return {
      message: err
    }
  }
  try {
    const json = JSON.stringify(err);
    if (json !== '{}') {
      return JSON.parse(json)
    }
  } catch (e) {}
  const error = {
    message: String(err.message || err)
  };
  if (err.code !== undefined) {
    error.code = String(err.code);
  }
  return error
}

const baseParts = /^(([a-z0-9]+:)\/\/)?([^/[\s:]+|\[[^\]]+\])?(:([^/\s]+))?(\/[^\s]*)?(.*)$/;
const httpFlags = /\[(post|get|((ipv4|ipv6|name)=([^\]]+)))\]/ig;
const updFlags = /\[(((pk|name)=([^\]]+)))\]/ig;

function parseEndpoint (endpoint) {
  const parts = baseParts.exec(endpoint);
  const protocol = parts[2] || 'https:';
  const host = parts[3];
  const port = parts[5];
  const path = parts[6];
  const rest = parts[7];
  if (protocol === 'https:' || protocol === 'http:') {
    const flags = parseFlags(rest, httpFlags);
    return {
      name: flags.name,
      protocol,
      ipv4: flags.ipv4,
      ipv6: flags.ipv6,
      host,
      port,
      path,
      method: flags.post ? 'POST' : 'GET'
    }
  }
  if (protocol === 'udp:' || protocol === 'udp4:' || protocol === 'udp6:') {
    const flags = parseFlags(rest, updFlags);
    const v6Parts = /^\[(.*)\]$/.exec(host);
    if (v6Parts && protocol === 'udp4:') {
      throw new Error(`Endpoint parsing error: Cannot use ipv6 host with udp4: (endpoint=${endpoint})`)
    }
    if (!v6Parts && protocol === 'udp6:') {
      throw new Error(`Endpoint parsing error: Incorrectly formatted host for udp6: (endpoint=${endpoint})`)
    }
    if (v6Parts) {
      return new UDP6Endpoint({ protocol: 'udp6:', ipv6: v6Parts[1], port, pk: flags.pk, name: flags.name })
    }
    return new UDP4Endpoint({ protocol: 'udp4:', ipv4: host, port, pk: flags.pk, name: flags.name })
  }
  throw new InvalidProtocolError(protocol, endpoint)
}

function parseFlags (rest, regex) {
  regex.lastIndex = 0;
  const result = {};
  while (true) {
    const match = regex.exec(rest);
    if (!match) break
    if (match[2]) {
      result[match[3].toLowerCase()] = match[4];
    } else {
      result[match[1].toLowerCase()] = true;
    }
  }
  return result
}

class InvalidProtocolError extends Error {
  constructor (protocol, endpoint) {
    super(`Invalid Endpoint: unsupported protocol "${protocol}" for endpoint: ${endpoint}, supported protocols: ${supportedProtocols.join(', ')}`);
    this.protocol = protocol;
    this.endpoint = endpoint;
  }

  toJSON () {
    return {
      code: this.code,
      endpoint: this.endpoint,
      timeout: this.timeout
    }
  }
}
InvalidProtocolError.prototype.name = 'InvalidProtocolError';
InvalidProtocolError.prototype.code = 'EPROTOCOL';

const supportedProtocols = ['http:', 'https:', 'udp4:', 'udp6:'];

class BaseEndpoint {
  constructor (opts, isHTTP) {
    this.name = opts.name || null;
    this.protocol = opts.protocol;
    const port = typeof opts.port === 'string' ? opts.port = parseInt(opts.port, 10) : opts.port;
    if (port === undefined || port === null) {
      this.port = isHTTP
        ? (this.protocol === 'https:' ? 443 : 80)
        : (opts.pk ? 443 : 53);
    } else if (typeof port !== 'number' && !isNaN(port)) {
      throw new Error(`Invalid Endpoint: port "${opts.port}" needs to be a number: ${JSON.stringify(opts)}`)
    } else {
      this.port = port;
    }
  }

  toJSON () {
    return this.toString()
  }
}

class UDPEndpoint extends BaseEndpoint {
  constructor (opts) {
    super(opts, false);
    this.pk = opts.pk || null;
  }

  toString () {
    const port = this.port !== (this.pk ? 443 : 53) ? `:${this.port}` : '';
    const pk = this.pk ? ` [pk=${this.pk}]` : '';
    const name = this.name ? ` [name=${this.name}]` : '';
    return `udp://${this.ipv4 || `[${this.ipv6}]`}${port}${pk}${name}`
  }
}

class UDP4Endpoint extends UDPEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'udp4:' }, opts));
    if (!opts.ipv4 || typeof opts.ipv4 !== 'string') {
      throw new Error(`Invalid Endpoint: .ipv4 "${opts.ipv4}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.ipv4 = opts.ipv4;
  }
}

class UDP6Endpoint extends UDPEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'udp6:' }, opts));
    if (!opts.ipv6 || typeof opts.ipv6 !== 'string') {
      throw new Error(`Invalid Endpoint: .ipv6 "${opts.ipv6}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.ipv6 = opts.ipv6;
  }
}

function safeHost (host) {
  return v6Regex.test(host) && !v4Regex.test(host) ? `[${host}]` : host
}

class HTTPEndpoint extends BaseEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'https:' }, opts), true);
    if (!opts.host) {
      if (opts.ipv4) {
        opts.host = opts.ipv4;
      }
      if (opts.ipv6) {
        opts.host = `[${opts.ipv6}]`;
      }
    }
    if (!opts.host || typeof opts.host !== 'string') {
      throw new Error(`Invalid Endpoint: host "${opts.path}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.host = opts.host;
    this.path = opts.path || '/dns-query';
    this.method = /^post$/i.test(opts.method) ? 'POST' : 'GET';
    this.ipv4 = opts.ipv4;
    this.ipv6 = opts.ipv6;
    if (!this.ipv6) {
      const v6Parts = v6Regex.exec(this.host);
      if (v6Parts) {
        this.ipv6 = v6Parts[1];
      }
    }
    if (!this.ipv4) {
      if (v4Regex.test(this.host)) {
        this.ipv4 = this.host;
      }
    }
    const url = `${this.protocol}//${safeHost(this.host)}:${this.port}${this.path}`;
    try {
      this.url = new URL$1(url);
    } catch (err) {
      throw new Error(err.message + ` [${url}]`)
    }
  }

  toString () {
    const protocol = this.protocol === 'https:' ? '' : 'http://';
    const port = this.port !== (this.protocol === 'https:' ? 443 : 80) ? `:${this.port}` : '';
    const method = this.method !== 'GET' ? ' [post]' : '';
    const path = this.path === '/dns-query' ? '' : this.path;
    const name = this.name ? ` [name=${this.name}]` : '';
    const ipv4 = this.ipv4 && this.ipv4 !== this.host ? ` [ipv4=${this.ipv4}]` : '';
    const ipv6 = this.ipv6 && this.ipv6 !== this.host ? ` [ipv6=${this.ipv6}]` : '';
    return `${protocol}${safeHost(this.host)}${port}${path}${method}${ipv4}${ipv6}${name}`
  }
}

function toEndpoint (input) {
  let opts;
  if (typeof input === 'string') {
    opts = parseEndpoint(input);
  } else {
    if (typeof input !== 'object' || input === null || Array.isArray(input)) {
      throw new Error(`Can not convert ${input} to an endpoint`)
    } else if (input instanceof BaseEndpoint) {
      return input
    }
    opts = input;
  }
  if (opts.protocol === null || opts.protocol === undefined) {
    opts.protocol = 'https:';
  }
  const protocol = opts.protocol;
  if (protocol === 'udp4:') {
    return new UDP4Endpoint(opts)
  }
  if (protocol === 'udp6:') {
    return new UDP6Endpoint(opts)
  }
  if (protocol === 'https:' || protocol === 'http:') {
    return new HTTPEndpoint(opts)
  }
  throw new InvalidProtocolError(protocol, JSON.stringify(opts))
}

/* global XMLHttpRequest, localStorage */
const contentType = 'application/dns-message';

function noop$3 () { }

function queryDns () {
  throw new Error('Only "doh" endpoints are supported in the browser')
}

async function loadJSON (url, cache, timeout, abortSignal) {
  const cacheKey = cache ? cache.localStoragePrefix + cache.name : null;
  if (cacheKey) {
    try {
      const cached = JSON.parse(localStorage.getItem(cacheKey));
      if (cached && cached.time > cache.maxTime) {
        return cached
      }
    } catch (err) {}
  }
  const { data } = await requestRaw(url, 'GET', null, timeout, abortSignal);
  const result = {
    time: Date.now(),
    data: JSON.parse(decode$1(data))
  };
  if (cacheKey) {
    try {
      localStorage.setItem(cacheKey, JSON.stringify(result));
    } catch (err) {
      result.time = null;
    }
  }
  return result
}

function requestRaw (url, method, data, timeout, abortSignal) {
  return new Promise((resolve, reject) => {
    const target = new URL$1(url);
    if (method === 'GET' && data) {
      target.search = '?dns=' + base64URL.decode(data);
    }
    const uri = target.toString();
    const xhr = new XMLHttpRequest();
    xhr.open(method, uri, true);
    xhr.setRequestHeader('Accept', contentType);
    if (method === 'POST') {
      xhr.setRequestHeader('Content-Type', contentType);
    }
    xhr.responseType = 'arraybuffer';
    xhr.timeout = timeout;
    xhr.ontimeout = ontimeout;
    xhr.onreadystatechange = onreadystatechange;
    xhr.onerror = onerror;
    xhr.onload = onload;
    if (method === 'POST') {
      xhr.send(data);
    } else {
      xhr.send();
    }

    if (abortSignal) {
      abortSignal.addEventListener('abort', onabort);
    }

    function ontimeout () {
      finish(new TimeoutError$1(timeout));
      try {
        xhr.abort();
      } catch (e) { }
    }

    function onload () {
      if (xhr.status !== 200) {
        finish(new HTTPStatusError(uri, xhr.status, method));
      } else {
        let buf;
        if (typeof xhr.response === 'string') {
          buf = encode$2(xhr.response);
        } else if (xhr.response instanceof Uint8Array) {
          buf = xhr.response;
        } else if (Array.isArray(xhr.response) || xhr.response instanceof ArrayBuffer) {
          buf = new Uint8Array(xhr.response);
        } else {
          throw new Error('Unprocessable response ' + xhr.response)
        }
        finish(null, buf);
      }
    }

    function onreadystatechange () {
      if (xhr.readyState > 1 && xhr.status !== 200 && xhr.status !== 0) {
        finish(new HTTPStatusError(uri, xhr.status, method));
        try {
          xhr.abort();
        } catch (e) { }
      }
    }

    let finish = function (error, data) {
      finish = noop$3;
      if (abortSignal) {
        abortSignal.removeEventListener('abort', onabort);
      }
      if (error) {
        resolve({
          error,
          response: xhr
        });
      } else {
        resolve({
          data,
          response: xhr
        });
      }
    };

    function onerror () {
      finish(xhr.status === 200 ? new Error('Inexplicable XHR Error') : new HTTPStatusError(uri, xhr.status, method));
    }

    function onabort () {
      finish(new AbortError$2());
      try {
        xhr.abort();
      } catch (e) { }
    }
  })
}

function request$1 (url, method, packet, timeout, abortSignal) {
  return requestRaw(url, method, packet, timeout, abortSignal)
}

function processResolvers$1 (resolvers) {
  return resolvers.filter(resolver => resolver.cors || resolver.endpoint.cors)
}

const resolvers = {
  data: [
    {
      name: 'adfree.usableprivacy.net',
      endpoint: {
        protocol: 'https:',
        host: 'adfree.usableprivacy.net'
      },
      description: 'Public updns DoH service with advertising, tracker and malware filters.\nHosted in Europe by @usableprivacy, details see: https://docs.usableprivacy.com',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      },
      filter: true
    },
    {
      name: 'adguard-dns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.adguard.com',
        ipv4: '94.140.15.15'
      },
      description: 'Remove ads and protect your computer from malware (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      },
      filter: true
    },
    {
      name: 'adguard-dns-family-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-family.adguard.com',
        ipv4: '94.140.15.16'
      },
      description: 'Adguard DNS with safesearch and adult content blocking (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      },
      filter: true
    },
    {
      name: 'adguard-dns-unfiltered-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-unfiltered.adguard.com',
        ipv4: '94.140.14.140'
      },
      description: 'AdGuard public DNS servers without filters (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      }
    },
    {
      name: 'ahadns-doh-chi',
      endpoint: {
        protocol: 'https:',
        host: 'doh.chi.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Chicago, USA. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=chi',
      country: 'United States',
      location: {
        lat: 41.8483,
        long: -87.6517
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-in',
      endpoint: {
        protocol: 'https:',
        host: 'doh.in.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Mumbai, India. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=in',
      country: 'India',
      location: {
        lat: 19.0748,
        long: 72.8856
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-la',
      endpoint: {
        protocol: 'https:',
        host: 'doh.la.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Los Angeles, USA. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=la',
      country: 'United States',
      location: {
        lat: 34.0549,
        long: -118.2578
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'doh.nl.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Amsterdam, Netherlands. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=nl',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-ny',
      endpoint: {
        protocol: 'https:',
        host: 'doh.ny.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in New York. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=ny',
      country: 'United States',
      location: {
        lat: 40.7308,
        long: -73.9975
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-pl',
      endpoint: {
        protocol: 'https:',
        host: 'doh.pl.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Poland. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=pl',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'alidns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.alidns.com',
        ipv4: '223.5.5.5',
        cors: true
      },
      description: 'A public DNS resolver that supports DoH/DoT in mainland China, provided by Alibaba-Cloud.\nWarning: GFW filtering rules are applied by that resolver.\nHomepage: https://alidns.com/',
      country: 'China',
      location: {
        lat: 34.7725,
        long: 113.7266
      },
      filter: true,
      log: true,
      cors: true
    },
    {
      name: 'ams-ads-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'dnsnl-noads.alekberg.net'
      },
      description: 'Resolver in Amsterdam. DoH protocol. Non-logging. Blocks ads, malware and trackers. DNSSEC enabled.',
      country: 'Romania',
      location: {
        lat: 45.9968,
        long: 24.997
      },
      filter: true
    },
    {
      name: 'ams-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'dnsnl.alekberg.net'
      },
      description: 'Resolver in Amsterdam. DoH protocol. Non-logging, non-filtering, DNSSEC.',
      country: 'Romania',
      location: {
        lat: 45.9968,
        long: 24.997
      }
    },
    {
      name: 'att',
      endpoint: {
        protocol: 'https:',
        host: 'dohtrial.att.net'
      },
      description: 'AT&T test DoH server.',
      log: true
    },
    {
      name: 'bcn-ads-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dnses-noads.alekberg.net'
      },
      description: 'Resolver in Spain. DoH protocol. Non-logging, remove ads and malware, DNSSEC.',
      country: 'Spain',
      location: {
        lat: 41.3891,
        long: 2.1611
      },
      filter: true
    },
    {
      name: 'bcn-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dnses.alekberg.net'
      },
      description: 'Resolver in Spain. DoH protocol. Non-logging, non-filtering, DNSSEC.',
      country: 'Spain',
      location: {
        lat: 41.3891,
        long: 2.1611
      }
    },
    {
      name: 'brahma-world',
      endpoint: {
        protocol: 'https:',
        host: 'dns.brahma.world'
      },
      description: 'DNS-over-HTTPS server. Non Logging, filters ads, trackers and malware. DNSSEC ready, QNAME Minimization, No EDNS Client-Subnet.\nHosted in Stockholm, Sweden. (https://dns.brahma.world)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'cisco-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.opendns.com',
        ipv4: '146.112.41.2'
      },
      description: 'Remove your DNS blind spot (DoH protocol)\nWarning: modifies your queries to include a copy of your network\naddress when forwarding them to a selection of companies and organizations.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true,
      log: true
    },
    {
      name: 'cloudflare',
      endpoint: {
        protocol: 'https:',
        host: 'dns.cloudflare.com',
        ipv4: '1.0.0.1',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) - aka 1.1.1.1 / 1.0.0.1',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      cors: true
    },
    {
      name: 'cloudflare-family',
      endpoint: {
        protocol: 'https:',
        host: 'family.cloudflare-dns.com',
        ipv4: '1.0.0.3',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) with malware protection and parental control - aka 1.1.1.3 / 1.0.0.3',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      filter: true,
      cors: true
    },
    {
      name: 'cloudflare-ipv6',
      endpoint: {
        protocol: 'https:',
        host: '1dot1dot1dot1.cloudflare-dns.com',
        cors: true
      },
      description: 'Cloudflare DNS over IPv6 (anycast)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'cloudflare-security',
      endpoint: {
        protocol: 'https:',
        host: 'security.cloudflare-dns.com',
        ipv4: '1.0.0.2',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) with malware blocking - aka 1.1.1.2 / 1.0.0.2',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      filter: true,
      cors: true
    },
    {
      name: 'controld-block-malware',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p1'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-block-malware-ad',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p2'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-block-malware-ad-social',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p3'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking and Social Networks domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-family-friendly',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/family'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking, Adult Content and Drugs domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-uncensored',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/uncensored'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS unblocks censored domains from various countries.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      }
    },
    {
      name: 'controld-unfiltered',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p0'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis is a Unfiltered DNS, no DNS record blocking or manipulation here, if you want to block Malware, Ads & Tracking or Social Network domains, use the other ControlD DNS configs.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      }
    },
    {
      name: 'dns.digitale-gesellschaft.ch',
      endpoint: {
        protocol: 'https:',
        host: 'dns.digitale-gesellschaft.ch'
      },
      description: 'Public DoH resolver operated by the Digital Society (https://www.digitale-gesellschaft.ch).\nHosted in Zurich, Switzerland.\nNon-logging, non-filtering, supports DNSSEC.',
      country: 'Switzerland',
      location: {
        lat: 47.1449,
        long: 8.1551
      }
    },
    {
      name: 'dns.ryan-palmer',
      endpoint: {
        protocol: 'https:',
        host: 'dns1.ryan-palmer.com'
      },
      description: 'Non-logging, non-filtering, DNSSEC DoH Server. Hosted in the UK.',
      country: 'United Kingdom',
      location: {
        lat: 51.5164,
        long: -0.093
      }
    },
    {
      name: 'dns.sb',
      endpoint: {
        protocol: 'https:',
        host: 'doh.sb',
        ipv4: '185.222.222.222',
        cors: true
      },
      description: 'DNSSEC-enabled DoH server by https://xtom.com/\nhttps://dns.sb/doh/',
      country: 'Unknown',
      location: {
        lat: 47,
        long: 8
      },
      cors: true
    },
    {
      name: 'dns.therifleman.name',
      endpoint: {
        protocol: 'https:',
        host: 'dns.therifleman.name'
      },
      description: 'DNS-over-HTTPS DNS forwarder from Mumbai, India. Blocks web and Android trackers and ads.\nIP addresses are not logged, but queries are logged for 24 hours for debugging.\nReport issues, send suggestions @ joker349 at protonmail.com.\nAlso supports DoT (for android) @ dns.therifleman.name and plain DNS @ 172.104.206.174',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'dnsforfamily-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-doh.dnsforfamily.com'
      },
      description: '(DoH Protocol) (Now supports DNSSEC). Block adult websites, gambling websites, malwares and advertisements.\nIt also enforces safe search in: Google, YouTube, Bing, DuckDuckGo and Yandex.\nSocial websites like Facebook and Instagram are not blocked. No DNS queries are logged.\nAs of 26-May-2022 5.9 million websites are blocked and new websites are added to blacklist daily.\nCompletely free, no ads or any commercial motive. Operating for 4 years now.\nProvided by: https://dnsforfamily.com',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true
    },
    {
      name: 'dnsforfamily-doh-no-safe-search',
      endpoint: {
        protocol: 'https:',
        host: 'dns-doh-no-safe-search.dnsforfamily.com'
      },
      description: '(DoH Protocol) (Now supports DNSSEC) Block adult websites, gambling websites, malwares and advertisements.\nUnlike other dnsforfamily servers, this one does not enforces safe search. So Google, YouTube, Bing, DuckDuckGo and Yandex are completely accessible without any restriction.\nSocial websites like Facebook and Instagram are not blocked. No DNS queries are logged.\nAs of 26-May-2022 5.9 million websites are blocked and new websites are added to blacklist daily.\nCompletely free, no ads or any commercial motive. Operating for 4 years now.\nWarning: This server is incompatible with anonymization.\nProvided by: https://dnsforfamily.com',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true
    },
    {
      name: 'dnsforge.de',
      endpoint: {
        protocol: 'https:',
        host: 'dnsforge.de',
        cors: true
      },
      description: 'Public DoH resolver running with Pihole for Adblocking (https://dnsforge.de).\nNon-logging, AD-filtering, supports DNSSEC. Hosted in Germany.',
      country: 'Germany',
      location: {
        lat: 52.2998,
        long: 9.447
      },
      filter: true,
      cors: true
    },
    {
      name: 'dnshome-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.dnshome.de'
      },
      description: 'https://www.dnshome.de/ public resolver in Germany'
    },
    {
      name: 'dnspod-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.pub',
        cors: true
      },
      description: 'A public DNS resolver in mainland China provided by DNSPod (Tencent Cloud).\nhttps://www.dnspod.cn/Products/Public.DNS?lang=en',
      filter: true,
      log: true,
      cors: true
    },
    {
      name: 'dnswarden-asia-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/adblock'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'dnswarden-asia-adultfilter-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/adultfilter'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'dnswarden-asia-uncensor-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/uncensored'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      }
    },
    {
      name: 'dnswarden-eu-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.eu.dnswarden.com'
      },
      description: 'Hosted in Germany. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Germany',
      location: {
        lat: 50.1103,
        long: 8.7147
      },
      filter: true
    },
    {
      name: 'dnswarden-us-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.us.dnswarden.com'
      },
      description: 'Hosted in USA (Dallas) . For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'United States',
      location: {
        lat: 32.7889,
        long: -96.8021
      },
      filter: true
    },
    {
      name: 'doh-ch-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-ch.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Switzerland. By https://blahdns.com/',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-adult',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/adult-filter/',
        cors: true
      },
      description: 'Blocks access to all adult, pornographic and explicit sites. It does\nnot block proxy or VPNs, nor mixed-content sites. Sites like Reddit\nare allowed. Google and Bing are set to the Safe Mode.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-family',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/family-filter/',
        cors: true
      },
      description: 'Blocks access to all adult, pornographic and explicit sites. It also\nblocks proxy and VPN domains that are used to bypass the filters.\nMixed content sites (like Reddit) are also blocked. Google, Bing and\nYoutube are set to the Safe Mode.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-security',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/security-filter/',
        cors: true
      },
      description: 'Block access to phishing, malware and malicious domains. It does not block adult content.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-crypto-sx',
      endpoint: {
        protocol: 'https:',
        host: 'doh.crypto.sx',
        cors: true
      },
      description: 'DNS-over-HTTPS server. Anycast, no logs, no censorship, DNSSEC.\nBackend hosted by Scaleway, globally cached via Cloudflare.\nMaintained by Frank Denis.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'doh-crypto-sx-ipv6',
      endpoint: {
        protocol: 'https:',
        host: 'doh-ipv6.crypto.sx',
        cors: true
      },
      description: 'DNS-over-HTTPS server accessible over IPv6. Anycast, no logs, no censorship, DNSSEC.\nBackend hosted by Scaleway, globally cached via Cloudflare.\nMaintained by Frank Denis.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'doh-de-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-de.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Germany. By https://blahdns.com/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-fi-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-fi.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Finland. By https://blahdns.com/',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-ibksturm',
      endpoint: {
        protocol: 'https:',
        host: 'ibksturm.synology.me'
      },
      description: 'DoH & DoT Server, No Logging, No Filters, DNSSEC\nRunning privately by ibksturm in Thurgau, Switzerland'
    },
    {
      name: 'doh-jp-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-jp.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Japan. By https://blahdns.com/',
      country: 'Japan',
      location: {
        lat: 35.6882,
        long: 139.7532
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh.ffmuc.net',
      endpoint: {
        protocol: 'https:',
        host: 'doh.ffmuc.net'
      },
      description: 'An open (non-logging, non-filtering, non-censoring) DoH resolver operated by Freifunk Munich with nodes in DE.\nhttps://ffmuc.net/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      }
    },
    {
      name: 'doh.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiarap.org'
      },
      description: 'Non-Logging DNS-over-HTTPS server, cached via Cloudflare.\nFilters out ads, trackers and malware, NO ECS, supports DNSSEC.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'google',
      endpoint: {
        protocol: 'https:',
        host: 'dns.google',
        ipv4: '8.8.8.8',
        cors: true
      },
      description: 'Google DNS (anycast)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      log: true,
      cors: true
    },
    {
      name: 'hdns',
      endpoint: {
        protocol: 'https:',
        host: 'query.hdns.io',
        cors: true
      },
      description: 'HDNS is a public DNS resolver that supports Handshake domains.\nhttps://www.hdns.io',
      country: 'United States',
      location: {
        lat: 37.7771,
        long: -122.406
      },
      cors: true
    },
    {
      name: 'he',
      endpoint: {
        protocol: 'https:',
        host: 'ordns.he.net'
      },
      description: 'Hurricane Electric DoH server (anycast)\nUnknown logging policy.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      log: true
    },
    {
      name: 'id-gmail-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiar.app'
      },
      description: 'Non-Logging DNS-over-HTTPS server located in Singapore.\nFilters out ads, trackers and malware, supports DNSSEC, provided by id-gmail.',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'iij',
      endpoint: {
        protocol: 'https:',
        host: 'public.dns.iij.jp'
      },
      description: 'DoH server operated by Internet Initiative Japan in Tokyo.\nhttps://www.iij.ad.jp/',
      country: 'Japan',
      location: {
        lat: 35.69,
        long: 139.69
      },
      log: true
    },
    {
      name: 'iqdns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'a.passcloud.xyz'
      },
      description: 'Non-logging DoH service runned by V2EX.com user johnsonwil.\nReturns "no such domain" for anti-Chinese government websites. Supports DNSSEC.\nFor more information: https://www.v2ex.com/t/785666',
      filter: true
    },
    {
      name: 'jp.tiar.app-doh',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiar.app'
      },
      description: 'Non-Logging, Non-Filtering DNS-over-HTTPS server in Japan.\nNo ECS, Support DNSSEC',
      country: 'Japan',
      location: {
        lat: 35.6882,
        long: 139.7532
      }
    },
    {
      name: 'jp.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiarap.org'
      },
      description: 'DNS-over-HTTPS Server. Non-Logging, Non-Filtering, No ECS, Support DNSSEC.\nCached via Cloudflare.'
    },
    {
      name: 'libredns',
      endpoint: {
        protocol: 'https:',
        host: 'doh.libredns.gr'
      },
      description: 'DoH server in Germany. No logging, but no DNS padding and no DNSSEC support.\nhttps://libredns.gr/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      }
    },
    {
      name: 'nextdns',
      endpoint: {
        protocol: 'https:',
        host: 'anycsast.dns.nextdns.io'
      },
      description: 'NextDNS is a cloud-based private DNS service that gives you full control\nover what is allowed and what is blocked on the Internet.\nDNSSEC, Anycast, Non-logging, NoFilters\nhttps://www.nextdns.io/',
      country: 'Netherlands',
      location: {
        lat: 52.3891,
        long: 4.6563
      }
    },
    {
      name: 'nextdns-ultralow',
      endpoint: {
        protocol: 'https:',
        host: 'dns.nextdns.io',
        path: '/dnscrypt-proxy'
      },
      description: 'NextDNS is a cloud-based private DNS service that gives you full control\nover what is allowed and what is blocked on the Internet.\nhttps://www.nextdns.io/\nTo select the server location, the "-ultralow" variant relies on bootstrap servers\ninstead of anycast.'
    },
    {
      name: 'njalla-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.njal.la',
        cors: true
      },
      description: 'Non-logging DoH server in Sweden operated by Njalla.\nhttps://dns.njal.la/',
      country: 'Sweden',
      location: {
        lat: 59.3247,
        long: 18.056
      },
      cors: true
    },
    {
      name: 'odoh-cloudflare',
      endpoint: {
        protocol: 'https:',
        host: 'odoh.cloudflare-dns.com',
        cors: true
      },
      description: 'Cloudflare ODoH server.\nhttps://cloudflare.com',
      cors: true
    },
    {
      name: 'odoh-crypto-sx',
      endpoint: {
        protocol: 'https:',
        host: 'odoh.crypto.sx',
        cors: true
      },
      description: 'ODoH target server. Anycast, no logs.\nBackend hosted by Scaleway. Maintained by Frank Denis.',
      cors: true
    },
    {
      name: 'odoh-id-gmail',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiar.app',
        path: '/odoh'
      },
      description: 'ODoH target server. Based in Singapore, no logs.\nFilter ads, trackers and malware.',
      filter: true
    },
    {
      name: 'odoh-jp.tiar.app',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiar.app',
        path: '/odoh'
      },
      description: 'ODoH target server. no logs.'
    },
    {
      name: 'odoh-jp.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiarap.org',
        path: '/odoh'
      },
      description: 'ODoH target server via Cloudflare, no logs.'
    },
    {
      name: 'odoh-resolver4.dns.openinternet.io',
      endpoint: {
        protocol: 'https:',
        host: 'resolver4.dns.openinternet.io'
      },
      description: "ODoH target server. no logs, no filter, DNSSEC.\nRunning on dedicated hardware colocated at Sonic.net in Santa Rosa, CA in the United States.\nUses Sonic's recusrive DNS servers as upstream resolvers (but is not affiliated with Sonic\nin any way). Provided by https://openinternet.io"
    },
    {
      name: 'odoh-tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiarap.org',
        path: '/odoh'
      },
      description: 'ODoH target server via Cloudflare, no logs.\nFilter ads, trackers and malware.',
      filter: true
    },
    {
      name: 'publicarray-au2-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh-2.seby.io',
        cors: true
      },
      description: 'DNSSEC  OpenNIC  Non-logging  Uncensored - hosted on ovh.com.au\nMaintained by publicarray - https://dns.seby.io',
      country: 'Australia',
      location: {
        lat: -33.8591,
        long: 151.2002
      },
      cors: true
    },
    {
      name: 'puredns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'puredns.org',
        ipv4: '146.190.6.13',
        cors: true
      },
      description: 'Public uncensored DNS resolver in Singapore - https://puredns.org\n** Only available in Indonesia and Singapore **',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'quad101',
      endpoint: {
        protocol: 'https:',
        host: 'dns.twnic.tw',
        cors: true
      },
      description: 'DNSSEC-aware public resolver by the Taiwan Network Information Center (TWNIC)\nhttps://101.101.101.101/index_en.html',
      cors: true
    },
    {
      name: 'quad9-doh-ip4-port443-filter-ecs-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns11.quad9.net',
        ipv4: '149.112.112.11'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter/ecs 9.9.9.11 - 149.112.112.11',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'quad9-doh-ip4-port443-filter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns.quad9.net',
        ipv4: '149.112.112.112'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter 9.9.9.9 - 149.112.112.9 - 149.112.112.112',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'quad9-doh-ip4-port443-nofilter-ecs-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns12.quad9.net',
        ipv4: '9.9.9.12'
      },
      description: 'Quad9 (anycast) no-dnssec/no-log/no-filter/ecs 9.9.9.12 - 149.112.112.12',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      }
    },
    {
      name: 'quad9-doh-ip4-port443-nofilter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns10.quad9.net',
        ipv4: '149.112.112.10'
      },
      description: 'Quad9 (anycast) no-dnssec/no-log/no-filter 9.9.9.10 - 149.112.112.10',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      }
    },
    {
      name: 'quad9-doh-ip6-port5053-filter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns9.quad9.net'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter 2620:fe::fe - 2620:fe::9 - 2620:fe::fe:9',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'safesurfer-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.safesurfer.io'
      },
      description: 'Family safety focused blocklist for over 2 million adult sites, as well as phishing and malware and more.\nFree to use, paid for customizing blocking for more categories+sites and viewing usage at my.safesurfer.io. Logs taken for viewing\nusage, data never sold - https://safesurfer.io',
      filter: true,
      log: true
    },
    {
      name: 'sth-ads-doh-se',
      endpoint: {
        protocol: 'https:',
        host: 'dnsse-noads.alekberg.net'
      },
      description: 'Resolver in Stockholm, Sweden. DoH server. Non-logging, remove ads and malware, DNSSEC.',
      country: 'Bulgaria',
      location: {
        lat: 42.696,
        long: 23.332
      },
      filter: true
    },
    {
      name: 'sth-doh-se',
      endpoint: {
        protocol: 'https:',
        host: 'dnsse.alekberg.net'
      },
      description: 'Resolver in Stockholm, Sweden. DoH server. Non-logging, non-filtering, DNSSEC.',
      country: 'Bulgaria',
      location: {
        lat: 42.696,
        long: 23.332
      }
    },
    {
      name: 'switch',
      endpoint: {
        protocol: 'https:',
        host: 'dns.switch.ch'
      },
      description: 'Public DoH service provided by SWITCH in Switzerland\nhttps://www.switch.ch\nProvides protection against malware, but does not block ads.',
      filter: true
    },
    {
      name: 'uncensoreddns-dk-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'unicast.uncensoreddns.org'
      },
      description: 'Also known as censurfridns.\nDoH, no logs, no filter, DNSSEC, unicast hosted in Denmark - https://blog.uncensoreddns.org',
      country: 'Denmark',
      location: {
        lat: 55.7123,
        long: 12.0564
      }
    },
    {
      name: 'uncensoreddns-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'anycast.uncensoreddns.org'
      },
      description: 'Also known as censurfridns.\nDoH, no logs, no filter, DNSSEC, anycast - https://blog.uncensoreddns.org',
      country: 'Denmark',
      location: {
        lat: 55.7123,
        long: 12.0564
      }
    },
    {
      name: 'v.dnscrypt.uk-doh-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'v.dnscrypt.uk'
      },
      description: 'DoH, no logs, uncensored, DNSSEC. Hosted in London UK on Digital Ocean\nhttps://www.dnscrypt.uk',
      country: 'United Kingdom',
      location: {
        lat: 51.4964,
        long: -0.1224
      }
    }
  ],
  time: 1654187067783
};

function processResolvers (res) {
  const time = (res.time === null || res.time === undefined) ? Date.now() : res.time;
  const resolvers = processResolvers$1(res.data.map(resolver => {
    resolver.endpoint = toEndpoint(Object.assign({ name: resolver.name }, resolver.endpoint));
    return resolver
  }));
  const endpoints = resolvers.map(resolver => resolver.endpoint);
  return {
    data: {
      resolvers,
      resolverByName: resolvers.reduce((byName, resolver) => {
        byName[resolver.name] = resolver;
        return byName
      }, {}),
      endpoints,
      endpointByName: endpoints.reduce((byName, endpoint) => {
        byName[endpoint.name] = endpoint;
        return byName
      }, {})
    },
    time
  }
}

const backup = processResolvers(resolvers);

function toMultiQuery (singleQuery) {
  const query = Object.assign({
    type: 'query'
  }, singleQuery);
  delete query.question;
  query.questions = [];
  if (singleQuery.question) {
    query.questions.push(singleQuery.question);
  }
  return query
}

function queryOne (endpoint, query, timeout, abortSignal) {
  if (abortSignal && abortSignal.aborted) {
    return Promise.reject(new AbortError$2())
  }
  if (endpoint.protocol === 'udp4:' || endpoint.protocol === 'udp6:') {
    return queryDns()
  }
  return queryDoh(endpoint, query, timeout, abortSignal)
}

function queryDoh (endpoint, query, timeout, abortSignal) {
  return request$1(
    endpoint.url,
    endpoint.method,
    encode$1(Object.assign({
      flags: RECURSION_DESIRED
    }, query)),
    timeout,
    abortSignal
  ).then(
    function (res) {
      const data = res.data;
      const response = res.response;
      let error = res.error;
      if (error === undefined) {
        if (data.length === 0) {
          error = new ResponseError('Empty.');
        } else {
          try {
            const decoded = decode(data);
            decoded.response = response;
            return decoded
          } catch (err) {
            error = new ResponseError('Invalid packet (cause=' + err.message + ')', err);
          }
        }
      }
      throw Object.assign(error, { response })
    }
  )
}

const UPDATE_URL = new URL$1('https://martinheidegger.github.io/dns-query/resolvers.json');

function isNameString (entry) {
  return /^@/.test(entry)
}

class Wellknown {
  constructor (opts) {
    this.opts = Object.assign({
      timeout: 5000,
      update: true,
      updateURL: UPDATE_URL,
      persist: false,
      localStoragePrefix: 'dnsquery_',
      maxAge: 300000 // 5 minutes
    }, opts);
    this._dataP = null;
  }

  _data (force, outdated) {
    if (!force && this._dataP !== null) {
      return this._dataP.then(res => {
        if (res.time < Date.now() - this.opts.maxAge) {
          return this._data(true, res)
        }
        return res
      })
    }
    this._dataP = (!this.opts.update
      ? Promise.resolve(backup)
      : loadJSON(
        this.opts.updateURL,
        this.opts.persist
          ? {
              name: 'resolvers.json',
              localStoragePrefix: this.opts.localStoragePrefix,
              maxTime: Date.now() - this.opts.maxAge
            }
          : null,
        this.opts.timeout
      )
        .then(res => processResolvers({
          data: res.data.resolvers,
          time: res.time
        }))
        .catch(() => outdated || backup)
    );
    return this._dataP
  }

  data () {
    return this._data(false).then(data => data.data)
  }

  endpoints (input) {
    if (input === null || input === undefined) {
      return this.data().then(data => data.endpoints)
    }
    if (input === 'doh') {
      input = filterDoh;
    }
    if (input === 'dns') {
      input = filterDns;
    }
    if (typeof input === 'function') {
      return this.data().then(data => data.endpoints.filter(input))
    }
    if (typeof input === 'string' || typeof input[Symbol.iterator] !== 'function') {
      return Promise.reject(new Error(`Endpoints (${input}) needs to be iterable (array).`))
    }
    input = Array.from(input).filter(Boolean);
    if (input.findIndex(isNameString) === -1) {
      try {
        return Promise.resolve(input.map(toEndpoint))
      } catch (err) {
        return Promise.reject(err)
      }
    }
    return this.data().then(data =>
      input.map(entry => {
        if (isNameString(entry)) {
          const found = data.endpointByName[entry.substring(1)];
          if (!found) {
            throw new Error(`Endpoint ${entry} is not known.`)
          }
          return found
        }
        return toEndpoint(entry)
      })
    )
  }
}

const wellknown = new Wellknown();

function isPromise (input) {
  if (input === null) {
    return false
  }
  if (typeof input !== 'object') {
    return false
  }
  return typeof input.then === 'function'
}

function toPromise (input) {
  return isPromise(input) ? input : Promise.resolve(input)
}

function query (q, opts) {
  opts = Object.assign({
    retries: 5,
    timeout: 30000 // 30 seconds
  }, opts);
  if (!q.question) return Promise.reject(new Error('To request data you need to specify a .question!'))
  return toPromise(opts.endpoints)
    .then(endpoints => {
      if (!Array.isArray(endpoints) || endpoints.length === 0) {
        throw new Error('No endpoints defined to lookup dns records.')
      }
      return queryN(endpoints.map(toEndpoint), toMultiQuery(q), opts)
    })
    .then(data => {
      data.question = data.questions[0];
      delete data.questions;
      return data
    })
}

function queryN (endpoints, q, opts) {
  const endpoint = endpoints.length === 1
    ? endpoints[0]
    : endpoints[Math.floor(Math.random() * endpoints.length) % endpoints.length];
  return queryOne(endpoint, q, opts.timeout, opts.signal)
    .then(
      data => {
        // Add the endpoint to give a chance to identify which endpoint returned the result
        data.endpoint = endpoint.toString();
        return data
      },
      err => {
        if (err.name === 'AbortError' || opts.retries === 0) {
          err.endpoint = endpoint.toString();
          throw err
        }
        if (opts.retries > 0) {
          opts.retries -= 1;
        }
        return queryN(endpoints, q, opts)
      }
    )
}

function filterDoh (endpoint) {
  return endpoint.protocol === 'https:' || endpoint.protocol === 'http:'
}

function filterDns (endpoint) {
  return endpoint.protocol === 'udp4:' || endpoint.protocol === 'udp6:'
}

const log$D = debug("waku:dns-over-https");
class DnsOverHttps {
    /**
     * Create new Dns-Over-Http DNS client.
     *
     * @param endpoints The endpoints for Dns-Over-Https queries;
     * Defaults to using dns-query's API..
     * @param retries Retries if a given endpoint fails.
     *
     * @throws {code: string} If DNS query fails.
     */
    static async create(endpoints, retries) {
        const _endpoints = endpoints ?? (await wellknown.endpoints("doh"));
        return new DnsOverHttps(_endpoints, retries);
    }
    constructor(endpoints, retries = 3) {
        this.endpoints = endpoints;
        this.retries = retries;
    }
    /**
     * Resolves a TXT record
     *
     * @param domain The domain name
     *
     * @throws if the query fails
     */
    async resolveTXT(domain) {
        let answers;
        try {
            const res = await query({
                question: { type: "TXT", name: domain },
            }, {
                endpoints: this.endpoints,
                retries: this.retries,
            });
            answers = res.answers;
        }
        catch (error) {
            log$D("query failed: ", error);
            throw new Error("DNS query failed");
        }
        if (!answers)
            throw new Error(`Could not resolve ${domain}`);
        const data = answers.map((a) => a.data);
        const result = [];
        data.forEach((d) => {
            if (typeof d === "string") {
                result.push(d);
            }
            else if (Array.isArray(d)) {
                d.forEach((sd) => {
                    if (typeof sd === "string") {
                        result.push(sd);
                    }
                    else {
                        result.push(bytesToUtf8(sd));
                    }
                });
            }
            else {
                result.push(bytesToUtf8(d));
            }
        });
        return result;
    }
}

var base32Exports = {};
var base32 = {
  get exports(){ return base32Exports; },
  set exports(v){ base32Exports = v; },
};

/*
 * [hi-base32]{@link https://github.com/emn178/hi-base32}
 *
 * @version 0.5.0
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2015-2018
 * @license MIT
 */

(function (module) {
	/*jslint bitwise: true */
	(function () {

	  var root = typeof window === 'object' ? window : {};
	  var NODE_JS = !root.HI_BASE32_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
	  if (NODE_JS) {
	    root = commonjsGlobal;
	  }
	  var COMMON_JS = !root.HI_BASE32_NO_COMMON_JS && 'object' === 'object' && module.exports;
	  var BASE32_ENCODE_CHAR = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'.split('');
	  var BASE32_DECODE_CHAR = {
	    'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8,
	    'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16,
	    'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24,
	    'Z': 25, '2': 26, '3': 27, '4': 28, '5': 29, '6': 30, '7': 31
	  };

	  var blocks = [0, 0, 0, 0, 0, 0, 0, 0];

	  var throwInvalidUtf8 = function (position, partial) {
	    if (partial.length > 10) {
	      partial = '...' + partial.substr(-10);
	    }
	    var err = new Error('Decoded data is not valid UTF-8.'
	      + ' Maybe try base32.decode.asBytes()?'
	      + ' Partial data after reading ' + position + ' bytes: ' + partial + ' <-');
	    err.position = position;
	    throw err;
	  };

	  var toUtf8String = function (bytes) {
	    var str = '', length = bytes.length, i = 0, followingChars = 0, b, c;
	    while (i < length) {
	      b = bytes[i++];
	      if (b <= 0x7F) {
	        str += String.fromCharCode(b);
	        continue;
	      } else if (b > 0xBF && b <= 0xDF) {
	        c = b & 0x1F;
	        followingChars = 1;
	      } else if (b <= 0xEF) {
	        c = b & 0x0F;
	        followingChars = 2;
	      } else if (b <= 0xF7) {
	        c = b & 0x07;
	        followingChars = 3;
	      } else {
	        throwInvalidUtf8(i, str);
	      }

	      for (var j = 0; j < followingChars; ++j) {
	        b = bytes[i++];
	        if (b < 0x80 || b > 0xBF) {
	          throwInvalidUtf8(i, str);
	        }
	        c <<= 6;
	        c += b & 0x3F;
	      }
	      if (c >= 0xD800 && c <= 0xDFFF) {
	        throwInvalidUtf8(i, str);
	      }
	      if (c > 0x10FFFF) {
	        throwInvalidUtf8(i, str);
	      }

	      if (c <= 0xFFFF) {
	        str += String.fromCharCode(c);
	      } else {
	        c -= 0x10000;
	        str += String.fromCharCode((c >> 10) + 0xD800);
	        str += String.fromCharCode((c & 0x3FF) + 0xDC00);
	      }
	    }
	    return str;
	  };

	  var decodeAsBytes = function (base32Str) {
	    if (base32Str === '') {
	      return [];
	    } else if (!/^[A-Z2-7=]+$/.test(base32Str)) {
	      throw new Error('Invalid base32 characters');
	    }
	    base32Str = base32Str.replace(/=/g, '');
	    var v1, v2, v3, v4, v5, v6, v7, v8, bytes = [], index = 0, length = base32Str.length;

	    // 4 char to 3 bytes
	    for (var i = 0, count = length >> 3 << 3; i < count;) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v8 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	      bytes[index++] = (v5 << 7 | v6 << 2 | v7 >>> 3) & 255;
	      bytes[index++] = (v7 << 5 | v8) & 255;
	    }

	    // remain bytes
	    var remain = length - count;
	    if (remain === 2) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	    } else if (remain === 4) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	    } else if (remain === 5) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	    } else if (remain === 7) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	      bytes[index++] = (v5 << 7 | v6 << 2 | v7 >>> 3) & 255;
	    }
	    return bytes;
	  };

	  var encodeAscii = function (str) {
	    var v1, v2, v3, v4, v5, base32Str = '', length = str.length;
	    for (var i = 0, count = parseInt(length / 5) * 5; i < count;) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i++);
	      v4 = str.charCodeAt(i++);
	      v5 = str.charCodeAt(i++);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	        BASE32_ENCODE_CHAR[v5 & 31];
	    }

	    // remain char
	    var remain = length - count;
	    if (remain === 1) {
	      v1 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	        '======';
	    } else if (remain === 2) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	        '====';
	    } else if (remain === 3) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	        '===';
	    } else if (remain === 4) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i++);
	      v4 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	        '=';
	    }
	    return base32Str;
	  };

	  var encodeUtf8 = function (str) {
	    var v1, v2, v3, v4, v5, code, end = false, base32Str = '',
	      index = 0, i, start = 0, length = str.length;
	      if (str === '') {
	        return base32Str;
	      }
	    do {
	      blocks[0] = blocks[5];
	      blocks[1] = blocks[6];
	      blocks[2] = blocks[7];
	      for (i = start; index < length && i < 5; ++index) {
	        code = str.charCodeAt(index);
	        if (code < 0x80) {
	          blocks[i++] = code;
	        } else if (code < 0x800) {
	          blocks[i++] = 0xc0 | (code >> 6);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        } else if (code < 0xd800 || code >= 0xe000) {
	          blocks[i++] = 0xe0 | (code >> 12);
	          blocks[i++] = 0x80 | ((code >> 6) & 0x3f);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        } else {
	          code = 0x10000 + (((code & 0x3ff) << 10) | (str.charCodeAt(++index) & 0x3ff));
	          blocks[i++] = 0xf0 | (code >> 18);
	          blocks[i++] = 0x80 | ((code >> 12) & 0x3f);
	          blocks[i++] = 0x80 | ((code >> 6) & 0x3f);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        }
	      }
	      start = i - 5;
	      if (index === length) {
	        ++index;
	      }
	      if (index > length && i < 6) {
	        end = true;
	      }
	      v1 = blocks[0];
	      if (i > 4) {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        v4 = blocks[3];
	        v5 = blocks[4];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	          BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	          BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	          BASE32_ENCODE_CHAR[v5 & 31];
	      } else if (i === 1) {
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	          '======';
	      } else if (i === 2) {
	        v2 = blocks[1];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	          '====';
	      } else if (i === 3) {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	          '===';
	      } else {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        v4 = blocks[3];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	          BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	          BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	          '=';
	      }
	    } while (!end);
	    return base32Str;
	  };

	  var encodeBytes = function (bytes) {
	    var v1, v2, v3, v4, v5, base32Str = '', length = bytes.length;
	    for (var i = 0, count = parseInt(length / 5) * 5; i < count;) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i++];
	      v4 = bytes[i++];
	      v5 = bytes[i++];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	        BASE32_ENCODE_CHAR[v5 & 31];
	    }

	    // remain char
	    var remain = length - count;
	    if (remain === 1) {
	      v1 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	        '======';
	    } else if (remain === 2) {
	      v1 = bytes[i++];
	      v2 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	        '====';
	    } else if (remain === 3) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	        '===';
	    } else if (remain === 4) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i++];
	      v4 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	        '=';
	    }
	    return base32Str;
	  };

	  var encode = function (input, asciiOnly) {
	    var notString = typeof(input) !== 'string';
	    if (notString && input.constructor === ArrayBuffer) {
	      input = new Uint8Array(input);
	    }
	    if (notString) {
	      return encodeBytes(input);
	    } else if (asciiOnly) {
	      return encodeAscii(input);
	    } else {
	      return encodeUtf8(input);
	    }
	  };

	  var decode = function (base32Str, asciiOnly) {
	    if (!asciiOnly) {
	      return toUtf8String(decodeAsBytes(base32Str));
	    }
	    if (base32Str === '') {
	      return '';
	    } else if (!/^[A-Z2-7=]+$/.test(base32Str)) {
	      throw new Error('Invalid base32 characters');
	    }
	    var v1, v2, v3, v4, v5, v6, v7, v8, str = '', length = base32Str.indexOf('=');
	    if (length === -1) {
	      length = base32Str.length;
	    }

	    // 8 char to 5 bytes
	    for (var i = 0, count = length >> 3 << 3; i < count;) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v8 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255) +
	        String.fromCharCode((v5 << 7 | v6 << 2 | v7 >>> 3) & 255) +
	        String.fromCharCode((v7 << 5 | v8) & 255);
	    }

	    // remain bytes
	    var remain = length - count;
	    if (remain === 2) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255);
	    } else if (remain === 4) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255);
	    } else if (remain === 5) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255);
	    } else if (remain === 7) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255) +
	        String.fromCharCode((v5 << 7 | v6 << 2 | v7 >>> 3) & 255);
	    }
	    return str;
	  };

	  var exports = {
	    encode: encode,
	    decode: decode
	  };
	  decode.asBytes = decodeAsBytes;

	  if (COMMON_JS) {
	    module.exports = exports;
	  } else {
	    root.base32 = exports;
	  }
	})();
} (base32));

class ENRTree {
    /**
     * Extracts the branch subdomain referenced by a DNS tree root string after verifying
     * the root record signature with its base32 compressed public key.
     */
    static parseAndVerifyRoot(root, publicKey) {
        if (!root.startsWith(this.ROOT_PREFIX))
            throw new Error(`ENRTree root entry must start with '${this.ROOT_PREFIX}'`);
        const rootValues = ENRTree.parseRootValues(root);
        const decodedPublicKey = base32Exports.decode.asBytes(publicKey);
        // The signature is a 65-byte secp256k1 over the keccak256 hash
        // of the record content, excluding the `sig=` part, encoded as URL-safe base64 string
        // (Trailing recovery bit must be trimmed to pass `ecdsaVerify` method)
        const signedComponent = root.split(" sig")[0];
        const signedComponentBuffer = utf8ToBytes(signedComponent);
        const signatureBuffer = fromString$2(rootValues.signature, "base64url").slice(0, 64);
        const isVerified = verifySignature(signatureBuffer, keccak256(signedComponentBuffer), new Uint8Array(decodedPublicKey));
        if (!isVerified)
            throw new Error("Unable to verify ENRTree root signature");
        return rootValues.eRoot;
    }
    static parseRootValues(txt) {
        const matches = txt.match(/^enrtree-root:v1 e=([^ ]+) l=([^ ]+) seq=(\d+) sig=([^ ]+)$/);
        if (!Array.isArray(matches))
            throw new Error("Could not parse ENRTree root entry");
        matches.shift(); // The first entry is the full match
        const [eRoot, lRoot, seq, signature] = matches;
        if (!eRoot)
            throw new Error("Could not parse 'e' value from ENRTree root entry");
        if (!lRoot)
            throw new Error("Could not parse 'l' value from ENRTree root entry");
        if (!seq)
            throw new Error("Could not parse 'seq' value from ENRTree root entry");
        if (!signature)
            throw new Error("Could not parse 'sig' value from ENRTree root entry");
        return { eRoot, lRoot, seq: Number(seq), signature };
    }
    /**
     * Returns the public key and top level domain of an ENR tree entry.
     * The domain is the starting point for traversing a set of linked DNS TXT records
     * and the public key is used to verify the root entry record
     */
    static parseTree(tree) {
        if (!tree.startsWith(this.TREE_PREFIX))
            throw new Error(`ENRTree tree entry must start with '${this.TREE_PREFIX}'`);
        const matches = tree.match(/^enrtree:\/\/([^@]+)@(.+)$/);
        if (!Array.isArray(matches))
            throw new Error("Could not parse ENRTree tree entry");
        matches.shift(); // The first entry is the full match
        const [publicKey, domain] = matches;
        if (!publicKey)
            throw new Error("Could not parse public key from ENRTree tree entry");
        if (!domain)
            throw new Error("Could not parse domain from ENRTree tree entry");
        return { publicKey, domain };
    }
    /**
     * Returns subdomains listed in an ENR branch entry. These in turn lead to
     * either further branch entries or ENR records.
     */
    static parseBranch(branch) {
        if (!branch.startsWith(this.BRANCH_PREFIX))
            throw new Error(`ENRTree branch entry must start with '${this.BRANCH_PREFIX}'`);
        return branch.split(this.BRANCH_PREFIX)[1].split(",");
    }
}
ENRTree.RECORD_PREFIX = ENR.RECORD_PREFIX;
ENRTree.TREE_PREFIX = "enrtree:";
ENRTree.BRANCH_PREFIX = "enrtree-branch:";
ENRTree.ROOT_PREFIX = "enrtree-root:";

const log$C = debug("waku:discovery:fetch_nodes");
/**
 * Fetch nodes using passed [[getNode]] until all wanted capabilities are
 * fulfilled or the number of [[getNode]] call exceeds the sum of
 * [[wantedNodeCapabilityCount]] plus [[errorTolerance]].
 */
async function fetchNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, errorTolerance, getNode) {
    const wanted = {
        relay: wantedNodeCapabilityCount.relay ?? 0,
        store: wantedNodeCapabilityCount.store ?? 0,
        filter: wantedNodeCapabilityCount.filter ?? 0,
        lightPush: wantedNodeCapabilityCount.lightPush ?? 0,
    };
    const maxSearches = wanted.relay + wanted.store + wanted.filter + wanted.lightPush;
    const actual = {
        relay: 0,
        store: 0,
        filter: 0,
        lightPush: 0,
    };
    let totalSearches = 0;
    const peers = [];
    while (!isSatisfied(wanted, actual) &&
        totalSearches < maxSearches + errorTolerance) {
        const peer = await getNode();
        if (peer && isNewPeer(peer, peers)) {
            // ENRs without a waku2 key are ignored.
            if (peer.waku2) {
                if (helpsSatisfyCapabilities(peer.waku2, wanted, actual)) {
                    addCapabilities(peer.waku2, actual);
                    peers.push(peer);
                }
            }
            log$C(`got new peer candidate from DNS address=${peer.nodeId}@${peer.ip}`);
        }
        totalSearches++;
    }
    return peers;
}
/**
 * Fetch nodes using passed [[getNode]] until all wanted capabilities are
 * fulfilled or the number of [[getNode]] call exceeds the sum of
 * [[wantedNodeCapabilityCount]] plus [[errorTolerance]].
 */
async function* yieldNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, errorTolerance, getNode) {
    const wanted = {
        relay: wantedNodeCapabilityCount.relay ?? 0,
        store: wantedNodeCapabilityCount.store ?? 0,
        filter: wantedNodeCapabilityCount.filter ?? 0,
        lightPush: wantedNodeCapabilityCount.lightPush ?? 0,
    };
    const maxSearches = wanted.relay + wanted.store + wanted.filter + wanted.lightPush;
    const actual = {
        relay: 0,
        store: 0,
        filter: 0,
        lightPush: 0,
    };
    let totalSearches = 0;
    const peerNodeIds = new Set();
    while (!isSatisfied(wanted, actual) &&
        totalSearches < maxSearches + errorTolerance) {
        const peer = await getNode();
        if (peer && peer.nodeId && !peerNodeIds.has(peer.nodeId)) {
            peerNodeIds.add(peer.nodeId);
            // ENRs without a waku2 key are ignored.
            if (peer.waku2) {
                if (helpsSatisfyCapabilities(peer.waku2, wanted, actual)) {
                    addCapabilities(peer.waku2, actual);
                    yield peer;
                }
            }
            log$C(`got new peer candidate from DNS address=${peer.nodeId}@${peer.ip}`);
        }
        totalSearches++;
    }
}
function isSatisfied(wanted, actual) {
    return (actual.relay >= wanted.relay &&
        actual.store >= wanted.store &&
        actual.filter >= wanted.filter &&
        actual.lightPush >= wanted.lightPush);
}
function isNewPeer(peer, peers) {
    if (!peer.nodeId)
        return false;
    for (const existingPeer of peers) {
        if (peer.nodeId === existingPeer.nodeId) {
            return false;
        }
    }
    return true;
}
function addCapabilities(node, total) {
    if (node.relay)
        total.relay += 1;
    if (node.store)
        total.store += 1;
    if (node.filter)
        total.filter += 1;
    if (node.lightPush)
        total.lightPush += 1;
}
/**
 * Checks if the proposed ENR [[node]] helps satisfy the [[wanted]] capabilities,
 * considering the [[actual]] capabilities of nodes retrieved so far..
 *
 * @throws If the function is called when the wanted capabilities are already fulfilled.
 */
function helpsSatisfyCapabilities(node, wanted, actual) {
    if (isSatisfied(wanted, actual)) {
        throw "Internal Error: Waku2 wanted capabilities are already fulfilled";
    }
    const missing = missingCapabilities(wanted, actual);
    return ((missing.relay && node.relay) ||
        (missing.store && node.store) ||
        (missing.filter && node.filter) ||
        (missing.lightPush && node.lightPush));
}
/**
 * Return a [[Waku2]] Object for which capabilities are set to true if they are
 * [[wanted]] yet missing from [[actual]].
 */
function missingCapabilities(wanted, actual) {
    return {
        relay: actual.relay < wanted.relay,
        store: actual.store < wanted.store,
        filter: actual.filter < wanted.filter,
        lightPush: actual.lightPush < wanted.lightPush,
    };
}

const log$B = debug("waku:discovery:dns");
class DnsNodeDiscovery {
    static async dnsOverHttp(dnsClient) {
        if (!dnsClient) {
            dnsClient = await DnsOverHttps.create();
        }
        return new DnsNodeDiscovery(dnsClient);
    }
    /**
     * Returns a list of verified peers listed in an EIP-1459 DNS tree. Method may
     * return fewer peers than requested if @link wantedNodeCapabilityCount requires
     * larger quantity of peers than available or the number of errors/duplicate
     * peers encountered by randomized search exceeds the sum of the fields of
     * @link wantedNodeCapabilityCount plus the @link _errorTolerance factor.
     */
    async getPeers(enrTreeUrls, wantedNodeCapabilityCount) {
        const networkIndex = Math.floor(Math.random() * enrTreeUrls.length);
        const { publicKey, domain } = ENRTree.parseTree(enrTreeUrls[networkIndex]);
        const context = {
            domain,
            publicKey,
            visits: {},
        };
        const peers = await fetchNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, this._errorTolerance, () => this._search(domain, context));
        log$B("retrieved peers: ", peers.map((peer) => {
            return {
                id: peer.peerId?.toString(),
                multiaddrs: peer.multiaddrs?.map((ma) => ma.toString()),
            };
        }));
        return peers;
    }
    constructor(dns) {
        this._errorTolerance = 10;
        this._DNSTreeCache = {};
        this.dns = dns;
    }
    /**
     * {@inheritDoc getPeers}
     */
    async *getNextPeer(enrTreeUrls, wantedNodeCapabilityCount) {
        const networkIndex = Math.floor(Math.random() * enrTreeUrls.length);
        const { publicKey, domain } = ENRTree.parseTree(enrTreeUrls[networkIndex]);
        const context = {
            domain,
            publicKey,
            visits: {},
        };
        for await (const peer of yieldNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, this._errorTolerance, () => this._search(domain, context))) {
            yield peer;
        }
    }
    /**
     * Runs a recursive, randomized descent of the DNS tree to retrieve a single
     * ENR record as an ENR. Returns null if parsing or DNS resolution fails.
     */
    async _search(subdomain, context) {
        try {
            const entry = await this._getTXTRecord(subdomain, context);
            context.visits[subdomain] = true;
            let next;
            let branches;
            const entryType = getEntryType(entry);
            try {
                switch (entryType) {
                    case ENRTree.ROOT_PREFIX:
                        next = ENRTree.parseAndVerifyRoot(entry, context.publicKey);
                        return await this._search(next, context);
                    case ENRTree.BRANCH_PREFIX:
                        branches = ENRTree.parseBranch(entry);
                        next = selectRandomPath(branches, context);
                        return await this._search(next, context);
                    case ENRTree.RECORD_PREFIX:
                        return EnrDecoder.fromString(entry);
                    default:
                        return null;
                }
            }
            catch (error) {
                log$B(`Failed to search DNS tree ${entryType} at subdomain ${subdomain}: ${error}`);
                return null;
            }
        }
        catch (error) {
            log$B(`Failed to retrieve TXT record at subdomain ${subdomain}: ${error}`);
            return null;
        }
    }
    /**
     * Retrieves the TXT record stored at a location from either
     * this DNS tree cache or via DNS query.
     *
     * @throws if the TXT Record contains non-UTF-8 values.
     */
    async _getTXTRecord(subdomain, context) {
        if (this._DNSTreeCache[subdomain]) {
            return this._DNSTreeCache[subdomain];
        }
        // Location is either the top level tree entry host or a subdomain of it.
        const location = subdomain !== context.domain
            ? `${subdomain}.${context.domain}`
            : context.domain;
        const response = await this.dns.resolveTXT(location);
        if (!response.length)
            throw new Error("Received empty result array while fetching TXT record");
        if (!response[0].length)
            throw new Error("Received empty TXT record");
        // Branch entries can be an array of strings of comma delimited subdomains, with
        // some subdomain strings split across the array elements
        const result = response.join("");
        this._DNSTreeCache[subdomain] = result;
        return result;
    }
}
function getEntryType(entry) {
    if (entry.startsWith(ENRTree.ROOT_PREFIX))
        return ENRTree.ROOT_PREFIX;
    if (entry.startsWith(ENRTree.BRANCH_PREFIX))
        return ENRTree.BRANCH_PREFIX;
    if (entry.startsWith(ENRTree.RECORD_PREFIX))
        return ENRTree.RECORD_PREFIX;
    return "";
}
/**
 * Returns a randomly selected subdomain string from the list provided by a branch
 * entry record.
 *
 * The client must track subdomains which are already resolved to avoid
 * going into an infinite loop b/c branch entries can contain
 * circular references. Its in the clients best interest to traverse the
 * tree in random order.
 */
function selectRandomPath(branches, context) {
    // Identify domains already visited in this traversal of the DNS tree.
    // Then filter against them to prevent cycles.
    const circularRefs = {};
    for (const [idx, subdomain] of branches.entries()) {
        if (context.visits[subdomain]) {
            circularRefs[idx] = true;
        }
    }
    // If all possible paths are circular...
    if (Object.keys(circularRefs).length === branches.length) {
        throw new Error("Unresolvable circular path detected");
    }
    // Randomly select a viable path
    let index;
    do {
        index = Math.floor(Math.random() * branches.length);
    } while (circularRefs[index]);
    return branches[index];
}

const log$A = debug("waku:peer-discovery-dns");
const enrTree = {
    TEST: "enrtree://AOGECG2SPND25EEFMAJ5WF3KSGJNSGV356DSTL2YVLLZWIV6SAYBM@test.waku.nodes.status.im",
    PROD: "enrtree://AOGECG2SPND25EEFMAJ5WF3KSGJNSGV356DSTL2YVLLZWIV6SAYBM@prod.waku.nodes.status.im",
};
const DEFAULT_BOOTSTRAP_TAG_NAME = "bootstrap";
const DEFAULT_BOOTSTRAP_TAG_VALUE = 50;
const DEFAULT_BOOTSTRAP_TAG_TTL = 120000;
/**
 * Parse options and expose function to return bootstrap peer addresses.
 */
class PeerDiscoveryDns extends EventEmitter$1 {
    constructor(components, options) {
        super();
        this._started = false;
        this._components = components;
        this._options = options;
        const { enrUrl } = options;
        log$A("Use following EIP-1459 ENR Tree URL: ", enrUrl);
    }
    /**
     * Start discovery process
     */
    async start() {
        log$A("Starting peer discovery via dns");
        this._started = true;
        if (this.nextPeer === undefined) {
            const { enrUrl, wantedNodeCapabilityCount } = this._options;
            const dns = await DnsNodeDiscovery.dnsOverHttp();
            this.nextPeer = dns.getNextPeer.bind(dns, [enrUrl], wantedNodeCapabilityCount);
        }
        for await (const peer of this.nextPeer()) {
            if (!this._started)
                return;
            const peerInfo = peer.peerInfo;
            if (!peerInfo)
                continue;
            if ((await this._components.peerStore.getTags(peerInfo.id)).find(({ name }) => name === DEFAULT_BOOTSTRAP_TAG_NAME))
                continue;
            await this._components.peerStore.tagPeer(peerInfo.id, DEFAULT_BOOTSTRAP_TAG_NAME, {
                value: this._options.tagValue ?? DEFAULT_BOOTSTRAP_TAG_VALUE,
                ttl: this._options.tagTTL ?? DEFAULT_BOOTSTRAP_TAG_TTL,
            });
            this.dispatchEvent(new CustomEvent("peer", { detail: peerInfo }));
        }
    }
    /**
     * Stop emitting events
     */
    stop() {
        this._started = false;
    }
    get [symbol$2]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return "@waku/bootstrap";
    }
}
function wakuDnsDiscovery(enrUrl, wantedNodeCapabilityCount) {
    return (components) => new PeerDiscoveryDns(components, { enrUrl, wantedNodeCapabilityCount });
}

function isStartable(obj) {
    return obj != null && typeof obj.start === 'function' && typeof obj.stop === 'function';
}

/**
 * Collect all values from the iterable and sort them using
 * the passed sorter function
 *
 * @template T
 * @param {AsyncIterable<T> | Iterable<T>} iterable
 * @param {(a: T, b: T) => -1 | 0 | 1} sorter
 * @returns {AsyncIterable<T>}
 */
const sortAll = (iterable, sorter) => {
  return (async function * () {
    const values = await all(iterable);
    yield * values.sort(sorter);
  })()
};

/**
 * Drains an (async) iterable discarding its' content and does not return
 * anything
 */
async function drain(source) {
    for await (const _ of source) { } // eslint-disable-line no-unused-vars,no-empty,@typescript-eslint/no-unused-vars
}

/**
 * Filters the passed (async) iterable by using the filter function
 */
async function* filter(source, fn) {
    for await (const entry of source) {
        if (await fn(entry)) {
            yield entry;
        }
    }
}

/**
 * Stop iteration after n items have been received
 */
async function* take(source, limit) {
    let items = 0;
    if (limit < 1) {
        return;
    }
    for await (const entry of source) {
        yield entry;
        items++;
        if (items === limit) {
            return;
        }
    }
}

/**
 * @typedef {import('interface-store').Options} Options
 * @typedef {import('interface-datastore').Key} Key
 * @typedef {import('interface-datastore').Pair} Pair
 * @typedef {import('interface-datastore').Datastore} Datastore
 * @typedef {import('interface-datastore').Query} Query
 * @typedef {import('interface-datastore').KeyQuery} KeyQuery
 * @typedef {import('interface-datastore').Batch} Batch
 */

/**
 * @template O
 * @typedef {import('interface-store').AwaitIterable<O>} AwaitIterable
 */

/**
 * @implements {Datastore}
 */
class BaseDatastore {
  /**
   * @returns {Promise<void>}
   */
  open () {
    return Promise.reject(new Error('.open is not implemented'))
  }

  /**
   * @returns {Promise<void>}
   */
  close () {
    return Promise.reject(new Error('.close is not implemented'))
  }

  /**
   * @param {Key} key
   * @param {Uint8Array} val
   * @param {Options} [options]
   * @returns {Promise<void>}
   */
  put (key, val, options) {
    return Promise.reject(new Error('.put is not implemented'))
  }

  /**
   * @param {Key} key
   * @param {Options} [options]
   * @returns {Promise<Uint8Array>}
   */
  get (key, options) {
    return Promise.reject(new Error('.get is not implemented'))
  }

  /**
   * @param {Key} key
   * @param {Options} [options]
   * @returns {Promise<boolean>}
   */
  has (key, options) {
    return Promise.reject(new Error('.has is not implemented'))
  }

  /**
   * @param {Key} key
   * @param {Options} [options]
   * @returns {Promise<void>}
   */
  delete (key, options) {
    return Promise.reject(new Error('.delete is not implemented'))
  }

  /**
   * @param {AwaitIterable<Pair>} source
   * @param {Options} [options]
   * @returns {AsyncIterable<Pair>}
   */
  async * putMany (source, options = {}) {
    for await (const { key, value } of source) {
      await this.put(key, value, options);
      yield { key, value };
    }
  }

  /**
   * @param {AwaitIterable<Key>} source
   * @param {Options} [options]
   * @returns {AsyncIterable<Uint8Array>}
   */
  async * getMany (source, options = {}) {
    for await (const key of source) {
      yield this.get(key, options);
    }
  }

  /**
   * @param {AwaitIterable<Key>} source
   * @param {Options} [options]
   * @returns {AsyncIterable<Key>}
   */
  async * deleteMany (source, options = {}) {
    for await (const key of source) {
      await this.delete(key, options);
      yield key;
    }
  }

  /**
   * @returns {Batch}
   */
  batch () {
    /** @type {Pair[]} */
    let puts = [];
    /** @type {Key[]} */
    let dels = [];

    return {
      put (key, value) {
        puts.push({ key, value });
      },

      delete (key) {
        dels.push(key);
      },
      commit: async (options) => {
        await drain(this.putMany(puts, options));
        puts = [];
        await drain(this.deleteMany(dels, options));
        dels = [];
      }
    }
  }

  /**
   * Extending classes should override `query` or implement this method
   *
   * @param {Query} q
   * @param {Options} [options]
   * @returns {AsyncIterable<Pair>}
   */
  // eslint-disable-next-line require-yield
  async * _all (q, options) {
    throw new Error('._all is not implemented')
  }

  /**
   * Extending classes should override `queryKeys` or implement this method
   *
   * @param {KeyQuery} q
   * @param {Options} [options]
   * @returns {AsyncIterable<Key>}
   */
  // eslint-disable-next-line require-yield
  async * _allKeys (q, options) {
    throw new Error('._allKeys is not implemented')
  }

  /**
   * @param {Query} q
   * @param {Options} [options]
   */
  query (q, options) {
    let it = this._all(q, options);

    if (q.prefix != null) {
      it = filter(it, (e) =>
        e.key.toString().startsWith(/** @type {string} */ (q.prefix))
      );
    }

    if (Array.isArray(q.filters)) {
      it = q.filters.reduce((it, f) => filter(it, f), it);
    }

    if (Array.isArray(q.orders)) {
      it = q.orders.reduce((it, f) => sortAll(it, f), it);
    }

    if (q.offset != null) {
      let i = 0;
      it = filter(it, () => i++ >= /** @type {number} */ (q.offset));
    }

    if (q.limit != null) {
      it = take(it, q.limit);
    }

    return it
  }

  /**
   * @param {KeyQuery} q
   * @param {Options} [options]
   */
  queryKeys (q, options) {
    let it = this._allKeys(q, options);

    if (q.prefix != null) {
      it = filter(it, (key) =>
        key.toString().startsWith(/** @type {string} */ (q.prefix))
      );
    }

    if (Array.isArray(q.filters)) {
      it = q.filters.reduce((it, f) => filter(it, f), it);
    }

    if (Array.isArray(q.orders)) {
      it = q.orders.reduce((it, f) => sortAll(it, f), it);
    }

    if (q.offset != null) {
      let i = 0;
      it = filter(it, () => i++ >= /** @type {number} */ (q.offset));
    }

    if (q.limit != null) {
      it = take(it, q.limit);
    }

    return it
  }
}

let nanoid$1 = (size = 21) =>
  crypto.getRandomValues(new Uint8Array(size)).reduce((id, byte) => {
    byte &= 63;
    if (byte < 36) {
      id += byte.toString(36);
    } else if (byte < 62) {
      id += (byte - 26).toString(36).toUpperCase();
    } else if (byte > 62) {
      id += '-';
    } else {
      id += '_';
    }
    return id
  }, '');

const pathSepS = '/';
const pathSepB = new TextEncoder().encode(pathSepS);
const pathSep = pathSepB[0];
/**
 * A Key represents the unique identifier of an object.
 * Our Key scheme is inspired by file systems and Google App Engine key model.
 * Keys are meant to be unique across a system. Keys are hierarchical,
 * incorporating more and more specific namespaces. Thus keys can be deemed
 * 'children' or 'ancestors' of other keys:
 * - `new Key('/Comedy')`
 * - `new Key('/Comedy/MontyPython')`
 * Also, every namespace can be parametrized to embed relevant object
 * information. For example, the Key `name` (most specific namespace) could
 * include the object type:
 * - `new Key('/Comedy/MontyPython/Actor:JohnCleese')`
 * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop')`
 * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop/Character:Mousebender')`
 *
 */
class Key {
    /**
     * @param {string | Uint8Array} s
     * @param {boolean} [clean]
     */
    constructor(s, clean) {
        if (typeof s === 'string') {
            this._buf = fromString$2(s);
        }
        else if (s instanceof Uint8Array) {
            this._buf = s;
        }
        else {
            throw new Error('Invalid key, should be String of Uint8Array');
        }
        if (clean == null) {
            clean = true;
        }
        if (clean) {
            this.clean();
        }
        if (this._buf.byteLength === 0 || this._buf[0] !== pathSep) {
            throw new Error('Invalid key');
        }
    }
    /**
     * Convert to the string representation
     *
     * @param {import('uint8arrays/to-string').SupportedEncodings} [encoding='utf8'] - The encoding to use.
     * @returns {string}
     */
    toString(encoding = 'utf8') {
        return toString$7(this._buf, encoding);
    }
    /**
     * Return the Uint8Array representation of the key
     *
     * @returns {Uint8Array}
     */
    uint8Array() {
        return this._buf;
    }
    /**
     * Return string representation of the key
     *
     * @returns {string}
     */
    get [Symbol.toStringTag]() {
        return `Key(${this.toString()})`;
    }
    /**
     * Constructs a key out of a namespace array.
     *
     * @param {Array<string>} list - The array of namespaces
     * @returns {Key}
     *
     * @example
     * ```js
     * Key.withNamespaces(['one', 'two'])
     * // => Key('/one/two')
     * ```
     */
    static withNamespaces(list) {
        return new Key(list.join(pathSepS));
    }
    /**
     * Returns a randomly (uuid) generated key.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * Key.random()
     * // => Key('/f98719ea086343f7b71f32ea9d9d521d')
     * ```
     */
    static random() {
        return new Key(nanoid$1().replace(/-/g, ''));
    }
    /**
     * @param {*} other
     */
    static asKey(other) {
        if (other instanceof Uint8Array || typeof other === 'string') {
            // we can create a key from this
            return new Key(other);
        }
        if (typeof other.uint8Array === 'function') {
            // this is an older version or may have crossed the esm/cjs boundary
            return new Key(other.uint8Array());
        }
        return null;
    }
    /**
     * Cleanup the current key
     *
     * @returns {void}
     */
    clean() {
        if (this._buf == null || this._buf.byteLength === 0) {
            this._buf = pathSepB;
        }
        if (this._buf[0] !== pathSep) {
            const bytes = new Uint8Array(this._buf.byteLength + 1);
            bytes.fill(pathSep, 0, 1);
            bytes.set(this._buf, 1);
            this._buf = bytes;
        }
        // normalize does not remove trailing slashes
        while (this._buf.byteLength > 1 && this._buf[this._buf.byteLength - 1] === pathSep) {
            this._buf = this._buf.subarray(0, -1);
        }
    }
    /**
     * Check if the given key is sorted lower than ourself.
     *
     * @param {Key} key - The other Key to check against
     * @returns {boolean}
     */
    less(key) {
        const list1 = this.list();
        const list2 = key.list();
        for (let i = 0; i < list1.length; i++) {
            if (list2.length < i + 1) {
                return false;
            }
            const c1 = list1[i];
            const c2 = list2[i];
            if (c1 < c2) {
                return true;
            }
            else if (c1 > c2) {
                return false;
            }
        }
        return list1.length < list2.length;
    }
    /**
     * Returns the key with all parts in reversed order.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').reverse()
     * // => Key('/Actor:JohnCleese/MontyPython/Comedy')
     * ```
     */
    reverse() {
        return Key.withNamespaces(this.list().slice().reverse());
    }
    /**
     * Returns the `namespaces` making up this Key.
     *
     * @returns {Array<string>}
     */
    namespaces() {
        return this.list();
    }
    /** Returns the "base" namespace of this key.
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').baseNamespace()
     * // => 'Actor:JohnCleese'
     * ```
     */
    baseNamespace() {
        const ns = this.namespaces();
        return ns[ns.length - 1];
    }
    /**
     * Returns the `list` representation of this key.
     *
     * @returns {Array<string>}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').list()
     * // => ['Comedy', 'MontyPythong', 'Actor:JohnCleese']
     * ```
     */
    list() {
        return this.toString().split(pathSepS).slice(1);
    }
    /**
     * Returns the "type" of this key (value of last namespace).
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').type()
     * // => 'Actor'
     * ```
     */
    type() {
        return namespaceType(this.baseNamespace());
    }
    /**
     * Returns the "name" of this key (field of last namespace).
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').name()
     * // => 'JohnCleese'
     * ```
     */
    name() {
        return namespaceValue(this.baseNamespace());
    }
    /**
     * Returns an "instance" of this type key (appends value to namespace).
     *
     * @param {string} s - The string to append.
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor').instance('JohnClesse')
     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')
     * ```
     */
    instance(s) {
        return new Key(this.toString() + ':' + s);
    }
    /**
     * Returns the "path" of this key (parent + type).
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').path()
     * // => Key('/Comedy/MontyPython/Actor')
     * ```
     */
    path() {
        let p = this.parent().toString();
        if (!p.endsWith(pathSepS)) {
            p += pathSepS;
        }
        p += this.type();
        return new Key(p);
    }
    /**
     * Returns the `parent` Key of this Key.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key("/Comedy/MontyPython/Actor:JohnCleese").parent()
     * // => Key("/Comedy/MontyPython")
     * ```
     */
    parent() {
        const list = this.list();
        if (list.length === 1) {
            return new Key(pathSepS);
        }
        return new Key(list.slice(0, -1).join(pathSepS));
    }
    /**
     * Returns the `child` Key of this Key.
     *
     * @param {Key} key - The child Key to add
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython').child(new Key('Actor:JohnCleese'))
     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')
     * ```
     */
    child(key) {
        if (this.toString() === pathSepS) {
            return key;
        }
        else if (key.toString() === pathSepS) {
            return this;
        }
        return new Key(this.toString() + key.toString(), false);
    }
    /**
     * Returns whether this key is a prefix of `other`
     *
     * @param {Key} other - The other key to test against
     * @returns {boolean}
     *
     * @example
     * ```js
     * new Key('/Comedy').isAncestorOf('/Comedy/MontyPython')
     * // => true
     * ```
     */
    isAncestorOf(other) {
        if (other.toString() === this.toString()) {
            return false;
        }
        return other.toString().startsWith(this.toString());
    }
    /**
     * Returns whether this key is a contains another as prefix.
     *
     * @param {Key} other - The other Key to test against
     * @returns {boolean}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython').isDecendantOf('/Comedy')
     * // => true
     * ```
     */
    isDecendantOf(other) {
        if (other.toString() === this.toString()) {
            return false;
        }
        return this.toString().startsWith(other.toString());
    }
    /**
     * Checks if this key has only one namespace.
     *
     * @returns {boolean}
     *
     */
    isTopLevel() {
        return this.list().length === 1;
    }
    /**
     * Concats one or more Keys into one new Key.
     *
     * @param {Array<Key>} keys - The array of keys to concatenate
     * @returns {Key}
     */
    concat(...keys) {
        return Key.withNamespaces([...this.namespaces(), ...flatten(keys.map(key => key.namespaces()))]);
    }
}
/**
 * The first component of a namespace. `foo` in `foo:bar`
 *
 * @param {string} ns
 * @returns {string}
 */
function namespaceType(ns) {
    const parts = ns.split(':');
    if (parts.length < 2) {
        return '';
    }
    return parts.slice(0, -1).join(':');
}
/**
 * The last component of a namespace, `baz` in `foo:bar:baz`.
 *
 * @param {string} ns
 * @returns {string}
 */
function namespaceValue(ns) {
    const parts = ns.split(':');
    return parts[parts.length - 1];
}
/**
 * Flatten array of arrays (only one level)
 *
 * @template T
 * @param {Array<any>} arr
 * @returns {T[]}
 */
function flatten(arr) {
    return ([]).concat(...arr);
}

/**
 * @param {Error} [err]
 */
function notFoundError (err) {
  err = err || new Error('Not Found');
  return errCode(err, 'ERR_NOT_FOUND')
}

/**
 * @typedef {import('interface-datastore').Pair} Pair
 * @typedef {import('interface-datastore').Datastore} Datastore
 * @typedef {import('interface-store').Options} Options
 */

/**
 * @class MemoryDatastore
 * @implements {Datastore}
 */
class MemoryDatastore extends BaseDatastore {
  constructor () {
    super();

    /** @type {Record<string, Uint8Array>} */
    this.data = {};
  }

  open () {
    return Promise.resolve()
  }

  close () {
    return Promise.resolve()
  }

  /**
   * @param {Key} key
   * @param {Uint8Array} val
   */
  async put (key, val) { // eslint-disable-line require-await
    this.data[key.toString()] = val;
  }

  /**
   * @param {Key} key
   */
  async get (key) {
    const exists = await this.has(key);
    if (!exists) throw notFoundError()
    return this.data[key.toString()]
  }

  /**
   * @param {Key} key
   */
  async has (key) { // eslint-disable-line require-await
    return this.data[key.toString()] !== undefined
  }

  /**
   * @param {Key} key
   */
  async delete (key) { // eslint-disable-line require-await
    delete this.data[key.toString()];
  }

  async * _all () {
    yield * Object.entries(this.data)
      .map(([key, value]) => ({ key: new Key(key), value }));
  }

  async * _allKeys () {
    yield * Object.entries(this.data)
      .map(([key]) => new Key(key));
  }
}

var messages;
(function (messages) {
    messages["NOT_STARTED_YET"] = "The libp2p node is not started yet";
    messages["DHT_DISABLED"] = "DHT is not available";
    messages["PUBSUB_DISABLED"] = "PubSub is not available";
    messages["CONN_ENCRYPTION_REQUIRED"] = "At least one connection encryption module is required";
    messages["ERR_TRANSPORTS_REQUIRED"] = "At least one transport module is required";
    messages["ERR_PROTECTOR_REQUIRED"] = "Private network is enforced, but no protector was provided";
    messages["NOT_FOUND"] = "Not found";
})(messages || (messages = {}));
var codes$1;
(function (codes) {
    codes["DHT_DISABLED"] = "ERR_DHT_DISABLED";
    codes["ERR_PUBSUB_DISABLED"] = "ERR_PUBSUB_DISABLED";
    codes["PUBSUB_NOT_STARTED"] = "ERR_PUBSUB_NOT_STARTED";
    codes["DHT_NOT_STARTED"] = "ERR_DHT_NOT_STARTED";
    codes["CONN_ENCRYPTION_REQUIRED"] = "ERR_CONN_ENCRYPTION_REQUIRED";
    codes["ERR_TRANSPORTS_REQUIRED"] = "ERR_TRANSPORTS_REQUIRED";
    codes["ERR_PROTECTOR_REQUIRED"] = "ERR_PROTECTOR_REQUIRED";
    codes["ERR_PEER_DIAL_INTERCEPTED"] = "ERR_PEER_DIAL_INTERCEPTED";
    codes["ERR_CONNECTION_INTERCEPTED"] = "ERR_CONNECTION_INTERCEPTED";
    codes["ERR_INVALID_PROTOCOLS_FOR_STREAM"] = "ERR_INVALID_PROTOCOLS_FOR_STREAM";
    codes["ERR_CONNECTION_ENDED"] = "ERR_CONNECTION_ENDED";
    codes["ERR_CONNECTION_FAILED"] = "ERR_CONNECTION_FAILED";
    codes["ERR_NODE_NOT_STARTED"] = "ERR_NODE_NOT_STARTED";
    codes["ERR_ALREADY_ABORTED"] = "ERR_ALREADY_ABORTED";
    codes["ERR_TOO_MANY_ADDRESSES"] = "ERR_TOO_MANY_ADDRESSES";
    codes["ERR_NO_VALID_ADDRESSES"] = "ERR_NO_VALID_ADDRESSES";
    codes["ERR_RELAYED_DIAL"] = "ERR_RELAYED_DIAL";
    codes["ERR_DIALED_SELF"] = "ERR_DIALED_SELF";
    codes["ERR_DISCOVERED_SELF"] = "ERR_DISCOVERED_SELF";
    codes["ERR_DUPLICATE_TRANSPORT"] = "ERR_DUPLICATE_TRANSPORT";
    codes["ERR_ENCRYPTION_FAILED"] = "ERR_ENCRYPTION_FAILED";
    codes["ERR_HOP_REQUEST_FAILED"] = "ERR_HOP_REQUEST_FAILED";
    codes["ERR_INVALID_KEY"] = "ERR_INVALID_KEY";
    codes["ERR_INVALID_MESSAGE"] = "ERR_INVALID_MESSAGE";
    codes["ERR_INVALID_PARAMETERS"] = "ERR_INVALID_PARAMETERS";
    codes["ERR_INVALID_PEER"] = "ERR_INVALID_PEER";
    codes["ERR_MUXER_UNAVAILABLE"] = "ERR_MUXER_UNAVAILABLE";
    codes["ERR_NOT_FOUND"] = "ERR_NOT_FOUND";
    codes["ERR_TIMEOUT"] = "ERR_TIMEOUT";
    codes["ERR_TRANSPORT_UNAVAILABLE"] = "ERR_TRANSPORT_UNAVAILABLE";
    codes["ERR_TRANSPORT_DIAL_FAILED"] = "ERR_TRANSPORT_DIAL_FAILED";
    codes["ERR_UNSUPPORTED_PROTOCOL"] = "ERR_UNSUPPORTED_PROTOCOL";
    codes["ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED"] = "ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED";
    codes["ERR_INVALID_MULTIADDR"] = "ERR_INVALID_MULTIADDR";
    codes["ERR_SIGNATURE_NOT_VALID"] = "ERR_SIGNATURE_NOT_VALID";
    codes["ERR_FIND_SELF"] = "ERR_FIND_SELF";
    codes["ERR_NO_ROUTERS_AVAILABLE"] = "ERR_NO_ROUTERS_AVAILABLE";
    codes["ERR_CONNECTION_NOT_MULTIPLEXED"] = "ERR_CONNECTION_NOT_MULTIPLEXED";
    codes["ERR_NO_DIAL_TOKENS"] = "ERR_NO_DIAL_TOKENS";
    codes["ERR_KEYCHAIN_REQUIRED"] = "ERR_KEYCHAIN_REQUIRED";
    codes["ERR_INVALID_CMS"] = "ERR_INVALID_CMS";
    codes["ERR_MISSING_KEYS"] = "ERR_MISSING_KEYS";
    codes["ERR_NO_KEY"] = "ERR_NO_KEY";
    codes["ERR_INVALID_KEY_NAME"] = "ERR_INVALID_KEY_NAME";
    codes["ERR_INVALID_KEY_TYPE"] = "ERR_INVALID_KEY_TYPE";
    codes["ERR_KEY_ALREADY_EXISTS"] = "ERR_KEY_ALREADY_EXISTS";
    codes["ERR_INVALID_KEY_SIZE"] = "ERR_INVALID_KEY_SIZE";
    codes["ERR_KEY_NOT_FOUND"] = "ERR_KEY_NOT_FOUND";
    codes["ERR_OLD_KEY_NAME_INVALID"] = "ERR_OLD_KEY_NAME_INVALID";
    codes["ERR_NEW_KEY_NAME_INVALID"] = "ERR_NEW_KEY_NAME_INVALID";
    codes["ERR_PASSWORD_REQUIRED"] = "ERR_PASSWORD_REQUIRED";
    codes["ERR_PEM_REQUIRED"] = "ERR_PEM_REQUIRED";
    codes["ERR_CANNOT_READ_KEY"] = "ERR_CANNOT_READ_KEY";
    codes["ERR_MISSING_PRIVATE_KEY"] = "ERR_MISSING_PRIVATE_KEY";
    codes["ERR_MISSING_PUBLIC_KEY"] = "ERR_MISSING_PUBLIC_KEY";
    codes["ERR_INVALID_OLD_PASS_TYPE"] = "ERR_INVALID_OLD_PASS_TYPE";
    codes["ERR_INVALID_NEW_PASS_TYPE"] = "ERR_INVALID_NEW_PASS_TYPE";
    codes["ERR_INVALID_PASS_LENGTH"] = "ERR_INVALID_PASS_LENGTH";
    codes["ERR_NOT_IMPLEMENTED"] = "ERR_NOT_IMPLEMENTED";
    codes["ERR_WRONG_PING_ACK"] = "ERR_WRONG_PING_ACK";
    codes["ERR_INVALID_RECORD"] = "ERR_INVALID_RECORD";
    codes["ERR_ALREADY_SUCCEEDED"] = "ERR_ALREADY_SUCCEEDED";
    codes["ERR_NO_HANDLER_FOR_PROTOCOL"] = "ERR_NO_HANDLER_FOR_PROTOCOL";
    codes["ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS"] = "ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS";
    codes["ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS"] = "ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS";
    codes["ERR_CONNECTION_DENIED"] = "ERR_CONNECTION_DENIED";
})(codes$1 || (codes$1 = {}));

/**
 * Takes an (async) iterable and returns one with each item mapped by the passed
 * function
 */
async function* map(source, func) {
    for await (const val of source) {
        yield func(val);
    }
}

/**
 * Store the multiaddrs from every peer in the passed peer store
 */
async function* storeAddresses(source, peerStore) {
    yield* map(source, async (peer) => {
        // ensure we have the addresses for a given peer
        await peerStore.addressBook.add(peer.id, peer.multiaddrs);
        return peer;
    });
}
/**
 * Filter peers by unique peer id
 */
function uniquePeers(source) {
    /** @type Set<string> */
    const seen = new Set();
    return filter(source, (peer) => {
        // dedupe by peer id
        if (seen.has(peer.id.toString())) {
            return false;
        }
        seen.add(peer.id.toString());
        return true;
    });
}
/**
 * Require at least `min` peers to be yielded from `source`
 */
async function* requirePeers(source, min = 1) {
    let seen = 0;
    for await (const peer of source) {
        seen++;
        yield peer;
    }
    if (seen < min) {
        throw errCode(new Error('not found'), 'NOT_FOUND');
    }
}

var timeBrowser = function getTime () {
  return Date.now()
};

const getTime = timeBrowser;

class Retimer {
  constructor (callback, timeout, args) {
    const that = this;

    this._started = getTime();
    this._rescheduled = 0;
    this._scheduled = timeout;
    this._args = args;
    this._triggered = false;

    this._timerWrapper = () => {
      if (that._rescheduled > 0) {
        that._scheduled = that._rescheduled - (getTime() - that._started);
        that._schedule(that._scheduled);
      } else {
        that._triggered = true;
        callback.apply(null, that._args);
      }
    };

    this._timer = setTimeout(this._timerWrapper, timeout);
  }

  reschedule (timeout) {
    if (!timeout) {
      timeout = this._scheduled;
    }
    const now = getTime();
    if ((now + timeout) - (this._started + this._scheduled) < 0) {
      clearTimeout(this._timer);
      this._schedule(timeout);
    } else if (!this._triggered) {
      this._started = now;
      this._rescheduled = timeout;
    } else {
      this._schedule(timeout);
    }
  }

  _schedule (timeout) {
    this._triggered = false;
    this._started = getTime();
    this._rescheduled = 0;
    this._scheduled = timeout;
    this._timer = setTimeout(this._timerWrapper, timeout);
  }

  clear () {
    clearTimeout(this._timer);
  }
}

function retimer$1 () {
  if (typeof arguments[0] !== 'function') {
    throw new Error('callback needed')
  }

  if (typeof arguments[1] !== 'number') {
    throw new Error('timeout needed')
  }

  let args;

  if (arguments.length > 0) {
    args = new Array(arguments.length - 2);

    /* eslint-disable no-var */
    for (var i = 0; i < args.length; i++) {
      args[i] = arguments[i + 2];
    }
  }

  return new Retimer(arguments[0], arguments[1], args)
}

var retimer_1 = retimer$1;

const { AbortController: AbortController$1 } = globalThis;

// @ts-expect-error no types
const retimer = retimer_1;

class TimeoutController extends AbortController$1 {
  /**
   * @constructor
   * @param {number} ms milliseconds
   */
  constructor (ms) {
    super();
    this._ms = ms;
    this._timer = retimer(() => this.abort(), ms);
    // Patch for safari not supported extending built in classes
    Object.setPrototypeOf(this, TimeoutController.prototype);
  }

  /**
   * Aborts the controller and clears the timer
   */
  abort () {
    this._timer.clear();
    return super.abort()
  }

  /**
   * Clears the timer
   */
  clear () {
    this._timer.clear();
  }

  /**
   * Resets the timer
   */
  reset () {
    this._timer.clear();
    this._timer = retimer(() => this.abort(), this._ms);
  }
}

var timeoutAbortController = {
  TimeoutController
};

/**
 * Returns the first result from an (async) iterable, unless empty, in which
 * case returns `undefined`
 */
async function first(source) {
    for await (const entry of source) { // eslint-disable-line no-unreachable-loop
        return entry;
    }
    return undefined;
}

const intervals = new Map();

const _generateId = () => `${Date.now()}:${Math.floor(Math.random() * 1000000)}`;

/**
 * Run a given task each {interval} ms
 *
 * @param {() => Promise} task
 * @param {number} interval
 * @param {string} id
 */
async function _runPeriodically (task, interval, id) {
  while (intervals.get(id)) {
    try {
      await task();
    } catch (err) {
      // Throw global context error if handler throws
      setTimeout(() => { throw err }, 1);
      break
    }

    if (!intervals.get(id)) {
      break
    }

    await new Promise(resolve => {
      const _timeout = setTimeout(resolve, interval);

      intervals.set(id, _timeout);
    });
  }
}

/**
 * Asynchronous setInterval that is properly delayed using promises and can be delayed on boot.
 *
 * @param {() => Promise} task
 * @param {number} interval
 * @param {number} [delay = interval]
 * @returns {string}
 */
function setDelayedInterval (task, interval, delay) {
  delay = delay || interval;

  const id = _generateId();
  const _timeout = setTimeout(() => {
    _runPeriodically(task, interval, id);
  }, delay);

  intervals.set(id, _timeout);

  return id
}

/**
 * Clear delayed interval.
 *
 * @param {string} id
 */
function clearDelayedInterval (id) {
  const _timeout = intervals.get(id);

  if (_timeout) {
    clearTimeout(_timeout);
    intervals.delete(id);
  }
}

var src = {
  setDelayedInterval,
  clearDelayedInterval
};

var eventsExports = {};
var events$1 = {
  get exports(){ return eventsExports; },
  set exports(v){ eventsExports = v; },
};

var R = typeof Reflect === 'object' ? Reflect : null;
var ReflectApply = R && typeof R.apply === 'function'
  ? R.apply
  : function ReflectApply(target, receiver, args) {
    return Function.prototype.apply.call(target, receiver, args);
  };

var ReflectOwnKeys;
if (R && typeof R.ownKeys === 'function') {
  ReflectOwnKeys = R.ownKeys;
} else if (Object.getOwnPropertySymbols) {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target)
      .concat(Object.getOwnPropertySymbols(target));
  };
} else {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target);
  };
}

function ProcessEmitWarning(warning) {
  if (console && console.warn) console.warn(warning);
}

var NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {
  return value !== value;
};

function EventEmitter() {
  EventEmitter.init.call(this);
}
events$1.exports = EventEmitter;
eventsExports.once = once;

// Backwards-compat with node 0.10.x
EventEmitter.EventEmitter = EventEmitter;

EventEmitter.prototype._events = undefined;
EventEmitter.prototype._eventsCount = 0;
EventEmitter.prototype._maxListeners = undefined;

// By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.
var defaultMaxListeners = 10;

function checkListener(listener) {
  if (typeof listener !== 'function') {
    throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
  }
}

Object.defineProperty(EventEmitter, 'defaultMaxListeners', {
  enumerable: true,
  get: function() {
    return defaultMaxListeners;
  },
  set: function(arg) {
    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {
      throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + '.');
    }
    defaultMaxListeners = arg;
  }
});

EventEmitter.init = function() {

  if (this._events === undefined ||
      this._events === Object.getPrototypeOf(this)._events) {
    this._events = Object.create(null);
    this._eventsCount = 0;
  }

  this._maxListeners = this._maxListeners || undefined;
};

// Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.
EventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {
  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {
    throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + '.');
  }
  this._maxListeners = n;
  return this;
};

function _getMaxListeners(that) {
  if (that._maxListeners === undefined)
    return EventEmitter.defaultMaxListeners;
  return that._maxListeners;
}

EventEmitter.prototype.getMaxListeners = function getMaxListeners() {
  return _getMaxListeners(this);
};

EventEmitter.prototype.emit = function emit(type) {
  var args = [];
  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);
  var doError = (type === 'error');

  var events = this._events;
  if (events !== undefined)
    doError = (doError && events.error === undefined);
  else if (!doError)
    return false;

  // If there is no 'error' event listener then throw.
  if (doError) {
    var er;
    if (args.length > 0)
      er = args[0];
    if (er instanceof Error) {
      // Note: The comments on the `throw` lines are intentional, they show
      // up in Node's output if this results in an unhandled exception.
      throw er; // Unhandled 'error' event
    }
    // At least give some kind of context to the user
    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));
    err.context = er;
    throw err; // Unhandled 'error' event
  }

  var handler = events[type];

  if (handler === undefined)
    return false;

  if (typeof handler === 'function') {
    ReflectApply(handler, this, args);
  } else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      ReflectApply(listeners[i], this, args);
  }

  return true;
};

function _addListener(target, type, listener, prepend) {
  var m;
  var events;
  var existing;

  checkListener(listener);

  events = target._events;
  if (events === undefined) {
    events = target._events = Object.create(null);
    target._eventsCount = 0;
  } else {
    // To avoid recursion in the case that type === "newListener"! Before
    // adding it to the listeners, first emit "newListener".
    if (events.newListener !== undefined) {
      target.emit('newListener', type,
                  listener.listener ? listener.listener : listener);

      // Re-assign `events` because a newListener handler could have caused the
      // this._events to be assigned to a new object
      events = target._events;
    }
    existing = events[type];
  }

  if (existing === undefined) {
    // Optimize the case of one listener. Don't need the extra array object.
    existing = events[type] = listener;
    ++target._eventsCount;
  } else {
    if (typeof existing === 'function') {
      // Adding the second element, need to change to array.
      existing = events[type] =
        prepend ? [listener, existing] : [existing, listener];
      // If we've already got an array, just append.
    } else if (prepend) {
      existing.unshift(listener);
    } else {
      existing.push(listener);
    }

    // Check for listener leak
    m = _getMaxListeners(target);
    if (m > 0 && existing.length > m && !existing.warned) {
      existing.warned = true;
      // No error code for this since it is a Warning
      // eslint-disable-next-line no-restricted-syntax
      var w = new Error('Possible EventEmitter memory leak detected. ' +
                          existing.length + ' ' + String(type) + ' listeners ' +
                          'added. Use emitter.setMaxListeners() to ' +
                          'increase limit');
      w.name = 'MaxListenersExceededWarning';
      w.emitter = target;
      w.type = type;
      w.count = existing.length;
      ProcessEmitWarning(w);
    }
  }

  return target;
}

EventEmitter.prototype.addListener = function addListener(type, listener) {
  return _addListener(this, type, listener, false);
};

EventEmitter.prototype.on = EventEmitter.prototype.addListener;

EventEmitter.prototype.prependListener =
    function prependListener(type, listener) {
      return _addListener(this, type, listener, true);
    };

function onceWrapper() {
  if (!this.fired) {
    this.target.removeListener(this.type, this.wrapFn);
    this.fired = true;
    if (arguments.length === 0)
      return this.listener.call(this.target);
    return this.listener.apply(this.target, arguments);
  }
}

function _onceWrap(target, type, listener) {
  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
  var wrapped = onceWrapper.bind(state);
  wrapped.listener = listener;
  state.wrapFn = wrapped;
  return wrapped;
}

EventEmitter.prototype.once = function once(type, listener) {
  checkListener(listener);
  this.on(type, _onceWrap(this, type, listener));
  return this;
};

EventEmitter.prototype.prependOnceListener =
    function prependOnceListener(type, listener) {
      checkListener(listener);
      this.prependListener(type, _onceWrap(this, type, listener));
      return this;
    };

// Emits a 'removeListener' event if and only if the listener was removed.
EventEmitter.prototype.removeListener =
    function removeListener(type, listener) {
      var list, events, position, i, originalListener;

      checkListener(listener);

      events = this._events;
      if (events === undefined)
        return this;

      list = events[type];
      if (list === undefined)
        return this;

      if (list === listener || list.listener === listener) {
        if (--this._eventsCount === 0)
          this._events = Object.create(null);
        else {
          delete events[type];
          if (events.removeListener)
            this.emit('removeListener', type, list.listener || listener);
        }
      } else if (typeof list !== 'function') {
        position = -1;

        for (i = list.length - 1; i >= 0; i--) {
          if (list[i] === listener || list[i].listener === listener) {
            originalListener = list[i].listener;
            position = i;
            break;
          }
        }

        if (position < 0)
          return this;

        if (position === 0)
          list.shift();
        else {
          spliceOne(list, position);
        }

        if (list.length === 1)
          events[type] = list[0];

        if (events.removeListener !== undefined)
          this.emit('removeListener', type, originalListener || listener);
      }

      return this;
    };

EventEmitter.prototype.off = EventEmitter.prototype.removeListener;

EventEmitter.prototype.removeAllListeners =
    function removeAllListeners(type) {
      var listeners, events, i;

      events = this._events;
      if (events === undefined)
        return this;

      // not listening for removeListener, no need to emit
      if (events.removeListener === undefined) {
        if (arguments.length === 0) {
          this._events = Object.create(null);
          this._eventsCount = 0;
        } else if (events[type] !== undefined) {
          if (--this._eventsCount === 0)
            this._events = Object.create(null);
          else
            delete events[type];
        }
        return this;
      }

      // emit removeListener for all listeners on all events
      if (arguments.length === 0) {
        var keys = Object.keys(events);
        var key;
        for (i = 0; i < keys.length; ++i) {
          key = keys[i];
          if (key === 'removeListener') continue;
          this.removeAllListeners(key);
        }
        this.removeAllListeners('removeListener');
        this._events = Object.create(null);
        this._eventsCount = 0;
        return this;
      }

      listeners = events[type];

      if (typeof listeners === 'function') {
        this.removeListener(type, listeners);
      } else if (listeners !== undefined) {
        // LIFO order
        for (i = listeners.length - 1; i >= 0; i--) {
          this.removeListener(type, listeners[i]);
        }
      }

      return this;
    };

function _listeners(target, type, unwrap) {
  var events = target._events;

  if (events === undefined)
    return [];

  var evlistener = events[type];
  if (evlistener === undefined)
    return [];

  if (typeof evlistener === 'function')
    return unwrap ? [evlistener.listener || evlistener] : [evlistener];

  return unwrap ?
    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
}

EventEmitter.prototype.listeners = function listeners(type) {
  return _listeners(this, type, true);
};

EventEmitter.prototype.rawListeners = function rawListeners(type) {
  return _listeners(this, type, false);
};

EventEmitter.listenerCount = function(emitter, type) {
  if (typeof emitter.listenerCount === 'function') {
    return emitter.listenerCount(type);
  } else {
    return listenerCount.call(emitter, type);
  }
};

EventEmitter.prototype.listenerCount = listenerCount;
function listenerCount(type) {
  var events = this._events;

  if (events !== undefined) {
    var evlistener = events[type];

    if (typeof evlistener === 'function') {
      return 1;
    } else if (evlistener !== undefined) {
      return evlistener.length;
    }
  }

  return 0;
}

EventEmitter.prototype.eventNames = function eventNames() {
  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
};

function arrayClone(arr, n) {
  var copy = new Array(n);
  for (var i = 0; i < n; ++i)
    copy[i] = arr[i];
  return copy;
}

function spliceOne(list, index) {
  for (; index + 1 < list.length; index++)
    list[index] = list[index + 1];
  list.pop();
}

function unwrapListeners(arr) {
  var ret = new Array(arr.length);
  for (var i = 0; i < ret.length; ++i) {
    ret[i] = arr[i].listener || arr[i];
  }
  return ret;
}

function once(emitter, name) {
  return new Promise(function (resolve, reject) {
    function errorListener(err) {
      emitter.removeListener(name, resolver);
      reject(err);
    }

    function resolver() {
      if (typeof emitter.removeListener === 'function') {
        emitter.removeListener('error', errorListener);
      }
      resolve([].slice.call(arguments));
    }
    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });
    if (name !== 'error') {
      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });
    }
  });
}

function addErrorHandlerIfEventEmitter(emitter, handler, flags) {
  if (typeof emitter.on === 'function') {
    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);
  }
}

function eventTargetAgnosticAddListener(emitter, name, listener, flags) {
  if (typeof emitter.on === 'function') {
    if (flags.once) {
      emitter.once(name, listener);
    } else {
      emitter.on(name, listener);
    }
  } else if (typeof emitter.addEventListener === 'function') {
    // EventTarget does not have `error` event semantics like Node
    // EventEmitters, we do not listen for `error` events here.
    emitter.addEventListener(name, function wrapListener(arg) {
      // IE does not have builtin `{ once: true }` support so we
      // have to do it manually.
      if (flags.once) {
        emitter.removeEventListener(name, wrapListener);
      }
      listener(arg);
    });
  } else {
    throw new TypeError('The "emitter" argument must be of type EventEmitter. Received type ' + typeof emitter);
  }
}

const log$z = logger$2('libp2p:peer-routing');
class DefaultPeerRouting {
    constructor(components, init) {
        this.components = components;
        this.routers = init.routers ?? [];
        this.refreshManagerInit = init.refreshManager ?? {};
        this.started = false;
        this._findClosestPeersTask = this._findClosestPeersTask.bind(this);
    }
    isStarted() {
        return this.started;
    }
    /**
     * Start peer routing service.
     */
    async start() {
        if (this.started || this.routers.length === 0 || this.timeoutId != null || this.refreshManagerInit.enabled === false) {
            return;
        }
        this.timeoutId = src.setDelayedInterval(this._findClosestPeersTask, this.refreshManagerInit.interval, this.refreshManagerInit.bootDelay);
        this.started = true;
    }
    /**
     * Recurrent task to find closest peers and add their addresses to the Address Book.
     */
    async _findClosestPeersTask() {
        if (this.abortController != null) {
            // we are already running the query
            return;
        }
        try {
            this.abortController = new timeoutAbortController.TimeoutController(this.refreshManagerInit.timeout ?? 10e3);
            // this controller may be used while dialing lots of peers so prevent MaxListenersExceededWarning
            // appearing in the console
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, this.abortController.signal);
            }
            catch { }
            // nb getClosestPeers adds the addresses to the address book
            await drain(this.getClosestPeers(this.components.peerId.toBytes(), { signal: this.abortController.signal }));
        }
        catch (err) {
            log$z.error(err);
        }
        finally {
            this.abortController?.clear();
            this.abortController = undefined;
        }
    }
    /**
     * Stop peer routing service.
     */
    async stop() {
        src.clearDelayedInterval(this.timeoutId);
        // abort query if it is in-flight
        this.abortController?.abort();
        this.started = false;
    }
    /**
     * Iterates over all peer routers in parallel to find the given peer
     */
    async findPeer(id, options) {
        if (this.routers.length === 0) {
            throw errCode(new Error('No peer routers available'), codes$1.ERR_NO_ROUTERS_AVAILABLE);
        }
        if (id.toString() === this.components.peerId.toString()) {
            throw errCode(new Error('Should not try to find self'), codes$1.ERR_FIND_SELF);
        }
        const output = await pipe(merge$1(...this.routers.map(router => (async function* () {
            try {
                yield await router.findPeer(id, options);
            }
            catch (err) {
                log$z.error(err);
            }
        })())), (source) => filter(source, Boolean), (source) => storeAddresses(source, this.components.peerStore), async (source) => await first(source));
        if (output != null) {
            return output;
        }
        throw errCode(new Error(messages.NOT_FOUND), codes$1.ERR_NOT_FOUND);
    }
    /**
     * Attempt to find the closest peers on the network to the given key
     */
    async *getClosestPeers(key, options) {
        if (this.routers.length === 0) {
            throw errCode(new Error('No peer routers available'), codes$1.ERR_NO_ROUTERS_AVAILABLE);
        }
        yield* pipe(merge$1(...this.routers.map(router => router.getClosestPeers(key, options))), (source) => storeAddresses(source, this.components.peerStore), (source) => uniquePeers(source), (source) => requirePeers(source));
    }
}

class CompoundContentRouting {
    constructor(components, init) {
        this.routers = init.routers ?? [];
        this.started = false;
        this.components = components;
    }
    isStarted() {
        return this.started;
    }
    async start() {
        this.started = true;
    }
    async stop() {
        this.started = false;
    }
    /**
     * Iterates over all content routers in parallel to find providers of the given key
     */
    async *findProviders(key, options = {}) {
        if (this.routers.length === 0) {
            throw errCode(new Error('No content this.routers available'), codes$1.ERR_NO_ROUTERS_AVAILABLE);
        }
        yield* pipe(merge$1(...this.routers.map(router => router.findProviders(key, options))), (source) => storeAddresses(source, this.components.peerStore), (source) => uniquePeers(source), (source) => requirePeers(source));
    }
    /**
     * Iterates over all content routers in parallel to notify it is
     * a provider of the given key
     */
    async provide(key, options = {}) {
        if (this.routers.length === 0) {
            throw errCode(new Error('No content routers available'), codes$1.ERR_NO_ROUTERS_AVAILABLE);
        }
        await Promise.all(this.routers.map(async (router) => await router.provide(key, options)));
    }
    /**
     * Store the given key/value pair in the available content routings
     */
    async put(key, value, options) {
        if (!this.isStarted()) {
            throw errCode(new Error(messages.NOT_STARTED_YET), codes$1.DHT_NOT_STARTED);
        }
        const dht = this.components.dht;
        if (dht != null) {
            await drain(dht.put(key, value, options));
        }
    }
    /**
     * Get the value to the given key.
     * Times out after 1 minute by default.
     */
    async get(key, options) {
        if (!this.isStarted()) {
            throw errCode(new Error(messages.NOT_STARTED_YET), codes$1.DHT_NOT_STARTED);
        }
        const dht = this.components.dht;
        if (dht != null) {
            for await (const event of dht.get(key, options)) {
                if (event.name === 'VALUE') {
                    return event.value;
                }
            }
        }
        throw errCode(new Error(messages.NOT_FOUND), codes$1.ERR_NOT_FOUND);
    }
    /**
     * Get the `n` values to the given key without sorting
     */
    async *getMany(key, nVals, options) {
        if (!this.isStarted()) {
            throw errCode(new Error(messages.NOT_STARTED_YET), codes$1.DHT_NOT_STARTED);
        }
        if (nVals == null || nVals === 0) {
            return;
        }
        let gotValues = 0;
        const dht = this.components.dht;
        if (dht != null) {
            for await (const event of dht.get(key, options)) {
                if (event.name === 'VALUE') {
                    yield { from: event.from, val: event.value };
                    gotValues++;
                    if (gotValues === nVals) {
                        break;
                    }
                }
            }
        }
        if (gotValues === 0) {
            throw errCode(new Error(messages.NOT_FOUND), codes$1.ERR_NOT_FOUND);
        }
    }
}

const defaultAddressFilter = (addrs) => addrs;
class DefaultAddressManager extends EventEmitter$1 {
    /**
     * Responsible for managing the peer addresses.
     * Peers can specify their listen and announce addresses.
     * The listen addresses will be used by the libp2p transports to listen for new connections,
     * while the announce addresses will be used for the peer addresses' to other peers in the network.
     */
    constructor(components, init) {
        super();
        const { listen = [], announce = [] } = init;
        this.components = components;
        this.listen = listen.map(ma => ma.toString());
        this.announce = new Set(announce.map(ma => ma.toString()));
        this.observed = new Set();
        this.announceFilter = init.announceFilter ?? defaultAddressFilter;
    }
    /**
     * Get peer listen multiaddrs
     */
    getListenAddrs() {
        return Array.from(this.listen).map((a) => multiaddr$1(a));
    }
    /**
     * Get peer announcing multiaddrs
     */
    getAnnounceAddrs() {
        return Array.from(this.announce).map((a) => multiaddr$1(a));
    }
    /**
     * Get observed multiaddrs
     */
    getObservedAddrs() {
        return Array.from(this.observed).map((a) => multiaddr$1(a));
    }
    /**
     * Add peer observed addresses
     * Signal that we have confidence an observed multiaddr is publicly dialable -
     * this will make it appear in the output of getAddresses()
     */
    confirmObservedAddr(addr) {
    }
    /**
     * Signal that we do not have confidence an observed multiaddr is publicly dialable -
     * this will remove it from the output of getObservedAddrs()
     */
    removeObservedAddr(addr) {
    }
    /**
     * Add peer observed addresses
     */
    addObservedAddr(addr) {
        let ma = multiaddr$1(addr);
        const remotePeer = ma.getPeerId();
        // strip our peer id if it has been passed
        if (remotePeer != null) {
            const remotePeerId = peerIdFromString(remotePeer);
            // use same encoding for comparison
            if (remotePeerId.equals(this.components.peerId)) {
                ma = ma.decapsulate(multiaddr$1(`/p2p/${this.components.peerId.toString()}`));
            }
        }
        const addrString = ma.toString();
        // do not trigger the change:addresses event if we already know about this address
        if (this.observed.has(addrString)) {
            return;
        }
        this.observed.add(addrString);
        this.dispatchEvent(new CustomEvent('change:addresses'));
    }
    getAddresses() {
        let addrs = this.getAnnounceAddrs().map(ma => ma.toString());
        if (addrs.length === 0) {
            // no configured announce addrs, add configured listen addresses
            addrs = this.components.transportManager.getAddrs().map(ma => ma.toString());
        }
        addrs = addrs.concat(this.getObservedAddrs().map(ma => ma.toString()));
        // dedupe multiaddrs
        const addrSet = new Set(addrs);
        // Create advertising list
        return this.announceFilter(Array.from(addrSet)
            .map(str => multiaddr$1(str)))
            .map(ma => {
            // do not append our peer id to a path multiaddr as it will become invalid
            if (ma.protos().pop()?.path === true) {
                return ma;
            }
            if (ma.getPeerId() === this.components.peerId.toString()) {
                return ma;
            }
            return ma.encapsulate(`/p2p/${this.components.peerId.toString()}`);
        });
    }
}

var isPlainObj = value => {
	if (Object.prototype.toString.call(value) !== '[object Object]') {
		return false;
	}

	const prototype = Object.getPrototypeOf(value);
	return prototype === null || prototype === Object.prototype;
};

const isOptionObject = isPlainObj;

const {hasOwnProperty} = Object.prototype;
const {propertyIsEnumerable} = Object;
const defineProperty = (object, name, value) => Object.defineProperty(object, name, {
	value,
	writable: true,
	enumerable: true,
	configurable: true
});

const globalThis$1 = commonjsGlobal;
const defaultMergeOptions = {
	concatArrays: false,
	ignoreUndefined: false
};

const getEnumerableOwnPropertyKeys = value => {
	const keys = [];

	for (const key in value) {
		if (hasOwnProperty.call(value, key)) {
			keys.push(key);
		}
	}

	/* istanbul ignore else  */
	if (Object.getOwnPropertySymbols) {
		const symbols = Object.getOwnPropertySymbols(value);

		for (const symbol of symbols) {
			if (propertyIsEnumerable.call(value, symbol)) {
				keys.push(symbol);
			}
		}
	}

	return keys;
};

function clone(value) {
	if (Array.isArray(value)) {
		return cloneArray(value);
	}

	if (isOptionObject(value)) {
		return cloneOptionObject(value);
	}

	return value;
}

function cloneArray(array) {
	const result = array.slice(0, 0);

	getEnumerableOwnPropertyKeys(array).forEach(key => {
		defineProperty(result, key, clone(array[key]));
	});

	return result;
}

function cloneOptionObject(object) {
	const result = Object.getPrototypeOf(object) === null ? Object.create(null) : {};

	getEnumerableOwnPropertyKeys(object).forEach(key => {
		defineProperty(result, key, clone(object[key]));
	});

	return result;
}

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {string[]} keys keys to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 */
const mergeKeys = (merged, source, keys, config) => {
	keys.forEach(key => {
		if (typeof source[key] === 'undefined' && config.ignoreUndefined) {
			return;
		}

		// Do not recurse into prototype chain of merged
		if (key in merged && merged[key] !== Object.getPrototypeOf(merged)) {
			defineProperty(merged, key, merge(merged[key], source[key], config));
		} else {
			defineProperty(merged, key, clone(source[key]));
		}
	});

	return merged;
};

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 *
 * see [Array.prototype.concat ( ...arguments )](http://www.ecma-international.org/ecma-262/6.0/#sec-array.prototype.concat)
 */
const concatArrays = (merged, source, config) => {
	let result = merged.slice(0, 0);
	let resultIndex = 0;

	[merged, source].forEach(array => {
		const indices = [];

		// `result.concat(array)` with cloning
		for (let k = 0; k < array.length; k++) {
			if (!hasOwnProperty.call(array, k)) {
				continue;
			}

			indices.push(String(k));

			if (array === merged) {
				// Already cloned
				defineProperty(result, resultIndex++, array[k]);
			} else {
				defineProperty(result, resultIndex++, clone(array[k]));
			}
		}

		// Merge non-index keys
		result = mergeKeys(result, array, getEnumerableOwnPropertyKeys(array).filter(key => !indices.includes(key)), config);
	});

	return result;
};

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 */
function merge(merged, source, config) {
	if (config.concatArrays && Array.isArray(merged) && Array.isArray(source)) {
		return concatArrays(merged, source, config);
	}

	if (!isOptionObject(source) || !isOptionObject(merged)) {
		return clone(source);
	}

	return mergeKeys(merged, source, getEnumerableOwnPropertyKeys(source), config);
}

var mergeOptions = function (...options) {
	const config = merge(clone(defaultMergeOptions), (this !== globalThis$1 && this) || {}, defaultMergeOptions);
	let merged = {_: {}};

	for (const option of options) {
		if (option === undefined) {
			continue;
		}

		if (!isOptionObject(option)) {
			throw new TypeError('`' + option + '` is not an Option Object');
		}

		merged = merge(merged, {_: option}, config);
	}

	return merged._;
};

/**
 * This code is based on `latency-monitor` (https://github.com/mlucool/latency-monitor) by `mlucool` (https://github.com/mlucool), available under Apache License 2.0 (https://github.com/mlucool/latency-monitor/blob/master/LICENSE)
 */
const log$y = logger$2('libp2p:connection-manager:latency-monitor:visibility-change-emitter');
/**
 * Listen to page visibility change events (i.e. when the page is focused / blurred) by an event emitter.
 *
 * Warning: This does not work on all browsers, but should work on all modern browsers
 *
 * @example
 *
 *     const myVisibilityEmitter = new VisibilityChangeEmitter();
 *
 *     myVisibilityEmitter.on('visibilityChange', (pageInFocus) => {
 *        if ( pageInFocus ){
 *            // Page is in focus
 *            console.log('In focus');
 *        }
 *        else {
 *            // Page is blurred
 *            console.log('Out of focus');
 *        }
 *     });
 *     // To access the visibility state directly, call:
 *     console.log('Am I focused now? ' + myVisibilityEmitter.isVisible());
 */
class VisibilityChangeEmitter extends EventEmitter$1 {
    constructor() {
        super();
        this.hidden = 'hidden';
        this.visibilityChange = 'visibilityChange';
        if (globalThis.document != null) {
            this._initializeVisibilityVarNames();
            this._addVisibilityChangeListener();
        }
    }
    /**
     * document.hidden and document.visibilityChange are the two variables we need to check for;
     * Since these variables are named differently in different browsers, this function sets
     * the appropriate name based on the browser being used. Once executed, tha actual names of
     * document.hidden and document.visibilityChange are found in this._hidden and this._visibilityChange
     * respectively
     *
     * @private
     */
    _initializeVisibilityVarNames() {
        let hidden = 'hidden';
        let visibilityChange = 'visibilitychange';
        if (typeof globalThis.document.hidden !== 'undefined') { // Opera 12.10 and Firefox 18 and later support
            hidden = 'hidden';
            visibilityChange = 'visibilitychange';
            // @ts-expect-error mozHidden is a non-standard field name
        }
        else if (typeof globalThis.document.mozHidden !== 'undefined') {
            hidden = 'mozHidden';
            visibilityChange = 'mozvisibilitychange';
            // @ts-expect-error msHidden is a non-standard field name
        }
        else if (typeof globalThis.document.msHidden !== 'undefined') {
            hidden = 'msHidden';
            visibilityChange = 'msvisibilitychange';
            // @ts-expect-error webkitHidden is a non-standard field name
        }
        else if (typeof globalThis.document.webkitHidden !== 'undefined') {
            hidden = 'webkitHidden';
            visibilityChange = 'webkitvisibilitychange';
        }
        this.hidden = hidden;
        this.visibilityChange = visibilityChange;
    }
    /**
     * Adds an event listener on the document that listens to changes in document.visibilityChange
     * (or whatever name by which the visibilityChange variable is known in the browser)
     *
     * @private
     */
    _addVisibilityChangeListener() {
        // @ts-expect-error cannot index document object with string key
        if (typeof globalThis.document.addEventListener === 'undefined' || typeof document[this.hidden] === 'undefined') {
            log$y('Checking page visibility requires a browser that supports the Page Visibility API.');
        }
        else {
            // Handle page visibility change
            globalThis.document.addEventListener(this.visibilityChange, this._handleVisibilityChange.bind(this), false);
        }
    }
    /**
     * The function returns ```true``` if the page is visible or ```false``` if the page is not visible and
     * ```undefined``` if the page visibility API is not supported by the browser.
     */
    isVisible() {
        // @ts-expect-error cannot index document object with string key
        if (this.hidden === undefined || document[this.hidden] === undefined) {
            return undefined;
        }
        // @ts-expect-error cannot index document object with string key
        return document[this.hidden] == null;
    }
    /**
     * The function that is called when document.visibilityChange has changed
     * It emits an event called visibilityChange and sends the value of document.hidden as a
     * parameter
     *
     * @private
     */
    _handleVisibilityChange() {
        // @ts-expect-error cannot index document object with string key
        const visible = globalThis.document[this.hidden] === false;
        log$y(visible ? 'Page Visible' : 'Page Hidden');
        // Emit the event
        this.dispatchEvent(new CustomEvent('visibilityChange', {
            detail: visible
        }));
    }
}

/**
 * This code is based on `latency-monitor` (https://github.com/mlucool/latency-monitor) by `mlucool` (https://github.com/mlucool), available under Apache License 2.0 (https://github.com/mlucool/latency-monitor/blob/master/LICENSE)
 */
const log$x = logger$2('libp2p:connection-manager:latency-monitor');
/**
 * A class to monitor latency of any async function which works in a browser or node. This works by periodically calling
 * the asyncTestFn and timing how long it takes the callback to be called. It can also periodically emit stats about this.
 * This can be disabled and stats can be pulled via setting dataEmitIntervalMs = 0.
 *
 * @extends {EventEmitter}
 *
 * The default implementation is an event loop latency monitor. This works by firing periodic events into the event loop
 * and timing how long it takes to get back.
 *
 * @example
 * const monitor = new LatencyMonitor();
 * monitor.on('data', (summary) => console.log('Event Loop Latency: %O', summary));
 *
 * @example
 * const monitor = new LatencyMonitor({latencyCheckIntervalMs: 1000, dataEmitIntervalMs: 60000, asyncTestFn:ping});
 * monitor.on('data', (summary) => console.log('Ping Pong Latency: %O', summary));
 */
class LatencyMonitor extends EventEmitter$1 {
    constructor(init = {}) {
        super();
        const { latencyCheckIntervalMs, dataEmitIntervalMs, asyncTestFn, latencyRandomPercentage } = init;
        // 0 isn't valid here, so its ok to use ||
        this.latencyCheckIntervalMs = latencyCheckIntervalMs ?? 500; // 0.5s
        this.latencyRandomPercentage = latencyRandomPercentage ?? 10;
        this.latencyCheckMultiply = 2 * (this.latencyRandomPercentage / 100.0) * this.latencyCheckIntervalMs;
        this.latencyCheckSubtract = this.latencyCheckMultiply / 2;
        this.dataEmitIntervalMs = (dataEmitIntervalMs === null || dataEmitIntervalMs === 0)
            ? undefined
            : dataEmitIntervalMs ?? 5 * 1000; // 5s
        log$x('latencyCheckIntervalMs: %s dataEmitIntervalMs: %s', this.latencyCheckIntervalMs, this.dataEmitIntervalMs);
        if (this.dataEmitIntervalMs != null) {
            log$x('Expecting ~%s events per summary', this.latencyCheckIntervalMs / this.dataEmitIntervalMs);
        }
        else {
            log$x('Not emitting summaries');
        }
        this.asyncTestFn = asyncTestFn; // If there is no asyncFn, we measure latency
        // If process: use high resolution timer
        if (globalThis.process?.hrtime != null) {
            log$x('Using process.hrtime for timing');
            this.now = globalThis.process.hrtime; // eslint-disable-line no-undef
            this.getDeltaMS = (startTime) => {
                const hrtime = this.now(startTime);
                return (hrtime[0] * 1000) + (hrtime[1] / 1000000);
            };
            // Let's try for a timer that only monotonically increases
        }
        else if (typeof window !== 'undefined' && window.performance?.now != null) {
            log$x('Using performance.now for timing');
            this.now = window.performance.now.bind(window.performance);
            this.getDeltaMS = (startTime) => Math.round(this.now() - startTime);
        }
        else {
            log$x('Using Date.now for timing');
            this.now = Date.now;
            this.getDeltaMS = (startTime) => this.now() - startTime;
        }
        this.latencyData = this.initLatencyData();
    }
    start() {
        // We check for isBrowser because of browsers set max rates of timeouts when a page is hidden,
        // so we fall back to another library
        // See: http://stackoverflow.com/questions/6032429/chrome-timeouts-interval-suspended-in-background-tabs
        if (isBrowser()) {
            this.visibilityChangeEmitter = new VisibilityChangeEmitter();
            this.visibilityChangeEmitter.addEventListener('visibilityChange', (evt) => {
                const { detail: pageInFocus } = evt;
                if (pageInFocus) {
                    this._startTimers();
                }
                else {
                    this._emitSummary();
                    this._stopTimers();
                }
            });
        }
        if (this.visibilityChangeEmitter?.isVisible() === true) {
            this._startTimers();
        }
    }
    stop() {
        this._stopTimers();
    }
    /**
     * Start internal timers
     *
     * @private
     */
    _startTimers() {
        // Timer already started, ignore this
        if (this.checkLatencyID != null) {
            return;
        }
        this.checkLatency();
        if (this.dataEmitIntervalMs != null) {
            this.emitIntervalID = setInterval(() => this._emitSummary(), this.dataEmitIntervalMs);
            if (typeof this.emitIntervalID.unref === 'function') {
                this.emitIntervalID.unref(); // Doesn't block exit
            }
        }
    }
    /**
     * Stop internal timers
     *
     * @private
     */
    _stopTimers() {
        if (this.checkLatencyID != null) {
            clearTimeout(this.checkLatencyID);
            this.checkLatencyID = undefined;
        }
        if (this.emitIntervalID != null) {
            clearInterval(this.emitIntervalID);
            this.emitIntervalID = undefined;
        }
    }
    /**
     * Emit summary only if there were events. It might not have any events if it was forced via a page hidden/show
     *
     * @private
     */
    _emitSummary() {
        const summary = this.getSummary();
        if (summary.events > 0) {
            this.dispatchEvent(new CustomEvent('data', {
                detail: summary
            }));
        }
    }
    /**
     * Calling this function will end the collection period. If a timing event was already fired and somewhere in the queue,
     * it will not count for this time period
     */
    getSummary() {
        // We might want to adjust for the number of expected events
        // Example: first 1 event it comes back, then such a long blocker that the next emit check comes
        // Then this fires - looks like no latency!!
        const latency = {
            events: this.latencyData.events,
            minMs: this.latencyData.minMs,
            maxMs: this.latencyData.maxMs,
            avgMs: this.latencyData.events > 0
                ? this.latencyData.totalMs / this.latencyData.events
                : Number.POSITIVE_INFINITY,
            lengthMs: this.getDeltaMS(this.latencyData.startTime)
        };
        this.latencyData = this.initLatencyData(); // Clear
        log$x.trace('Summary: %O', latency);
        return latency;
    }
    /**
     * Randomly calls an async fn every roughly latencyCheckIntervalMs (plus some randomness). If no async fn is found,
     * it will simply report on event loop latency.
     */
    checkLatency() {
        // Randomness is needed to avoid alignment by accident to regular things in the event loop
        const randomness = (Math.random() * this.latencyCheckMultiply) - this.latencyCheckSubtract;
        // We use this to ensure that in case some overlap somehow, we don't take the wrong startTime/offset
        const localData = {
            deltaOffset: Math.ceil(this.latencyCheckIntervalMs + randomness),
            startTime: this.now()
        };
        const cb = () => {
            // We are already stopped, ignore this datapoint
            if (this.checkLatencyID == null) {
                return;
            }
            const deltaMS = this.getDeltaMS(localData.startTime) - localData.deltaOffset;
            this.checkLatency(); // Start again ASAP
            // Add the data point. If this gets complex, refactor it
            this.latencyData.events++;
            this.latencyData.minMs = Math.min(this.latencyData.minMs, deltaMS);
            this.latencyData.maxMs = Math.max(this.latencyData.maxMs, deltaMS);
            this.latencyData.totalMs += deltaMS;
            log$x.trace('MS: %s Data: %O', deltaMS, this.latencyData);
        };
        log$x.trace('localData: %O', localData);
        this.checkLatencyID = setTimeout(() => {
            // This gets rid of including event loop
            if (this.asyncTestFn != null) {
                // Clear timing related things
                localData.deltaOffset = 0;
                localData.startTime = this.now();
                this.asyncTestFn(cb);
            }
            else {
                // setTimeout is not more accurate than 1ms, so this will ensure positive numbers. Add 1 to emitted data to remove.
                // This is not the best, but for now it'll be just fine. This isn't meant to be sub ms accurate.
                localData.deltaOffset -= 1;
                // If there is no function to test, we mean check latency which is a special case that is really cb => cb()
                // We avoid that for the few extra function all overheads. Also, we want to keep the timers different
                cb();
            }
        }, localData.deltaOffset);
        if (typeof this.checkLatencyID.unref === 'function') {
            this.checkLatencyID.unref(); // Doesn't block exit
        }
    }
    initLatencyData() {
        return {
            startTime: this.now(),
            minMs: Number.POSITIVE_INFINITY,
            maxMs: Number.NEGATIVE_INFINITY,
            events: 0,
            totalMs: 0
        };
    }
}
function isBrowser() {
    return typeof globalThis.window !== 'undefined';
}

const OPEN = 'OPEN';
const CLOSING = 'CLOSING';
const CLOSED = 'CLOSED';

/**
 * Calls the passed map function on every entry of the passed iterable iterator
 */
function mapIterable(iter, map) {
    const iterator = {
        [Symbol.iterator]: () => {
            return iterator;
        },
        next: () => {
            const next = iter.next();
            const val = next.value;
            if (next.done === true || val == null) {
                const result = {
                    done: true,
                    value: undefined
                };
                return result;
            }
            return {
                done: false,
                value: map(val)
            };
        }
    };
    return iterator;
}

/**
 * We can't use PeerIds as map keys because map keys are
 * compared using same-value-zero equality, so this is just
 * a map that stringifies the PeerIds before storing them.
 *
 * PeerIds cache stringified versions of themselves so this
 * should be a cheap operation.
 *
 * @example
 *
 * ```JavaScript
 * import { peerMap } from '@libp2p/peer-collections'
 *
 * const map = peerMap<string>()
 * map.set(peerId, 'value')
 * ```
 */
class PeerMap {
    constructor(map) {
        this.map = new Map();
        if (map != null) {
            for (const [key, value] of map.entries()) {
                this.map.set(key.toString(), value);
            }
        }
    }
    [Symbol.iterator]() {
        return this.entries();
    }
    clear() {
        this.map.clear();
    }
    delete(peer) {
        this.map.delete(peer.toString());
    }
    entries() {
        return mapIterable(this.map.entries(), (val) => {
            return [peerIdFromString(val[0]), val[1]];
        });
    }
    forEach(fn) {
        this.map.forEach((value, key) => {
            fn(value, peerIdFromString(key), this);
        });
    }
    get(peer) {
        return this.map.get(peer.toString());
    }
    has(peer) {
        return this.map.has(peer.toString());
    }
    set(peer, value) {
        this.map.set(peer.toString(), value);
    }
    keys() {
        return mapIterable(this.map.keys(), (val) => {
            return peerIdFromString(val);
        });
    }
    values() {
        return this.map.values();
    }
    get size() {
        return this.map.size;
    }
}

/**
 * We can't use PeerIds as set entries because set entries are
 * compared using same-value-zero equality, so this is just
 * a map that stringifies the PeerIds before storing them.
 *
 * PeerIds cache stringified versions of themselves so this
 * should be a cheap operation.
 *
 * @example
 *
 * ```JavaScript
 * import { peerSet } from '@libp2p/peer-collections'
 *
 * const set = peerSet()
 * set.add(peerId)
 * ```
 */
class PeerSet {
    constructor(set) {
        this.set = new Set();
        if (set != null) {
            for (const key of set) {
                this.set.add(key.toString());
            }
        }
    }
    get size() {
        return this.set.size;
    }
    [Symbol.iterator]() {
        return this.values();
    }
    add(peer) {
        this.set.add(peer.toString());
    }
    clear() {
        this.set.clear();
    }
    delete(peer) {
        this.set.delete(peer.toString());
    }
    entries() {
        return mapIterable(this.set.entries(), (val) => {
            const peerId = peerIdFromString(val[0]);
            return [peerId, peerId];
        });
    }
    forEach(predicate) {
        this.set.forEach((str) => {
            const id = peerIdFromString(str);
            predicate(id, id, this);
        });
    }
    has(peer) {
        return this.set.has(peer.toString());
    }
    values() {
        return mapIterable(this.set.values(), (val) => {
            return peerIdFromString(val);
        });
    }
    intersection(other) {
        const output = new PeerSet();
        for (const peerId of other) {
            if (this.has(peerId)) {
                output.add(peerId);
            }
        }
        return output;
    }
    difference(other) {
        const output = new PeerSet();
        for (const peerId of this) {
            if (!other.has(peerId)) {
                output.add(peerId);
            }
        }
        return output;
    }
    union(other) {
        const output = new PeerSet();
        for (const peerId of other) {
            output.add(peerId);
        }
        for (const peerId of this) {
            output.add(peerId);
        }
        return output;
    }
}

const KEEP_ALIVE = 'keep-alive';

/**
 * Extracts a PeerId and/or multiaddr from the passed PeerId or Multiaddr
 */
function getPeerAddress(peer) {
    if (isPeerId(peer)) {
        return {
            peerId: peer
        };
    }
    if (isMultiaddr$1(peer)) {
        const peerId = peer.getPeerId();
        return {
            multiaddr: peer,
            peerId: peerId == null ? undefined : peerIdFromString(peerId)
        };
    }
    throw errCode(new Error(`${peer} is not a PeerId or a Multiaddr`), // eslint-disable-line @typescript-eslint/restrict-template-expressions
    codes$1.ERR_INVALID_MULTIADDR);
}

const log$w = logger$2('libp2p:connection-manager');
const defaultOptions$4 = {
    maxConnections: Infinity,
    minConnections: 0,
    maxEventLoopDelay: Infinity,
    pollInterval: 2000,
    autoDialInterval: 10000,
    inboundConnectionThreshold: 5,
    maxIncomingPendingConnections: 10
};
const STARTUP_RECONNECT_TIMEOUT = 60000;
/**
 * Responsible for managing known connections.
 */
class DefaultConnectionManager extends EventEmitter$1 {
    constructor(components, init) {
        super();
        this.opts = mergeOptions.call({ ignoreUndefined: true }, defaultOptions$4, init);
        if (this.opts.maxConnections < this.opts.minConnections) {
            throw errCode(new Error('Connection Manager maxConnections must be greater than minConnections'), codes$1.ERR_INVALID_PARAMETERS);
        }
        log$w('options: %o', this.opts);
        this.components = components;
        /**
         * Map of connections per peer
         */
        this.connections = new Map();
        this.started = false;
        if (init.maxEventLoopDelay != null && init.maxEventLoopDelay > 0 && init.maxEventLoopDelay !== Infinity) {
            this.latencyMonitor = new LatencyMonitor({
                latencyCheckIntervalMs: init.pollInterval,
                dataEmitIntervalMs: init.pollInterval
            });
        }
        try {
            // This emitter gets listened to a lot
            eventsExports.setMaxListeners?.(Infinity, this);
        }
        catch { }
        this.onConnect = this.onConnect.bind(this);
        this.onDisconnect = this.onDisconnect.bind(this);
        this.startupReconnectTimeout = init.startupReconnectTimeout ?? STARTUP_RECONNECT_TIMEOUT;
        this.dialTimeout = init.dialTimeout ?? 30000;
        this.allow = (init.allow ?? []).map(ma => multiaddr$1(ma));
        this.deny = (init.deny ?? []).map(ma => multiaddr$1(ma));
        this.inboundConnectionRateLimiter = new rateLimiterFlexible.RateLimiterMemory({
            points: this.opts.inboundConnectionThreshold,
            duration: 1
        });
        this.incomingPendingConnections = 0;
    }
    isStarted() {
        return this.started;
    }
    /**
     * Starts the Connection Manager. If Metrics are not enabled on libp2p
     * only event loop and connection limits will be monitored.
     */
    async start() {
        // track inbound/outbound connections
        this.components.metrics?.registerMetricGroup('libp2p_connection_manager_connections', {
            calculate: () => {
                const metric = {
                    inbound: 0,
                    outbound: 0
                };
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        if (conn.stat.direction === 'inbound') {
                            metric.inbound++;
                        }
                        else {
                            metric.outbound++;
                        }
                    }
                }
                return metric;
            }
        });
        // track total number of streams per protocol
        this.components.metrics?.registerMetricGroup('libp2p_protocol_streams_total', {
            label: 'protocol',
            calculate: () => {
                const metric = {};
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        for (const stream of conn.streams) {
                            const key = `${stream.stat.direction} ${stream.stat.protocol ?? 'unnegotiated'}`;
                            metric[key] = (metric[key] ?? 0) + 1;
                        }
                    }
                }
                return metric;
            }
        });
        // track 90th percentile of streams per protocol
        this.components.metrics?.registerMetricGroup('libp2p_connection_manager_protocol_streams_per_connection_90th_percentile', {
            label: 'protocol',
            calculate: () => {
                const allStreams = {};
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        const streams = {};
                        for (const stream of conn.streams) {
                            const key = `${stream.stat.direction} ${stream.stat.protocol ?? 'unnegotiated'}`;
                            streams[key] = (streams[key] ?? 0) + 1;
                        }
                        for (const [protocol, count] of Object.entries(streams)) {
                            allStreams[protocol] = allStreams[protocol] ?? [];
                            allStreams[protocol].push(count);
                        }
                    }
                }
                const metric = {};
                for (let [protocol, counts] of Object.entries(allStreams)) {
                    counts = counts.sort((a, b) => a - b);
                    const index = Math.floor(counts.length * 0.9);
                    metric[protocol] = counts[index];
                }
                return metric;
            }
        });
        // latency monitor
        this.latencyMonitor?.start();
        this._onLatencyMeasure = this._onLatencyMeasure.bind(this);
        this.latencyMonitor?.addEventListener('data', this._onLatencyMeasure);
        this.started = true;
        log$w('started');
    }
    async afterStart() {
        this.components.upgrader.addEventListener('connection', this.onConnect);
        this.components.upgrader.addEventListener('connectionEnd', this.onDisconnect);
        // re-connect to any peers with the KEEP_ALIVE tag
        void Promise.resolve()
            .then(async () => {
            const keepAlivePeers = [];
            for (const peer of await this.components.peerStore.all()) {
                const tags = await this.components.peerStore.getTags(peer.id);
                const hasKeepAlive = tags.filter(tag => tag.name === KEEP_ALIVE).length > 0;
                if (hasKeepAlive) {
                    keepAlivePeers.push(peer.id);
                }
            }
            this.connectOnStartupController?.clear();
            this.connectOnStartupController = new timeoutAbortController.TimeoutController(this.startupReconnectTimeout);
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, this.connectOnStartupController.signal);
            }
            catch { }
            await Promise.all(keepAlivePeers.map(async (peer) => {
                await this.openConnection(peer, {
                    signal: this.connectOnStartupController?.signal
                })
                    .catch(err => {
                    log$w.error(err);
                });
            }));
        })
            .catch(err => {
            log$w.error(err);
        })
            .finally(() => {
            this.connectOnStartupController?.clear();
        });
    }
    async beforeStop() {
        // if we are still dialing KEEP_ALIVE peers, abort those dials
        this.connectOnStartupController?.abort();
        this.components.upgrader.removeEventListener('connection', this.onConnect);
        this.components.upgrader.removeEventListener('connectionEnd', this.onDisconnect);
    }
    /**
     * Stops the Connection Manager
     */
    async stop() {
        this.latencyMonitor?.removeEventListener('data', this._onLatencyMeasure);
        this.latencyMonitor?.stop();
        this.started = false;
        await this._close();
        log$w('stopped');
    }
    /**
     * Cleans up the connections
     */
    async _close() {
        // Close all connections we're tracking
        const tasks = [];
        for (const connectionList of this.connections.values()) {
            for (const connection of connectionList) {
                tasks.push((async () => {
                    try {
                        await connection.close();
                    }
                    catch (err) {
                        log$w.error(err);
                    }
                })());
            }
        }
        log$w('closing %d connections', tasks.length);
        await Promise.all(tasks);
        this.connections.clear();
    }
    onConnect(evt) {
        void this._onConnect(evt).catch(err => {
            log$w.error(err);
        });
    }
    /**
     * Tracks the incoming connection and check the connection limit
     */
    async _onConnect(evt) {
        const { detail: connection } = evt;
        if (!this.started) {
            // This can happen when we are in the process of shutting down the node
            await connection.close();
            return;
        }
        const peerId = connection.remotePeer;
        const peerIdStr = peerId.toString();
        const storedConns = this.connections.get(peerIdStr);
        if (storedConns != null) {
            storedConns.push(connection);
        }
        else {
            this.connections.set(peerIdStr, [connection]);
        }
        if (peerId.publicKey != null) {
            await this.components.peerStore.keyBook.set(peerId, peerId.publicKey);
        }
        const numConnections = this.getConnections().length;
        const toPrune = numConnections - this.opts.maxConnections;
        await this._checkMaxLimit('maxConnections', numConnections, toPrune);
        this.dispatchEvent(new CustomEvent('peer:connect', { detail: connection }));
    }
    /**
     * Removes the connection from tracking
     */
    onDisconnect(evt) {
        const { detail: connection } = evt;
        if (!this.started) {
            // This can happen when we are in the process of shutting down the node
            return;
        }
        const peerId = connection.remotePeer.toString();
        let storedConn = this.connections.get(peerId);
        if (storedConn != null && storedConn.length > 1) {
            storedConn = storedConn.filter((conn) => conn.id !== connection.id);
            this.connections.set(peerId, storedConn);
        }
        else if (storedConn != null) {
            this.connections.delete(peerId);
            this.dispatchEvent(new CustomEvent('peer:disconnect', { detail: connection }));
        }
    }
    getConnections(peerId) {
        if (peerId != null) {
            return this.connections.get(peerId.toString()) ?? [];
        }
        let conns = [];
        for (const c of this.connections.values()) {
            conns = conns.concat(c);
        }
        return conns;
    }
    async openConnection(peerIdOrMultiaddr, options = {}) {
        const { peerId, multiaddr } = getPeerAddress(peerIdOrMultiaddr);
        if (peerId == null && multiaddr == null) {
            throw errCode(new TypeError('Can only open connections to PeerIds or Multiaddrs'), codes$1.ERR_INVALID_PARAMETERS);
        }
        if (peerId != null) {
            log$w('dial to', peerId);
            const existingConnections = this.getConnections(peerId);
            if (existingConnections.length > 0) {
                log$w('had an existing connection to %p', peerId);
                return existingConnections[0];
            }
        }
        let timeoutController;
        if (options?.signal == null) {
            timeoutController = new timeoutAbortController.TimeoutController(this.dialTimeout);
            options.signal = timeoutController.signal;
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, timeoutController.signal);
            }
            catch { }
        }
        try {
            const connection = await this.components.dialer.dial(peerIdOrMultiaddr, options);
            let peerConnections = this.connections.get(connection.remotePeer.toString());
            if (peerConnections == null) {
                peerConnections = [];
                this.connections.set(connection.remotePeer.toString(), peerConnections);
            }
            // we get notified of connections via the Upgrader emitting "connection"
            // events, double check we aren't already tracking this connection before
            // storing it
            let trackedConnection = false;
            for (const conn of peerConnections) {
                if (conn.id === connection.id) {
                    trackedConnection = true;
                }
            }
            if (!trackedConnection) {
                peerConnections.push(connection);
            }
            return connection;
        }
        finally {
            if (timeoutController != null) {
                timeoutController.clear();
            }
        }
    }
    async closeConnections(peerId) {
        const connections = this.connections.get(peerId.toString()) ?? [];
        await Promise.all(connections.map(async (connection) => {
            return await connection.close();
        }));
    }
    /**
     * Get all open connections with a peer
     */
    getAll(peerId) {
        if (!isPeerId(peerId)) {
            throw errCode(new Error('peerId must be an instance of peer-id'), codes$1.ERR_INVALID_PARAMETERS);
        }
        const id = peerId.toString();
        const connections = this.connections.get(id);
        // Return all open connections
        if (connections != null) {
            return connections.filter(connection => connection.stat.status === OPEN);
        }
        return [];
    }
    /**
     * If the event loop is slow, maybe close a connection
     */
    _onLatencyMeasure(evt) {
        const { detail: summary } = evt;
        this._checkMaxLimit('maxEventLoopDelay', summary.avgMs, 1)
            .catch(err => {
            log$w.error(err);
        });
    }
    /**
     * If the `value` of `name` has exceeded its limit, maybe close a connection
     */
    async _checkMaxLimit(name, value, toPrune = 1) {
        const limit = this.opts[name];
        if (limit == null) {
            log$w.trace('limit %s was not set so it cannot be applied', name);
            return;
        }
        log$w.trace('checking limit of %s. current value: %d of %d', name, value, limit);
        if (value > limit) {
            log$w('%s: limit exceeded: %p, %d/%d, pruning %d connection(s)', this.components.peerId, name, value, limit, toPrune);
            await this._pruneConnections(toPrune);
        }
    }
    /**
     * If we have more connections than our maximum, select some excess connections
     * to prune based on peer value
     */
    async _pruneConnections(toPrune) {
        const connections = this.getConnections();
        const peerValues = new PeerMap();
        // work out peer values
        for (const connection of connections) {
            const remotePeer = connection.remotePeer;
            if (peerValues.has(remotePeer)) {
                continue;
            }
            const tags = await this.components.peerStore.getTags(remotePeer);
            // sum all tag values
            peerValues.set(remotePeer, tags.reduce((acc, curr) => {
                return acc + curr.value;
            }, 0));
        }
        // sort by value, lowest to highest
        const sortedConnections = connections.sort((a, b) => {
            const peerAValue = peerValues.get(a.remotePeer) ?? 0;
            const peerBValue = peerValues.get(b.remotePeer) ?? 0;
            if (peerAValue > peerBValue) {
                return 1;
            }
            if (peerAValue < peerBValue) {
                return -1;
            }
            // if the peers have an equal tag value then we want to close short-lived connections first
            const connectionALifespan = a.stat.timeline.open;
            const connectionBLifespan = b.stat.timeline.open;
            if (connectionALifespan < connectionBLifespan) {
                return 1;
            }
            if (connectionALifespan > connectionBLifespan) {
                return -1;
            }
            return 0;
        });
        // close some connections
        const toClose = [];
        for (const connection of sortedConnections) {
            log$w('too many connections open - closing a connection to %p', connection.remotePeer);
            toClose.push(connection);
            if (toClose.length === toPrune) {
                break;
            }
        }
        // close connections
        await Promise.all(toClose.map(async (connection) => {
            try {
                await connection.close();
            }
            catch (err) {
                log$w.error(err);
            }
            // TODO: should not need to invoke this manually
            this.onDisconnect(new CustomEvent('connectionEnd', {
                detail: connection
            }));
        }));
    }
    async acceptIncomingConnection(maConn) {
        // check deny list
        const denyConnection = this.deny.some(ma => {
            return maConn.remoteAddr.toString().startsWith(ma.toString());
        });
        if (denyConnection) {
            log$w('connection from %s refused - connection remote address was in deny list', maConn.remoteAddr);
            return false;
        }
        // check allow list
        const allowConnection = this.allow.some(ma => {
            return maConn.remoteAddr.toString().startsWith(ma.toString());
        });
        if (allowConnection) {
            this.incomingPendingConnections++;
            return true;
        }
        // check pending connections
        if (this.incomingPendingConnections === this.opts.maxIncomingPendingConnections) {
            log$w('connection from %s refused - incomingPendingConnections exceeded by peer %s', maConn.remoteAddr);
            return false;
        }
        if (maConn.remoteAddr.isThinWaistAddress()) {
            const host = maConn.remoteAddr.nodeAddress().address;
            try {
                await this.inboundConnectionRateLimiter.consume(host, 1);
            }
            catch {
                log$w('connection from %s refused - inboundConnectionThreshold exceeded by host %s', host, maConn.remoteAddr);
                return false;
            }
        }
        if (this.getConnections().length < this.opts.maxConnections) {
            this.incomingPendingConnections++;
            return true;
        }
        log$w('connection from %s refused - maxConnections exceeded', maConn.remoteAddr);
        return false;
    }
    afterUpgradeInbound() {
        this.incomingPendingConnections--;
    }
}

/**
 * Collects all values from an async iterator, sorts them
 * using the passed function and yields them
 */
async function* sort(source, sorter) {
    const arr = await all(source);
    yield* arr.sort(sorter);
}

const log$v = logger$2('libp2p:connection-manager:auto-dialler');
const defaultOptions$3 = {
    enabled: true,
    minConnections: 0,
    autoDialInterval: 10000
};
class AutoDialler {
    /**
     * Proactively tries to connect to known peers stored in the PeerStore.
     * It will keep the number of connections below the upper limit and sort
     * the peers to connect based on wether we know their keys and protocols.
     */
    constructor(components, init) {
        this.components = components;
        this.options = mergeOptions.call({ ignoreUndefined: true }, defaultOptions$3, init);
        this.running = false;
        this._autoDial = this._autoDial.bind(this);
        log$v('options: %j', this.options);
    }
    isStarted() {
        return this.running;
    }
    /**
     * Starts the auto dialer
     */
    async start() {
        if (!this.options.enabled) {
            log$v('not enabled');
            return;
        }
        this.running = true;
        void this._autoDial().catch(err => {
            log$v.error('could start autodial', err);
        });
        log$v('started');
    }
    /**
     * Stops the auto dialler
     */
    async stop() {
        if (!this.options.enabled) {
            log$v('not enabled');
            return;
        }
        this.running = false;
        if (this.autoDialTimeout != null) {
            this.autoDialTimeout.clear();
        }
        log$v('stopped');
    }
    async _autoDial() {
        if (this.autoDialTimeout != null) {
            this.autoDialTimeout.clear();
        }
        const minConnections = this.options.minConnections;
        // Already has enough connections
        if (this.components.connectionManager.getConnections().length >= minConnections) {
            this.autoDialTimeout = retimer_1(this._autoDial, this.options.autoDialInterval);
            return;
        }
        // Sort peers on whether we know protocols or public keys for them
        const allPeers = await this.components.peerStore.all();
        const peers = await pipe(
        // shuffle the peers
        allPeers.sort(() => Math.random() > 0.5 ? 1 : -1), (source) => filter(source, (peer) => !peer.id.equals(this.components.peerId)), (source) => sort(source, (a, b) => {
            if (b.protocols.length > a.protocols.length) {
                return 1;
            }
            else if (b.id.publicKey != null && a.id.publicKey == null) {
                return 1;
            }
            return -1;
        }), async (source) => await all(source));
        for (let i = 0; this.running && i < peers.length && this.components.connectionManager.getConnections().length < minConnections; i++) {
            // Connection Manager was stopped during async dial
            if (!this.running) {
                return;
            }
            const peer = peers[i];
            if (this.components.connectionManager.getConnections(peer.id).length === 0) {
                log$v('connecting to a peerStore stored peer %p', peer.id);
                try {
                    await this.components.connectionManager.openConnection(peer.id);
                }
                catch (err) {
                    log$v.error('could not connect to peerStore stored peer', err);
                }
            }
        }
        // Connection Manager was stopped
        if (!this.running) {
            return;
        }
        this.autoDialTimeout = retimer_1(this._autoDial, this.options.autoDialInterval);
    }
}

/* eslint-disable import/export */
var CircuitRelay;
(function (CircuitRelay) {
    (function (Status) {
        Status["SUCCESS"] = "SUCCESS";
        Status["HOP_SRC_ADDR_TOO_LONG"] = "HOP_SRC_ADDR_TOO_LONG";
        Status["HOP_DST_ADDR_TOO_LONG"] = "HOP_DST_ADDR_TOO_LONG";
        Status["HOP_SRC_MULTIADDR_INVALID"] = "HOP_SRC_MULTIADDR_INVALID";
        Status["HOP_DST_MULTIADDR_INVALID"] = "HOP_DST_MULTIADDR_INVALID";
        Status["HOP_NO_CONN_TO_DST"] = "HOP_NO_CONN_TO_DST";
        Status["HOP_CANT_DIAL_DST"] = "HOP_CANT_DIAL_DST";
        Status["HOP_CANT_OPEN_DST_STREAM"] = "HOP_CANT_OPEN_DST_STREAM";
        Status["HOP_CANT_SPEAK_RELAY"] = "HOP_CANT_SPEAK_RELAY";
        Status["HOP_CANT_RELAY_TO_SELF"] = "HOP_CANT_RELAY_TO_SELF";
        Status["STOP_SRC_ADDR_TOO_LONG"] = "STOP_SRC_ADDR_TOO_LONG";
        Status["STOP_DST_ADDR_TOO_LONG"] = "STOP_DST_ADDR_TOO_LONG";
        Status["STOP_SRC_MULTIADDR_INVALID"] = "STOP_SRC_MULTIADDR_INVALID";
        Status["STOP_DST_MULTIADDR_INVALID"] = "STOP_DST_MULTIADDR_INVALID";
        Status["STOP_RELAY_REFUSED"] = "STOP_RELAY_REFUSED";
        Status["MALFORMED_MESSAGE"] = "MALFORMED_MESSAGE";
    })(CircuitRelay.Status || (CircuitRelay.Status = {}));
    let __StatusValues;
    (function (__StatusValues) {
        __StatusValues[__StatusValues["SUCCESS"] = 100] = "SUCCESS";
        __StatusValues[__StatusValues["HOP_SRC_ADDR_TOO_LONG"] = 220] = "HOP_SRC_ADDR_TOO_LONG";
        __StatusValues[__StatusValues["HOP_DST_ADDR_TOO_LONG"] = 221] = "HOP_DST_ADDR_TOO_LONG";
        __StatusValues[__StatusValues["HOP_SRC_MULTIADDR_INVALID"] = 250] = "HOP_SRC_MULTIADDR_INVALID";
        __StatusValues[__StatusValues["HOP_DST_MULTIADDR_INVALID"] = 251] = "HOP_DST_MULTIADDR_INVALID";
        __StatusValues[__StatusValues["HOP_NO_CONN_TO_DST"] = 260] = "HOP_NO_CONN_TO_DST";
        __StatusValues[__StatusValues["HOP_CANT_DIAL_DST"] = 261] = "HOP_CANT_DIAL_DST";
        __StatusValues[__StatusValues["HOP_CANT_OPEN_DST_STREAM"] = 262] = "HOP_CANT_OPEN_DST_STREAM";
        __StatusValues[__StatusValues["HOP_CANT_SPEAK_RELAY"] = 270] = "HOP_CANT_SPEAK_RELAY";
        __StatusValues[__StatusValues["HOP_CANT_RELAY_TO_SELF"] = 280] = "HOP_CANT_RELAY_TO_SELF";
        __StatusValues[__StatusValues["STOP_SRC_ADDR_TOO_LONG"] = 320] = "STOP_SRC_ADDR_TOO_LONG";
        __StatusValues[__StatusValues["STOP_DST_ADDR_TOO_LONG"] = 321] = "STOP_DST_ADDR_TOO_LONG";
        __StatusValues[__StatusValues["STOP_SRC_MULTIADDR_INVALID"] = 350] = "STOP_SRC_MULTIADDR_INVALID";
        __StatusValues[__StatusValues["STOP_DST_MULTIADDR_INVALID"] = 351] = "STOP_DST_MULTIADDR_INVALID";
        __StatusValues[__StatusValues["STOP_RELAY_REFUSED"] = 390] = "STOP_RELAY_REFUSED";
        __StatusValues[__StatusValues["MALFORMED_MESSAGE"] = 400] = "MALFORMED_MESSAGE";
    })(__StatusValues || (__StatusValues = {}));
    (function (Status) {
        Status.codec = () => {
            return enumeration$1(__StatusValues);
        };
    })(CircuitRelay.Status || (CircuitRelay.Status = {}));
    (function (Type) {
        Type["HOP"] = "HOP";
        Type["STOP"] = "STOP";
        Type["STATUS"] = "STATUS";
        Type["CAN_HOP"] = "CAN_HOP";
    })(CircuitRelay.Type || (CircuitRelay.Type = {}));
    let __TypeValues;
    (function (__TypeValues) {
        __TypeValues[__TypeValues["HOP"] = 1] = "HOP";
        __TypeValues[__TypeValues["STOP"] = 2] = "STOP";
        __TypeValues[__TypeValues["STATUS"] = 3] = "STATUS";
        __TypeValues[__TypeValues["CAN_HOP"] = 4] = "CAN_HOP";
    })(__TypeValues || (__TypeValues = {}));
    (function (Type) {
        Type.codec = () => {
            return enumeration$1(__TypeValues);
        };
    })(CircuitRelay.Type || (CircuitRelay.Type = {}));
    (function (Peer) {
        let _codec;
        Peer.codec = () => {
            if (_codec == null) {
                _codec = message$4((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if (opts.writeDefaults === true || (obj.id != null && obj.id.byteLength > 0)) {
                        w.uint32(10);
                        w.bytes(obj.id);
                    }
                    if (obj.addrs != null) {
                        for (const value of obj.addrs) {
                            w.uint32(18);
                            w.bytes(value);
                        }
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        id: new Uint8Array(0),
                        addrs: []
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.id = reader.bytes();
                                break;
                            case 2:
                                obj.addrs.push(reader.bytes());
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        Peer.encode = (obj) => {
            return encodeMessage$4(obj, Peer.codec());
        };
        Peer.decode = (buf) => {
            return decodeMessage$5(buf, Peer.codec());
        };
    })(CircuitRelay.Peer || (CircuitRelay.Peer = {}));
    let _codec;
    CircuitRelay.codec = () => {
        if (_codec == null) {
            _codec = message$4((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.type != null) {
                    w.uint32(8);
                    CircuitRelay.Type.codec().encode(obj.type, w);
                }
                if (obj.srcPeer != null) {
                    w.uint32(18);
                    CircuitRelay.Peer.codec().encode(obj.srcPeer, w, {
                        writeDefaults: false
                    });
                }
                if (obj.dstPeer != null) {
                    w.uint32(26);
                    CircuitRelay.Peer.codec().encode(obj.dstPeer, w, {
                        writeDefaults: false
                    });
                }
                if (obj.code != null) {
                    w.uint32(32);
                    CircuitRelay.Status.codec().encode(obj.code, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.type = CircuitRelay.Type.codec().decode(reader);
                            break;
                        case 2:
                            obj.srcPeer = CircuitRelay.Peer.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.dstPeer = CircuitRelay.Peer.codec().decode(reader, reader.uint32());
                            break;
                        case 4:
                            obj.code = CircuitRelay.Status.codec().decode(reader);
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    CircuitRelay.encode = (obj) => {
        return encodeMessage$4(obj, CircuitRelay.codec());
    };
    CircuitRelay.decode = (buf) => {
        return decodeMessage$5(buf, CircuitRelay.codec());
    };
})(CircuitRelay || (CircuitRelay = {}));

const log$u = logger$2('libp2p:stream:converter');
/**
 * Convert a duplex iterable into a MultiaddrConnection.
 * https://github.com/libp2p/interface-transport#multiaddrconnection
 */
function streamToMaConnection(props, options = {}) {
    const { stream, remoteAddr } = props;
    const { sink, source } = stream;
    const mapSource = (async function* () {
        for await (const list of source) {
            yield* list;
        }
    }());
    const maConn = {
        async sink(source) {
            if (options.signal != null) {
                source = abortableSource(source, options.signal);
            }
            try {
                await sink(source);
                await close();
            }
            catch (err) {
                // If aborted we can safely ignore
                if (err.type !== 'aborted') {
                    // If the source errored the socket will already have been destroyed by
                    // toIterable.duplex(). If the socket errored it will already be
                    // destroyed. There's nothing to do here except log the error & return.
                    log$u(err);
                }
            }
        },
        source: (options.signal != null) ? abortableSource(mapSource, options.signal) : mapSource,
        remoteAddr,
        /** @type {Timeline} */
        timeline: { open: Date.now(), close: undefined },
        async close() {
            await sink(async function* () {
                yield new Uint8Array(0);
            }());
            await close();
        }
    };
    async function close() {
        if (maConn.timeline.close == null) {
            maConn.timeline.close = Date.now();
        }
        return await Promise.resolve();
    }
    return maConn;
}

const RELAY_CODEC = '/libp2p/circuit/relay/0.1.0';

function createListener(options) {
    const listeningAddrs = new Map();
    /**
     * Add swarm handler and listen for incoming connections
     */
    async function listen(addr) {
        const addrString = addr.toString().split('/p2p-circuit').find(a => a !== '');
        const ma = multiaddr$1(addrString);
        const relayPeerStr = ma.getPeerId();
        if (relayPeerStr == null) {
            throw new Error('Could not determine relay peer from multiaddr');
        }
        const relayPeerId = peerIdFromString(relayPeerStr);
        await options.peerStore.addressBook.add(relayPeerId, [ma]);
        const relayConn = await options.connectionManager.openConnection(relayPeerId);
        const relayedAddr = relayConn.remoteAddr.encapsulate('/p2p-circuit');
        listeningAddrs.set(relayConn.remotePeer.toString(), relayedAddr);
        listener.dispatchEvent(new CustomEvent('listening'));
    }
    /**
     * Get fixed up multiaddrs
     *
     * NOTE: This method will grab the peers multiaddrs and expand them such that:
     *
     * a) If it's an existing /p2p-circuit address for a specific relay i.e.
     * `/ip4/0.0.0.0/tcp/0/ipfs/QmRelay/p2p-circuit` this method will expand the
     * address to `/ip4/0.0.0.0/tcp/0/ipfs/QmRelay/p2p-circuit/ipfs/QmPeer` where
     * `QmPeer` is this peers id
     * b) If it's not a /p2p-circuit address, it will encapsulate the address as a /p2p-circuit
     * addr, such when dialing over a relay with this address, it will create the circuit using
     * the encapsulated transport address. This is useful when for example, a peer should only
     * be dialed over TCP rather than any other transport
     *
     * @returns {Multiaddr[]}
     */
    function getAddrs() {
        const addrs = [];
        for (const addr of listeningAddrs.values()) {
            addrs.push(addr);
        }
        return addrs;
    }
    const listener = Object.assign(new EventEmitter$1(), {
        close: async () => await Promise.resolve(),
        listen,
        getAddrs
    });
    // Remove listeningAddrs when a peer disconnects
    options.connectionManager.addEventListener('peer:disconnect', (evt) => {
        const { detail: connection } = evt;
        const deleted = listeningAddrs.delete(connection.remotePeer.toString());
        if (deleted) {
            // Announce listen addresses change
            listener.dispatchEvent(new CustomEvent('close'));
        }
    });
    return listener;
}

/**
 * Write a response
 */
function writeResponse(streamHandler, status) {
    streamHandler.write({
        type: CircuitRelay.Type.STATUS,
        code: status
    });
}
/**
 * Validate incomming HOP/STOP message
 */
function validateAddrs(msg, streamHandler) {
    try {
        if (msg.dstPeer?.addrs != null) {
            msg.dstPeer.addrs.forEach((addr) => {
                return multiaddr$1(addr);
            });
        }
    }
    catch (err) {
        writeResponse(streamHandler, msg.type === CircuitRelay.Type.HOP
            ? CircuitRelay.Status.HOP_DST_MULTIADDR_INVALID
            : CircuitRelay.Status.STOP_DST_MULTIADDR_INVALID);
        throw err;
    }
    try {
        if (msg.srcPeer?.addrs != null) {
            msg.srcPeer.addrs.forEach((addr) => {
                return multiaddr$1(addr);
            });
        }
    }
    catch (err) {
        writeResponse(streamHandler, msg.type === CircuitRelay.Type.HOP
            ? CircuitRelay.Status.HOP_SRC_MULTIADDR_INVALID
            : CircuitRelay.Status.STOP_SRC_MULTIADDR_INVALID);
        throw err;
    }
}

const log$t = logger$2('libp2p:circuit:stream-handler');
class StreamHandler {
    constructor(options) {
        const { stream, maxLength = 4096 } = options;
        this.stream = stream;
        this.shake = handshake(this.stream);
        this.decoder = decode$a.fromReader(this.shake.reader, { maxDataLength: maxLength });
    }
    /**
     * Read and decode message
     */
    async read() {
        // @ts-expect-error FIXME is a source, needs to be a generator
        const msg = await this.decoder.next();
        if (msg.value != null) {
            const value = CircuitRelay.decode(msg.value);
            log$t('read message type', value.type);
            return value;
        }
        log$t('read received no value, closing stream');
        // End the stream, we didn't get data
        this.close();
    }
    /**
     * Encode and write array of buffers
     */
    write(msg) {
        log$t('write message type %s', msg.type);
        this.shake.write(encode$b.single(CircuitRelay.encode(msg)));
    }
    /**
     * Return the handshake rest stream and invalidate handler
     */
    rest() {
        this.shake.rest();
        return this.shake.stream;
    }
    /**
     * @param {CircuitRelay} msg - An unencoded CircuitRelay protobuf message
     */
    end(msg) {
        this.write(msg);
        this.close();
    }
    /**
     * Close the stream
     */
    close() {
        log$t('closing the stream');
        void this.rest().sink([]).catch(err => {
            log$t.error(err);
        });
    }
}

const log$s = logger$2('libp2p:circuit:stop');
/**
 * Handles incoming STOP requests
 */
function handleStop(options) {
    const { connection, request, streamHandler } = options;
    // Validate the STOP request has the required input
    try {
        validateAddrs(request, streamHandler);
    }
    catch (err) {
        log$s.error('invalid stop request via peer %p %o', connection.remotePeer, err);
        return;
    }
    // The request is valid
    log$s('stop request is valid');
    streamHandler.write({
        type: CircuitRelay.Type.STATUS,
        code: CircuitRelay.Status.SUCCESS
    });
    return streamHandler.rest();
}
/**
 * Creates a STOP request
 */
async function stop(options) {
    const { connection, request, signal } = options;
    const stream = await connection.newStream(RELAY_CODEC, {
        signal
    });
    log$s('starting stop request to %p', connection.remotePeer);
    const streamHandler = new StreamHandler({ stream });
    streamHandler.write(request);
    const response = await streamHandler.read();
    if (response == null) {
        streamHandler.close();
        return;
    }
    if (response.code === CircuitRelay.Status.SUCCESS) {
        log$s('stop request to %p was successful', connection.remotePeer);
        return streamHandler.rest();
    }
    log$s('stop request failed with code %d', response.code);
    streamHandler.close();
}

const log$r = logger$2('libp2p:circuit:hop');
async function handleHop(hopRequest) {
    const { connection, request, streamHandler, circuit, connectionManager } = hopRequest;
    // Ensure hop is enabled
    if (!circuit.hopEnabled()) {
        log$r('HOP request received but we are not acting as a relay');
        return streamHandler.end({
            type: CircuitRelay.Type.STATUS,
            code: CircuitRelay.Status.HOP_CANT_SPEAK_RELAY
        });
    }
    // Validate the HOP request has the required input
    try {
        validateAddrs(request, streamHandler);
    }
    catch (err) {
        log$r.error('invalid hop request via peer %p %o', connection.remotePeer, err);
        return;
    }
    if (request.dstPeer == null) {
        log$r('HOP request received but we do not receive a dstPeer');
        return;
    }
    // Get the connection to the destination (stop) peer
    const destinationPeer = peerIdFromBytes(request.dstPeer.id);
    const destinationConnections = connectionManager.getConnections(destinationPeer);
    if (destinationConnections.length === 0 && !circuit.hopActive()) {
        log$r('HOP request received but we are not connected to the destination peer');
        return streamHandler.end({
            type: CircuitRelay.Type.STATUS,
            code: CircuitRelay.Status.HOP_NO_CONN_TO_DST
        });
    }
    // TODO: Handle being an active relay
    if (destinationConnections.length === 0) {
        log$r('did not have connection to remote peer');
        return streamHandler.end({
            type: CircuitRelay.Type.STATUS,
            code: CircuitRelay.Status.HOP_NO_CONN_TO_DST
        });
    }
    // Handle the incoming HOP request by performing a STOP request
    const stopRequest = {
        type: CircuitRelay.Type.STOP,
        dstPeer: request.dstPeer,
        srcPeer: request.srcPeer
    };
    let destinationStream;
    try {
        log$r('performing STOP request');
        const result = await stop({
            connection: destinationConnections[0],
            request: stopRequest
        });
        if (result == null) {
            throw new Error('Could not stop');
        }
        destinationStream = result;
    }
    catch (err) {
        log$r.error(err);
        return;
    }
    log$r('hop request from %p is valid', connection.remotePeer);
    streamHandler.write({
        type: CircuitRelay.Type.STATUS,
        code: CircuitRelay.Status.SUCCESS
    });
    const sourceStream = streamHandler.rest();
    log$r('creating related connections');
    // Short circuit the two streams to create the relayed connection
    return await pipe(sourceStream, destinationStream, sourceStream);
}
/**
 * Performs a HOP request to a relay peer, to request a connection to another
 * peer. A new, virtual, connection will be created between the two via the relay.
 */
async function hop(options) {
    const { connection, request, signal } = options;
    // Create a new stream to the relay
    const stream = await connection.newStream(RELAY_CODEC, {
        signal
    });
    // Send the HOP request
    const streamHandler = new StreamHandler({ stream });
    streamHandler.write(request);
    const response = await streamHandler.read();
    if (response == null) {
        throw errCode(new Error('HOP request had no response'), codes$1.ERR_HOP_REQUEST_FAILED);
    }
    if (response.code === CircuitRelay.Status.SUCCESS) {
        log$r('hop request was successful');
        return streamHandler.rest();
    }
    log$r('hop request failed with code %d, closing stream', response.code);
    streamHandler.close();
    throw errCode(new Error(`HOP request failed with code "${response.code ?? 'unknown'}"`), codes$1.ERR_HOP_REQUEST_FAILED);
}
/**
 * Performs a CAN_HOP request to a relay peer, in order to understand its capabilities
 */
async function canHop(options) {
    const { connection, signal } = options;
    // Create a new stream to the relay
    const stream = await connection.newStream(RELAY_CODEC, {
        signal
    });
    // Send the HOP request
    const streamHandler = new StreamHandler({ stream });
    streamHandler.write({
        type: CircuitRelay.Type.CAN_HOP
    });
    const response = await streamHandler.read();
    await streamHandler.close();
    if (response == null || response.code !== CircuitRelay.Status.SUCCESS) {
        return false;
    }
    return true;
}
/**
 * Creates an unencoded CAN_HOP response based on the Circuits configuration
 */
function handleCanHop(options) {
    const { connection, streamHandler, circuit } = options;
    const canHop = circuit.hopEnabled();
    log$r('can hop (%s) request from %p', canHop, connection.remotePeer);
    streamHandler.end({
        type: CircuitRelay.Type.STATUS,
        code: canHop ? CircuitRelay.Status.SUCCESS : CircuitRelay.Status.HOP_CANT_SPEAK_RELAY
    });
}

const log$q = logger$2('libp2p:circuit');
class Circuit {
    constructor(components, init) {
        this._init = init;
        this.components = components;
        this._started = false;
    }
    isStarted() {
        return this._started;
    }
    async start() {
        if (this._started) {
            return;
        }
        this._started = true;
        await this.components.registrar.handle(RELAY_CODEC, (data) => {
            void this._onProtocol(data).catch(err => {
                log$q.error(err);
            });
        }, { ...this._init })
            .catch(err => {
            log$q.error(err);
        });
    }
    async stop() {
        await this.components.registrar.unhandle(RELAY_CODEC);
    }
    hopEnabled() {
        return true;
    }
    hopActive() {
        return true;
    }
    get [symbol$3]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return 'libp2p/circuit-relay-v1';
    }
    async _onProtocol(data) {
        const { connection, stream } = data;
        const controller = new timeoutAbortController.TimeoutController(this._init.hop.timeout);
        try {
            // fails on node < 15.4
            eventsExports.setMaxListeners?.(Infinity, controller.signal);
        }
        catch { }
        try {
            const source = abortableDuplex(stream, controller.signal);
            const streamHandler = new StreamHandler({
                stream: {
                    ...stream,
                    ...source
                }
            });
            const request = await streamHandler.read();
            if (request == null) {
                log$q('request was invalid, could not read from stream');
                streamHandler.write({
                    type: CircuitRelay.Type.STATUS,
                    code: CircuitRelay.Status.MALFORMED_MESSAGE
                });
                streamHandler.close();
                return;
            }
            let virtualConnection;
            switch (request.type) {
                case CircuitRelay.Type.CAN_HOP: {
                    log$q('received CAN_HOP request from %p', connection.remotePeer);
                    await handleCanHop({ circuit: this, connection, streamHandler });
                    break;
                }
                case CircuitRelay.Type.HOP: {
                    log$q('received HOP request from %p', connection.remotePeer);
                    await handleHop({
                        connection,
                        request,
                        streamHandler,
                        circuit: this,
                        connectionManager: this.components.connectionManager
                    });
                    break;
                }
                case CircuitRelay.Type.STOP: {
                    log$q('received STOP request from %p', connection.remotePeer);
                    virtualConnection = await handleStop({
                        connection,
                        request,
                        streamHandler
                    });
                    break;
                }
                default: {
                    log$q('Request of type %s not supported', request.type);
                    streamHandler.write({
                        type: CircuitRelay.Type.STATUS,
                        code: CircuitRelay.Status.MALFORMED_MESSAGE
                    });
                    streamHandler.close();
                    return;
                }
            }
            if (virtualConnection != null) {
                const remoteAddr = connection.remoteAddr
                    .encapsulate('/p2p-circuit')
                    .encapsulate(multiaddr$1(request.dstPeer?.addrs[0]));
                const localAddr = multiaddr$1(request.srcPeer?.addrs[0]);
                const maConn = streamToMaConnection({
                    stream: virtualConnection,
                    remoteAddr,
                    localAddr
                });
                const type = request.type === CircuitRelay.Type.HOP ? 'relay' : 'inbound';
                log$q('new %s connection %s', type, maConn.remoteAddr);
                const conn = await this.components.upgrader.upgradeInbound(maConn);
                log$q('%s connection %s upgraded', type, maConn.remoteAddr);
                if (this.handler != null) {
                    this.handler(conn);
                }
            }
        }
        finally {
            controller.clear();
        }
    }
    /**
     * Dial a peer over a relay
     */
    async dial(ma, options = {}) {
        // Check the multiaddr to see if it contains a relay and a destination peer
        const addrs = ma.toString().split('/p2p-circuit');
        const relayAddr = multiaddr$1(addrs[0]);
        const destinationAddr = multiaddr$1(addrs[addrs.length - 1]);
        const relayId = relayAddr.getPeerId();
        const destinationId = destinationAddr.getPeerId();
        if (relayId == null || destinationId == null) {
            const errMsg = 'Circuit relay dial failed as addresses did not have peer id';
            log$q.error(errMsg);
            throw errCode(new Error(errMsg), codes$1.ERR_RELAYED_DIAL);
        }
        const relayPeer = peerIdFromString(relayId);
        const destinationPeer = peerIdFromString(destinationId);
        let disconnectOnFailure = false;
        const relayConnections = this.components.connectionManager.getConnections(relayPeer);
        let relayConnection = relayConnections[0];
        if (relayConnection == null) {
            await this.components.peerStore.addressBook.add(relayPeer, [relayAddr]);
            relayConnection = await this.components.connectionManager.openConnection(relayPeer, options);
            disconnectOnFailure = true;
        }
        try {
            const virtualConnection = await hop({
                ...options,
                connection: relayConnection,
                request: {
                    type: CircuitRelay.Type.HOP,
                    srcPeer: {
                        id: this.components.peerId.toBytes(),
                        addrs: this.components.addressManager.getAddresses().map(addr => addr.bytes)
                    },
                    dstPeer: {
                        id: destinationPeer.toBytes(),
                        addrs: [multiaddr$1(destinationAddr).bytes]
                    }
                }
            });
            const localAddr = relayAddr.encapsulate(`/p2p-circuit/p2p/${this.components.peerId.toString()}`);
            const maConn = streamToMaConnection({
                stream: virtualConnection,
                remoteAddr: ma,
                localAddr
            });
            log$q('new outbound connection %s', maConn.remoteAddr);
            return await this.components.upgrader.upgradeOutbound(maConn);
        }
        catch (err) {
            log$q.error('Circuit relay dial failed', err);
            disconnectOnFailure && await relayConnection.close();
            throw err;
        }
    }
    /**
     * Create a listener
     */
    createListener(options) {
        // Called on successful HOP and STOP requests
        this.handler = options.handler;
        return createListener({
            connectionManager: this.components.connectionManager,
            peerStore: this.components.peerStore
        });
    }
    /**
     * Filter check for all Multiaddrs that this transport can dial on
     *
     * @param {Multiaddr[]} multiaddrs
     * @returns {Multiaddr[]}
     */
    filter(multiaddrs) {
        multiaddrs = Array.isArray(multiaddrs) ? multiaddrs : [multiaddrs];
        return multiaddrs.filter((ma) => {
            return Circuit$1.matches(ma);
        });
    }
}

/**
 * Convert a namespace string into a cid
 */
async function namespaceToCid(namespace) {
    const bytes = new TextEncoder().encode(namespace);
    const hash = await sha256.digest(bytes);
    return CID.createV0(hash);
}

const minute = 60 * 1000;
/**
 * Delay before HOP relay service is advertised on the network
 */
const ADVERTISE_BOOT_DELAY = 15 * minute;
/**
 * Delay Between HOP relay service advertisements on the network
 */
const ADVERTISE_TTL = 30 * minute;
/**
 * Multicodec code
 */
const CIRCUIT_PROTO_CODE = 290;
/**
 * PeerStore metadaBook key for HOP relay service
 */
const HOP_METADATA_KEY = 'hop_relay';
/**
 * PeerStore metadaBook value for HOP relay service
 */
const HOP_METADATA_VALUE = 'true';
/**
 * Relay HOP relay service namespace for discovery
 */
const RELAY_RENDEZVOUS_NS = '/libp2p/relay';

var Netmask_1;
// Generated by CoffeeScript 1.12.7
(function() {
  var Netmask, atob, chr, chr0, chrA, chra, ip2long, long2ip;

  long2ip = function(long) {
    var a, b, c, d;
    a = (long & (0xff << 24)) >>> 24;
    b = (long & (0xff << 16)) >>> 16;
    c = (long & (0xff << 8)) >>> 8;
    d = long & 0xff;
    return [a, b, c, d].join('.');
  };

  ip2long = function(ip) {
    var b, c, i, j, n, ref;
    b = [];
    for (i = j = 0; j <= 3; i = ++j) {
      if (ip.length === 0) {
        break;
      }
      if (i > 0) {
        if (ip[0] !== '.') {
          throw new Error('Invalid IP');
        }
        ip = ip.substring(1);
      }
      ref = atob(ip), n = ref[0], c = ref[1];
      ip = ip.substring(c);
      b.push(n);
    }
    if (ip.length !== 0) {
      throw new Error('Invalid IP');
    }
    switch (b.length) {
      case 1:
        if (b[0] > 0xFFFFFFFF) {
          throw new Error('Invalid IP');
        }
        return b[0] >>> 0;
      case 2:
        if (b[0] > 0xFF || b[1] > 0xFFFFFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1]) >>> 0;
      case 3:
        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFFFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1] << 16 | b[2]) >>> 0;
      case 4:
        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFF || b[3] > 0xFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1] << 16 | b[2] << 8 | b[3]) >>> 0;
      default:
        throw new Error('Invalid IP');
    }
  };

  chr = function(b) {
    return b.charCodeAt(0);
  };

  chr0 = chr('0');

  chra = chr('a');

  chrA = chr('A');

  atob = function(s) {
    var base, dmax, i, n, start;
    n = 0;
    base = 10;
    dmax = '9';
    i = 0;
    if (s.length > 1 && s[i] === '0') {
      if (s[i + 1] === 'x' || s[i + 1] === 'X') {
        i += 2;
        base = 16;
      } else if ('0' <= s[i + 1] && s[i + 1] <= '9') {
        i++;
        base = 8;
        dmax = '7';
      }
    }
    start = i;
    while (i < s.length) {
      if ('0' <= s[i] && s[i] <= dmax) {
        n = (n * base + (chr(s[i]) - chr0)) >>> 0;
      } else if (base === 16) {
        if ('a' <= s[i] && s[i] <= 'f') {
          n = (n * base + (10 + chr(s[i]) - chra)) >>> 0;
        } else if ('A' <= s[i] && s[i] <= 'F') {
          n = (n * base + (10 + chr(s[i]) - chrA)) >>> 0;
        } else {
          break;
        }
      } else {
        break;
      }
      if (n > 0xFFFFFFFF) {
        throw new Error('too large');
      }
      i++;
    }
    if (i === start) {
      throw new Error('empty octet');
    }
    return [n, i];
  };

  Netmask = (function() {
    function Netmask(net, mask) {
      var i, j, ref;
      if (typeof net !== 'string') {
        throw new Error("Missing `net' parameter");
      }
      if (!mask) {
        ref = net.split('/', 2), net = ref[0], mask = ref[1];
      }
      if (!mask) {
        mask = 32;
      }
      if (typeof mask === 'string' && mask.indexOf('.') > -1) {
        try {
          this.maskLong = ip2long(mask);
        } catch (error1) {
          throw new Error("Invalid mask: " + mask);
        }
        for (i = j = 32; j >= 0; i = --j) {
          if (this.maskLong === (0xffffffff << (32 - i)) >>> 0) {
            this.bitmask = i;
            break;
          }
        }
      } else if (mask || mask === 0) {
        this.bitmask = parseInt(mask, 10);
        this.maskLong = 0;
        if (this.bitmask > 0) {
          this.maskLong = (0xffffffff << (32 - this.bitmask)) >>> 0;
        }
      } else {
        throw new Error("Invalid mask: empty");
      }
      try {
        this.netLong = (ip2long(net) & this.maskLong) >>> 0;
      } catch (error1) {
        throw new Error("Invalid net address: " + net);
      }
      if (!(this.bitmask <= 32)) {
        throw new Error("Invalid mask for ip4: " + mask);
      }
      this.size = Math.pow(2, 32 - this.bitmask);
      this.base = long2ip(this.netLong);
      this.mask = long2ip(this.maskLong);
      this.hostmask = long2ip(~this.maskLong);
      this.first = this.bitmask <= 30 ? long2ip(this.netLong + 1) : this.base;
      this.last = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 2) : long2ip(this.netLong + this.size - 1);
      this.broadcast = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 1) : void 0;
    }

    Netmask.prototype.contains = function(ip) {
      if (typeof ip === 'string' && (ip.indexOf('/') > 0 || ip.split('.').length !== 4)) {
        ip = new Netmask(ip);
      }
      if (ip instanceof Netmask) {
        return this.contains(ip.base) && this.contains(ip.broadcast || ip.last);
      } else {
        return (ip2long(ip) & this.maskLong) >>> 0 === (this.netLong & this.maskLong) >>> 0;
      }
    };

    Netmask.prototype.next = function(count) {
      if (count == null) {
        count = 1;
      }
      return new Netmask(long2ip(this.netLong + (this.size * count)), this.mask);
    };

    Netmask.prototype.forEach = function(fn) {
      var index, lastLong, long;
      long = ip2long(this.first);
      lastLong = ip2long(this.last);
      index = 0;
      while (long <= lastLong) {
        fn(long2ip(long), long, index);
        index++;
        long++;
      }
    };

    Netmask.prototype.toString = function() {
      return this.base + "/" + this.bitmask;
    };

    return Netmask;

  })();

  Netmask_1 = Netmask;

}).call(commonjsGlobal);

const word = '[a-fA-F\\d:]';

const boundry = options => options && options.includeBoundaries
	? `(?:(?<=\\s|^)(?=${word})|(?<=${word})(?=\\s|$))`
	: '';

const v4 = '(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]\\d|\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]\\d|\\d)){3}';

const v6segment = '[a-fA-F\\d]{1,4}';

const v6 = `
(?:
(?:${v6segment}:){7}(?:${v6segment}|:)|                                    // 1:2:3:4:5:6:7::  1:2:3:4:5:6:7:8
(?:${v6segment}:){6}(?:${v4}|:${v6segment}|:)|                             // 1:2:3:4:5:6::    1:2:3:4:5:6::8   1:2:3:4:5:6::8  1:2:3:4:5:6::1.2.3.4
(?:${v6segment}:){5}(?::${v4}|(?::${v6segment}){1,2}|:)|                   // 1:2:3:4:5::      1:2:3:4:5::7:8   1:2:3:4:5::8    1:2:3:4:5::7:1.2.3.4
(?:${v6segment}:){4}(?:(?::${v6segment}){0,1}:${v4}|(?::${v6segment}){1,3}|:)| // 1:2:3:4::        1:2:3:4::6:7:8   1:2:3:4::8      1:2:3:4::6:7:1.2.3.4
(?:${v6segment}:){3}(?:(?::${v6segment}){0,2}:${v4}|(?::${v6segment}){1,4}|:)| // 1:2:3::          1:2:3::5:6:7:8   1:2:3::8        1:2:3::5:6:7:1.2.3.4
(?:${v6segment}:){2}(?:(?::${v6segment}){0,3}:${v4}|(?::${v6segment}){1,5}|:)| // 1:2::            1:2::4:5:6:7:8   1:2::8          1:2::4:5:6:7:1.2.3.4
(?:${v6segment}:){1}(?:(?::${v6segment}){0,4}:${v4}|(?::${v6segment}){1,6}|:)| // 1::              1::3:4:5:6:7:8   1::8            1::3:4:5:6:7:1.2.3.4
(?::(?:(?::${v6segment}){0,5}:${v4}|(?::${v6segment}){1,7}|:))             // ::2:3:4:5:6:7:8  ::2:3:4:5:6:7:8  ::8             ::1.2.3.4
)(?:%[0-9a-zA-Z]{1,})?                                             // %eth0            %1
`.replace(/\s*\/\/.*$/gm, '').replace(/\n/g, '').trim();

// Pre-compile only the exact regexes because adding a global flag make regexes stateful
const v46Exact = new RegExp(`(?:^${v4}$)|(?:^${v6}$)`);
const v4exact = new RegExp(`^${v4}$`);
const v6exact = new RegExp(`^${v6}$`);

const ipRegex = options => options && options.exact
	? v46Exact
	: new RegExp(`(?:${boundry(options)}${v4}${boundry(options)})|(?:${boundry(options)}${v6}${boundry(options)})`, 'g');

ipRegex.v4 = options => options && options.exact ? v4exact : new RegExp(`${boundry(options)}${v4}${boundry(options)}`, 'g');
ipRegex.v6 = options => options && options.exact ? v6exact : new RegExp(`${boundry(options)}${v6}${boundry(options)}`, 'g');

var ipaddrExports = {};
var ipaddr$1 = {
  get exports(){ return ipaddrExports; },
  set exports(v){ ipaddrExports = v; },
};

(function (module) {
	(function (root) {
	    // A list of regular expressions that match arbitrary IPv4 addresses,
	    // for which a number of weird notations exist.
	    // Note that an address like 0010.0xa5.1.1 is considered legal.
	    const ipv4Part = '(0?\\d+|0x[a-f0-9]+)';
	    const ipv4Regexes = {
	        fourOctet: new RegExp(`^${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}$`, 'i'),
	        threeOctet: new RegExp(`^${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}$`, 'i'),
	        twoOctet: new RegExp(`^${ipv4Part}\\.${ipv4Part}$`, 'i'),
	        longValue: new RegExp(`^${ipv4Part}$`, 'i')
	    };

	    // Regular Expression for checking Octal numbers
	    const octalRegex = new RegExp(`^0[0-7]+$`, 'i');
	    const hexRegex = new RegExp(`^0x[a-f0-9]+$`, 'i');

	    const zoneIndex = '%[0-9a-z]{1,}';

	    // IPv6-matching regular expressions.
	    // For IPv6, the task is simpler: it is enough to match the colon-delimited
	    // hexadecimal IPv6 and a transitional variant with dotted-decimal IPv4 at
	    // the end.
	    const ipv6Part = '(?:[0-9a-f]+::?)+';
	    const ipv6Regexes = {
	        zoneIndex: new RegExp(zoneIndex, 'i'),
	        'native': new RegExp(`^(::)?(${ipv6Part})?([0-9a-f]+)?(::)?(${zoneIndex})?$`, 'i'),
	        deprecatedTransitional: new RegExp(`^(?:::)(${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}(${zoneIndex})?)$`, 'i'),
	        transitional: new RegExp(`^((?:${ipv6Part})|(?:::)(?:${ipv6Part})?)${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}(${zoneIndex})?$`, 'i')
	    };

	    // Expand :: in an IPv6 address or address part consisting of `parts` groups.
	    function expandIPv6 (string, parts) {
	        // More than one '::' means invalid adddress
	        if (string.indexOf('::') !== string.lastIndexOf('::')) {
	            return null;
	        }

	        let colonCount = 0;
	        let lastColon = -1;
	        let zoneId = (string.match(ipv6Regexes.zoneIndex) || [])[0];
	        let replacement, replacementCount;

	        // Remove zone index and save it for later
	        if (zoneId) {
	            zoneId = zoneId.substring(1);
	            string = string.replace(/%.+$/, '');
	        }

	        // How many parts do we already have?
	        while ((lastColon = string.indexOf(':', lastColon + 1)) >= 0) {
	            colonCount++;
	        }

	        // 0::0 is two parts more than ::
	        if (string.substr(0, 2) === '::') {
	            colonCount--;
	        }

	        if (string.substr(-2, 2) === '::') {
	            colonCount--;
	        }

	        // The following loop would hang if colonCount > parts
	        if (colonCount > parts) {
	            return null;
	        }

	        // replacement = ':' + '0:' * (parts - colonCount)
	        replacementCount = parts - colonCount;
	        replacement = ':';
	        while (replacementCount--) {
	            replacement += '0:';
	        }

	        // Insert the missing zeroes
	        string = string.replace('::', replacement);

	        // Trim any garbage which may be hanging around if :: was at the edge in
	        // the source strin
	        if (string[0] === ':') {
	            string = string.slice(1);
	        }

	        if (string[string.length - 1] === ':') {
	            string = string.slice(0, -1);
	        }

	        parts = (function () {
	            const ref = string.split(':');
	            const results = [];

	            for (let i = 0; i < ref.length; i++) {
	                results.push(parseInt(ref[i], 16));
	            }

	            return results;
	        })();

	        return {
	            parts: parts,
	            zoneId: zoneId
	        };
	    }

	    // A generic CIDR (Classless Inter-Domain Routing) RFC1518 range matcher.
	    function matchCIDR (first, second, partSize, cidrBits) {
	        if (first.length !== second.length) {
	            throw new Error('ipaddr: cannot match CIDR for objects with different lengths');
	        }

	        let part = 0;
	        let shift;

	        while (cidrBits > 0) {
	            shift = partSize - cidrBits;
	            if (shift < 0) {
	                shift = 0;
	            }

	            if (first[part] >> shift !== second[part] >> shift) {
	                return false;
	            }

	            cidrBits -= partSize;
	            part += 1;
	        }

	        return true;
	    }

	    function parseIntAuto (string) {
	        // Hexadedimal base 16 (0x#)
	        if (hexRegex.test(string)) {
	            return parseInt(string, 16);
	        }
	        // While octal representation is discouraged by ECMAScript 3
	        // and forbidden by ECMAScript 5, we silently allow it to
	        // work only if the rest of the string has numbers less than 8.
	        if (string[0] === '0' && !isNaN(parseInt(string[1], 10))) {
	        if (octalRegex.test(string)) {
	            return parseInt(string, 8);
	        }
	            throw new Error(`ipaddr: cannot parse ${string} as octal`);
	        }
	        // Always include the base 10 radix!
	        return parseInt(string, 10);
	    }

	    function padPart (part, length) {
	        while (part.length < length) {
	            part = `0${part}`;
	        }

	        return part;
	    }

	    const ipaddr = {};

	    // An IPv4 address (RFC791).
	    ipaddr.IPv4 = (function () {
	        // Constructs a new IPv4 address from an array of four octets
	        // in network order (MSB first)
	        // Verifies the input.
	        function IPv4 (octets) {
	            if (octets.length !== 4) {
	                throw new Error('ipaddr: ipv4 octet count should be 4');
	            }

	            let i, octet;

	            for (i = 0; i < octets.length; i++) {
	                octet = octets[i];
	                if (!((0 <= octet && octet <= 255))) {
	                    throw new Error('ipaddr: ipv4 octet should fit in 8 bits');
	                }
	            }

	            this.octets = octets;
	        }

	        // Special IPv4 address ranges.
	        // See also https://en.wikipedia.org/wiki/Reserved_IP_addresses
	        IPv4.prototype.SpecialRanges = {
	            unspecified: [[new IPv4([0, 0, 0, 0]), 8]],
	            broadcast: [[new IPv4([255, 255, 255, 255]), 32]],
	            // RFC3171
	            multicast: [[new IPv4([224, 0, 0, 0]), 4]],
	            // RFC3927
	            linkLocal: [[new IPv4([169, 254, 0, 0]), 16]],
	            // RFC5735
	            loopback: [[new IPv4([127, 0, 0, 0]), 8]],
	            // RFC6598
	            carrierGradeNat: [[new IPv4([100, 64, 0, 0]), 10]],
	            // RFC1918
	            'private': [
	                [new IPv4([10, 0, 0, 0]), 8],
	                [new IPv4([172, 16, 0, 0]), 12],
	                [new IPv4([192, 168, 0, 0]), 16]
	            ],
	            // Reserved and testing-only ranges; RFCs 5735, 5737, 2544, 1700
	            reserved: [
	                [new IPv4([192, 0, 0, 0]), 24],
	                [new IPv4([192, 0, 2, 0]), 24],
	                [new IPv4([192, 88, 99, 0]), 24],
	                [new IPv4([198, 51, 100, 0]), 24],
	                [new IPv4([203, 0, 113, 0]), 24],
	                [new IPv4([240, 0, 0, 0]), 4]
	            ]
	        };

	        // The 'kind' method exists on both IPv4 and IPv6 classes.
	        IPv4.prototype.kind = function () {
	            return 'ipv4';
	        };

	        // Checks if this address matches other one within given CIDR range.
	        IPv4.prototype.match = function (other, cidrRange) {
	            let ref;
	            if (cidrRange === undefined) {
	                ref = other;
	                other = ref[0];
	                cidrRange = ref[1];
	            }

	            if (other.kind() !== 'ipv4') {
	                throw new Error('ipaddr: cannot match ipv4 address with non-ipv4 one');
	            }

	            return matchCIDR(this.octets, other.octets, 8, cidrRange);
	        };

	        // returns a number of leading ones in IPv4 address, making sure that
	        // the rest is a solid sequence of 0's (valid netmask)
	        // returns either the CIDR length or null if mask is not valid
	        IPv4.prototype.prefixLengthFromSubnetMask = function () {
	            let cidr = 0;
	            // non-zero encountered stop scanning for zeroes
	            let stop = false;
	            // number of zeroes in octet
	            const zerotable = {
	                0: 8,
	                128: 7,
	                192: 6,
	                224: 5,
	                240: 4,
	                248: 3,
	                252: 2,
	                254: 1,
	                255: 0
	            };
	            let i, octet, zeros;

	            for (i = 3; i >= 0; i -= 1) {
	                octet = this.octets[i];
	                if (octet in zerotable) {
	                    zeros = zerotable[octet];
	                    if (stop && zeros !== 0) {
	                        return null;
	                    }

	                    if (zeros !== 8) {
	                        stop = true;
	                    }

	                    cidr += zeros;
	                } else {
	                    return null;
	                }
	            }

	            return 32 - cidr;
	        };

	        // Checks if the address corresponds to one of the special ranges.
	        IPv4.prototype.range = function () {
	            return ipaddr.subnetMatch(this, this.SpecialRanges);
	        };

	        // Returns an array of byte-sized values in network order (MSB first)
	        IPv4.prototype.toByteArray = function () {
	            return this.octets.slice(0);
	        };

	        // Converts this IPv4 address to an IPv4-mapped IPv6 address.
	        IPv4.prototype.toIPv4MappedAddress = function () {
	            return ipaddr.IPv6.parse(`::ffff:${this.toString()}`);
	        };

	        // Symmetrical method strictly for aligning with the IPv6 methods.
	        IPv4.prototype.toNormalizedString = function () {
	            return this.toString();
	        };

	        // Returns the address in convenient, decimal-dotted format.
	        IPv4.prototype.toString = function () {
	            return this.octets.join('.');
	        };

	        return IPv4;
	    })();

	    // A utility function to return broadcast address given the IPv4 interface and prefix length in CIDR notation
	    ipaddr.IPv4.broadcastAddressFromCIDR = function (string) {

	        try {
	            const cidr = this.parseCIDR(string);
	            const ipInterfaceOctets = cidr[0].toByteArray();
	            const subnetMaskOctets = this.subnetMaskFromPrefixLength(cidr[1]).toByteArray();
	            const octets = [];
	            let i = 0;
	            while (i < 4) {
	                // Broadcast address is bitwise OR between ip interface and inverted mask
	                octets.push(parseInt(ipInterfaceOctets[i], 10) | parseInt(subnetMaskOctets[i], 10) ^ 255);
	                i++;
	            }

	            return new this(octets);
	        } catch (e) {
	            throw new Error('ipaddr: the address does not have IPv4 CIDR format');
	        }
	    };

	    // Checks if a given string is formatted like IPv4 address.
	    ipaddr.IPv4.isIPv4 = function (string) {
	        return this.parser(string) !== null;
	    };

	    // Checks if a given string is a valid IPv4 address.
	    ipaddr.IPv4.isValid = function (string) {
	        try {
	            new this(this.parser(string));
	            return true;
	        } catch (e) {
	            return false;
	        }
	    };

	    // Checks if a given string is a full four-part IPv4 Address.
	    ipaddr.IPv4.isValidFourPartDecimal = function (string) {
	        if (ipaddr.IPv4.isValid(string) && string.match(/^(0|[1-9]\d*)(\.(0|[1-9]\d*)){3}$/)) {
	            return true;
	        } else {
	            return false;
	        }
	    };

	    // A utility function to return network address given the IPv4 interface and prefix length in CIDR notation
	    ipaddr.IPv4.networkAddressFromCIDR = function (string) {
	        let cidr, i, ipInterfaceOctets, octets, subnetMaskOctets;

	        try {
	            cidr = this.parseCIDR(string);
	            ipInterfaceOctets = cidr[0].toByteArray();
	            subnetMaskOctets = this.subnetMaskFromPrefixLength(cidr[1]).toByteArray();
	            octets = [];
	            i = 0;
	            while (i < 4) {
	                // Network address is bitwise AND between ip interface and mask
	                octets.push(parseInt(ipInterfaceOctets[i], 10) & parseInt(subnetMaskOctets[i], 10));
	                i++;
	            }

	            return new this(octets);
	        } catch (e) {
	            throw new Error('ipaddr: the address does not have IPv4 CIDR format');
	        }
	    };

	    // Tries to parse and validate a string with IPv4 address.
	    // Throws an error if it fails.
	    ipaddr.IPv4.parse = function (string) {
	        const parts = this.parser(string);

	        if (parts === null) {
	            throw new Error('ipaddr: string is not formatted like an IPv4 Address');
	        }

	        return new this(parts);
	    };

	    // Parses the string as an IPv4 Address with CIDR Notation.
	    ipaddr.IPv4.parseCIDR = function (string) {
	        let match;

	        if ((match = string.match(/^(.+)\/(\d+)$/))) {
	            const maskLength = parseInt(match[2]);
	            if (maskLength >= 0 && maskLength <= 32) {
	                const parsed = [this.parse(match[1]), maskLength];
	                Object.defineProperty(parsed, 'toString', {
	                    value: function () {
	                        return this.join('/');
	                    }
	                });
	                return parsed;
	            }
	        }

	        throw new Error('ipaddr: string is not formatted like an IPv4 CIDR range');
	    };

	    // Classful variants (like a.b, where a is an octet, and b is a 24-bit
	    // value representing last three octets; this corresponds to a class C
	    // address) are omitted due to classless nature of modern Internet.
	    ipaddr.IPv4.parser = function (string) {
	        let match, part, value;

	        // parseInt recognizes all that octal & hexadecimal weirdness for us
	        if ((match = string.match(ipv4Regexes.fourOctet))) {
	            return (function () {
	                const ref = match.slice(1, 6);
	                const results = [];

	                for (let i = 0; i < ref.length; i++) {
	                    part = ref[i];
	                    results.push(parseIntAuto(part));
	                }

	                return results;
	            })();
	        } else if ((match = string.match(ipv4Regexes.longValue))) {
	            value = parseIntAuto(match[1]);
	            if (value > 0xffffffff || value < 0) {
	                throw new Error('ipaddr: address outside defined range');
	            }

	            return ((function () {
	                const results = [];
	                let shift;

	                for (shift = 0; shift <= 24; shift += 8) {
	                    results.push((value >> shift) & 0xff);
	                }

	                return results;
	            })()).reverse();
	        } else if ((match = string.match(ipv4Regexes.twoOctet))) {
	            return (function () {
	                const ref = match.slice(1, 4);
	                const results = [];

	                value = parseIntAuto(ref[1]);
	                if (value > 0xffffff || value < 0) {
	                    throw new Error('ipaddr: address outside defined range');
	                }

	                results.push(parseIntAuto(ref[0]));
	                results.push((value >> 16) & 0xff);
	                results.push((value >>  8) & 0xff);
	                results.push( value        & 0xff);

	                return results;
	            })();
	        } else if ((match = string.match(ipv4Regexes.threeOctet))) {
	            return (function () {
	                const ref = match.slice(1, 5);
	                const results = [];

	                value = parseIntAuto(ref[2]);
	                if (value > 0xffff || value < 0) {
	                    throw new Error('ipaddr: address outside defined range');
	                }

	                results.push(parseIntAuto(ref[0]));
	                results.push(parseIntAuto(ref[1]));
	                results.push((value >> 8) & 0xff);
	                results.push( value       & 0xff);

	                return results;
	            })();
	        } else {
	            return null;
	        }
	    };

	    // A utility function to return subnet mask in IPv4 format given the prefix length
	    ipaddr.IPv4.subnetMaskFromPrefixLength = function (prefix) {
	        prefix = parseInt(prefix);
	        if (prefix < 0 || prefix > 32) {
	            throw new Error('ipaddr: invalid IPv4 prefix length');
	        }

	        const octets = [0, 0, 0, 0];
	        let j = 0;
	        const filledOctetCount = Math.floor(prefix / 8);

	        while (j < filledOctetCount) {
	            octets[j] = 255;
	            j++;
	        }

	        if (filledOctetCount < 4) {
	            octets[filledOctetCount] = Math.pow(2, prefix % 8) - 1 << 8 - (prefix % 8);
	        }

	        return new this(octets);
	    };

	    // An IPv6 address (RFC2460)
	    ipaddr.IPv6 = (function () {
	        // Constructs an IPv6 address from an array of eight 16 - bit parts
	        // or sixteen 8 - bit parts in network order(MSB first).
	        // Throws an error if the input is invalid.
	        function IPv6 (parts, zoneId) {
	            let i, part;

	            if (parts.length === 16) {
	                this.parts = [];
	                for (i = 0; i <= 14; i += 2) {
	                    this.parts.push((parts[i] << 8) | parts[i + 1]);
	                }
	            } else if (parts.length === 8) {
	                this.parts = parts;
	            } else {
	                throw new Error('ipaddr: ipv6 part count should be 8 or 16');
	            }

	            for (i = 0; i < this.parts.length; i++) {
	                part = this.parts[i];
	                if (!((0 <= part && part <= 0xffff))) {
	                    throw new Error('ipaddr: ipv6 part should fit in 16 bits');
	                }
	            }

	            if (zoneId) {
	                this.zoneId = zoneId;
	            }
	        }

	        // Special IPv6 ranges
	        IPv6.prototype.SpecialRanges = {
	            // RFC4291, here and after
	            unspecified: [new IPv6([0, 0, 0, 0, 0, 0, 0, 0]), 128],
	            linkLocal: [new IPv6([0xfe80, 0, 0, 0, 0, 0, 0, 0]), 10],
	            multicast: [new IPv6([0xff00, 0, 0, 0, 0, 0, 0, 0]), 8],
	            loopback: [new IPv6([0, 0, 0, 0, 0, 0, 0, 1]), 128],
	            uniqueLocal: [new IPv6([0xfc00, 0, 0, 0, 0, 0, 0, 0]), 7],
	            ipv4Mapped: [new IPv6([0, 0, 0, 0, 0, 0xffff, 0, 0]), 96],
	            // RFC6145
	            rfc6145: [new IPv6([0, 0, 0, 0, 0xffff, 0, 0, 0]), 96],
	            // RFC6052
	            rfc6052: [new IPv6([0x64, 0xff9b, 0, 0, 0, 0, 0, 0]), 96],
	            // RFC3056
	            '6to4': [new IPv6([0x2002, 0, 0, 0, 0, 0, 0, 0]), 16],
	            // RFC6052, RFC6146
	            teredo: [new IPv6([0x2001, 0, 0, 0, 0, 0, 0, 0]), 32],
	            // RFC4291
	            reserved: [[new IPv6([0x2001, 0xdb8, 0, 0, 0, 0, 0, 0]), 32]]
	        };

	        // Checks if this address is an IPv4-mapped IPv6 address.
	        IPv6.prototype.isIPv4MappedAddress = function () {
	            return this.range() === 'ipv4Mapped';
	        };

	        // The 'kind' method exists on both IPv4 and IPv6 classes.
	        IPv6.prototype.kind = function () {
	            return 'ipv6';
	        };

	        // Checks if this address matches other one within given CIDR range.
	        IPv6.prototype.match = function (other, cidrRange) {
	            let ref;

	            if (cidrRange === undefined) {
	                ref = other;
	                other = ref[0];
	                cidrRange = ref[1];
	            }

	            if (other.kind() !== 'ipv6') {
	                throw new Error('ipaddr: cannot match ipv6 address with non-ipv6 one');
	            }

	            return matchCIDR(this.parts, other.parts, 16, cidrRange);
	        };

	        // returns a number of leading ones in IPv6 address, making sure that
	        // the rest is a solid sequence of 0's (valid netmask)
	        // returns either the CIDR length or null if mask is not valid
	        IPv6.prototype.prefixLengthFromSubnetMask = function () {
	            let cidr = 0;
	            // non-zero encountered stop scanning for zeroes
	            let stop = false;
	            // number of zeroes in octet
	            const zerotable = {
	                0: 16,
	                32768: 15,
	                49152: 14,
	                57344: 13,
	                61440: 12,
	                63488: 11,
	                64512: 10,
	                65024: 9,
	                65280: 8,
	                65408: 7,
	                65472: 6,
	                65504: 5,
	                65520: 4,
	                65528: 3,
	                65532: 2,
	                65534: 1,
	                65535: 0
	            };
	            let part, zeros;

	            for (let i = 7; i >= 0; i -= 1) {
	                part = this.parts[i];
	                if (part in zerotable) {
	                    zeros = zerotable[part];
	                    if (stop && zeros !== 0) {
	                        return null;
	                    }

	                    if (zeros !== 16) {
	                        stop = true;
	                    }

	                    cidr += zeros;
	                } else {
	                    return null;
	                }
	            }

	            return 128 - cidr;
	        };


	        // Checks if the address corresponds to one of the special ranges.
	        IPv6.prototype.range = function () {
	            return ipaddr.subnetMatch(this, this.SpecialRanges);
	        };

	        // Returns an array of byte-sized values in network order (MSB first)
	        IPv6.prototype.toByteArray = function () {
	            let part;
	            const bytes = [];
	            const ref = this.parts;
	            for (let i = 0; i < ref.length; i++) {
	                part = ref[i];
	                bytes.push(part >> 8);
	                bytes.push(part & 0xff);
	            }

	            return bytes;
	        };

	        // Returns the address in expanded format with all zeroes included, like
	        // 2001:0db8:0008:0066:0000:0000:0000:0001
	        IPv6.prototype.toFixedLengthString = function () {
	            const addr = ((function () {
	                const results = [];
	                for (let i = 0; i < this.parts.length; i++) {
	                    results.push(padPart(this.parts[i].toString(16), 4));
	                }

	                return results;
	            }).call(this)).join(':');

	            let suffix = '';

	            if (this.zoneId) {
	                suffix = `%${this.zoneId}`;
	            }

	            return addr + suffix;
	        };

	        // Converts this address to IPv4 address if it is an IPv4-mapped IPv6 address.
	        // Throws an error otherwise.
	        IPv6.prototype.toIPv4Address = function () {
	            if (!this.isIPv4MappedAddress()) {
	                throw new Error('ipaddr: trying to convert a generic ipv6 address to ipv4');
	            }

	            const ref = this.parts.slice(-2);
	            const high = ref[0];
	            const low = ref[1];

	            return new ipaddr.IPv4([high >> 8, high & 0xff, low >> 8, low & 0xff]);
	        };

	        // Returns the address in expanded format with all zeroes included, like
	        // 2001:db8:8:66:0:0:0:1
	        //
	        // Deprecated: use toFixedLengthString() instead.
	        IPv6.prototype.toNormalizedString = function () {
	            const addr = ((function () {
	                const results = [];

	                for (let i = 0; i < this.parts.length; i++) {
	                    results.push(this.parts[i].toString(16));
	                }

	                return results;
	            }).call(this)).join(':');

	            let suffix = '';

	            if (this.zoneId) {
	                suffix = `%${this.zoneId}`;
	            }

	            return addr + suffix;
	        };

	        // Returns the address in compact, human-readable format like
	        // 2001:db8:8:66::1
	        // in line with RFC 5952 (see https://tools.ietf.org/html/rfc5952#section-4)
	        IPv6.prototype.toRFC5952String = function () {
	            const regex = /((^|:)(0(:|$)){2,})/g;
	            const string = this.toNormalizedString();
	            let bestMatchIndex = 0;
	            let bestMatchLength = -1;
	            let match;

	            while ((match = regex.exec(string))) {
	                if (match[0].length > bestMatchLength) {
	                    bestMatchIndex = match.index;
	                    bestMatchLength = match[0].length;
	                }
	            }

	            if (bestMatchLength < 0) {
	                return string;
	            }

	            return `${string.substring(0, bestMatchIndex)}::${string.substring(bestMatchIndex + bestMatchLength)}`;
	        };

	        // Returns the address in compact, human-readable format like
	        // 2001:db8:8:66::1
	        //
	        // Deprecated: use toRFC5952String() instead.
	        IPv6.prototype.toString = function () {
	            // Replace the first sequence of 1 or more '0' parts with '::'
	            return this.toNormalizedString().replace(/((^|:)(0(:|$))+)/, '::');
	        };

	        return IPv6;

	    })();

	    // A utility function to return broadcast address given the IPv6 interface and prefix length in CIDR notation
	    ipaddr.IPv6.broadcastAddressFromCIDR = function (string) {
	        try {
	            const cidr = this.parseCIDR(string);
	            const ipInterfaceOctets = cidr[0].toByteArray();
	            const subnetMaskOctets = this.subnetMaskFromPrefixLength(cidr[1]).toByteArray();
	            const octets = [];
	            let i = 0;
	            while (i < 16) {
	                // Broadcast address is bitwise OR between ip interface and inverted mask
	                octets.push(parseInt(ipInterfaceOctets[i], 10) | parseInt(subnetMaskOctets[i], 10) ^ 255);
	                i++;
	            }

	            return new this(octets);
	        } catch (e) {
	            throw new Error(`ipaddr: the address does not have IPv6 CIDR format (${e})`);
	        }
	    };

	    // Checks if a given string is formatted like IPv6 address.
	    ipaddr.IPv6.isIPv6 = function (string) {
	        return this.parser(string) !== null;
	    };

	    // Checks to see if string is a valid IPv6 Address
	    ipaddr.IPv6.isValid = function (string) {

	        // Since IPv6.isValid is always called first, this shortcut
	        // provides a substantial performance gain.
	        if (typeof string === 'string' && string.indexOf(':') === -1) {
	            return false;
	        }

	        try {
	            const addr = this.parser(string);
	            new this(addr.parts, addr.zoneId);
	            return true;
	        } catch (e) {
	            return false;
	        }
	    };

	    // A utility function to return network address given the IPv6 interface and prefix length in CIDR notation
	    ipaddr.IPv6.networkAddressFromCIDR = function (string) {
	        let cidr, i, ipInterfaceOctets, octets, subnetMaskOctets;

	        try {
	            cidr = this.parseCIDR(string);
	            ipInterfaceOctets = cidr[0].toByteArray();
	            subnetMaskOctets = this.subnetMaskFromPrefixLength(cidr[1]).toByteArray();
	            octets = [];
	            i = 0;
	            while (i < 16) {
	                // Network address is bitwise AND between ip interface and mask
	                octets.push(parseInt(ipInterfaceOctets[i], 10) & parseInt(subnetMaskOctets[i], 10));
	                i++;
	            }

	            return new this(octets);
	        } catch (e) {
	            throw new Error(`ipaddr: the address does not have IPv6 CIDR format (${e})`);
	        }
	    };

	    // Tries to parse and validate a string with IPv6 address.
	    // Throws an error if it fails.
	    ipaddr.IPv6.parse = function (string) {
	        const addr = this.parser(string);

	        if (addr.parts === null) {
	            throw new Error('ipaddr: string is not formatted like an IPv6 Address');
	        }

	        return new this(addr.parts, addr.zoneId);
	    };

	    ipaddr.IPv6.parseCIDR = function (string) {
	        let maskLength, match, parsed;

	        if ((match = string.match(/^(.+)\/(\d+)$/))) {
	            maskLength = parseInt(match[2]);
	            if (maskLength >= 0 && maskLength <= 128) {
	                parsed = [this.parse(match[1]), maskLength];
	                Object.defineProperty(parsed, 'toString', {
	                    value: function () {
	                        return this.join('/');
	                    }
	                });
	                return parsed;
	            }
	        }

	        throw new Error('ipaddr: string is not formatted like an IPv6 CIDR range');
	    };

	    // Parse an IPv6 address.
	    ipaddr.IPv6.parser = function (string) {
	        let addr, i, match, octet, octets, zoneId;

	        if ((match = string.match(ipv6Regexes.deprecatedTransitional))) {
	            return this.parser(`::ffff:${match[1]}`);
	        }
	        if (ipv6Regexes.native.test(string)) {
	            return expandIPv6(string, 8);
	        }
	        if ((match = string.match(ipv6Regexes.transitional))) {
	            zoneId = match[6] || '';
	            addr = expandIPv6(match[1].slice(0, -1) + zoneId, 6);
	            if (addr.parts) {
	                octets = [
	                    parseInt(match[2]),
	                    parseInt(match[3]),
	                    parseInt(match[4]),
	                    parseInt(match[5])
	                ];
	                for (i = 0; i < octets.length; i++) {
	                    octet = octets[i];
	                    if (!((0 <= octet && octet <= 255))) {
	                        return null;
	                    }
	                }

	                addr.parts.push(octets[0] << 8 | octets[1]);
	                addr.parts.push(octets[2] << 8 | octets[3]);
	                return {
	                    parts: addr.parts,
	                    zoneId: addr.zoneId
	                };
	            }
	        }

	        return null;
	    };

	    // A utility function to return subnet mask in IPv6 format given the prefix length
	    ipaddr.IPv6.subnetMaskFromPrefixLength = function (prefix) {
	        prefix = parseInt(prefix);
	        if (prefix < 0 || prefix > 128) {
	            throw new Error('ipaddr: invalid IPv6 prefix length');
	        }

	        const octets = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
	        let j = 0;
	        const filledOctetCount = Math.floor(prefix / 8);

	        while (j < filledOctetCount) {
	            octets[j] = 255;
	            j++;
	        }

	        if (filledOctetCount < 16) {
	            octets[filledOctetCount] = Math.pow(2, prefix % 8) - 1 << 8 - (prefix % 8);
	        }

	        return new this(octets);
	    };

	    // Try to parse an array in network order (MSB first) for IPv4 and IPv6
	    ipaddr.fromByteArray = function (bytes) {
	        const length = bytes.length;

	        if (length === 4) {
	            return new ipaddr.IPv4(bytes);
	        } else if (length === 16) {
	            return new ipaddr.IPv6(bytes);
	        } else {
	            throw new Error('ipaddr: the binary input is neither an IPv6 nor IPv4 address');
	        }
	    };

	    // Checks if the address is valid IP address
	    ipaddr.isValid = function (string) {
	        return ipaddr.IPv6.isValid(string) || ipaddr.IPv4.isValid(string);
	    };


	    // Attempts to parse an IP Address, first through IPv6 then IPv4.
	    // Throws an error if it could not be parsed.
	    ipaddr.parse = function (string) {
	        if (ipaddr.IPv6.isValid(string)) {
	            return ipaddr.IPv6.parse(string);
	        } else if (ipaddr.IPv4.isValid(string)) {
	            return ipaddr.IPv4.parse(string);
	        } else {
	            throw new Error('ipaddr: the address has neither IPv6 nor IPv4 format');
	        }
	    };

	    // Attempt to parse CIDR notation, first through IPv6 then IPv4.
	    // Throws an error if it could not be parsed.
	    ipaddr.parseCIDR = function (string) {
	        try {
	            return ipaddr.IPv6.parseCIDR(string);
	        } catch (e) {
	            try {
	                return ipaddr.IPv4.parseCIDR(string);
	            } catch (e2) {
	                throw new Error('ipaddr: the address has neither IPv6 nor IPv4 CIDR format');
	            }
	        }
	    };

	    // Parse an address and return plain IPv4 address if it is an IPv4-mapped address
	    ipaddr.process = function (string) {
	        const addr = this.parse(string);

	        if (addr.kind() === 'ipv6' && addr.isIPv4MappedAddress()) {
	            return addr.toIPv4Address();
	        } else {
	            return addr;
	        }
	    };

	    // An utility function to ease named range matching. See examples below.
	    // rangeList can contain both IPv4 and IPv6 subnet entries and will not throw errors
	    // on matching IPv4 addresses to IPv6 ranges or vice versa.
	    ipaddr.subnetMatch = function (address, rangeList, defaultName) {
	        let i, rangeName, rangeSubnets, subnet;

	        if (defaultName === undefined || defaultName === null) {
	            defaultName = 'unicast';
	        }

	        for (rangeName in rangeList) {
	            if (Object.prototype.hasOwnProperty.call(rangeList, rangeName)) {
	                rangeSubnets = rangeList[rangeName];
	                // ECMA5 Array.isArray isn't available everywhere
	                if (rangeSubnets[0] && !(rangeSubnets[0] instanceof Array)) {
	                    rangeSubnets = [rangeSubnets];
	                }

	                for (i = 0; i < rangeSubnets.length; i++) {
	                    subnet = rangeSubnets[i];
	                    if (address.kind() === subnet[0].kind() && address.match.apply(address, subnet)) {
	                        return rangeName;
	                    }
	                }
	            }
	        }

	        return defaultName;
	    };

	    // Export for both the CommonJS and browser-like environment
	    if (module.exports) {
	        module.exports = ipaddr;

	    } else {
	        root.ipaddr = ipaddr;
	    }

	}(commonjsGlobal));
} (ipaddr$1));

var ipaddr = ipaddrExports;

const { isValid: is_valid, parse } = ipaddr;
const PRIVATE_IP_RANGES = [
    '0.0.0.0/8',
    '10.0.0.0/8',
    '100.64.0.0/10',
    '127.0.0.0/8',
    '169.254.0.0/16',
    '172.16.0.0/12',
    '192.0.0.0/24',
    '192.0.0.0/29',
    '192.0.0.8/32',
    '192.0.0.9/32',
    '192.0.0.10/32',
    '192.0.0.170/32',
    '192.0.0.171/32',
    '192.0.2.0/24',
    '192.31.196.0/24',
    '192.52.193.0/24',
    '192.88.99.0/24',
    '192.168.0.0/16',
    '192.175.48.0/24',
    '198.18.0.0/15',
    '198.51.100.0/24',
    '203.0.113.0/24',
    '240.0.0.0/4',
    '255.255.255.255/32'
];
const NETMASK_RANGES = PRIVATE_IP_RANGES.map(ip_range => new Netmask_1(ip_range));
function ipv4_check(ip_addr) {
    for (let r of NETMASK_RANGES) {
        if (r.contains(ip_addr))
            return true;
    }
    return false;
}
function ipv6_check(ip_addr) {
    return /^::$/.test(ip_addr) ||
        /^::1$/.test(ip_addr) ||
        /^::f{4}:([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ip_addr) ||
        /^::f{4}:0.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ip_addr) ||
        /^64:ff9b::([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ip_addr) ||
        /^100::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^2001::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^2001:2[0-9a-fA-F]:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^2001:db8:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^2002:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^f[c-d]([0-9a-fA-F]{2,2}):/i.test(ip_addr) ||
        /^fe[8-9a-bA-B][0-9a-fA-F]:/i.test(ip_addr) ||
        /^ff([0-9a-fA-F]{2,2}):/i.test(ip_addr);
}
var is_ip_private = (ip) => {
    if (is_valid(ip)) {
        const parsed = parse(ip);
        if (parsed.kind() === 'ipv4')
            return ipv4_check(parsed.toNormalizedString());
        else if (parsed.kind() === 'ipv6')
            return ipv6_check(ip);
    }
    else if (isIP(ip) && ipRegex.v6().test(ip))
        return ipv6_check(ip);
    return undefined;
};

/**
 * Check if a given multiaddr has a private address.
 */
function isPrivate(ma) {
    const { address } = ma.nodeAddress();
    return Boolean(is_ip_private(address));
}

/**
 * @packageDocumentation
 *
 * Provides strategies to sort a list of multiaddrs.
 *
 * @example
 *
 * ```typescript
 * import { publicAddressesFirst } from '@libp2p/utils/address-sort'
 * import { multiaddr } from '@multformats/multiaddr'
 *
 *
 * const addresses = [
 *   multiaddr('/ip4/127.0.0.1/tcp/9000'),
 *   multiaddr('/ip4/82.41.53.1/tcp/9000')
 * ].sort(publicAddressesFirst)
 *
 * console.info(addresses)
 * // ['/ip4/82.41.53.1/tcp/9000', '/ip4/127.0.0.1/tcp/9000']
 * ```
 */
/**
 * Compare function for array.sort().
 * This sort aims to move the private addresses to the end of the array.
 * In case of equality, a certified address will come first.
 */
function publicAddressesFirst(a, b) {
    const isAPrivate = isPrivate(a.multiaddr);
    const isBPrivate = isPrivate(b.multiaddr);
    if (isAPrivate && !isBPrivate) {
        return 1;
    }
    else if (!isAPrivate && isBPrivate) {
        return -1;
    }
    // Check certified?
    if (a.isCertified && !b.isCertified) {
        return -1;
    }
    else if (!a.isCertified && b.isCertified) {
        return 1;
    }
    return 0;
}

const log$p = logger$2('libp2p:auto-relay');
const noop$2 = () => { };
class AutoRelay {
    constructor(components, init) {
        this.components = components;
        this.addressSorter = init.addressSorter ?? publicAddressesFirst;
        this.maxListeners = init.maxListeners ?? 1;
        this.listenRelays = new Set();
        this.onError = init.onError ?? noop$2;
        this._onProtocolChange = this._onProtocolChange.bind(this);
        this._onPeerDisconnected = this._onPeerDisconnected.bind(this);
        this.components.peerStore.addEventListener('change:protocols', (evt) => {
            void this._onProtocolChange(evt).catch(err => {
                log$p.error(err);
            });
        });
        this.components.connectionManager.addEventListener('peer:disconnect', this._onPeerDisconnected);
    }
    /**
     * Check if a peer supports the relay protocol.
     * If the protocol is not supported, check if it was supported before and remove it as a listen relay.
     * If the protocol is supported, check if the peer supports **HOP** and add it as a listener if
     * inside the threshold.
     */
    async _onProtocolChange(evt) {
        const { peerId, protocols } = evt.detail;
        const id = peerId.toString();
        // Check if it has the protocol
        const hasProtocol = protocols.find(protocol => protocol === RELAY_CODEC);
        // If no protocol, check if we were keeping the peer before as a listenRelay
        if (hasProtocol == null) {
            if (this.listenRelays.has(id)) {
                await this._removeListenRelay(id);
            }
            return;
        }
        if (this.listenRelays.has(id)) {
            return;
        }
        // If protocol, check if can hop, store info in the metadataBook and listen on it
        try {
            const connections = this.components.connectionManager.getConnections(peerId);
            if (connections.length === 0) {
                return;
            }
            const connection = connections[0];
            // Do not hop on a relayed connection
            if (connection.remoteAddr.protoCodes().includes(CIRCUIT_PROTO_CODE)) {
                log$p(`relayed connection to ${id} will not be used to hop on`);
                return;
            }
            const supportsHop = await canHop({ connection });
            if (supportsHop) {
                await this.components.peerStore.metadataBook.setValue(peerId, HOP_METADATA_KEY, fromString$2(HOP_METADATA_VALUE));
                await this._addListenRelay(connection, id);
            }
        }
        catch (err) {
            this.onError(err);
        }
    }
    /**
     * Peer disconnects
     */
    _onPeerDisconnected(evt) {
        const connection = evt.detail;
        const peerId = connection.remotePeer;
        const id = peerId.toString();
        // Not listening on this relay
        if (!this.listenRelays.has(id)) {
            return;
        }
        this._removeListenRelay(id).catch(err => {
            log$p.error(err);
        });
    }
    /**
     * Attempt to listen on the given relay connection
     */
    async _addListenRelay(connection, id) {
        try {
            // Check if already listening on enough relays
            if (this.listenRelays.size >= this.maxListeners) {
                return;
            }
            // Get peer known addresses and sort them with public addresses first
            const remoteAddrs = await pipe(await this.components.peerStore.addressBook.get(connection.remotePeer), (source) => sort(source, this.addressSorter), async (source) => await all(source));
            // Attempt to listen on relay
            const result = await Promise.all(remoteAddrs.map(async (addr) => {
                try {
                    let multiaddr = addr.multiaddr;
                    if (multiaddr.getPeerId() == null) {
                        multiaddr = multiaddr.encapsulate(`/p2p/${connection.remotePeer.toString()}`);
                    }
                    multiaddr = multiaddr.encapsulate('/p2p-circuit');
                    // Announce multiaddrs will update on listen success by TransportManager event being triggered
                    await this.components.transportManager.listen([multiaddr]);
                    return true;
                }
                catch (err) {
                    log$p.error('error listening on circuit address', err);
                    this.onError(err);
                }
                return false;
            }));
            if (result.includes(true)) {
                this.listenRelays.add(id);
            }
        }
        catch (err) {
            this.onError(err);
            this.listenRelays.delete(id);
        }
    }
    /**
     * Remove listen relay
     */
    async _removeListenRelay(id) {
        if (this.listenRelays.delete(id)) {
            // TODO: this should be responsibility of the connMgr
            await this._listenOnAvailableHopRelays([id]);
        }
    }
    /**
     * Try to listen on available hop relay connections.
     * The following order will happen while we do not have enough relays.
     * 1. Check the metadata store for known relays, try to listen on the ones we are already connected.
     * 2. Dial and try to listen on the peers we know that support hop but are not connected.
     * 3. Search the network.
     */
    async _listenOnAvailableHopRelays(peersToIgnore = []) {
        // TODO: The peer redial issue on disconnect should be handled by connection gating
        // Check if already listening on enough relays
        if (this.listenRelays.size >= this.maxListeners) {
            return;
        }
        const knownHopsToDial = [];
        const peers = await this.components.peerStore.all();
        // Check if we have known hop peers to use and attempt to listen on the already connected
        for (const { id, metadata } of peers) {
            const idStr = id.toString();
            // Continue to next if listening on this or peer to ignore
            if (this.listenRelays.has(idStr)) {
                continue;
            }
            if (peersToIgnore.includes(idStr)) {
                continue;
            }
            const supportsHop = metadata.get(HOP_METADATA_KEY);
            // Continue to next if it does not support Hop
            if ((supportsHop == null) || toString$7(supportsHop) !== HOP_METADATA_VALUE) {
                continue;
            }
            const connections = this.components.connectionManager.getConnections(id);
            // If not connected, store for possible later use.
            if (connections.length === 0) {
                knownHopsToDial.push(id);
                continue;
            }
            await this._addListenRelay(connections[0], idStr);
            // Check if already listening on enough relays
            if (this.listenRelays.size >= this.maxListeners) {
                return;
            }
        }
        // Try to listen on known peers that are not connected
        for (const peerId of knownHopsToDial) {
            await this._tryToListenOnRelay(peerId);
            // Check if already listening on enough relays
            if (this.listenRelays.size >= this.maxListeners) {
                return;
            }
        }
        // Try to find relays to hop on the network
        try {
            const cid = await namespaceToCid(RELAY_RENDEZVOUS_NS);
            for await (const provider of this.components.contentRouting.findProviders(cid)) {
                if (provider.multiaddrs.length === 0) {
                    continue;
                }
                const peerId = provider.id;
                if (peerId.equals(this.components.peerId)) {
                    // Skip the provider if it's us as dialing will fail
                    continue;
                }
                await this.components.peerStore.addressBook.add(peerId, provider.multiaddrs);
                await this._tryToListenOnRelay(peerId);
                // Check if already listening on enough relays
                if (this.listenRelays.size >= this.maxListeners) {
                    return;
                }
            }
        }
        catch (err) {
            this.onError(err);
        }
    }
    async _tryToListenOnRelay(peerId) {
        try {
            const connection = await this.components.connectionManager.openConnection(peerId);
            await this._addListenRelay(connection, peerId.toString());
        }
        catch (err) {
            log$p.error('Could not use %p as relay', peerId, err);
            this.onError(err, `could not connect and listen on known hop relay ${peerId.toString()}`);
        }
    }
}

const log$o = logger$2('libp2p:relay');
class Relay {
    /**
     * Creates an instance of Relay
     */
    constructor(components, init) {
        this.components = components;
        // Create autoRelay if enabled
        this.autoRelay = init.autoRelay?.enabled !== false
            ? new AutoRelay(components, {
                addressSorter: init.addressSorter,
                ...init.autoRelay
            })
            : undefined;
        this.started = false;
        this.init = init;
        this._advertiseService = this._advertiseService.bind(this);
    }
    isStarted() {
        return this.started;
    }
    /**
     * Start Relay service
     */
    async start() {
        // Advertise service if HOP enabled
        if (this.init.hop.enabled !== false && this.init.advertise.enabled !== false) {
            this.timeout = src.setDelayedInterval(this._advertiseService, this.init.advertise.ttl, this.init.advertise.bootDelay);
        }
        this.started = true;
    }
    /**
     * Stop Relay service
     */
    async stop() {
        if (this.timeout != null) {
            src.clearDelayedInterval(this.timeout);
        }
        this.started = false;
    }
    /**
     * Advertise hop relay service in the network.
     */
    async _advertiseService() {
        try {
            const cid = await namespaceToCid(RELAY_RENDEZVOUS_NS);
            await this.components.contentRouting.provide(cid);
        }
        catch (err) {
            if (err.code === codes$1.ERR_NO_ROUTERS_AVAILABLE) {
                log$o.error('a content router, such as a DHT, must be provided in order to advertise the relay service', err);
                // Stop the advertise
                await this.stop();
            }
            else {
                log$o.error(err);
            }
        }
    }
}

function isHighSurrogate$1(codePoint) {
  return codePoint >= 0xd800 && codePoint <= 0xdbff;
}

function isLowSurrogate$1(codePoint) {
  return codePoint >= 0xdc00 && codePoint <= 0xdfff;
}

// Truncate string by size in bytes
var truncate$2 = function truncate(getLength, string, byteLength) {
  if (typeof string !== "string") {
    throw new Error("Input must be string");
  }

  var charLength = string.length;
  var curByteLength = 0;
  var codePoint;
  var segment;

  for (var i = 0; i < charLength; i += 1) {
    codePoint = string.charCodeAt(i);
    segment = string[i];

    if (isHighSurrogate$1(codePoint) && isLowSurrogate$1(string.charCodeAt(i + 1))) {
      i += 1;
      segment += string[i];
    }

    curByteLength += getLength(segment);

    if (curByteLength === byteLength) {
      return string.slice(0, i + 1);
    }
    else if (curByteLength > byteLength) {
      return string.slice(0, i - segment.length + 1);
    }
  }

  return string;
};

function isHighSurrogate(codePoint) {
  return codePoint >= 0xd800 && codePoint <= 0xdbff;
}

function isLowSurrogate(codePoint) {
  return codePoint >= 0xdc00 && codePoint <= 0xdfff;
}

// Truncate string by size in bytes
var browser$1 = function getByteLength(string) {
  if (typeof string !== "string") {
    throw new Error("Input must be string");
  }

  var charLength = string.length;
  var byteLength = 0;
  var codePoint = null;
  var prevCodePoint = null;
  for (var i = 0; i < charLength; i++) {
    codePoint = string.charCodeAt(i);
    // handle 4-byte non-BMP chars
    // low surrogate
    if (isLowSurrogate(codePoint)) {
      // when parsing previous hi-surrogate, 3 is added to byteLength
      if (prevCodePoint != null && isHighSurrogate(prevCodePoint)) {
        byteLength += 1;
      }
      else {
        byteLength += 3;
      }
    }
    else if (codePoint <= 0x7f ) {
      byteLength += 1;
    }
    else if (codePoint >= 0x80 && codePoint <= 0x7ff) {
      byteLength += 2;
    }
    else if (codePoint >= 0x800 && codePoint <= 0xffff) {
      byteLength += 3;
    }
    prevCodePoint = codePoint;
  }

  return byteLength;
};

var truncate$1 = truncate$2;
var getLength = browser$1;
var browser = truncate$1.bind(null, getLength);

/*jshint node:true*/

/**
 * Replaces characters in strings that are illegal/unsafe for filenames.
 * Unsafe characters are either removed or replaced by a substitute set
 * in the optional `options` object.
 *
 * Illegal Characters on Various Operating Systems
 * / ? < > \ : * | "
 * https://kb.acronis.com/content/39790
 *
 * Unicode Control codes
 * C0 0x00-0x1f & C1 (0x80-0x9f)
 * http://en.wikipedia.org/wiki/C0_and_C1_control_codes
 *
 * Reserved filenames on Unix-based systems (".", "..")
 * Reserved filenames in Windows ("CON", "PRN", "AUX", "NUL", "COM1",
 * "COM2", "COM3", "COM4", "COM5", "COM6", "COM7", "COM8", "COM9",
 * "LPT1", "LPT2", "LPT3", "LPT4", "LPT5", "LPT6", "LPT7", "LPT8", and
 * "LPT9") case-insesitively and with or without filename extensions.
 *
 * Capped at 255 characters in length.
 * http://unix.stackexchange.com/questions/32795/what-is-the-maximum-allowed-filename-and-folder-size-with-ecryptfs
 *
 * @param  {String} input   Original filename
 * @param  {Object} options {replacement: String | Function }
 * @return {String}         Sanitized filename
 */

var truncate = browser;

var illegalRe = /[\/\?<>\\:\*\|"]/g;
var controlRe = /[\x00-\x1f\x80-\x9f]/g;
var reservedRe = /^\.+$/;
var windowsReservedRe = /^(con|prn|aux|nul|com[0-9]|lpt[0-9])(\..*)?$/i;
var windowsTrailingRe = /[\. ]+$/;

function sanitize(input, replacement) {
  if (typeof input !== 'string') {
    throw new Error('Input must be string');
  }
  var sanitized = input
    .replace(illegalRe, replacement)
    .replace(controlRe, replacement)
    .replace(reservedRe, replacement)
    .replace(windowsReservedRe, replacement)
    .replace(windowsTrailingRe, replacement);
  return truncate(sanitized, 255);
}

var sanitizeFilename = function (input, options) {
  var replacement = (options && options.replacement) || '';
  var output = sanitize(input, replacement);
  if (replacement === '') {
    return output;
  }
  return sanitize(output, '');
};

/**
 * Javascript implementation of ASN.1 validators for PKCS#7 v1.5.
 *
 * @author Dave Longley
 * @author Stefan Siegl
 *
 * Copyright (c) 2012-2015 Digital Bazaar, Inc.
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 *
 * The ASN.1 representation of PKCS#7 is as follows
 * (see RFC #2315 for details, http://www.ietf.org/rfc/rfc2315.txt):
 *
 * A PKCS#7 message consists of a ContentInfo on root level, which may
 * contain any number of further ContentInfo nested into it.
 *
 * ContentInfo ::= SEQUENCE {
 *   contentType                ContentType,
 *   content               [0]  EXPLICIT ANY DEFINED BY contentType OPTIONAL
 * }
 *
 * ContentType ::= OBJECT IDENTIFIER
 *
 * EnvelopedData ::= SEQUENCE {
 *   version                    Version,
 *   recipientInfos             RecipientInfos,
 *   encryptedContentInfo       EncryptedContentInfo
 * }
 *
 * EncryptedData ::= SEQUENCE {
 *   version                    Version,
 *   encryptedContentInfo       EncryptedContentInfo
 * }
 *
 * id-signedData OBJECT IDENTIFIER ::= { iso(1) member-body(2)
 *   us(840) rsadsi(113549) pkcs(1) pkcs7(7) 2 }
 *
 * SignedData ::= SEQUENCE {
 *   version           INTEGER,
 *   digestAlgorithms  DigestAlgorithmIdentifiers,
 *   contentInfo       ContentInfo,
 *   certificates      [0] IMPLICIT Certificates OPTIONAL,
 *   crls              [1] IMPLICIT CertificateRevocationLists OPTIONAL,
 *   signerInfos       SignerInfos
 * }
 *
 * SignerInfos ::= SET OF SignerInfo
 *
 * SignerInfo ::= SEQUENCE {
 *   version                    Version,
 *   issuerAndSerialNumber      IssuerAndSerialNumber,
 *   digestAlgorithm            DigestAlgorithmIdentifier,
 *   authenticatedAttributes    [0] IMPLICIT Attributes OPTIONAL,
 *   digestEncryptionAlgorithm  DigestEncryptionAlgorithmIdentifier,
 *   encryptedDigest            EncryptedDigest,
 *   unauthenticatedAttributes  [1] IMPLICIT Attributes OPTIONAL
 * }
 *
 * EncryptedDigest ::= OCTET STRING
 *
 * Attributes ::= SET OF Attribute
 *
 * Attribute ::= SEQUENCE {
 *   attrType    OBJECT IDENTIFIER,
 *   attrValues  SET OF AttributeValue
 * }
 *
 * AttributeValue ::= ANY
 *
 * Version ::= INTEGER
 *
 * RecipientInfos ::= SET OF RecipientInfo
 *
 * EncryptedContentInfo ::= SEQUENCE {
 *   contentType                 ContentType,
 *   contentEncryptionAlgorithm  ContentEncryptionAlgorithmIdentifier,
 *   encryptedContent       [0]  IMPLICIT EncryptedContent OPTIONAL
 * }
 *
 * ContentEncryptionAlgorithmIdentifier ::= AlgorithmIdentifier
 *
 * The AlgorithmIdentifier contains an Object Identifier (OID) and parameters
 * for the algorithm, if any. In the case of AES and DES3, there is only one,
 * the IV.
 *
 * AlgorithmIdentifer ::= SEQUENCE {
 *    algorithm OBJECT IDENTIFIER,
 *    parameters ANY DEFINED BY algorithm OPTIONAL
 * }
 *
 * EncryptedContent ::= OCTET STRING
 *
 * RecipientInfo ::= SEQUENCE {
 *   version                     Version,
 *   issuerAndSerialNumber       IssuerAndSerialNumber,
 *   keyEncryptionAlgorithm      KeyEncryptionAlgorithmIdentifier,
 *   encryptedKey                EncryptedKey
 * }
 *
 * IssuerAndSerialNumber ::= SEQUENCE {
 *   issuer                      Name,
 *   serialNumber                CertificateSerialNumber
 * }
 *
 * CertificateSerialNumber ::= INTEGER
 *
 * KeyEncryptionAlgorithmIdentifier ::= AlgorithmIdentifier
 *
 * EncryptedKey ::= OCTET STRING
 */

var forge$5 = forge$s;



// shortcut for ASN.1 API
var asn1$2 = forge$5.asn1;

// shortcut for PKCS#7 API
var p7v = forge$5.pkcs7asn1 = forge$5.pkcs7asn1 || {};
forge$5.pkcs7 = forge$5.pkcs7 || {};
forge$5.pkcs7.asn1 = p7v;

var contentInfoValidator = {
  name: 'ContentInfo',
  tagClass: asn1$2.Class.UNIVERSAL,
  type: asn1$2.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'ContentInfo.ContentType',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.OID,
    constructed: false,
    capture: 'contentType'
  }, {
    name: 'ContentInfo.content',
    tagClass: asn1$2.Class.CONTEXT_SPECIFIC,
    type: 0,
    constructed: true,
    optional: true,
    captureAsn1: 'content'
  }]
};
p7v.contentInfoValidator = contentInfoValidator;

var encryptedContentInfoValidator = {
  name: 'EncryptedContentInfo',
  tagClass: asn1$2.Class.UNIVERSAL,
  type: asn1$2.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'EncryptedContentInfo.contentType',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.OID,
    constructed: false,
    capture: 'contentType'
  }, {
    name: 'EncryptedContentInfo.contentEncryptionAlgorithm',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'EncryptedContentInfo.contentEncryptionAlgorithm.algorithm',
      tagClass: asn1$2.Class.UNIVERSAL,
      type: asn1$2.Type.OID,
      constructed: false,
      capture: 'encAlgorithm'
    }, {
      name: 'EncryptedContentInfo.contentEncryptionAlgorithm.parameter',
      tagClass: asn1$2.Class.UNIVERSAL,
      captureAsn1: 'encParameter'
    }]
  }, {
    name: 'EncryptedContentInfo.encryptedContent',
    tagClass: asn1$2.Class.CONTEXT_SPECIFIC,
    type: 0,
    /* The PKCS#7 structure output by OpenSSL somewhat differs from what
     * other implementations do generate.
     *
     * OpenSSL generates a structure like this:
     * SEQUENCE {
     *    ...
     *    [0]
     *       26 DA 67 D2 17 9C 45 3C B1 2A A8 59 2F 29 33 38
     *       C3 C3 DF 86 71 74 7A 19 9F 40 D0 29 BE 85 90 45
     *       ...
     * }
     *
     * Whereas other implementations (and this PKCS#7 module) generate:
     * SEQUENCE {
     *    ...
     *    [0] {
     *       OCTET STRING
     *          26 DA 67 D2 17 9C 45 3C B1 2A A8 59 2F 29 33 38
     *          C3 C3 DF 86 71 74 7A 19 9F 40 D0 29 BE 85 90 45
     *          ...
     *    }
     * }
     *
     * In order to support both, we just capture the context specific
     * field here.  The OCTET STRING bit is removed below.
     */
    capture: 'encryptedContent',
    captureAsn1: 'encryptedContentAsn1'
  }]
};

p7v.envelopedDataValidator = {
  name: 'EnvelopedData',
  tagClass: asn1$2.Class.UNIVERSAL,
  type: asn1$2.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'EnvelopedData.Version',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.INTEGER,
    constructed: false,
    capture: 'version'
  }, {
    name: 'EnvelopedData.RecipientInfos',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SET,
    constructed: true,
    captureAsn1: 'recipientInfos'
  }].concat(encryptedContentInfoValidator)
};

p7v.encryptedDataValidator = {
  name: 'EncryptedData',
  tagClass: asn1$2.Class.UNIVERSAL,
  type: asn1$2.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'EncryptedData.Version',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.INTEGER,
    constructed: false,
    capture: 'version'
  }].concat(encryptedContentInfoValidator)
};

var signerValidator = {
  name: 'SignerInfo',
  tagClass: asn1$2.Class.UNIVERSAL,
  type: asn1$2.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'SignerInfo.version',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.INTEGER,
    constructed: false
  }, {
    name: 'SignerInfo.issuerAndSerialNumber',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'SignerInfo.issuerAndSerialNumber.issuer',
      tagClass: asn1$2.Class.UNIVERSAL,
      type: asn1$2.Type.SEQUENCE,
      constructed: true,
      captureAsn1: 'issuer'
    }, {
      name: 'SignerInfo.issuerAndSerialNumber.serialNumber',
      tagClass: asn1$2.Class.UNIVERSAL,
      type: asn1$2.Type.INTEGER,
      constructed: false,
      capture: 'serial'
    }]
  }, {
    name: 'SignerInfo.digestAlgorithm',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'SignerInfo.digestAlgorithm.algorithm',
      tagClass: asn1$2.Class.UNIVERSAL,
      type: asn1$2.Type.OID,
      constructed: false,
      capture: 'digestAlgorithm'
    }, {
      name: 'SignerInfo.digestAlgorithm.parameter',
      tagClass: asn1$2.Class.UNIVERSAL,
      constructed: false,
      captureAsn1: 'digestParameter',
      optional: true
    }]
  }, {
    name: 'SignerInfo.authenticatedAttributes',
    tagClass: asn1$2.Class.CONTEXT_SPECIFIC,
    type: 0,
    constructed: true,
    optional: true,
    capture: 'authenticatedAttributes'
  }, {
    name: 'SignerInfo.digestEncryptionAlgorithm',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SEQUENCE,
    constructed: true,
    capture: 'signatureAlgorithm'
  }, {
    name: 'SignerInfo.encryptedDigest',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.OCTETSTRING,
    constructed: false,
    capture: 'signature'
  }, {
    name: 'SignerInfo.unauthenticatedAttributes',
    tagClass: asn1$2.Class.CONTEXT_SPECIFIC,
    type: 1,
    constructed: true,
    optional: true,
    capture: 'unauthenticatedAttributes'
  }]
};

p7v.signedDataValidator = {
  name: 'SignedData',
  tagClass: asn1$2.Class.UNIVERSAL,
  type: asn1$2.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'SignedData.Version',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.INTEGER,
    constructed: false,
    capture: 'version'
  }, {
    name: 'SignedData.DigestAlgorithms',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SET,
    constructed: true,
    captureAsn1: 'digestAlgorithms'
  },
  contentInfoValidator,
  {
    name: 'SignedData.Certificates',
    tagClass: asn1$2.Class.CONTEXT_SPECIFIC,
    type: 0,
    optional: true,
    captureAsn1: 'certificates'
  }, {
    name: 'SignedData.CertificateRevocationLists',
    tagClass: asn1$2.Class.CONTEXT_SPECIFIC,
    type: 1,
    optional: true,
    captureAsn1: 'crls'
  }, {
    name: 'SignedData.SignerInfos',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SET,
    capture: 'signerInfos',
    optional: true,
    value: [signerValidator]
  }]
};

p7v.recipientInfoValidator = {
  name: 'RecipientInfo',
  tagClass: asn1$2.Class.UNIVERSAL,
  type: asn1$2.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'RecipientInfo.version',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.INTEGER,
    constructed: false,
    capture: 'version'
  }, {
    name: 'RecipientInfo.issuerAndSerial',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'RecipientInfo.issuerAndSerial.issuer',
      tagClass: asn1$2.Class.UNIVERSAL,
      type: asn1$2.Type.SEQUENCE,
      constructed: true,
      captureAsn1: 'issuer'
    }, {
      name: 'RecipientInfo.issuerAndSerial.serialNumber',
      tagClass: asn1$2.Class.UNIVERSAL,
      type: asn1$2.Type.INTEGER,
      constructed: false,
      capture: 'serial'
    }]
  }, {
    name: 'RecipientInfo.keyEncryptionAlgorithm',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'RecipientInfo.keyEncryptionAlgorithm.algorithm',
      tagClass: asn1$2.Class.UNIVERSAL,
      type: asn1$2.Type.OID,
      constructed: false,
      capture: 'encAlgorithm'
    }, {
      name: 'RecipientInfo.keyEncryptionAlgorithm.parameter',
      tagClass: asn1$2.Class.UNIVERSAL,
      constructed: false,
      captureAsn1: 'encParameter',
      optional: true
    }]
  }, {
    name: 'RecipientInfo.encryptedKey',
    tagClass: asn1$2.Class.UNIVERSAL,
    type: asn1$2.Type.OCTETSTRING,
    constructed: false,
    capture: 'encKey'
  }]
};

/**
 * Javascript implementation of mask generation function MGF1.
 *
 * @author Stefan Siegl
 * @author Dave Longley
 *
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 * Copyright (c) 2014 Digital Bazaar, Inc.
 */

var forge$4 = forge$s;


forge$4.mgf = forge$4.mgf || {};
var mgf1 = forge$4.mgf.mgf1 = forge$4.mgf1 = forge$4.mgf1 || {};

/**
 * Creates a MGF1 mask generation function object.
 *
 * @param md the message digest API to use (eg: forge.md.sha1.create()).
 *
 * @return a mask generation function object.
 */
mgf1.create = function(md) {
  var mgf = {
    /**
     * Generate mask of specified length.
     *
     * @param {String} seed The seed for mask generation.
     * @param maskLen Number of bytes to generate.
     * @return {String} The generated mask.
     */
    generate: function(seed, maskLen) {
      /* 2. Let T be the empty octet string. */
      var t = new forge$4.util.ByteBuffer();

      /* 3. For counter from 0 to ceil(maskLen / hLen), do the following: */
      var len = Math.ceil(maskLen / md.digestLength);
      for(var i = 0; i < len; i++) {
        /* a. Convert counter to an octet string C of length 4 octets */
        var c = new forge$4.util.ByteBuffer();
        c.putInt32(i);

        /* b. Concatenate the hash of the seed mgfSeed and C to the octet
         * string T: */
        md.start();
        md.update(seed + c.getBytes());
        t.putBuffer(md.digest());
      }

      /* Output the leading maskLen octets of T as the octet string mask. */
      t.truncate(t.length() - maskLen);
      return t.getBytes();
    }
  };

  return mgf;
};

/**
 * Node.js module for Forge mask generation functions.
 *
 * @author Stefan Siegl
 *
 * Copyright 2012 Stefan Siegl <stesie@brokenpipe.de>
 */

var forge$3 = forge$s;


forge$3.mgf = forge$3.mgf || {};
forge$3.mgf.mgf1 = forge$3.mgf1;

/**
 * Javascript implementation of PKCS#1 PSS signature padding.
 *
 * @author Stefan Siegl
 *
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 */

var forge$2 = forge$s;



// shortcut for PSS API
var pss = forge$2.pss = forge$2.pss || {};

/**
 * Creates a PSS signature scheme object.
 *
 * There are several ways to provide a salt for encoding:
 *
 * 1. Specify the saltLength only and the built-in PRNG will generate it.
 * 2. Specify the saltLength and a custom PRNG with 'getBytesSync' defined that
 *   will be used.
 * 3. Specify the salt itself as a forge.util.ByteBuffer.
 *
 * @param options the options to use:
 *          md the message digest object to use, a forge md instance.
 *          mgf the mask generation function to use, a forge mgf instance.
 *          [saltLength] the length of the salt in octets.
 *          [prng] the pseudo-random number generator to use to produce a salt.
 *          [salt] the salt to use when encoding.
 *
 * @return a signature scheme object.
 */
pss.create = function(options) {
  // backwards compatibility w/legacy args: hash, mgf, sLen
  if(arguments.length === 3) {
    options = {
      md: arguments[0],
      mgf: arguments[1],
      saltLength: arguments[2]
    };
  }

  var hash = options.md;
  var mgf = options.mgf;
  var hLen = hash.digestLength;

  var salt_ = options.salt || null;
  if(typeof salt_ === 'string') {
    // assume binary-encoded string
    salt_ = forge$2.util.createBuffer(salt_);
  }

  var sLen;
  if('saltLength' in options) {
    sLen = options.saltLength;
  } else if(salt_ !== null) {
    sLen = salt_.length();
  } else {
    throw new Error('Salt length not specified or specific salt not given.');
  }

  if(salt_ !== null && salt_.length() !== sLen) {
    throw new Error('Given salt length does not match length of given salt.');
  }

  var prng = options.prng || forge$2.random;

  var pssobj = {};

  /**
   * Encodes a PSS signature.
   *
   * This function implements EMSA-PSS-ENCODE as per RFC 3447, section 9.1.1.
   *
   * @param md the message digest object with the hash to sign.
   * @param modsBits the length of the RSA modulus in bits.
   *
   * @return the encoded message as a binary-encoded string of length
   *           ceil((modBits - 1) / 8).
   */
  pssobj.encode = function(md, modBits) {
    var i;
    var emBits = modBits - 1;
    var emLen = Math.ceil(emBits / 8);

    /* 2. Let mHash = Hash(M), an octet string of length hLen. */
    var mHash = md.digest().getBytes();

    /* 3. If emLen < hLen + sLen + 2, output "encoding error" and stop. */
    if(emLen < hLen + sLen + 2) {
      throw new Error('Message is too long to encrypt.');
    }

    /* 4. Generate a random octet string salt of length sLen; if sLen = 0,
     *    then salt is the empty string. */
    var salt;
    if(salt_ === null) {
      salt = prng.getBytesSync(sLen);
    } else {
      salt = salt_.bytes();
    }

    /* 5. Let M' = (0x)00 00 00 00 00 00 00 00 || mHash || salt; */
    var m_ = new forge$2.util.ByteBuffer();
    m_.fillWithByte(0, 8);
    m_.putBytes(mHash);
    m_.putBytes(salt);

    /* 6. Let H = Hash(M'), an octet string of length hLen. */
    hash.start();
    hash.update(m_.getBytes());
    var h = hash.digest().getBytes();

    /* 7. Generate an octet string PS consisting of emLen - sLen - hLen - 2
     *    zero octets.  The length of PS may be 0. */
    var ps = new forge$2.util.ByteBuffer();
    ps.fillWithByte(0, emLen - sLen - hLen - 2);

    /* 8. Let DB = PS || 0x01 || salt; DB is an octet string of length
     *    emLen - hLen - 1. */
    ps.putByte(0x01);
    ps.putBytes(salt);
    var db = ps.getBytes();

    /* 9. Let dbMask = MGF(H, emLen - hLen - 1). */
    var maskLen = emLen - hLen - 1;
    var dbMask = mgf.generate(h, maskLen);

    /* 10. Let maskedDB = DB \xor dbMask. */
    var maskedDB = '';
    for(i = 0; i < maskLen; i++) {
      maskedDB += String.fromCharCode(db.charCodeAt(i) ^ dbMask.charCodeAt(i));
    }

    /* 11. Set the leftmost 8emLen - emBits bits of the leftmost octet in
     *     maskedDB to zero. */
    var mask = (0xFF00 >> (8 * emLen - emBits)) & 0xFF;
    maskedDB = String.fromCharCode(maskedDB.charCodeAt(0) & ~mask) +
      maskedDB.substr(1);

    /* 12. Let EM = maskedDB || H || 0xbc.
     * 13. Output EM. */
    return maskedDB + h + String.fromCharCode(0xbc);
  };

  /**
   * Verifies a PSS signature.
   *
   * This function implements EMSA-PSS-VERIFY as per RFC 3447, section 9.1.2.
   *
   * @param mHash the message digest hash, as a binary-encoded string, to
   *         compare against the signature.
   * @param em the encoded message, as a binary-encoded string
   *          (RSA decryption result).
   * @param modsBits the length of the RSA modulus in bits.
   *
   * @return true if the signature was verified, false if not.
   */
  pssobj.verify = function(mHash, em, modBits) {
    var i;
    var emBits = modBits - 1;
    var emLen = Math.ceil(emBits / 8);

    /* c. Convert the message representative m to an encoded message EM
     *    of length emLen = ceil((modBits - 1) / 8) octets, where modBits
     *    is the length in bits of the RSA modulus n */
    em = em.substr(-emLen);

    /* 3. If emLen < hLen + sLen + 2, output "inconsistent" and stop. */
    if(emLen < hLen + sLen + 2) {
      throw new Error('Inconsistent parameters to PSS signature verification.');
    }

    /* 4. If the rightmost octet of EM does not have hexadecimal value
     *    0xbc, output "inconsistent" and stop. */
    if(em.charCodeAt(emLen - 1) !== 0xbc) {
      throw new Error('Encoded message does not end in 0xBC.');
    }

    /* 5. Let maskedDB be the leftmost emLen - hLen - 1 octets of EM, and
     *    let H be the next hLen octets. */
    var maskLen = emLen - hLen - 1;
    var maskedDB = em.substr(0, maskLen);
    var h = em.substr(maskLen, hLen);

    /* 6. If the leftmost 8emLen - emBits bits of the leftmost octet in
     *    maskedDB are not all equal to zero, output "inconsistent" and stop. */
    var mask = (0xFF00 >> (8 * emLen - emBits)) & 0xFF;
    if((maskedDB.charCodeAt(0) & mask) !== 0) {
      throw new Error('Bits beyond keysize not zero as expected.');
    }

    /* 7. Let dbMask = MGF(H, emLen - hLen - 1). */
    var dbMask = mgf.generate(h, maskLen);

    /* 8. Let DB = maskedDB \xor dbMask. */
    var db = '';
    for(i = 0; i < maskLen; i++) {
      db += String.fromCharCode(maskedDB.charCodeAt(i) ^ dbMask.charCodeAt(i));
    }

    /* 9. Set the leftmost 8emLen - emBits bits of the leftmost octet
     * in DB to zero. */
    db = String.fromCharCode(db.charCodeAt(0) & ~mask) + db.substr(1);

    /* 10. If the emLen - hLen - sLen - 2 leftmost octets of DB are not zero
     * or if the octet at position emLen - hLen - sLen - 1 (the leftmost
     * position is "position 1") does not have hexadecimal value 0x01,
     * output "inconsistent" and stop. */
    var checkLen = emLen - hLen - sLen - 2;
    for(i = 0; i < checkLen; i++) {
      if(db.charCodeAt(i) !== 0x00) {
        throw new Error('Leftmost octets not zero as expected');
      }
    }

    if(db.charCodeAt(checkLen) !== 0x01) {
      throw new Error('Inconsistent PSS signature, 0x01 marker not found');
    }

    /* 11. Let salt be the last sLen octets of DB. */
    var salt = db.substr(-sLen);

    /* 12.  Let M' = (0x)00 00 00 00 00 00 00 00 || mHash || salt */
    var m_ = new forge$2.util.ByteBuffer();
    m_.fillWithByte(0, 8);
    m_.putBytes(mHash);
    m_.putBytes(salt);

    /* 13. Let H' = Hash(M'), an octet string of length hLen. */
    hash.start();
    hash.update(m_.getBytes());
    var h_ = hash.digest().getBytes();

    /* 14. If H = H', output "consistent." Otherwise, output "inconsistent." */
    return h === h_;
  };

  return pssobj;
};

/**
 * Javascript implementation of X.509 and related components (such as
 * Certification Signing Requests) of a Public Key Infrastructure.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 *
 * The ASN.1 representation of an X.509v3 certificate is as follows
 * (see RFC 2459):
 *
 * Certificate ::= SEQUENCE {
 *   tbsCertificate       TBSCertificate,
 *   signatureAlgorithm   AlgorithmIdentifier,
 *   signatureValue       BIT STRING
 * }
 *
 * TBSCertificate ::= SEQUENCE {
 *   version         [0]  EXPLICIT Version DEFAULT v1,
 *   serialNumber         CertificateSerialNumber,
 *   signature            AlgorithmIdentifier,
 *   issuer               Name,
 *   validity             Validity,
 *   subject              Name,
 *   subjectPublicKeyInfo SubjectPublicKeyInfo,
 *   issuerUniqueID  [1]  IMPLICIT UniqueIdentifier OPTIONAL,
 *                        -- If present, version shall be v2 or v3
 *   subjectUniqueID [2]  IMPLICIT UniqueIdentifier OPTIONAL,
 *                        -- If present, version shall be v2 or v3
 *   extensions      [3]  EXPLICIT Extensions OPTIONAL
 *                        -- If present, version shall be v3
 * }
 *
 * Version ::= INTEGER  { v1(0), v2(1), v3(2) }
 *
 * CertificateSerialNumber ::= INTEGER
 *
 * Name ::= CHOICE {
 *   // only one possible choice for now
 *   RDNSequence
 * }
 *
 * RDNSequence ::= SEQUENCE OF RelativeDistinguishedName
 *
 * RelativeDistinguishedName ::= SET OF AttributeTypeAndValue
 *
 * AttributeTypeAndValue ::= SEQUENCE {
 *   type     AttributeType,
 *   value    AttributeValue
 * }
 * AttributeType ::= OBJECT IDENTIFIER
 * AttributeValue ::= ANY DEFINED BY AttributeType
 *
 * Validity ::= SEQUENCE {
 *   notBefore      Time,
 *   notAfter       Time
 * }
 *
 * Time ::= CHOICE {
 *   utcTime        UTCTime,
 *   generalTime    GeneralizedTime
 * }
 *
 * UniqueIdentifier ::= BIT STRING
 *
 * SubjectPublicKeyInfo ::= SEQUENCE {
 *   algorithm            AlgorithmIdentifier,
 *   subjectPublicKey     BIT STRING
 * }
 *
 * Extensions ::= SEQUENCE SIZE (1..MAX) OF Extension
 *
 * Extension ::= SEQUENCE {
 *   extnID      OBJECT IDENTIFIER,
 *   critical    BOOLEAN DEFAULT FALSE,
 *   extnValue   OCTET STRING
 * }
 *
 * The only key algorithm currently supported for PKI is RSA.
 *
 * RSASSA-PSS signatures are described in RFC 3447 and RFC 4055.
 *
 * PKCS#10 v1.7 describes certificate signing requests:
 *
 * CertificationRequestInfo:
 *
 * CertificationRequestInfo ::= SEQUENCE {
 *   version       INTEGER { v1(0) } (v1,...),
 *   subject       Name,
 *   subjectPKInfo SubjectPublicKeyInfo{{ PKInfoAlgorithms }},
 *   attributes    [0] Attributes{{ CRIAttributes }}
 * }
 *
 * Attributes { ATTRIBUTE:IOSet } ::= SET OF Attribute{{ IOSet }}
 *
 * CRIAttributes  ATTRIBUTE  ::= {
 *   ... -- add any locally defined attributes here -- }
 *
 * Attribute { ATTRIBUTE:IOSet } ::= SEQUENCE {
 *   type   ATTRIBUTE.&id({IOSet}),
 *   values SET SIZE(1..MAX) OF ATTRIBUTE.&Type({IOSet}{@type})
 * }
 *
 * CertificationRequest ::= SEQUENCE {
 *   certificationRequestInfo CertificationRequestInfo,
 *   signatureAlgorithm AlgorithmIdentifier{{ SignatureAlgorithms }},
 *   signature          BIT STRING
 * }
 */

var forge$1 = forge$s;











// shortcut for asn.1 API
var asn1$1 = forge$1.asn1;

/* Public Key Infrastructure (PKI) implementation. */
var pki$1 = forge$1.pki = forge$1.pki || {};
var oids = pki$1.oids;

// short name OID mappings
var _shortNames = {};
_shortNames['CN'] = oids['commonName'];
_shortNames['commonName'] = 'CN';
_shortNames['C'] = oids['countryName'];
_shortNames['countryName'] = 'C';
_shortNames['L'] = oids['localityName'];
_shortNames['localityName'] = 'L';
_shortNames['ST'] = oids['stateOrProvinceName'];
_shortNames['stateOrProvinceName'] = 'ST';
_shortNames['O'] = oids['organizationName'];
_shortNames['organizationName'] = 'O';
_shortNames['OU'] = oids['organizationalUnitName'];
_shortNames['organizationalUnitName'] = 'OU';
_shortNames['E'] = oids['emailAddress'];
_shortNames['emailAddress'] = 'E';

// validator for an SubjectPublicKeyInfo structure
// Note: Currently only works with an RSA public key
var publicKeyValidator = forge$1.pki.rsa.publicKeyValidator;

// validator for an X.509v3 certificate
var x509CertificateValidator = {
  name: 'Certificate',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'Certificate.TBSCertificate',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.SEQUENCE,
    constructed: true,
    captureAsn1: 'tbsCertificate',
    value: [{
      name: 'Certificate.TBSCertificate.version',
      tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
      type: 0,
      constructed: true,
      optional: true,
      value: [{
        name: 'Certificate.TBSCertificate.version.integer',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.INTEGER,
        constructed: false,
        capture: 'certVersion'
      }]
    }, {
      name: 'Certificate.TBSCertificate.serialNumber',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.INTEGER,
      constructed: false,
      capture: 'certSerialNumber'
    }, {
      name: 'Certificate.TBSCertificate.signature',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.SEQUENCE,
      constructed: true,
      value: [{
        name: 'Certificate.TBSCertificate.signature.algorithm',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.OID,
        constructed: false,
        capture: 'certinfoSignatureOid'
      }, {
        name: 'Certificate.TBSCertificate.signature.parameters',
        tagClass: asn1$1.Class.UNIVERSAL,
        optional: true,
        captureAsn1: 'certinfoSignatureParams'
      }]
    }, {
      name: 'Certificate.TBSCertificate.issuer',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.SEQUENCE,
      constructed: true,
      captureAsn1: 'certIssuer'
    }, {
      name: 'Certificate.TBSCertificate.validity',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.SEQUENCE,
      constructed: true,
      // Note: UTC and generalized times may both appear so the capture
      // names are based on their detected order, the names used below
      // are only for the common case, which validity time really means
      // "notBefore" and which means "notAfter" will be determined by order
      value: [{
        // notBefore (Time) (UTC time case)
        name: 'Certificate.TBSCertificate.validity.notBefore (utc)',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.UTCTIME,
        constructed: false,
        optional: true,
        capture: 'certValidity1UTCTime'
      }, {
        // notBefore (Time) (generalized time case)
        name: 'Certificate.TBSCertificate.validity.notBefore (generalized)',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.GENERALIZEDTIME,
        constructed: false,
        optional: true,
        capture: 'certValidity2GeneralizedTime'
      }, {
        // notAfter (Time) (only UTC time is supported)
        name: 'Certificate.TBSCertificate.validity.notAfter (utc)',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.UTCTIME,
        constructed: false,
        optional: true,
        capture: 'certValidity3UTCTime'
      }, {
        // notAfter (Time) (only UTC time is supported)
        name: 'Certificate.TBSCertificate.validity.notAfter (generalized)',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.GENERALIZEDTIME,
        constructed: false,
        optional: true,
        capture: 'certValidity4GeneralizedTime'
      }]
    }, {
      // Name (subject) (RDNSequence)
      name: 'Certificate.TBSCertificate.subject',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.SEQUENCE,
      constructed: true,
      captureAsn1: 'certSubject'
    },
    // SubjectPublicKeyInfo
    publicKeyValidator,
    {
      // issuerUniqueID (optional)
      name: 'Certificate.TBSCertificate.issuerUniqueID',
      tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
      type: 1,
      constructed: true,
      optional: true,
      value: [{
        name: 'Certificate.TBSCertificate.issuerUniqueID.id',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.BITSTRING,
        constructed: false,
        // TODO: support arbitrary bit length ids
        captureBitStringValue: 'certIssuerUniqueId'
      }]
    }, {
      // subjectUniqueID (optional)
      name: 'Certificate.TBSCertificate.subjectUniqueID',
      tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
      type: 2,
      constructed: true,
      optional: true,
      value: [{
        name: 'Certificate.TBSCertificate.subjectUniqueID.id',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.BITSTRING,
        constructed: false,
        // TODO: support arbitrary bit length ids
        captureBitStringValue: 'certSubjectUniqueId'
      }]
    }, {
      // Extensions (optional)
      name: 'Certificate.TBSCertificate.extensions',
      tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
      type: 3,
      constructed: true,
      captureAsn1: 'certExtensions',
      optional: true
    }]
  }, {
    // AlgorithmIdentifier (signature algorithm)
    name: 'Certificate.signatureAlgorithm',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.SEQUENCE,
    constructed: true,
    value: [{
      // algorithm
      name: 'Certificate.signatureAlgorithm.algorithm',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.OID,
      constructed: false,
      capture: 'certSignatureOid'
    }, {
      name: 'Certificate.TBSCertificate.signature.parameters',
      tagClass: asn1$1.Class.UNIVERSAL,
      optional: true,
      captureAsn1: 'certSignatureParams'
    }]
  }, {
    // SignatureValue
    name: 'Certificate.signatureValue',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.BITSTRING,
    constructed: false,
    captureBitStringValue: 'certSignature'
  }]
};

var rsassaPssParameterValidator = {
  name: 'rsapss',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'rsapss.hashAlgorithm',
    tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
    type: 0,
    constructed: true,
    value: [{
      name: 'rsapss.hashAlgorithm.AlgorithmIdentifier',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Class.SEQUENCE,
      constructed: true,
      optional: true,
      value: [{
        name: 'rsapss.hashAlgorithm.AlgorithmIdentifier.algorithm',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.OID,
        constructed: false,
        capture: 'hashOid'
        /* parameter block omitted, for SHA1 NULL anyhow. */
      }]
    }]
  }, {
    name: 'rsapss.maskGenAlgorithm',
    tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
    type: 1,
    constructed: true,
    value: [{
      name: 'rsapss.maskGenAlgorithm.AlgorithmIdentifier',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Class.SEQUENCE,
      constructed: true,
      optional: true,
      value: [{
        name: 'rsapss.maskGenAlgorithm.AlgorithmIdentifier.algorithm',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.OID,
        constructed: false,
        capture: 'maskGenOid'
      }, {
        name: 'rsapss.maskGenAlgorithm.AlgorithmIdentifier.params',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.SEQUENCE,
        constructed: true,
        value: [{
          name: 'rsapss.maskGenAlgorithm.AlgorithmIdentifier.params.algorithm',
          tagClass: asn1$1.Class.UNIVERSAL,
          type: asn1$1.Type.OID,
          constructed: false,
          capture: 'maskGenHashOid'
          /* parameter block omitted, for SHA1 NULL anyhow. */
        }]
      }]
    }]
  }, {
    name: 'rsapss.saltLength',
    tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
    type: 2,
    optional: true,
    value: [{
      name: 'rsapss.saltLength.saltLength',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Class.INTEGER,
      constructed: false,
      capture: 'saltLength'
    }]
  }, {
    name: 'rsapss.trailerField',
    tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
    type: 3,
    optional: true,
    value: [{
      name: 'rsapss.trailer.trailer',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Class.INTEGER,
      constructed: false,
      capture: 'trailer'
    }]
  }]
};

// validator for a CertificationRequestInfo structure
var certificationRequestInfoValidator = {
  name: 'CertificationRequestInfo',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  captureAsn1: 'certificationRequestInfo',
  value: [{
    name: 'CertificationRequestInfo.integer',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'certificationRequestInfoVersion'
  }, {
    // Name (subject) (RDNSequence)
    name: 'CertificationRequestInfo.subject',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.SEQUENCE,
    constructed: true,
    captureAsn1: 'certificationRequestInfoSubject'
  },
  // SubjectPublicKeyInfo
  publicKeyValidator,
  {
    name: 'CertificationRequestInfo.attributes',
    tagClass: asn1$1.Class.CONTEXT_SPECIFIC,
    type: 0,
    constructed: true,
    optional: true,
    capture: 'certificationRequestInfoAttributes',
    value: [{
      name: 'CertificationRequestInfo.attributes',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.SEQUENCE,
      constructed: true,
      value: [{
        name: 'CertificationRequestInfo.attributes.type',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.OID,
        constructed: false
      }, {
        name: 'CertificationRequestInfo.attributes.value',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.SET,
        constructed: true
      }]
    }]
  }]
};

// validator for a CertificationRequest structure
var certificationRequestValidator = {
  name: 'CertificationRequest',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  captureAsn1: 'csr',
  value: [
    certificationRequestInfoValidator, {
      // AlgorithmIdentifier (signature algorithm)
      name: 'CertificationRequest.signatureAlgorithm',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.SEQUENCE,
      constructed: true,
      value: [{
        // algorithm
        name: 'CertificationRequest.signatureAlgorithm.algorithm',
        tagClass: asn1$1.Class.UNIVERSAL,
        type: asn1$1.Type.OID,
        constructed: false,
        capture: 'csrSignatureOid'
      }, {
        name: 'CertificationRequest.signatureAlgorithm.parameters',
        tagClass: asn1$1.Class.UNIVERSAL,
        optional: true,
        captureAsn1: 'csrSignatureParams'
      }]
    }, {
      // signature
      name: 'CertificationRequest.signature',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.BITSTRING,
      constructed: false,
      captureBitStringValue: 'csrSignature'
    }
  ]
};

/**
 * Converts an RDNSequence of ASN.1 DER-encoded RelativeDistinguishedName
 * sets into an array with objects that have type and value properties.
 *
 * @param rdn the RDNSequence to convert.
 * @param md a message digest to append type and value to if provided.
 */
pki$1.RDNAttributesAsArray = function(rdn, md) {
  var rval = [];

  // each value in 'rdn' in is a SET of RelativeDistinguishedName
  var set, attr, obj;
  for(var si = 0; si < rdn.value.length; ++si) {
    // get the RelativeDistinguishedName set
    set = rdn.value[si];

    // each value in the SET is an AttributeTypeAndValue sequence
    // containing first a type (an OID) and second a value (defined by
    // the OID)
    for(var i = 0; i < set.value.length; ++i) {
      obj = {};
      attr = set.value[i];
      obj.type = asn1$1.derToOid(attr.value[0].value);
      obj.value = attr.value[1].value;
      obj.valueTagClass = attr.value[1].type;
      // if the OID is known, get its name and short name
      if(obj.type in oids) {
        obj.name = oids[obj.type];
        if(obj.name in _shortNames) {
          obj.shortName = _shortNames[obj.name];
        }
      }
      if(md) {
        md.update(obj.type);
        md.update(obj.value);
      }
      rval.push(obj);
    }
  }

  return rval;
};

/**
 * Converts ASN.1 CRIAttributes into an array with objects that have type and
 * value properties.
 *
 * @param attributes the CRIAttributes to convert.
 */
pki$1.CRIAttributesAsArray = function(attributes) {
  var rval = [];

  // each value in 'attributes' in is a SEQUENCE with an OID and a SET
  for(var si = 0; si < attributes.length; ++si) {
    // get the attribute sequence
    var seq = attributes[si];

    // each value in the SEQUENCE containing first a type (an OID) and
    // second a set of values (defined by the OID)
    var type = asn1$1.derToOid(seq.value[0].value);
    var values = seq.value[1].value;
    for(var vi = 0; vi < values.length; ++vi) {
      var obj = {};
      obj.type = type;
      obj.value = values[vi].value;
      obj.valueTagClass = values[vi].type;
      // if the OID is known, get its name and short name
      if(obj.type in oids) {
        obj.name = oids[obj.type];
        if(obj.name in _shortNames) {
          obj.shortName = _shortNames[obj.name];
        }
      }
      // parse extensions
      if(obj.type === oids.extensionRequest) {
        obj.extensions = [];
        for(var ei = 0; ei < obj.value.length; ++ei) {
          obj.extensions.push(pki$1.certificateExtensionFromAsn1(obj.value[ei]));
        }
      }
      rval.push(obj);
    }
  }

  return rval;
};

/**
 * Gets an issuer or subject attribute from its name, type, or short name.
 *
 * @param obj the issuer or subject object.
 * @param options a short name string or an object with:
 *          shortName the short name for the attribute.
 *          name the name for the attribute.
 *          type the type for the attribute.
 *
 * @return the attribute.
 */
function _getAttribute(obj, options) {
  if(typeof options === 'string') {
    options = {shortName: options};
  }

  var rval = null;
  var attr;
  for(var i = 0; rval === null && i < obj.attributes.length; ++i) {
    attr = obj.attributes[i];
    if(options.type && options.type === attr.type) {
      rval = attr;
    } else if(options.name && options.name === attr.name) {
      rval = attr;
    } else if(options.shortName && options.shortName === attr.shortName) {
      rval = attr;
    }
  }
  return rval;
}

/**
 * Converts signature parameters from ASN.1 structure.
 *
 * Currently only RSASSA-PSS supported.  The PKCS#1 v1.5 signature scheme had
 * no parameters.
 *
 * RSASSA-PSS-params  ::=  SEQUENCE  {
 *   hashAlgorithm      [0] HashAlgorithm DEFAULT
 *                             sha1Identifier,
 *   maskGenAlgorithm   [1] MaskGenAlgorithm DEFAULT
 *                             mgf1SHA1Identifier,
 *   saltLength         [2] INTEGER DEFAULT 20,
 *   trailerField       [3] INTEGER DEFAULT 1
 * }
 *
 * HashAlgorithm  ::=  AlgorithmIdentifier
 *
 * MaskGenAlgorithm  ::=  AlgorithmIdentifier
 *
 * AlgorithmIdentifer ::= SEQUENCE {
 *   algorithm OBJECT IDENTIFIER,
 *   parameters ANY DEFINED BY algorithm OPTIONAL
 * }
 *
 * @param oid The OID specifying the signature algorithm
 * @param obj The ASN.1 structure holding the parameters
 * @param fillDefaults Whether to use return default values where omitted
 * @return signature parameter object
 */
var _readSignatureParameters = function(oid, obj, fillDefaults) {
  var params = {};

  if(oid !== oids['RSASSA-PSS']) {
    return params;
  }

  if(fillDefaults) {
    params = {
      hash: {
        algorithmOid: oids['sha1']
      },
      mgf: {
        algorithmOid: oids['mgf1'],
        hash: {
          algorithmOid: oids['sha1']
        }
      },
      saltLength: 20
    };
  }

  var capture = {};
  var errors = [];
  if(!asn1$1.validate(obj, rsassaPssParameterValidator, capture, errors)) {
    var error = new Error('Cannot read RSASSA-PSS parameter block.');
    error.errors = errors;
    throw error;
  }

  if(capture.hashOid !== undefined) {
    params.hash = params.hash || {};
    params.hash.algorithmOid = asn1$1.derToOid(capture.hashOid);
  }

  if(capture.maskGenOid !== undefined) {
    params.mgf = params.mgf || {};
    params.mgf.algorithmOid = asn1$1.derToOid(capture.maskGenOid);
    params.mgf.hash = params.mgf.hash || {};
    params.mgf.hash.algorithmOid = asn1$1.derToOid(capture.maskGenHashOid);
  }

  if(capture.saltLength !== undefined) {
    params.saltLength = capture.saltLength.charCodeAt(0);
  }

  return params;
};

/**
 * Create signature digest for OID.
 *
 * @param options
 *   signatureOid: the OID specifying the signature algorithm.
 *   type: a human readable type for error messages
 * @return a created md instance. throws if unknown oid.
 */
var _createSignatureDigest = function(options) {
  switch(oids[options.signatureOid]) {
    case 'sha1WithRSAEncryption':
    // deprecated alias
    case 'sha1WithRSASignature':
      return forge$1.md.sha1.create();
    case 'md5WithRSAEncryption':
      return forge$1.md.md5.create();
    case 'sha256WithRSAEncryption':
      return forge$1.md.sha256.create();
    case 'sha384WithRSAEncryption':
      return forge$1.md.sha384.create();
    case 'sha512WithRSAEncryption':
      return forge$1.md.sha512.create();
    case 'RSASSA-PSS':
      return forge$1.md.sha256.create();
    default:
      var error = new Error(
        'Could not compute ' + options.type + ' digest. ' +
        'Unknown signature OID.');
      error.signatureOid = options.signatureOid;
      throw error;
  }
};

/**
 * Verify signature on certificate or CSR.
 *
 * @param options:
 *   certificate the certificate or CSR to verify.
 *   md the signature digest.
 *   signature the signature
 * @return a created md instance. throws if unknown oid.
 */
var _verifySignature = function(options) {
  var cert = options.certificate;
  var scheme;

  switch(cert.signatureOid) {
    case oids.sha1WithRSAEncryption:
    // deprecated alias
    case oids.sha1WithRSASignature:
      /* use PKCS#1 v1.5 padding scheme */
      break;
    case oids['RSASSA-PSS']:
      var hash, mgf;

      /* initialize mgf */
      hash = oids[cert.signatureParameters.mgf.hash.algorithmOid];
      if(hash === undefined || forge$1.md[hash] === undefined) {
        var error = new Error('Unsupported MGF hash function.');
        error.oid = cert.signatureParameters.mgf.hash.algorithmOid;
        error.name = hash;
        throw error;
      }

      mgf = oids[cert.signatureParameters.mgf.algorithmOid];
      if(mgf === undefined || forge$1.mgf[mgf] === undefined) {
        var error = new Error('Unsupported MGF function.');
        error.oid = cert.signatureParameters.mgf.algorithmOid;
        error.name = mgf;
        throw error;
      }

      mgf = forge$1.mgf[mgf].create(forge$1.md[hash].create());

      /* initialize hash function */
      hash = oids[cert.signatureParameters.hash.algorithmOid];
      if(hash === undefined || forge$1.md[hash] === undefined) {
        var error = new Error('Unsupported RSASSA-PSS hash function.');
        error.oid = cert.signatureParameters.hash.algorithmOid;
        error.name = hash;
        throw error;
      }

      scheme = forge$1.pss.create(
        forge$1.md[hash].create(), mgf, cert.signatureParameters.saltLength
      );
      break;
  }

  // verify signature on cert using public key
  return cert.publicKey.verify(
    options.md.digest().getBytes(), options.signature, scheme
  );
};

/**
 * Converts an X.509 certificate from PEM format.
 *
 * Note: If the certificate is to be verified then compute hash should
 * be set to true. This will scan the TBSCertificate part of the ASN.1
 * object while it is converted so it doesn't need to be converted back
 * to ASN.1-DER-encoding later.
 *
 * @param pem the PEM-formatted certificate.
 * @param computeHash true to compute the hash for verification.
 * @param strict true to be strict when checking ASN.1 value lengths, false to
 *          allow truncated values (default: true).
 *
 * @return the certificate.
 */
pki$1.certificateFromPem = function(pem, computeHash, strict) {
  var msg = forge$1.pem.decode(pem)[0];

  if(msg.type !== 'CERTIFICATE' &&
    msg.type !== 'X509 CERTIFICATE' &&
    msg.type !== 'TRUSTED CERTIFICATE') {
    var error = new Error(
      'Could not convert certificate from PEM; PEM header type ' +
      'is not "CERTIFICATE", "X509 CERTIFICATE", or "TRUSTED CERTIFICATE".');
    error.headerType = msg.type;
    throw error;
  }
  if(msg.procType && msg.procType.type === 'ENCRYPTED') {
    throw new Error(
      'Could not convert certificate from PEM; PEM is encrypted.');
  }

  // convert DER to ASN.1 object
  var obj = asn1$1.fromDer(msg.body, strict);

  return pki$1.certificateFromAsn1(obj, computeHash);
};

/**
 * Converts an X.509 certificate to PEM format.
 *
 * @param cert the certificate.
 * @param maxline the maximum characters per line, defaults to 64.
 *
 * @return the PEM-formatted certificate.
 */
pki$1.certificateToPem = function(cert, maxline) {
  // convert to ASN.1, then DER, then PEM-encode
  var msg = {
    type: 'CERTIFICATE',
    body: asn1$1.toDer(pki$1.certificateToAsn1(cert)).getBytes()
  };
  return forge$1.pem.encode(msg, {maxline: maxline});
};

/**
 * Converts an RSA public key from PEM format.
 *
 * @param pem the PEM-formatted public key.
 *
 * @return the public key.
 */
pki$1.publicKeyFromPem = function(pem) {
  var msg = forge$1.pem.decode(pem)[0];

  if(msg.type !== 'PUBLIC KEY' && msg.type !== 'RSA PUBLIC KEY') {
    var error = new Error('Could not convert public key from PEM; PEM header ' +
      'type is not "PUBLIC KEY" or "RSA PUBLIC KEY".');
    error.headerType = msg.type;
    throw error;
  }
  if(msg.procType && msg.procType.type === 'ENCRYPTED') {
    throw new Error('Could not convert public key from PEM; PEM is encrypted.');
  }

  // convert DER to ASN.1 object
  var obj = asn1$1.fromDer(msg.body);

  return pki$1.publicKeyFromAsn1(obj);
};

/**
 * Converts an RSA public key to PEM format (using a SubjectPublicKeyInfo).
 *
 * @param key the public key.
 * @param maxline the maximum characters per line, defaults to 64.
 *
 * @return the PEM-formatted public key.
 */
pki$1.publicKeyToPem = function(key, maxline) {
  // convert to ASN.1, then DER, then PEM-encode
  var msg = {
    type: 'PUBLIC KEY',
    body: asn1$1.toDer(pki$1.publicKeyToAsn1(key)).getBytes()
  };
  return forge$1.pem.encode(msg, {maxline: maxline});
};

/**
 * Converts an RSA public key to PEM format (using an RSAPublicKey).
 *
 * @param key the public key.
 * @param maxline the maximum characters per line, defaults to 64.
 *
 * @return the PEM-formatted public key.
 */
pki$1.publicKeyToRSAPublicKeyPem = function(key, maxline) {
  // convert to ASN.1, then DER, then PEM-encode
  var msg = {
    type: 'RSA PUBLIC KEY',
    body: asn1$1.toDer(pki$1.publicKeyToRSAPublicKey(key)).getBytes()
  };
  return forge$1.pem.encode(msg, {maxline: maxline});
};

/**
 * Gets a fingerprint for the given public key.
 *
 * @param options the options to use.
 *          [md] the message digest object to use (defaults to forge.md.sha1).
 *          [type] the type of fingerprint, such as 'RSAPublicKey',
 *            'SubjectPublicKeyInfo' (defaults to 'RSAPublicKey').
 *          [encoding] an alternative output encoding, such as 'hex'
 *            (defaults to none, outputs a byte buffer).
 *          [delimiter] the delimiter to use between bytes for 'hex' encoded
 *            output, eg: ':' (defaults to none).
 *
 * @return the fingerprint as a byte buffer or other encoding based on options.
 */
pki$1.getPublicKeyFingerprint = function(key, options) {
  options = options || {};
  var md = options.md || forge$1.md.sha1.create();
  var type = options.type || 'RSAPublicKey';

  var bytes;
  switch(type) {
    case 'RSAPublicKey':
      bytes = asn1$1.toDer(pki$1.publicKeyToRSAPublicKey(key)).getBytes();
      break;
    case 'SubjectPublicKeyInfo':
      bytes = asn1$1.toDer(pki$1.publicKeyToAsn1(key)).getBytes();
      break;
    default:
      throw new Error('Unknown fingerprint type "' + options.type + '".');
  }

  // hash public key bytes
  md.start();
  md.update(bytes);
  var digest = md.digest();
  if(options.encoding === 'hex') {
    var hex = digest.toHex();
    if(options.delimiter) {
      return hex.match(/.{2}/g).join(options.delimiter);
    }
    return hex;
  } else if(options.encoding === 'binary') {
    return digest.getBytes();
  } else if(options.encoding) {
    throw new Error('Unknown encoding "' + options.encoding + '".');
  }
  return digest;
};

/**
 * Converts a PKCS#10 certification request (CSR) from PEM format.
 *
 * Note: If the certification request is to be verified then compute hash
 * should be set to true. This will scan the CertificationRequestInfo part of
 * the ASN.1 object while it is converted so it doesn't need to be converted
 * back to ASN.1-DER-encoding later.
 *
 * @param pem the PEM-formatted certificate.
 * @param computeHash true to compute the hash for verification.
 * @param strict true to be strict when checking ASN.1 value lengths, false to
 *          allow truncated values (default: true).
 *
 * @return the certification request (CSR).
 */
pki$1.certificationRequestFromPem = function(pem, computeHash, strict) {
  var msg = forge$1.pem.decode(pem)[0];

  if(msg.type !== 'CERTIFICATE REQUEST') {
    var error = new Error('Could not convert certification request from PEM; ' +
      'PEM header type is not "CERTIFICATE REQUEST".');
    error.headerType = msg.type;
    throw error;
  }
  if(msg.procType && msg.procType.type === 'ENCRYPTED') {
    throw new Error('Could not convert certification request from PEM; ' +
      'PEM is encrypted.');
  }

  // convert DER to ASN.1 object
  var obj = asn1$1.fromDer(msg.body, strict);

  return pki$1.certificationRequestFromAsn1(obj, computeHash);
};

/**
 * Converts a PKCS#10 certification request (CSR) to PEM format.
 *
 * @param csr the certification request.
 * @param maxline the maximum characters per line, defaults to 64.
 *
 * @return the PEM-formatted certification request.
 */
pki$1.certificationRequestToPem = function(csr, maxline) {
  // convert to ASN.1, then DER, then PEM-encode
  var msg = {
    type: 'CERTIFICATE REQUEST',
    body: asn1$1.toDer(pki$1.certificationRequestToAsn1(csr)).getBytes()
  };
  return forge$1.pem.encode(msg, {maxline: maxline});
};

/**
 * Creates an empty X.509v3 RSA certificate.
 *
 * @return the certificate.
 */
pki$1.createCertificate = function() {
  var cert = {};
  cert.version = 0x02;
  cert.serialNumber = '00';
  cert.signatureOid = null;
  cert.signature = null;
  cert.siginfo = {};
  cert.siginfo.algorithmOid = null;
  cert.validity = {};
  cert.validity.notBefore = new Date();
  cert.validity.notAfter = new Date();

  cert.issuer = {};
  cert.issuer.getField = function(sn) {
    return _getAttribute(cert.issuer, sn);
  };
  cert.issuer.addField = function(attr) {
    _fillMissingFields([attr]);
    cert.issuer.attributes.push(attr);
  };
  cert.issuer.attributes = [];
  cert.issuer.hash = null;

  cert.subject = {};
  cert.subject.getField = function(sn) {
    return _getAttribute(cert.subject, sn);
  };
  cert.subject.addField = function(attr) {
    _fillMissingFields([attr]);
    cert.subject.attributes.push(attr);
  };
  cert.subject.attributes = [];
  cert.subject.hash = null;

  cert.extensions = [];
  cert.publicKey = null;
  cert.md = null;

  /**
   * Sets the subject of this certificate.
   *
   * @param attrs the array of subject attributes to use.
   * @param uniqueId an optional a unique ID to use.
   */
  cert.setSubject = function(attrs, uniqueId) {
    // set new attributes, clear hash
    _fillMissingFields(attrs);
    cert.subject.attributes = attrs;
    delete cert.subject.uniqueId;
    if(uniqueId) {
      // TODO: support arbitrary bit length ids
      cert.subject.uniqueId = uniqueId;
    }
    cert.subject.hash = null;
  };

  /**
   * Sets the issuer of this certificate.
   *
   * @param attrs the array of issuer attributes to use.
   * @param uniqueId an optional a unique ID to use.
   */
  cert.setIssuer = function(attrs, uniqueId) {
    // set new attributes, clear hash
    _fillMissingFields(attrs);
    cert.issuer.attributes = attrs;
    delete cert.issuer.uniqueId;
    if(uniqueId) {
      // TODO: support arbitrary bit length ids
      cert.issuer.uniqueId = uniqueId;
    }
    cert.issuer.hash = null;
  };

  /**
   * Sets the extensions of this certificate.
   *
   * @param exts the array of extensions to use.
   */
  cert.setExtensions = function(exts) {
    for(var i = 0; i < exts.length; ++i) {
      _fillMissingExtensionFields(exts[i], {cert: cert});
    }
    // set new extensions
    cert.extensions = exts;
  };

  /**
   * Gets an extension by its name or id.
   *
   * @param options the name to use or an object with:
   *          name the name to use.
   *          id the id to use.
   *
   * @return the extension or null if not found.
   */
  cert.getExtension = function(options) {
    if(typeof options === 'string') {
      options = {name: options};
    }

    var rval = null;
    var ext;
    for(var i = 0; rval === null && i < cert.extensions.length; ++i) {
      ext = cert.extensions[i];
      if(options.id && ext.id === options.id) {
        rval = ext;
      } else if(options.name && ext.name === options.name) {
        rval = ext;
      }
    }
    return rval;
  };

  /**
   * Signs this certificate using the given private key.
   *
   * @param key the private key to sign with.
   * @param md the message digest object to use (defaults to forge.md.sha1).
   */
  cert.sign = function(key, md) {
    // TODO: get signature OID from private key
    cert.md = md || forge$1.md.sha1.create();
    var algorithmOid = oids[cert.md.algorithm + 'WithRSAEncryption'];
    if(!algorithmOid) {
      var error = new Error('Could not compute certificate digest. ' +
        'Unknown message digest algorithm OID.');
      error.algorithm = cert.md.algorithm;
      throw error;
    }
    cert.signatureOid = cert.siginfo.algorithmOid = algorithmOid;

    // get TBSCertificate, convert to DER
    cert.tbsCertificate = pki$1.getTBSCertificate(cert);
    var bytes = asn1$1.toDer(cert.tbsCertificate);

    // digest and sign
    cert.md.update(bytes.getBytes());
    cert.signature = key.sign(cert.md);
  };

  /**
   * Attempts verify the signature on the passed certificate using this
   * certificate's public key.
   *
   * @param child the certificate to verify.
   *
   * @return true if verified, false if not.
   */
  cert.verify = function(child) {
    var rval = false;

    if(!cert.issued(child)) {
      var issuer = child.issuer;
      var subject = cert.subject;
      var error = new Error(
        'The parent certificate did not issue the given child ' +
        'certificate; the child certificate\'s issuer does not match the ' +
        'parent\'s subject.');
      error.expectedIssuer = subject.attributes;
      error.actualIssuer = issuer.attributes;
      throw error;
    }

    var md = child.md;
    if(md === null) {
      // create digest for OID signature types
      md = _createSignatureDigest({
        signatureOid: child.signatureOid,
        type: 'certificate'
      });

      // produce DER formatted TBSCertificate and digest it
      var tbsCertificate = child.tbsCertificate || pki$1.getTBSCertificate(child);
      var bytes = asn1$1.toDer(tbsCertificate);
      md.update(bytes.getBytes());
    }

    if(md !== null) {
      rval = _verifySignature({
        certificate: cert, md: md, signature: child.signature
      });
    }

    return rval;
  };

  /**
   * Returns true if this certificate's issuer matches the passed
   * certificate's subject. Note that no signature check is performed.
   *
   * @param parent the certificate to check.
   *
   * @return true if this certificate's issuer matches the passed certificate's
   *         subject.
   */
  cert.isIssuer = function(parent) {
    var rval = false;

    var i = cert.issuer;
    var s = parent.subject;

    // compare hashes if present
    if(i.hash && s.hash) {
      rval = (i.hash === s.hash);
    } else if(i.attributes.length === s.attributes.length) {
      // all attributes are the same so issuer matches subject
      rval = true;
      var iattr, sattr;
      for(var n = 0; rval && n < i.attributes.length; ++n) {
        iattr = i.attributes[n];
        sattr = s.attributes[n];
        if(iattr.type !== sattr.type || iattr.value !== sattr.value) {
          // attribute mismatch
          rval = false;
        }
      }
    }

    return rval;
  };

  /**
   * Returns true if this certificate's subject matches the issuer of the
   * given certificate). Note that not signature check is performed.
   *
   * @param child the certificate to check.
   *
   * @return true if this certificate's subject matches the passed
   *         certificate's issuer.
   */
  cert.issued = function(child) {
    return child.isIssuer(cert);
  };

  /**
   * Generates the subjectKeyIdentifier for this certificate as byte buffer.
   *
   * @return the subjectKeyIdentifier for this certificate as byte buffer.
   */
  cert.generateSubjectKeyIdentifier = function() {
    /* See: 4.2.1.2 section of the the RFC3280, keyIdentifier is either:

      (1) The keyIdentifier is composed of the 160-bit SHA-1 hash of the
        value of the BIT STRING subjectPublicKey (excluding the tag,
        length, and number of unused bits).

      (2) The keyIdentifier is composed of a four bit type field with
        the value 0100 followed by the least significant 60 bits of the
        SHA-1 hash of the value of the BIT STRING subjectPublicKey
        (excluding the tag, length, and number of unused bit string bits).
    */

    // skipping the tag, length, and number of unused bits is the same
    // as just using the RSAPublicKey (for RSA keys, which are the
    // only ones supported)
    return pki$1.getPublicKeyFingerprint(cert.publicKey, {type: 'RSAPublicKey'});
  };

  /**
   * Verifies the subjectKeyIdentifier extension value for this certificate
   * against its public key. If no extension is found, false will be
   * returned.
   *
   * @return true if verified, false if not.
   */
  cert.verifySubjectKeyIdentifier = function() {
    var oid = oids['subjectKeyIdentifier'];
    for(var i = 0; i < cert.extensions.length; ++i) {
      var ext = cert.extensions[i];
      if(ext.id === oid) {
        var ski = cert.generateSubjectKeyIdentifier().getBytes();
        return (forge$1.util.hexToBytes(ext.subjectKeyIdentifier) === ski);
      }
    }
    return false;
  };

  return cert;
};

/**
 * Converts an X.509v3 RSA certificate from an ASN.1 object.
 *
 * Note: If the certificate is to be verified then compute hash should
 * be set to true. There is currently no implementation for converting
 * a certificate back to ASN.1 so the TBSCertificate part of the ASN.1
 * object needs to be scanned before the cert object is created.
 *
 * @param obj the asn1 representation of an X.509v3 RSA certificate.
 * @param computeHash true to compute the hash for verification.
 *
 * @return the certificate.
 */
pki$1.certificateFromAsn1 = function(obj, computeHash) {
  // validate certificate and capture data
  var capture = {};
  var errors = [];
  if(!asn1$1.validate(obj, x509CertificateValidator, capture, errors)) {
    var error = new Error('Cannot read X.509 certificate. ' +
      'ASN.1 object is not an X509v3 Certificate.');
    error.errors = errors;
    throw error;
  }

  // get oid
  var oid = asn1$1.derToOid(capture.publicKeyOid);
  if(oid !== pki$1.oids.rsaEncryption) {
    throw new Error('Cannot read public key. OID is not RSA.');
  }

  // create certificate
  var cert = pki$1.createCertificate();
  cert.version = capture.certVersion ?
    capture.certVersion.charCodeAt(0) : 0;
  var serial = forge$1.util.createBuffer(capture.certSerialNumber);
  cert.serialNumber = serial.toHex();
  cert.signatureOid = forge$1.asn1.derToOid(capture.certSignatureOid);
  cert.signatureParameters = _readSignatureParameters(
    cert.signatureOid, capture.certSignatureParams, true);
  cert.siginfo.algorithmOid = forge$1.asn1.derToOid(capture.certinfoSignatureOid);
  cert.siginfo.parameters = _readSignatureParameters(cert.siginfo.algorithmOid,
    capture.certinfoSignatureParams, false);
  cert.signature = capture.certSignature;

  var validity = [];
  if(capture.certValidity1UTCTime !== undefined) {
    validity.push(asn1$1.utcTimeToDate(capture.certValidity1UTCTime));
  }
  if(capture.certValidity2GeneralizedTime !== undefined) {
    validity.push(asn1$1.generalizedTimeToDate(
      capture.certValidity2GeneralizedTime));
  }
  if(capture.certValidity3UTCTime !== undefined) {
    validity.push(asn1$1.utcTimeToDate(capture.certValidity3UTCTime));
  }
  if(capture.certValidity4GeneralizedTime !== undefined) {
    validity.push(asn1$1.generalizedTimeToDate(
      capture.certValidity4GeneralizedTime));
  }
  if(validity.length > 2) {
    throw new Error('Cannot read notBefore/notAfter validity times; more ' +
      'than two times were provided in the certificate.');
  }
  if(validity.length < 2) {
    throw new Error('Cannot read notBefore/notAfter validity times; they ' +
      'were not provided as either UTCTime or GeneralizedTime.');
  }
  cert.validity.notBefore = validity[0];
  cert.validity.notAfter = validity[1];

  // keep TBSCertificate to preserve signature when exporting
  cert.tbsCertificate = capture.tbsCertificate;

  if(computeHash) {
    // create digest for OID signature type
    cert.md = _createSignatureDigest({
      signatureOid: cert.signatureOid,
      type: 'certificate'
    });

    // produce DER formatted TBSCertificate and digest it
    var bytes = asn1$1.toDer(cert.tbsCertificate);
    cert.md.update(bytes.getBytes());
  }

  // handle issuer, build issuer message digest
  var imd = forge$1.md.sha1.create();
  var ibytes = asn1$1.toDer(capture.certIssuer);
  imd.update(ibytes.getBytes());
  cert.issuer.getField = function(sn) {
    return _getAttribute(cert.issuer, sn);
  };
  cert.issuer.addField = function(attr) {
    _fillMissingFields([attr]);
    cert.issuer.attributes.push(attr);
  };
  cert.issuer.attributes = pki$1.RDNAttributesAsArray(capture.certIssuer);
  if(capture.certIssuerUniqueId) {
    cert.issuer.uniqueId = capture.certIssuerUniqueId;
  }
  cert.issuer.hash = imd.digest().toHex();

  // handle subject, build subject message digest
  var smd = forge$1.md.sha1.create();
  var sbytes = asn1$1.toDer(capture.certSubject);
  smd.update(sbytes.getBytes());
  cert.subject.getField = function(sn) {
    return _getAttribute(cert.subject, sn);
  };
  cert.subject.addField = function(attr) {
    _fillMissingFields([attr]);
    cert.subject.attributes.push(attr);
  };
  cert.subject.attributes = pki$1.RDNAttributesAsArray(capture.certSubject);
  if(capture.certSubjectUniqueId) {
    cert.subject.uniqueId = capture.certSubjectUniqueId;
  }
  cert.subject.hash = smd.digest().toHex();

  // handle extensions
  if(capture.certExtensions) {
    cert.extensions = pki$1.certificateExtensionsFromAsn1(capture.certExtensions);
  } else {
    cert.extensions = [];
  }

  // convert RSA public key from ASN.1
  cert.publicKey = pki$1.publicKeyFromAsn1(capture.subjectPublicKeyInfo);

  return cert;
};

/**
 * Converts an ASN.1 extensions object (with extension sequences as its
 * values) into an array of extension objects with types and values.
 *
 * Supported extensions:
 *
 * id-ce-keyUsage OBJECT IDENTIFIER ::=  { id-ce 15 }
 * KeyUsage ::= BIT STRING {
 *   digitalSignature        (0),
 *   nonRepudiation          (1),
 *   keyEncipherment         (2),
 *   dataEncipherment        (3),
 *   keyAgreement            (4),
 *   keyCertSign             (5),
 *   cRLSign                 (6),
 *   encipherOnly            (7),
 *   decipherOnly            (8)
 * }
 *
 * id-ce-basicConstraints OBJECT IDENTIFIER ::=  { id-ce 19 }
 * BasicConstraints ::= SEQUENCE {
 *   cA                      BOOLEAN DEFAULT FALSE,
 *   pathLenConstraint       INTEGER (0..MAX) OPTIONAL
 * }
 *
 * subjectAltName EXTENSION ::= {
 *   SYNTAX GeneralNames
 *   IDENTIFIED BY id-ce-subjectAltName
 * }
 *
 * GeneralNames ::= SEQUENCE SIZE (1..MAX) OF GeneralName
 *
 * GeneralName ::= CHOICE {
 *   otherName      [0] INSTANCE OF OTHER-NAME,
 *   rfc822Name     [1] IA5String,
 *   dNSName        [2] IA5String,
 *   x400Address    [3] ORAddress,
 *   directoryName  [4] Name,
 *   ediPartyName   [5] EDIPartyName,
 *   uniformResourceIdentifier [6] IA5String,
 *   IPAddress      [7] OCTET STRING,
 *   registeredID   [8] OBJECT IDENTIFIER
 * }
 *
 * OTHER-NAME ::= TYPE-IDENTIFIER
 *
 * EDIPartyName ::= SEQUENCE {
 *   nameAssigner [0] DirectoryString {ub-name} OPTIONAL,
 *   partyName    [1] DirectoryString {ub-name}
 * }
 *
 * @param exts the extensions ASN.1 with extension sequences to parse.
 *
 * @return the array.
 */
pki$1.certificateExtensionsFromAsn1 = function(exts) {
  var rval = [];
  for(var i = 0; i < exts.value.length; ++i) {
    // get extension sequence
    var extseq = exts.value[i];
    for(var ei = 0; ei < extseq.value.length; ++ei) {
      rval.push(pki$1.certificateExtensionFromAsn1(extseq.value[ei]));
    }
  }

  return rval;
};

/**
 * Parses a single certificate extension from ASN.1.
 *
 * @param ext the extension in ASN.1 format.
 *
 * @return the parsed extension as an object.
 */
pki$1.certificateExtensionFromAsn1 = function(ext) {
  // an extension has:
  // [0] extnID      OBJECT IDENTIFIER
  // [1] critical    BOOLEAN DEFAULT FALSE
  // [2] extnValue   OCTET STRING
  var e = {};
  e.id = asn1$1.derToOid(ext.value[0].value);
  e.critical = false;
  if(ext.value[1].type === asn1$1.Type.BOOLEAN) {
    e.critical = (ext.value[1].value.charCodeAt(0) !== 0x00);
    e.value = ext.value[2].value;
  } else {
    e.value = ext.value[1].value;
  }
  // if the oid is known, get its name
  if(e.id in oids) {
    e.name = oids[e.id];

    // handle key usage
    if(e.name === 'keyUsage') {
      // get value as BIT STRING
      var ev = asn1$1.fromDer(e.value);
      var b2 = 0x00;
      var b3 = 0x00;
      if(ev.value.length > 1) {
        // skip first byte, just indicates unused bits which
        // will be padded with 0s anyway
        // get bytes with flag bits
        b2 = ev.value.charCodeAt(1);
        b3 = ev.value.length > 2 ? ev.value.charCodeAt(2) : 0;
      }
      // set flags
      e.digitalSignature = (b2 & 0x80) === 0x80;
      e.nonRepudiation = (b2 & 0x40) === 0x40;
      e.keyEncipherment = (b2 & 0x20) === 0x20;
      e.dataEncipherment = (b2 & 0x10) === 0x10;
      e.keyAgreement = (b2 & 0x08) === 0x08;
      e.keyCertSign = (b2 & 0x04) === 0x04;
      e.cRLSign = (b2 & 0x02) === 0x02;
      e.encipherOnly = (b2 & 0x01) === 0x01;
      e.decipherOnly = (b3 & 0x80) === 0x80;
    } else if(e.name === 'basicConstraints') {
      // handle basic constraints
      // get value as SEQUENCE
      var ev = asn1$1.fromDer(e.value);
      // get cA BOOLEAN flag (defaults to false)
      if(ev.value.length > 0 && ev.value[0].type === asn1$1.Type.BOOLEAN) {
        e.cA = (ev.value[0].value.charCodeAt(0) !== 0x00);
      } else {
        e.cA = false;
      }
      // get path length constraint
      var value = null;
      if(ev.value.length > 0 && ev.value[0].type === asn1$1.Type.INTEGER) {
        value = ev.value[0].value;
      } else if(ev.value.length > 1) {
        value = ev.value[1].value;
      }
      if(value !== null) {
        e.pathLenConstraint = asn1$1.derToInteger(value);
      }
    } else if(e.name === 'extKeyUsage') {
      // handle extKeyUsage
      // value is a SEQUENCE of OIDs
      var ev = asn1$1.fromDer(e.value);
      for(var vi = 0; vi < ev.value.length; ++vi) {
        var oid = asn1$1.derToOid(ev.value[vi].value);
        if(oid in oids) {
          e[oids[oid]] = true;
        } else {
          e[oid] = true;
        }
      }
    } else if(e.name === 'nsCertType') {
      // handle nsCertType
      // get value as BIT STRING
      var ev = asn1$1.fromDer(e.value);
      var b2 = 0x00;
      if(ev.value.length > 1) {
        // skip first byte, just indicates unused bits which
        // will be padded with 0s anyway
        // get bytes with flag bits
        b2 = ev.value.charCodeAt(1);
      }
      // set flags
      e.client = (b2 & 0x80) === 0x80;
      e.server = (b2 & 0x40) === 0x40;
      e.email = (b2 & 0x20) === 0x20;
      e.objsign = (b2 & 0x10) === 0x10;
      e.reserved = (b2 & 0x08) === 0x08;
      e.sslCA = (b2 & 0x04) === 0x04;
      e.emailCA = (b2 & 0x02) === 0x02;
      e.objCA = (b2 & 0x01) === 0x01;
    } else if(
      e.name === 'subjectAltName' ||
      e.name === 'issuerAltName') {
      // handle subjectAltName/issuerAltName
      e.altNames = [];

      // ev is a SYNTAX SEQUENCE
      var gn;
      var ev = asn1$1.fromDer(e.value);
      for(var n = 0; n < ev.value.length; ++n) {
        // get GeneralName
        gn = ev.value[n];

        var altName = {
          type: gn.type,
          value: gn.value
        };
        e.altNames.push(altName);

        // Note: Support for types 1,2,6,7,8
        switch(gn.type) {
          // rfc822Name
          case 1:
          // dNSName
          case 2:
          // uniformResourceIdentifier (URI)
          case 6:
            break;
          // IPAddress
          case 7:
            // convert to IPv4/IPv6 string representation
            altName.ip = forge$1.util.bytesToIP(gn.value);
            break;
          // registeredID
          case 8:
            altName.oid = asn1$1.derToOid(gn.value);
            break;
            // unsupported
        }
      }
    } else if(e.name === 'subjectKeyIdentifier') {
      // value is an OCTETSTRING w/the hash of the key-type specific
      // public key structure (eg: RSAPublicKey)
      var ev = asn1$1.fromDer(e.value);
      e.subjectKeyIdentifier = forge$1.util.bytesToHex(ev.value);
    }
  }
  return e;
};

/**
 * Converts a PKCS#10 certification request (CSR) from an ASN.1 object.
 *
 * Note: If the certification request is to be verified then compute hash
 * should be set to true. There is currently no implementation for converting
 * a certificate back to ASN.1 so the CertificationRequestInfo part of the
 * ASN.1 object needs to be scanned before the csr object is created.
 *
 * @param obj the asn1 representation of a PKCS#10 certification request (CSR).
 * @param computeHash true to compute the hash for verification.
 *
 * @return the certification request (CSR).
 */
pki$1.certificationRequestFromAsn1 = function(obj, computeHash) {
  // validate certification request and capture data
  var capture = {};
  var errors = [];
  if(!asn1$1.validate(obj, certificationRequestValidator, capture, errors)) {
    var error = new Error('Cannot read PKCS#10 certificate request. ' +
      'ASN.1 object is not a PKCS#10 CertificationRequest.');
    error.errors = errors;
    throw error;
  }

  // get oid
  var oid = asn1$1.derToOid(capture.publicKeyOid);
  if(oid !== pki$1.oids.rsaEncryption) {
    throw new Error('Cannot read public key. OID is not RSA.');
  }

  // create certification request
  var csr = pki$1.createCertificationRequest();
  csr.version = capture.csrVersion ? capture.csrVersion.charCodeAt(0) : 0;
  csr.signatureOid = forge$1.asn1.derToOid(capture.csrSignatureOid);
  csr.signatureParameters = _readSignatureParameters(
    csr.signatureOid, capture.csrSignatureParams, true);
  csr.siginfo.algorithmOid = forge$1.asn1.derToOid(capture.csrSignatureOid);
  csr.siginfo.parameters = _readSignatureParameters(
    csr.siginfo.algorithmOid, capture.csrSignatureParams, false);
  csr.signature = capture.csrSignature;

  // keep CertificationRequestInfo to preserve signature when exporting
  csr.certificationRequestInfo = capture.certificationRequestInfo;

  if(computeHash) {
    // create digest for OID signature type
    csr.md = _createSignatureDigest({
      signatureOid: csr.signatureOid,
      type: 'certification request'
    });

    // produce DER formatted CertificationRequestInfo and digest it
    var bytes = asn1$1.toDer(csr.certificationRequestInfo);
    csr.md.update(bytes.getBytes());
  }

  // handle subject, build subject message digest
  var smd = forge$1.md.sha1.create();
  csr.subject.getField = function(sn) {
    return _getAttribute(csr.subject, sn);
  };
  csr.subject.addField = function(attr) {
    _fillMissingFields([attr]);
    csr.subject.attributes.push(attr);
  };
  csr.subject.attributes = pki$1.RDNAttributesAsArray(
    capture.certificationRequestInfoSubject, smd);
  csr.subject.hash = smd.digest().toHex();

  // convert RSA public key from ASN.1
  csr.publicKey = pki$1.publicKeyFromAsn1(capture.subjectPublicKeyInfo);

  // convert attributes from ASN.1
  csr.getAttribute = function(sn) {
    return _getAttribute(csr, sn);
  };
  csr.addAttribute = function(attr) {
    _fillMissingFields([attr]);
    csr.attributes.push(attr);
  };
  csr.attributes = pki$1.CRIAttributesAsArray(
    capture.certificationRequestInfoAttributes || []);

  return csr;
};

/**
 * Creates an empty certification request (a CSR or certificate signing
 * request). Once created, its public key and attributes can be set and then
 * it can be signed.
 *
 * @return the empty certification request.
 */
pki$1.createCertificationRequest = function() {
  var csr = {};
  csr.version = 0x00;
  csr.signatureOid = null;
  csr.signature = null;
  csr.siginfo = {};
  csr.siginfo.algorithmOid = null;

  csr.subject = {};
  csr.subject.getField = function(sn) {
    return _getAttribute(csr.subject, sn);
  };
  csr.subject.addField = function(attr) {
    _fillMissingFields([attr]);
    csr.subject.attributes.push(attr);
  };
  csr.subject.attributes = [];
  csr.subject.hash = null;

  csr.publicKey = null;
  csr.attributes = [];
  csr.getAttribute = function(sn) {
    return _getAttribute(csr, sn);
  };
  csr.addAttribute = function(attr) {
    _fillMissingFields([attr]);
    csr.attributes.push(attr);
  };
  csr.md = null;

  /**
   * Sets the subject of this certification request.
   *
   * @param attrs the array of subject attributes to use.
   */
  csr.setSubject = function(attrs) {
    // set new attributes
    _fillMissingFields(attrs);
    csr.subject.attributes = attrs;
    csr.subject.hash = null;
  };

  /**
   * Sets the attributes of this certification request.
   *
   * @param attrs the array of attributes to use.
   */
  csr.setAttributes = function(attrs) {
    // set new attributes
    _fillMissingFields(attrs);
    csr.attributes = attrs;
  };

  /**
   * Signs this certification request using the given private key.
   *
   * @param key the private key to sign with.
   * @param md the message digest object to use (defaults to forge.md.sha1).
   */
  csr.sign = function(key, md) {
    // TODO: get signature OID from private key
    csr.md = md || forge$1.md.sha1.create();
    var algorithmOid = oids[csr.md.algorithm + 'WithRSAEncryption'];
    if(!algorithmOid) {
      var error = new Error('Could not compute certification request digest. ' +
        'Unknown message digest algorithm OID.');
      error.algorithm = csr.md.algorithm;
      throw error;
    }
    csr.signatureOid = csr.siginfo.algorithmOid = algorithmOid;

    // get CertificationRequestInfo, convert to DER
    csr.certificationRequestInfo = pki$1.getCertificationRequestInfo(csr);
    var bytes = asn1$1.toDer(csr.certificationRequestInfo);

    // digest and sign
    csr.md.update(bytes.getBytes());
    csr.signature = key.sign(csr.md);
  };

  /**
   * Attempts verify the signature on the passed certification request using
   * its public key.
   *
   * A CSR that has been exported to a file in PEM format can be verified using
   * OpenSSL using this command:
   *
   * openssl req -in <the-csr-pem-file> -verify -noout -text
   *
   * @return true if verified, false if not.
   */
  csr.verify = function() {
    var rval = false;

    var md = csr.md;
    if(md === null) {
      md = _createSignatureDigest({
        signatureOid: csr.signatureOid,
        type: 'certification request'
      });

      // produce DER formatted CertificationRequestInfo and digest it
      var cri = csr.certificationRequestInfo ||
        pki$1.getCertificationRequestInfo(csr);
      var bytes = asn1$1.toDer(cri);
      md.update(bytes.getBytes());
    }

    if(md !== null) {
      rval = _verifySignature({
        certificate: csr, md: md, signature: csr.signature
      });
    }

    return rval;
  };

  return csr;
};

/**
 * Converts an X.509 subject or issuer to an ASN.1 RDNSequence.
 *
 * @param obj the subject or issuer (distinguished name).
 *
 * @return the ASN.1 RDNSequence.
 */
function _dnToAsn1(obj) {
  // create an empty RDNSequence
  var rval = asn1$1.create(
    asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);

  // iterate over attributes
  var attr, set;
  var attrs = obj.attributes;
  for(var i = 0; i < attrs.length; ++i) {
    attr = attrs[i];
    var value = attr.value;

    // reuse tag class for attribute value if available
    var valueTagClass = asn1$1.Type.PRINTABLESTRING;
    if('valueTagClass' in attr) {
      valueTagClass = attr.valueTagClass;

      if(valueTagClass === asn1$1.Type.UTF8) {
        value = forge$1.util.encodeUtf8(value);
      }
      // FIXME: handle more encodings
    }

    // create a RelativeDistinguishedName set
    // each value in the set is an AttributeTypeAndValue first
    // containing the type (an OID) and second the value
    set = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SET, true, [
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
        // AttributeType
        asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
          asn1$1.oidToDer(attr.type).getBytes()),
        // AttributeValue
        asn1$1.create(asn1$1.Class.UNIVERSAL, valueTagClass, false, value)
      ])
    ]);
    rval.value.push(set);
  }

  return rval;
}

/**
 * Fills in missing fields in attributes.
 *
 * @param attrs the attributes to fill missing fields in.
 */
function _fillMissingFields(attrs) {
  var attr;
  for(var i = 0; i < attrs.length; ++i) {
    attr = attrs[i];

    // populate missing name
    if(typeof attr.name === 'undefined') {
      if(attr.type && attr.type in pki$1.oids) {
        attr.name = pki$1.oids[attr.type];
      } else if(attr.shortName && attr.shortName in _shortNames) {
        attr.name = pki$1.oids[_shortNames[attr.shortName]];
      }
    }

    // populate missing type (OID)
    if(typeof attr.type === 'undefined') {
      if(attr.name && attr.name in pki$1.oids) {
        attr.type = pki$1.oids[attr.name];
      } else {
        var error = new Error('Attribute type not specified.');
        error.attribute = attr;
        throw error;
      }
    }

    // populate missing shortname
    if(typeof attr.shortName === 'undefined') {
      if(attr.name && attr.name in _shortNames) {
        attr.shortName = _shortNames[attr.name];
      }
    }

    // convert extensions to value
    if(attr.type === oids.extensionRequest) {
      attr.valueConstructed = true;
      attr.valueTagClass = asn1$1.Type.SEQUENCE;
      if(!attr.value && attr.extensions) {
        attr.value = [];
        for(var ei = 0; ei < attr.extensions.length; ++ei) {
          attr.value.push(pki$1.certificateExtensionToAsn1(
            _fillMissingExtensionFields(attr.extensions[ei])));
        }
      }
    }

    if(typeof attr.value === 'undefined') {
      var error = new Error('Attribute value not specified.');
      error.attribute = attr;
      throw error;
    }
  }
}

/**
 * Fills in missing fields in certificate extensions.
 *
 * @param e the extension.
 * @param [options] the options to use.
 *          [cert] the certificate the extensions are for.
 *
 * @return the extension.
 */
function _fillMissingExtensionFields(e, options) {
  options = options || {};

  // populate missing name
  if(typeof e.name === 'undefined') {
    if(e.id && e.id in pki$1.oids) {
      e.name = pki$1.oids[e.id];
    }
  }

  // populate missing id
  if(typeof e.id === 'undefined') {
    if(e.name && e.name in pki$1.oids) {
      e.id = pki$1.oids[e.name];
    } else {
      var error = new Error('Extension ID not specified.');
      error.extension = e;
      throw error;
    }
  }

  if(typeof e.value !== 'undefined') {
    return e;
  }

  // handle missing value:

  // value is a BIT STRING
  if(e.name === 'keyUsage') {
    // build flags
    var unused = 0;
    var b2 = 0x00;
    var b3 = 0x00;
    if(e.digitalSignature) {
      b2 |= 0x80;
      unused = 7;
    }
    if(e.nonRepudiation) {
      b2 |= 0x40;
      unused = 6;
    }
    if(e.keyEncipherment) {
      b2 |= 0x20;
      unused = 5;
    }
    if(e.dataEncipherment) {
      b2 |= 0x10;
      unused = 4;
    }
    if(e.keyAgreement) {
      b2 |= 0x08;
      unused = 3;
    }
    if(e.keyCertSign) {
      b2 |= 0x04;
      unused = 2;
    }
    if(e.cRLSign) {
      b2 |= 0x02;
      unused = 1;
    }
    if(e.encipherOnly) {
      b2 |= 0x01;
      unused = 0;
    }
    if(e.decipherOnly) {
      b3 |= 0x80;
      unused = 7;
    }

    // create bit string
    var value = String.fromCharCode(unused);
    if(b3 !== 0) {
      value += String.fromCharCode(b2) + String.fromCharCode(b3);
    } else if(b2 !== 0) {
      value += String.fromCharCode(b2);
    }
    e.value = asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.BITSTRING, false, value);
  } else if(e.name === 'basicConstraints') {
    // basicConstraints is a SEQUENCE
    e.value = asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);
    // cA BOOLEAN flag defaults to false
    if(e.cA) {
      e.value.value.push(asn1$1.create(
        asn1$1.Class.UNIVERSAL, asn1$1.Type.BOOLEAN, false,
        String.fromCharCode(0xFF)));
    }
    if('pathLenConstraint' in e) {
      e.value.value.push(asn1$1.create(
        asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
        asn1$1.integerToDer(e.pathLenConstraint).getBytes()));
    }
  } else if(e.name === 'extKeyUsage') {
    // extKeyUsage is a SEQUENCE of OIDs
    e.value = asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);
    var seq = e.value.value;
    for(var key in e) {
      if(e[key] !== true) {
        continue;
      }
      // key is name in OID map
      if(key in oids) {
        seq.push(asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID,
          false, asn1$1.oidToDer(oids[key]).getBytes()));
      } else if(key.indexOf('.') !== -1) {
        // assume key is an OID
        seq.push(asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID,
          false, asn1$1.oidToDer(key).getBytes()));
      }
    }
  } else if(e.name === 'nsCertType') {
    // nsCertType is a BIT STRING
    // build flags
    var unused = 0;
    var b2 = 0x00;

    if(e.client) {
      b2 |= 0x80;
      unused = 7;
    }
    if(e.server) {
      b2 |= 0x40;
      unused = 6;
    }
    if(e.email) {
      b2 |= 0x20;
      unused = 5;
    }
    if(e.objsign) {
      b2 |= 0x10;
      unused = 4;
    }
    if(e.reserved) {
      b2 |= 0x08;
      unused = 3;
    }
    if(e.sslCA) {
      b2 |= 0x04;
      unused = 2;
    }
    if(e.emailCA) {
      b2 |= 0x02;
      unused = 1;
    }
    if(e.objCA) {
      b2 |= 0x01;
      unused = 0;
    }

    // create bit string
    var value = String.fromCharCode(unused);
    if(b2 !== 0) {
      value += String.fromCharCode(b2);
    }
    e.value = asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.BITSTRING, false, value);
  } else if(e.name === 'subjectAltName' || e.name === 'issuerAltName') {
    // SYNTAX SEQUENCE
    e.value = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);

    var altName;
    for(var n = 0; n < e.altNames.length; ++n) {
      altName = e.altNames[n];
      var value = altName.value;
      // handle IP
      if(altName.type === 7 && altName.ip) {
        value = forge$1.util.bytesFromIP(altName.ip);
        if(value === null) {
          var error = new Error(
            'Extension "ip" value is not a valid IPv4 or IPv6 address.');
          error.extension = e;
          throw error;
        }
      } else if(altName.type === 8) {
        // handle OID
        if(altName.oid) {
          value = asn1$1.oidToDer(asn1$1.oidToDer(altName.oid));
        } else {
          // deprecated ... convert value to OID
          value = asn1$1.oidToDer(value);
        }
      }
      e.value.value.push(asn1$1.create(
        asn1$1.Class.CONTEXT_SPECIFIC, altName.type, false,
        value));
    }
  } else if(e.name === 'nsComment' && options.cert) {
    // sanity check value is ASCII (req'd) and not too big
    if(!(/^[\x00-\x7F]*$/.test(e.comment)) ||
      (e.comment.length < 1) || (e.comment.length > 128)) {
      throw new Error('Invalid "nsComment" content.');
    }
    // IA5STRING opaque comment
    e.value = asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.IA5STRING, false, e.comment);
  } else if(e.name === 'subjectKeyIdentifier' && options.cert) {
    var ski = options.cert.generateSubjectKeyIdentifier();
    e.subjectKeyIdentifier = ski.toHex();
    // OCTETSTRING w/digest
    e.value = asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.OCTETSTRING, false, ski.getBytes());
  } else if(e.name === 'authorityKeyIdentifier' && options.cert) {
    // SYNTAX SEQUENCE
    e.value = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);
    var seq = e.value.value;

    if(e.keyIdentifier) {
      var keyIdentifier = (e.keyIdentifier === true ?
        options.cert.generateSubjectKeyIdentifier().getBytes() :
        e.keyIdentifier);
      seq.push(
        asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 0, false, keyIdentifier));
    }

    if(e.authorityCertIssuer) {
      var authorityCertIssuer = [
        asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 4, true, [
          _dnToAsn1(e.authorityCertIssuer === true ?
            options.cert.issuer : e.authorityCertIssuer)
        ])
      ];
      seq.push(
        asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 1, true, authorityCertIssuer));
    }

    if(e.serialNumber) {
      var serialNumber = forge$1.util.hexToBytes(e.serialNumber === true ?
        options.cert.serialNumber : e.serialNumber);
      seq.push(
        asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 2, false, serialNumber));
    }
  } else if(e.name === 'cRLDistributionPoints') {
    e.value = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);
    var seq = e.value.value;

    // Create sub SEQUENCE of DistributionPointName
    var subSeq = asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);

    // Create fullName CHOICE
    var fullNameGeneralNames = asn1$1.create(
      asn1$1.Class.CONTEXT_SPECIFIC, 0, true, []);
    var altName;
    for(var n = 0; n < e.altNames.length; ++n) {
      altName = e.altNames[n];
      var value = altName.value;
      // handle IP
      if(altName.type === 7 && altName.ip) {
        value = forge$1.util.bytesFromIP(altName.ip);
        if(value === null) {
          var error = new Error(
            'Extension "ip" value is not a valid IPv4 or IPv6 address.');
          error.extension = e;
          throw error;
        }
      } else if(altName.type === 8) {
        // handle OID
        if(altName.oid) {
          value = asn1$1.oidToDer(asn1$1.oidToDer(altName.oid));
        } else {
          // deprecated ... convert value to OID
          value = asn1$1.oidToDer(value);
        }
      }
      fullNameGeneralNames.value.push(asn1$1.create(
        asn1$1.Class.CONTEXT_SPECIFIC, altName.type, false,
        value));
    }

    // Add to the parent SEQUENCE
    subSeq.value.push(asn1$1.create(
      asn1$1.Class.CONTEXT_SPECIFIC, 0, true, [fullNameGeneralNames]));
    seq.push(subSeq);
  }

  // ensure value has been defined by now
  if(typeof e.value === 'undefined') {
    var error = new Error('Extension value not specified.');
    error.extension = e;
    throw error;
  }

  return e;
}

/**
 * Convert signature parameters object to ASN.1
 *
 * @param {String} oid Signature algorithm OID
 * @param params The signature parametrs object
 * @return ASN.1 object representing signature parameters
 */
function _signatureParametersToAsn1(oid, params) {
  switch(oid) {
    case oids['RSASSA-PSS']:
      var parts = [];

      if(params.hash.algorithmOid !== undefined) {
        parts.push(asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 0, true, [
          asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
            asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
              asn1$1.oidToDer(params.hash.algorithmOid).getBytes()),
            asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.NULL, false, '')
          ])
        ]));
      }

      if(params.mgf.algorithmOid !== undefined) {
        parts.push(asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 1, true, [
          asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
            asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
              asn1$1.oidToDer(params.mgf.algorithmOid).getBytes()),
            asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
              asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
                asn1$1.oidToDer(params.mgf.hash.algorithmOid).getBytes()),
              asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.NULL, false, '')
            ])
          ])
        ]));
      }

      if(params.saltLength !== undefined) {
        parts.push(asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 2, true, [
          asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
            asn1$1.integerToDer(params.saltLength).getBytes())
        ]));
      }

      return asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, parts);

    default:
      return asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.NULL, false, '');
  }
}

/**
 * Converts a certification request's attributes to an ASN.1 set of
 * CRIAttributes.
 *
 * @param csr certification request.
 *
 * @return the ASN.1 set of CRIAttributes.
 */
function _CRIAttributesToAsn1(csr) {
  // create an empty context-specific container
  var rval = asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 0, true, []);

  // no attributes, return empty container
  if(csr.attributes.length === 0) {
    return rval;
  }

  // each attribute has a sequence with a type and a set of values
  var attrs = csr.attributes;
  for(var i = 0; i < attrs.length; ++i) {
    var attr = attrs[i];
    var value = attr.value;

    // reuse tag class for attribute value if available
    var valueTagClass = asn1$1.Type.UTF8;
    if('valueTagClass' in attr) {
      valueTagClass = attr.valueTagClass;
    }
    if(valueTagClass === asn1$1.Type.UTF8) {
      value = forge$1.util.encodeUtf8(value);
    }
    var valueConstructed = false;
    if('valueConstructed' in attr) {
      valueConstructed = attr.valueConstructed;
    }
    // FIXME: handle more encodings

    // create a RelativeDistinguishedName set
    // each value in the set is an AttributeTypeAndValue first
    // containing the type (an OID) and second the value
    var seq = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
      // AttributeType
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
        asn1$1.oidToDer(attr.type).getBytes()),
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SET, true, [
        // AttributeValue
        asn1$1.create(
          asn1$1.Class.UNIVERSAL, valueTagClass, valueConstructed, value)
      ])
    ]);
    rval.value.push(seq);
  }

  return rval;
}

var jan_1_1950 = new Date('1950-01-01T00:00:00Z');
var jan_1_2050 = new Date('2050-01-01T00:00:00Z');

/**
 * Converts a Date object to ASN.1
 * Handles the different format before and after 1st January 2050
 *
 * @param date date object.
 *
 * @return the ASN.1 object representing the date.
 */
function _dateToAsn1(date) {
  if(date >= jan_1_1950 && date < jan_1_2050) {
    return asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.UTCTIME, false,
      asn1$1.dateToUtcTime(date));
  } else {
    return asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.GENERALIZEDTIME, false,
      asn1$1.dateToGeneralizedTime(date));
  }
}

/**
 * Gets the ASN.1 TBSCertificate part of an X.509v3 certificate.
 *
 * @param cert the certificate.
 *
 * @return the asn1 TBSCertificate.
 */
pki$1.getTBSCertificate = function(cert) {
  // TBSCertificate
  var notBefore = _dateToAsn1(cert.validity.notBefore);
  var notAfter = _dateToAsn1(cert.validity.notAfter);
  var tbs = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
    // version
    asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 0, true, [
      // integer
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
        asn1$1.integerToDer(cert.version).getBytes())
    ]),
    // serialNumber
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      forge$1.util.hexToBytes(cert.serialNumber)),
    // signature
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
      // algorithm
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
        asn1$1.oidToDer(cert.siginfo.algorithmOid).getBytes()),
      // parameters
      _signatureParametersToAsn1(
        cert.siginfo.algorithmOid, cert.siginfo.parameters)
    ]),
    // issuer
    _dnToAsn1(cert.issuer),
    // validity
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
      notBefore,
      notAfter
    ]),
    // subject
    _dnToAsn1(cert.subject),
    // SubjectPublicKeyInfo
    pki$1.publicKeyToAsn1(cert.publicKey)
  ]);

  if(cert.issuer.uniqueId) {
    // issuerUniqueID (optional)
    tbs.value.push(
      asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 1, true, [
        asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.BITSTRING, false,
          // TODO: support arbitrary bit length ids
          String.fromCharCode(0x00) +
          cert.issuer.uniqueId
        )
      ])
    );
  }
  if(cert.subject.uniqueId) {
    // subjectUniqueID (optional)
    tbs.value.push(
      asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 2, true, [
        asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.BITSTRING, false,
          // TODO: support arbitrary bit length ids
          String.fromCharCode(0x00) +
          cert.subject.uniqueId
        )
      ])
    );
  }

  if(cert.extensions.length > 0) {
    // extensions (optional)
    tbs.value.push(pki$1.certificateExtensionsToAsn1(cert.extensions));
  }

  return tbs;
};

/**
 * Gets the ASN.1 CertificationRequestInfo part of a
 * PKCS#10 CertificationRequest.
 *
 * @param csr the certification request.
 *
 * @return the asn1 CertificationRequestInfo.
 */
pki$1.getCertificationRequestInfo = function(csr) {
  // CertificationRequestInfo
  var cri = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
    // version
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      asn1$1.integerToDer(csr.version).getBytes()),
    // subject
    _dnToAsn1(csr.subject),
    // SubjectPublicKeyInfo
    pki$1.publicKeyToAsn1(csr.publicKey),
    // attributes
    _CRIAttributesToAsn1(csr)
  ]);

  return cri;
};

/**
 * Converts a DistinguishedName (subject or issuer) to an ASN.1 object.
 *
 * @param dn the DistinguishedName.
 *
 * @return the asn1 representation of a DistinguishedName.
 */
pki$1.distinguishedNameToAsn1 = function(dn) {
  return _dnToAsn1(dn);
};

/**
 * Converts an X.509v3 RSA certificate to an ASN.1 object.
 *
 * @param cert the certificate.
 *
 * @return the asn1 representation of an X.509v3 RSA certificate.
 */
pki$1.certificateToAsn1 = function(cert) {
  // prefer cached TBSCertificate over generating one
  var tbsCertificate = cert.tbsCertificate || pki$1.getTBSCertificate(cert);

  // Certificate
  return asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
    // TBSCertificate
    tbsCertificate,
    // AlgorithmIdentifier (signature algorithm)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
      // algorithm
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
        asn1$1.oidToDer(cert.signatureOid).getBytes()),
      // parameters
      _signatureParametersToAsn1(cert.signatureOid, cert.signatureParameters)
    ]),
    // SignatureValue
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.BITSTRING, false,
      String.fromCharCode(0x00) + cert.signature)
  ]);
};

/**
 * Converts X.509v3 certificate extensions to ASN.1.
 *
 * @param exts the extensions to convert.
 *
 * @return the extensions in ASN.1 format.
 */
pki$1.certificateExtensionsToAsn1 = function(exts) {
  // create top-level extension container
  var rval = asn1$1.create(asn1$1.Class.CONTEXT_SPECIFIC, 3, true, []);

  // create extension sequence (stores a sequence for each extension)
  var seq = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);
  rval.value.push(seq);

  for(var i = 0; i < exts.length; ++i) {
    seq.value.push(pki$1.certificateExtensionToAsn1(exts[i]));
  }

  return rval;
};

/**
 * Converts a single certificate extension to ASN.1.
 *
 * @param ext the extension to convert.
 *
 * @return the extension in ASN.1 format.
 */
pki$1.certificateExtensionToAsn1 = function(ext) {
  // create a sequence for each extension
  var extseq = asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);

  // extnID (OID)
  extseq.value.push(asn1$1.create(
    asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
    asn1$1.oidToDer(ext.id).getBytes()));

  // critical defaults to false
  if(ext.critical) {
    // critical BOOLEAN DEFAULT FALSE
    extseq.value.push(asn1$1.create(
      asn1$1.Class.UNIVERSAL, asn1$1.Type.BOOLEAN, false,
      String.fromCharCode(0xFF)));
  }

  var value = ext.value;
  if(typeof ext.value !== 'string') {
    // value is asn.1
    value = asn1$1.toDer(value).getBytes();
  }

  // extnValue (OCTET STRING)
  extseq.value.push(asn1$1.create(
    asn1$1.Class.UNIVERSAL, asn1$1.Type.OCTETSTRING, false, value));

  return extseq;
};

/**
 * Converts a PKCS#10 certification request to an ASN.1 object.
 *
 * @param csr the certification request.
 *
 * @return the asn1 representation of a certification request.
 */
pki$1.certificationRequestToAsn1 = function(csr) {
  // prefer cached CertificationRequestInfo over generating one
  var cri = csr.certificationRequestInfo ||
    pki$1.getCertificationRequestInfo(csr);

  // Certificate
  return asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
    // CertificationRequestInfo
    cri,
    // AlgorithmIdentifier (signature algorithm)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
      // algorithm
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
        asn1$1.oidToDer(csr.signatureOid).getBytes()),
      // parameters
      _signatureParametersToAsn1(csr.signatureOid, csr.signatureParameters)
    ]),
    // signature
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.BITSTRING, false,
      String.fromCharCode(0x00) + csr.signature)
  ]);
};

/**
 * Creates a CA store.
 *
 * @param certs an optional array of certificate objects or PEM-formatted
 *          certificate strings to add to the CA store.
 *
 * @return the CA store.
 */
pki$1.createCaStore = function(certs) {
  // create CA store
  var caStore = {
    // stored certificates
    certs: {}
  };

  /**
   * Gets the certificate that issued the passed certificate or its
   * 'parent'.
   *
   * @param cert the certificate to get the parent for.
   *
   * @return the parent certificate or null if none was found.
   */
  caStore.getIssuer = function(cert) {
    var rval = getBySubject(cert.issuer);

    // see if there are multiple matches
    /*if(forge.util.isArray(rval)) {
      // TODO: resolve multiple matches by checking
      // authorityKey/subjectKey/issuerUniqueID/other identifiers, etc.
      // FIXME: or alternatively do authority key mapping
      // if possible (X.509v1 certs can't work?)
      throw new Error('Resolving multiple issuer matches not implemented yet.');
    }*/

    return rval;
  };

  /**
   * Adds a trusted certificate to the store.
   *
   * @param cert the certificate to add as a trusted certificate (either a
   *          pki.certificate object or a PEM-formatted certificate).
   */
  caStore.addCertificate = function(cert) {
    // convert from pem if necessary
    if(typeof cert === 'string') {
      cert = forge$1.pki.certificateFromPem(cert);
    }

    ensureSubjectHasHash(cert.subject);

    if(!caStore.hasCertificate(cert)) { // avoid duplicate certificates in store
      if(cert.subject.hash in caStore.certs) {
        // subject hash already exists, append to array
        var tmp = caStore.certs[cert.subject.hash];
        if(!forge$1.util.isArray(tmp)) {
          tmp = [tmp];
        }
        tmp.push(cert);
        caStore.certs[cert.subject.hash] = tmp;
      } else {
        caStore.certs[cert.subject.hash] = cert;
      }
    }
  };

  /**
   * Checks to see if the given certificate is in the store.
   *
   * @param cert the certificate to check (either a pki.certificate or a
   *          PEM-formatted certificate).
   *
   * @return true if the certificate is in the store, false if not.
   */
  caStore.hasCertificate = function(cert) {
    // convert from pem if necessary
    if(typeof cert === 'string') {
      cert = forge$1.pki.certificateFromPem(cert);
    }

    var match = getBySubject(cert.subject);
    if(!match) {
      return false;
    }
    if(!forge$1.util.isArray(match)) {
      match = [match];
    }
    // compare DER-encoding of certificates
    var der1 = asn1$1.toDer(pki$1.certificateToAsn1(cert)).getBytes();
    for(var i = 0; i < match.length; ++i) {
      var der2 = asn1$1.toDer(pki$1.certificateToAsn1(match[i])).getBytes();
      if(der1 === der2) {
        return true;
      }
    }
    return false;
  };

  /**
   * Lists all of the certificates kept in the store.
   *
   * @return an array of all of the pki.certificate objects in the store.
   */
  caStore.listAllCertificates = function() {
    var certList = [];

    for(var hash in caStore.certs) {
      if(caStore.certs.hasOwnProperty(hash)) {
        var value = caStore.certs[hash];
        if(!forge$1.util.isArray(value)) {
          certList.push(value);
        } else {
          for(var i = 0; i < value.length; ++i) {
            certList.push(value[i]);
          }
        }
      }
    }

    return certList;
  };

  /**
   * Removes a certificate from the store.
   *
   * @param cert the certificate to remove (either a pki.certificate or a
   *          PEM-formatted certificate).
   *
   * @return the certificate that was removed or null if the certificate
   *           wasn't in store.
   */
  caStore.removeCertificate = function(cert) {
    var result;

    // convert from pem if necessary
    if(typeof cert === 'string') {
      cert = forge$1.pki.certificateFromPem(cert);
    }
    ensureSubjectHasHash(cert.subject);
    if(!caStore.hasCertificate(cert)) {
      return null;
    }

    var match = getBySubject(cert.subject);

    if(!forge$1.util.isArray(match)) {
      result = caStore.certs[cert.subject.hash];
      delete caStore.certs[cert.subject.hash];
      return result;
    }

    // compare DER-encoding of certificates
    var der1 = asn1$1.toDer(pki$1.certificateToAsn1(cert)).getBytes();
    for(var i = 0; i < match.length; ++i) {
      var der2 = asn1$1.toDer(pki$1.certificateToAsn1(match[i])).getBytes();
      if(der1 === der2) {
        result = match[i];
        match.splice(i, 1);
      }
    }
    if(match.length === 0) {
      delete caStore.certs[cert.subject.hash];
    }

    return result;
  };

  function getBySubject(subject) {
    ensureSubjectHasHash(subject);
    return caStore.certs[subject.hash] || null;
  }

  function ensureSubjectHasHash(subject) {
    // produce subject hash if it doesn't exist
    if(!subject.hash) {
      var md = forge$1.md.sha1.create();
      subject.attributes = pki$1.RDNAttributesAsArray(_dnToAsn1(subject), md);
      subject.hash = md.digest().toHex();
    }
  }

  // auto-add passed in certs
  if(certs) {
    // parse PEM-formatted certificates as necessary
    for(var i = 0; i < certs.length; ++i) {
      var cert = certs[i];
      caStore.addCertificate(cert);
    }
  }

  return caStore;
};

/**
 * Certificate verification errors, based on TLS.
 */
pki$1.certificateError = {
  bad_certificate: 'forge.pki.BadCertificate',
  unsupported_certificate: 'forge.pki.UnsupportedCertificate',
  certificate_revoked: 'forge.pki.CertificateRevoked',
  certificate_expired: 'forge.pki.CertificateExpired',
  certificate_unknown: 'forge.pki.CertificateUnknown',
  unknown_ca: 'forge.pki.UnknownCertificateAuthority'
};

/**
 * Verifies a certificate chain against the given Certificate Authority store
 * with an optional custom verify callback.
 *
 * @param caStore a certificate store to verify against.
 * @param chain the certificate chain to verify, with the root or highest
 *          authority at the end (an array of certificates).
 * @param options a callback to be called for every certificate in the chain or
 *                  an object with:
 *                  verify a callback to be called for every certificate in the
 *                    chain
 *                  validityCheckDate the date against which the certificate
 *                    validity period should be checked. Pass null to not check
 *                    the validity period. By default, the current date is used.
 *
 * The verify callback has the following signature:
 *
 * verified - Set to true if certificate was verified, otherwise the
 *   pki.certificateError for why the certificate failed.
 * depth - The current index in the chain, where 0 is the end point's cert.
 * certs - The certificate chain, *NOTE* an empty chain indicates an anonymous
 *   end point.
 *
 * The function returns true on success and on failure either the appropriate
 * pki.certificateError or an object with 'error' set to the appropriate
 * pki.certificateError and 'message' set to a custom error message.
 *
 * @return true if successful, error thrown if not.
 */
pki$1.verifyCertificateChain = function(caStore, chain, options) {
  /* From: RFC3280 - Internet X.509 Public Key Infrastructure Certificate
    Section 6: Certification Path Validation
    See inline parentheticals related to this particular implementation.

    The primary goal of path validation is to verify the binding between
    a subject distinguished name or a subject alternative name and subject
    public key, as represented in the end entity certificate, based on the
    public key of the trust anchor. This requires obtaining a sequence of
    certificates that support that binding. That sequence should be provided
    in the passed 'chain'. The trust anchor should be in the given CA
    store. The 'end entity' certificate is the certificate provided by the
    end point (typically a server) and is the first in the chain.

    To meet this goal, the path validation process verifies, among other
    things, that a prospective certification path (a sequence of n
    certificates or a 'chain') satisfies the following conditions:

    (a) for all x in {1, ..., n-1}, the subject of certificate x is
          the issuer of certificate x+1;

    (b) certificate 1 is issued by the trust anchor;

    (c) certificate n is the certificate to be validated; and

    (d) for all x in {1, ..., n}, the certificate was valid at the
          time in question.

    Note that here 'n' is index 0 in the chain and 1 is the last certificate
    in the chain and it must be signed by a certificate in the connection's
    CA store.

    The path validation process also determines the set of certificate
    policies that are valid for this path, based on the certificate policies
    extension, policy mapping extension, policy constraints extension, and
    inhibit any-policy extension.

    Note: Policy mapping extension not supported (Not Required).

    Note: If the certificate has an unsupported critical extension, then it
    must be rejected.

    Note: A certificate is self-issued if the DNs that appear in the subject
    and issuer fields are identical and are not empty.

    The path validation algorithm assumes the following seven inputs are
    provided to the path processing logic. What this specific implementation
    will use is provided parenthetically:

    (a) a prospective certification path of length n (the 'chain')
    (b) the current date/time: ('now').
    (c) user-initial-policy-set: A set of certificate policy identifiers
          naming the policies that are acceptable to the certificate user.
          The user-initial-policy-set contains the special value any-policy
          if the user is not concerned about certificate policy
          (Not implemented. Any policy is accepted).
    (d) trust anchor information, describing a CA that serves as a trust
          anchor for the certification path. The trust anchor information
          includes:

      (1)  the trusted issuer name,
      (2)  the trusted public key algorithm,
      (3)  the trusted public key, and
      (4)  optionally, the trusted public key parameters associated
             with the public key.

      (Trust anchors are provided via certificates in the CA store).

      The trust anchor information may be provided to the path processing
      procedure in the form of a self-signed certificate. The trusted anchor
      information is trusted because it was delivered to the path processing
      procedure by some trustworthy out-of-band procedure. If the trusted
      public key algorithm requires parameters, then the parameters are
      provided along with the trusted public key (No parameters used in this
      implementation).

    (e) initial-policy-mapping-inhibit, which indicates if policy mapping is
          allowed in the certification path.
          (Not implemented, no policy checking)

    (f) initial-explicit-policy, which indicates if the path must be valid
          for at least one of the certificate policies in the user-initial-
          policy-set.
          (Not implemented, no policy checking)

    (g) initial-any-policy-inhibit, which indicates whether the
          anyPolicy OID should be processed if it is included in a
          certificate.
          (Not implemented, so any policy is valid provided that it is
          not marked as critical) */

  /* Basic Path Processing:

    For each certificate in the 'chain', the following is checked:

    1. The certificate validity period includes the current time.
    2. The certificate was signed by its parent (where the parent is either
       the next in the chain or from the CA store). Allow processing to
       continue to the next step if no parent is found but the certificate is
       in the CA store.
    3. TODO: The certificate has not been revoked.
    4. The certificate issuer name matches the parent's subject name.
    5. TODO: If the certificate is self-issued and not the final certificate
       in the chain, skip this step, otherwise verify that the subject name
       is within one of the permitted subtrees of X.500 distinguished names
       and that each of the alternative names in the subjectAltName extension
       (critical or non-critical) is within one of the permitted subtrees for
       that name type.
    6. TODO: If the certificate is self-issued and not the final certificate
       in the chain, skip this step, otherwise verify that the subject name
       is not within one of the excluded subtrees for X.500 distinguished
       names and none of the subjectAltName extension names are excluded for
       that name type.
    7. The other steps in the algorithm for basic path processing involve
       handling the policy extension which is not presently supported in this
       implementation. Instead, if a critical policy extension is found, the
       certificate is rejected as not supported.
    8. If the certificate is not the first or if its the only certificate in
       the chain (having no parent from the CA store or is self-signed) and it
       has a critical key usage extension, verify that the keyCertSign bit is
       set. If the key usage extension exists, verify that the basic
       constraints extension exists. If the basic constraints extension exists,
       verify that the cA flag is set. If pathLenConstraint is set, ensure that
       the number of certificates that precede in the chain (come earlier
       in the chain as implemented below), excluding the very first in the
       chain (typically the end-entity one), isn't greater than the
       pathLenConstraint. This constraint limits the number of intermediate
       CAs that may appear below a CA before only end-entity certificates
       may be issued. */

  // if a verify callback is passed as the third parameter, package it within
  // the options object. This is to support a legacy function signature that
  // expected the verify callback as the third parameter.
  if(typeof options === 'function') {
    options = {verify: options};
  }
  options = options || {};

  // copy cert chain references to another array to protect against changes
  // in verify callback
  chain = chain.slice(0);
  var certs = chain.slice(0);

  var validityCheckDate = options.validityCheckDate;
  // if no validityCheckDate is specified, default to the current date. Make
  // sure to maintain the value null because it indicates that the validity
  // period should not be checked.
  if(typeof validityCheckDate === 'undefined') {
    validityCheckDate = new Date();
  }

  // verify each cert in the chain using its parent, where the parent
  // is either the next in the chain or from the CA store
  var first = true;
  var error = null;
  var depth = 0;
  do {
    var cert = chain.shift();
    var parent = null;
    var selfSigned = false;

    if(validityCheckDate) {
      // 1. check valid time
      if(validityCheckDate < cert.validity.notBefore ||
         validityCheckDate > cert.validity.notAfter) {
        error = {
          message: 'Certificate is not valid yet or has expired.',
          error: pki$1.certificateError.certificate_expired,
          notBefore: cert.validity.notBefore,
          notAfter: cert.validity.notAfter,
          // TODO: we might want to reconsider renaming 'now' to
          // 'validityCheckDate' should this API be changed in the future.
          now: validityCheckDate
        };
      }
    }

    // 2. verify with parent from chain or CA store
    if(error === null) {
      parent = chain[0] || caStore.getIssuer(cert);
      if(parent === null) {
        // check for self-signed cert
        if(cert.isIssuer(cert)) {
          selfSigned = true;
          parent = cert;
        }
      }

      if(parent) {
        // FIXME: current CA store implementation might have multiple
        // certificates where the issuer can't be determined from the
        // certificate (happens rarely with, eg: old certificates) so normalize
        // by always putting parents into an array
        // TODO: there's may be an extreme degenerate case currently uncovered
        // where an old intermediate certificate seems to have a matching parent
        // but none of the parents actually verify ... but the intermediate
        // is in the CA and it should pass this check; needs investigation
        var parents = parent;
        if(!forge$1.util.isArray(parents)) {
          parents = [parents];
        }

        // try to verify with each possible parent (typically only one)
        var verified = false;
        while(!verified && parents.length > 0) {
          parent = parents.shift();
          try {
            verified = parent.verify(cert);
          } catch(ex) {
            // failure to verify, don't care why, try next one
          }
        }

        if(!verified) {
          error = {
            message: 'Certificate signature is invalid.',
            error: pki$1.certificateError.bad_certificate
          };
        }
      }

      if(error === null && (!parent || selfSigned) &&
        !caStore.hasCertificate(cert)) {
        // no parent issuer and certificate itself is not trusted
        error = {
          message: 'Certificate is not trusted.',
          error: pki$1.certificateError.unknown_ca
        };
      }
    }

    // TODO: 3. check revoked

    // 4. check for matching issuer/subject
    if(error === null && parent && !cert.isIssuer(parent)) {
      // parent is not issuer
      error = {
        message: 'Certificate issuer is invalid.',
        error: pki$1.certificateError.bad_certificate
      };
    }

    // 5. TODO: check names with permitted names tree

    // 6. TODO: check names against excluded names tree

    // 7. check for unsupported critical extensions
    if(error === null) {
      // supported extensions
      var se = {
        keyUsage: true,
        basicConstraints: true
      };
      for(var i = 0; error === null && i < cert.extensions.length; ++i) {
        var ext = cert.extensions[i];
        if(ext.critical && !(ext.name in se)) {
          error = {
            message:
              'Certificate has an unsupported critical extension.',
            error: pki$1.certificateError.unsupported_certificate
          };
        }
      }
    }

    // 8. check for CA if cert is not first or is the only certificate
    // remaining in chain with no parent or is self-signed
    if(error === null &&
      (!first || (chain.length === 0 && (!parent || selfSigned)))) {
      // first check keyUsage extension and then basic constraints
      var bcExt = cert.getExtension('basicConstraints');
      var keyUsageExt = cert.getExtension('keyUsage');
      if(keyUsageExt !== null) {
        // keyCertSign must be true and there must be a basic
        // constraints extension
        if(!keyUsageExt.keyCertSign || bcExt === null) {
          // bad certificate
          error = {
            message:
              'Certificate keyUsage or basicConstraints conflict ' +
              'or indicate that the certificate is not a CA. ' +
              'If the certificate is the only one in the chain or ' +
              'isn\'t the first then the certificate must be a ' +
              'valid CA.',
            error: pki$1.certificateError.bad_certificate
          };
        }
      }
      // basic constraints cA flag must be set
      if(error === null && bcExt !== null && !bcExt.cA) {
        // bad certificate
        error = {
          message:
            'Certificate basicConstraints indicates the certificate ' +
            'is not a CA.',
          error: pki$1.certificateError.bad_certificate
        };
      }
      // if error is not null and keyUsage is available, then we know it
      // has keyCertSign and there is a basic constraints extension too,
      // which means we can check pathLenConstraint (if it exists)
      if(error === null && keyUsageExt !== null &&
        'pathLenConstraint' in bcExt) {
        // pathLen is the maximum # of intermediate CA certs that can be
        // found between the current certificate and the end-entity (depth 0)
        // certificate; this number does not include the end-entity (depth 0,
        // last in the chain) even if it happens to be a CA certificate itself
        var pathLen = depth - 1;
        if(pathLen > bcExt.pathLenConstraint) {
          // pathLenConstraint violated, bad certificate
          error = {
            message:
              'Certificate basicConstraints pathLenConstraint violated.',
            error: pki$1.certificateError.bad_certificate
          };
        }
      }
    }

    // call application callback
    var vfd = (error === null) ? true : error.error;
    var ret = options.verify ? options.verify(vfd, depth, certs) : vfd;
    if(ret === true) {
      // clear any set error
      error = null;
    } else {
      // if passed basic tests, set default message and alert
      if(vfd === true) {
        error = {
          message: 'The application rejected the certificate.',
          error: pki$1.certificateError.bad_certificate
        };
      }

      // check for custom error info
      if(ret || ret === 0) {
        // set custom message and error
        if(typeof ret === 'object' && !forge$1.util.isArray(ret)) {
          if(ret.message) {
            error.message = ret.message;
          }
          if(ret.error) {
            error.error = ret.error;
          }
        } else if(typeof ret === 'string') {
          // set custom error
          error.error = ret;
        }
      }

      // throw error
      throw error;
    }

    // no longer first cert in chain
    first = false;
    ++depth;
  } while(chain.length > 0);

  return true;
};

/**
 * Javascript implementation of PKCS#7 v1.5.
 *
 * @author Stefan Siegl
 * @author Dave Longley
 *
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 * Copyright (c) 2012-2015 Digital Bazaar, Inc.
 *
 * Currently this implementation only supports ContentType of EnvelopedData,
 * EncryptedData, or SignedData at the root level. The top level elements may
 * contain only a ContentInfo of ContentType Data, i.e. plain data. Further
 * nesting is not (yet) supported.
 *
 * The Forge validators for PKCS #7's ASN.1 structures are available from
 * a separate file pkcs7asn1.js, since those are referenced from other
 * PKCS standards like PKCS #12.
 */

var forge = forge$s;










// shortcut for ASN.1 API
var asn1 = forge.asn1;

// shortcut for PKCS#7 API
var p7 = forge.pkcs7 = forge.pkcs7 || {};

/**
 * Converts a PKCS#7 message from PEM format.
 *
 * @param pem the PEM-formatted PKCS#7 message.
 *
 * @return the PKCS#7 message.
 */
p7.messageFromPem = function(pem) {
  var msg = forge.pem.decode(pem)[0];

  if(msg.type !== 'PKCS7') {
    var error = new Error('Could not convert PKCS#7 message from PEM; PEM ' +
      'header type is not "PKCS#7".');
    error.headerType = msg.type;
    throw error;
  }
  if(msg.procType && msg.procType.type === 'ENCRYPTED') {
    throw new Error('Could not convert PKCS#7 message from PEM; PEM is encrypted.');
  }

  // convert DER to ASN.1 object
  var obj = asn1.fromDer(msg.body);

  return p7.messageFromAsn1(obj);
};

/**
 * Converts a PKCS#7 message to PEM format.
 *
 * @param msg The PKCS#7 message object
 * @param maxline The maximum characters per line, defaults to 64.
 *
 * @return The PEM-formatted PKCS#7 message.
 */
p7.messageToPem = function(msg, maxline) {
  // convert to ASN.1, then DER, then PEM-encode
  var pemObj = {
    type: 'PKCS7',
    body: asn1.toDer(msg.toAsn1()).getBytes()
  };
  return forge.pem.encode(pemObj, {maxline: maxline});
};

/**
 * Converts a PKCS#7 message from an ASN.1 object.
 *
 * @param obj the ASN.1 representation of a ContentInfo.
 *
 * @return the PKCS#7 message.
 */
p7.messageFromAsn1 = function(obj) {
  // validate root level ContentInfo and capture data
  var capture = {};
  var errors = [];
  if(!asn1.validate(obj, p7.asn1.contentInfoValidator, capture, errors)) {
    var error = new Error('Cannot read PKCS#7 message. ' +
      'ASN.1 object is not an PKCS#7 ContentInfo.');
    error.errors = errors;
    throw error;
  }

  var contentType = asn1.derToOid(capture.contentType);
  var msg;

  switch(contentType) {
    case forge.pki.oids.envelopedData:
      msg = p7.createEnvelopedData();
      break;

    case forge.pki.oids.encryptedData:
      msg = p7.createEncryptedData();
      break;

    case forge.pki.oids.signedData:
      msg = p7.createSignedData();
      break;

    default:
      throw new Error('Cannot read PKCS#7 message. ContentType with OID ' +
        contentType + ' is not (yet) supported.');
  }

  msg.fromAsn1(capture.content.value[0]);
  return msg;
};

p7.createSignedData = function() {
  var msg = null;
  msg = {
    type: forge.pki.oids.signedData,
    version: 1,
    certificates: [],
    crls: [],
    // TODO: add json-formatted signer stuff here?
    signers: [],
    // populated during sign()
    digestAlgorithmIdentifiers: [],
    contentInfo: null,
    signerInfos: [],

    fromAsn1: function(obj) {
      // validate SignedData content block and capture data.
      _fromAsn1(msg, obj, p7.asn1.signedDataValidator);
      msg.certificates = [];
      msg.crls = [];
      msg.digestAlgorithmIdentifiers = [];
      msg.contentInfo = null;
      msg.signerInfos = [];

      if(msg.rawCapture.certificates) {
        var certs = msg.rawCapture.certificates.value;
        for(var i = 0; i < certs.length; ++i) {
          msg.certificates.push(forge.pki.certificateFromAsn1(certs[i]));
        }
      }

      // TODO: parse crls
    },

    toAsn1: function() {
      // degenerate case with no content
      if(!msg.contentInfo) {
        msg.sign();
      }

      var certs = [];
      for(var i = 0; i < msg.certificates.length; ++i) {
        certs.push(forge.pki.certificateToAsn1(msg.certificates[i]));
      }

      var crls = [];
      // TODO: implement CRLs

      // [0] SignedData
      var signedData = asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
          // Version
          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
            asn1.integerToDer(msg.version).getBytes()),
          // DigestAlgorithmIdentifiers
          asn1.create(
            asn1.Class.UNIVERSAL, asn1.Type.SET, true,
            msg.digestAlgorithmIdentifiers),
          // ContentInfo
          msg.contentInfo
        ])
      ]);
      if(certs.length > 0) {
        // [0] IMPLICIT ExtendedCertificatesAndCertificates OPTIONAL
        signedData.value[0].value.push(
          asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, certs));
      }
      if(crls.length > 0) {
        // [1] IMPLICIT CertificateRevocationLists OPTIONAL
        signedData.value[0].value.push(
          asn1.create(asn1.Class.CONTEXT_SPECIFIC, 1, true, crls));
      }
      // SignerInfos
      signedData.value[0].value.push(
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true,
          msg.signerInfos));

      // ContentInfo
      return asn1.create(
        asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
          // ContentType
          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
            asn1.oidToDer(msg.type).getBytes()),
          // [0] SignedData
          signedData
        ]);
    },

    /**
     * Add (another) entity to list of signers.
     *
     * Note: If authenticatedAttributes are provided, then, per RFC 2315,
     * they must include at least two attributes: content type and
     * message digest. The message digest attribute value will be
     * auto-calculated during signing and will be ignored if provided.
     *
     * Here's an example of providing these two attributes:
     *
     * forge.pkcs7.createSignedData();
     * p7.addSigner({
     *   issuer: cert.issuer.attributes,
     *   serialNumber: cert.serialNumber,
     *   key: privateKey,
     *   digestAlgorithm: forge.pki.oids.sha1,
     *   authenticatedAttributes: [{
     *     type: forge.pki.oids.contentType,
     *     value: forge.pki.oids.data
     *   }, {
     *     type: forge.pki.oids.messageDigest
     *   }]
     * });
     *
     * TODO: Support [subjectKeyIdentifier] as signer's ID.
     *
     * @param signer the signer information:
     *          key the signer's private key.
     *          [certificate] a certificate containing the public key
     *            associated with the signer's private key; use this option as
     *            an alternative to specifying signer.issuer and
     *            signer.serialNumber.
     *          [issuer] the issuer attributes (eg: cert.issuer.attributes).
     *          [serialNumber] the signer's certificate's serial number in
     *           hexadecimal (eg: cert.serialNumber).
     *          [digestAlgorithm] the message digest OID, as a string, to use
     *            (eg: forge.pki.oids.sha1).
     *          [authenticatedAttributes] an optional array of attributes
     *            to also sign along with the content.
     */
    addSigner: function(signer) {
      var issuer = signer.issuer;
      var serialNumber = signer.serialNumber;
      if(signer.certificate) {
        var cert = signer.certificate;
        if(typeof cert === 'string') {
          cert = forge.pki.certificateFromPem(cert);
        }
        issuer = cert.issuer.attributes;
        serialNumber = cert.serialNumber;
      }
      var key = signer.key;
      if(!key) {
        throw new Error(
          'Could not add PKCS#7 signer; no private key specified.');
      }
      if(typeof key === 'string') {
        key = forge.pki.privateKeyFromPem(key);
      }

      // ensure OID known for digest algorithm
      var digestAlgorithm = signer.digestAlgorithm || forge.pki.oids.sha1;
      switch(digestAlgorithm) {
      case forge.pki.oids.sha1:
      case forge.pki.oids.sha256:
      case forge.pki.oids.sha384:
      case forge.pki.oids.sha512:
      case forge.pki.oids.md5:
        break;
      default:
        throw new Error(
          'Could not add PKCS#7 signer; unknown message digest algorithm: ' +
          digestAlgorithm);
      }

      // if authenticatedAttributes is present, then the attributes
      // must contain at least PKCS #9 content-type and message-digest
      var authenticatedAttributes = signer.authenticatedAttributes || [];
      if(authenticatedAttributes.length > 0) {
        var contentType = false;
        var messageDigest = false;
        for(var i = 0; i < authenticatedAttributes.length; ++i) {
          var attr = authenticatedAttributes[i];
          if(!contentType && attr.type === forge.pki.oids.contentType) {
            contentType = true;
            if(messageDigest) {
              break;
            }
            continue;
          }
          if(!messageDigest && attr.type === forge.pki.oids.messageDigest) {
            messageDigest = true;
            if(contentType) {
              break;
            }
            continue;
          }
        }

        if(!contentType || !messageDigest) {
          throw new Error('Invalid signer.authenticatedAttributes. If ' +
            'signer.authenticatedAttributes is specified, then it must ' +
            'contain at least two attributes, PKCS #9 content-type and ' +
            'PKCS #9 message-digest.');
        }
      }

      msg.signers.push({
        key: key,
        version: 1,
        issuer: issuer,
        serialNumber: serialNumber,
        digestAlgorithm: digestAlgorithm,
        signatureAlgorithm: forge.pki.oids.rsaEncryption,
        signature: null,
        authenticatedAttributes: authenticatedAttributes,
        unauthenticatedAttributes: []
      });
    },

    /**
     * Signs the content.
     * @param options Options to apply when signing:
     *    [detached] boolean. If signing should be done in detached mode. Defaults to false.
     */
    sign: function(options) {
      options = options || {};
      // auto-generate content info
      if(typeof msg.content !== 'object' || msg.contentInfo === null) {
        // use Data ContentInfo
        msg.contentInfo = asn1.create(
          asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
            // ContentType
            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
              asn1.oidToDer(forge.pki.oids.data).getBytes())
          ]);

        // add actual content, if present
        if('content' in msg) {
          var content;
          if(msg.content instanceof forge.util.ByteBuffer) {
            content = msg.content.bytes();
          } else if(typeof msg.content === 'string') {
            content = forge.util.encodeUtf8(msg.content);
          }

          if (options.detached) {
            msg.detachedContent = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, content);
          } else {
            msg.contentInfo.value.push(
              // [0] EXPLICIT content
              asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [
                asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,
                  content)
              ]));
          }
        }
      }

      // no signers, return early (degenerate case for certificate container)
      if(msg.signers.length === 0) {
        return;
      }

      // generate digest algorithm identifiers
      var mds = addDigestAlgorithmIds();

      // generate signerInfos
      addSignerInfos(mds);
    },

    verify: function() {
      throw new Error('PKCS#7 signature verification not yet implemented.');
    },

    /**
     * Add a certificate.
     *
     * @param cert the certificate to add.
     */
    addCertificate: function(cert) {
      // convert from PEM
      if(typeof cert === 'string') {
        cert = forge.pki.certificateFromPem(cert);
      }
      msg.certificates.push(cert);
    },

    /**
     * Add a certificate revokation list.
     *
     * @param crl the certificate revokation list to add.
     */
    addCertificateRevokationList: function(crl) {
      throw new Error('PKCS#7 CRL support not yet implemented.');
    }
  };
  return msg;

  function addDigestAlgorithmIds() {
    var mds = {};

    for(var i = 0; i < msg.signers.length; ++i) {
      var signer = msg.signers[i];
      var oid = signer.digestAlgorithm;
      if(!(oid in mds)) {
        // content digest
        mds[oid] = forge.md[forge.pki.oids[oid]].create();
      }
      if(signer.authenticatedAttributes.length === 0) {
        // no custom attributes to digest; use content message digest
        signer.md = mds[oid];
      } else {
        // custom attributes to be digested; use own message digest
        // TODO: optimize to just copy message digest state if that
        // feature is ever supported with message digests
        signer.md = forge.md[forge.pki.oids[oid]].create();
      }
    }

    // add unique digest algorithm identifiers
    msg.digestAlgorithmIdentifiers = [];
    for(var oid in mds) {
      msg.digestAlgorithmIdentifiers.push(
        // AlgorithmIdentifier
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
          // algorithm
          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
            asn1.oidToDer(oid).getBytes()),
          // parameters (null)
          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')
        ]));
    }

    return mds;
  }

  function addSignerInfos(mds) {
    var content;

    if (msg.detachedContent) {
      // Signature has been made in detached mode.
      content = msg.detachedContent;
    } else {
      // Note: ContentInfo is a SEQUENCE with 2 values, second value is
      // the content field and is optional for a ContentInfo but required here
      // since signers are present
      // get ContentInfo content
      content = msg.contentInfo.value[1];
      // skip [0] EXPLICIT content wrapper
      content = content.value[0];
    }

    if(!content) {
      throw new Error(
        'Could not sign PKCS#7 message; there is no content to sign.');
    }

    // get ContentInfo content type
    var contentType = asn1.derToOid(msg.contentInfo.value[0].value);

    // serialize content
    var bytes = asn1.toDer(content);

    // skip identifier and length per RFC 2315 9.3
    // skip identifier (1 byte)
    bytes.getByte();
    // read and discard length bytes
    asn1.getBerValueLength(bytes);
    bytes = bytes.getBytes();

    // digest content DER value bytes
    for(var oid in mds) {
      mds[oid].start().update(bytes);
    }

    // sign content
    var signingTime = new Date();
    for(var i = 0; i < msg.signers.length; ++i) {
      var signer = msg.signers[i];

      if(signer.authenticatedAttributes.length === 0) {
        // if ContentInfo content type is not "Data", then
        // authenticatedAttributes must be present per RFC 2315
        if(contentType !== forge.pki.oids.data) {
          throw new Error(
            'Invalid signer; authenticatedAttributes must be present ' +
            'when the ContentInfo content type is not PKCS#7 Data.');
        }
      } else {
        // process authenticated attributes
        // [0] IMPLICIT
        signer.authenticatedAttributesAsn1 = asn1.create(
          asn1.Class.CONTEXT_SPECIFIC, 0, true, []);

        // per RFC 2315, attributes are to be digested using a SET container
        // not the above [0] IMPLICIT container
        var attrsAsn1 = asn1.create(
          asn1.Class.UNIVERSAL, asn1.Type.SET, true, []);

        for(var ai = 0; ai < signer.authenticatedAttributes.length; ++ai) {
          var attr = signer.authenticatedAttributes[ai];
          if(attr.type === forge.pki.oids.messageDigest) {
            // use content message digest as value
            attr.value = mds[signer.digestAlgorithm].digest();
          } else if(attr.type === forge.pki.oids.signingTime) {
            // auto-populate signing time if not already set
            if(!attr.value) {
              attr.value = signingTime;
            }
          }

          // convert to ASN.1 and push onto Attributes SET (for signing) and
          // onto authenticatedAttributesAsn1 to complete SignedData ASN.1
          // TODO: optimize away duplication
          attrsAsn1.value.push(_attributeToAsn1(attr));
          signer.authenticatedAttributesAsn1.value.push(_attributeToAsn1(attr));
        }

        // DER-serialize and digest SET OF attributes only
        bytes = asn1.toDer(attrsAsn1).getBytes();
        signer.md.start().update(bytes);
      }

      // sign digest
      signer.signature = signer.key.sign(signer.md, 'RSASSA-PKCS1-V1_5');
    }

    // add signer info
    msg.signerInfos = _signersToAsn1(msg.signers);
  }
};

/**
 * Creates an empty PKCS#7 message of type EncryptedData.
 *
 * @return the message.
 */
p7.createEncryptedData = function() {
  var msg = null;
  msg = {
    type: forge.pki.oids.encryptedData,
    version: 0,
    encryptedContent: {
      algorithm: forge.pki.oids['aes256-CBC']
    },

    /**
     * Reads an EncryptedData content block (in ASN.1 format)
     *
     * @param obj The ASN.1 representation of the EncryptedData content block
     */
    fromAsn1: function(obj) {
      // Validate EncryptedData content block and capture data.
      _fromAsn1(msg, obj, p7.asn1.encryptedDataValidator);
    },

    /**
     * Decrypt encrypted content
     *
     * @param key The (symmetric) key as a byte buffer
     */
    decrypt: function(key) {
      if(key !== undefined) {
        msg.encryptedContent.key = key;
      }
      _decryptContent(msg);
    }
  };
  return msg;
};

/**
 * Creates an empty PKCS#7 message of type EnvelopedData.
 *
 * @return the message.
 */
p7.createEnvelopedData = function() {
  var msg = null;
  msg = {
    type: forge.pki.oids.envelopedData,
    version: 0,
    recipients: [],
    encryptedContent: {
      algorithm: forge.pki.oids['aes256-CBC']
    },

    /**
     * Reads an EnvelopedData content block (in ASN.1 format)
     *
     * @param obj the ASN.1 representation of the EnvelopedData content block.
     */
    fromAsn1: function(obj) {
      // validate EnvelopedData content block and capture data
      var capture = _fromAsn1(msg, obj, p7.asn1.envelopedDataValidator);
      msg.recipients = _recipientsFromAsn1(capture.recipientInfos.value);
    },

    toAsn1: function() {
      // ContentInfo
      return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
        // ContentType
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
          asn1.oidToDer(msg.type).getBytes()),
        // [0] EnvelopedData
        asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [
          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
            // Version
            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
              asn1.integerToDer(msg.version).getBytes()),
            // RecipientInfos
            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true,
              _recipientsToAsn1(msg.recipients)),
            // EncryptedContentInfo
            asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true,
              _encryptedContentToAsn1(msg.encryptedContent))
          ])
        ])
      ]);
    },

    /**
     * Find recipient by X.509 certificate's issuer.
     *
     * @param cert the certificate with the issuer to look for.
     *
     * @return the recipient object.
     */
    findRecipient: function(cert) {
      var sAttr = cert.issuer.attributes;

      for(var i = 0; i < msg.recipients.length; ++i) {
        var r = msg.recipients[i];
        var rAttr = r.issuer;

        if(r.serialNumber !== cert.serialNumber) {
          continue;
        }

        if(rAttr.length !== sAttr.length) {
          continue;
        }

        var match = true;
        for(var j = 0; j < sAttr.length; ++j) {
          if(rAttr[j].type !== sAttr[j].type ||
            rAttr[j].value !== sAttr[j].value) {
            match = false;
            break;
          }
        }

        if(match) {
          return r;
        }
      }

      return null;
    },

    /**
     * Decrypt enveloped content
     *
     * @param recipient The recipient object related to the private key
     * @param privKey The (RSA) private key object
     */
    decrypt: function(recipient, privKey) {
      if(msg.encryptedContent.key === undefined && recipient !== undefined &&
        privKey !== undefined) {
        switch(recipient.encryptedContent.algorithm) {
          case forge.pki.oids.rsaEncryption:
          case forge.pki.oids.desCBC:
            var key = privKey.decrypt(recipient.encryptedContent.content);
            msg.encryptedContent.key = forge.util.createBuffer(key);
            break;

          default:
            throw new Error('Unsupported asymmetric cipher, ' +
              'OID ' + recipient.encryptedContent.algorithm);
        }
      }

      _decryptContent(msg);
    },

    /**
     * Add (another) entity to list of recipients.
     *
     * @param cert The certificate of the entity to add.
     */
    addRecipient: function(cert) {
      msg.recipients.push({
        version: 0,
        issuer: cert.issuer.attributes,
        serialNumber: cert.serialNumber,
        encryptedContent: {
          // We simply assume rsaEncryption here, since forge.pki only
          // supports RSA so far.  If the PKI module supports other
          // ciphers one day, we need to modify this one as well.
          algorithm: forge.pki.oids.rsaEncryption,
          key: cert.publicKey
        }
      });
    },

    /**
     * Encrypt enveloped content.
     *
     * This function supports two optional arguments, cipher and key, which
     * can be used to influence symmetric encryption.  Unless cipher is
     * provided, the cipher specified in encryptedContent.algorithm is used
     * (defaults to AES-256-CBC).  If no key is provided, encryptedContent.key
     * is (re-)used.  If that one's not set, a random key will be generated
     * automatically.
     *
     * @param [key] The key to be used for symmetric encryption.
     * @param [cipher] The OID of the symmetric cipher to use.
     */
    encrypt: function(key, cipher) {
      // Part 1: Symmetric encryption
      if(msg.encryptedContent.content === undefined) {
        cipher = cipher || msg.encryptedContent.algorithm;
        key = key || msg.encryptedContent.key;

        var keyLen, ivLen, ciphFn;
        switch(cipher) {
          case forge.pki.oids['aes128-CBC']:
            keyLen = 16;
            ivLen = 16;
            ciphFn = forge.aes.createEncryptionCipher;
            break;

          case forge.pki.oids['aes192-CBC']:
            keyLen = 24;
            ivLen = 16;
            ciphFn = forge.aes.createEncryptionCipher;
            break;

          case forge.pki.oids['aes256-CBC']:
            keyLen = 32;
            ivLen = 16;
            ciphFn = forge.aes.createEncryptionCipher;
            break;

          case forge.pki.oids['des-EDE3-CBC']:
            keyLen = 24;
            ivLen = 8;
            ciphFn = forge.des.createEncryptionCipher;
            break;

          default:
            throw new Error('Unsupported symmetric cipher, OID ' + cipher);
        }

        if(key === undefined) {
          key = forge.util.createBuffer(forge.random.getBytes(keyLen));
        } else if(key.length() != keyLen) {
          throw new Error('Symmetric key has wrong length; ' +
            'got ' + key.length() + ' bytes, expected ' + keyLen + '.');
        }

        // Keep a copy of the key & IV in the object, so the caller can
        // use it for whatever reason.
        msg.encryptedContent.algorithm = cipher;
        msg.encryptedContent.key = key;
        msg.encryptedContent.parameter = forge.util.createBuffer(
          forge.random.getBytes(ivLen));

        var ciph = ciphFn(key);
        ciph.start(msg.encryptedContent.parameter.copy());
        ciph.update(msg.content);

        // The finish function does PKCS#7 padding by default, therefore
        // no action required by us.
        if(!ciph.finish()) {
          throw new Error('Symmetric encryption failed.');
        }

        msg.encryptedContent.content = ciph.output;
      }

      // Part 2: asymmetric encryption for each recipient
      for(var i = 0; i < msg.recipients.length; ++i) {
        var recipient = msg.recipients[i];

        // Nothing to do, encryption already done.
        if(recipient.encryptedContent.content !== undefined) {
          continue;
        }

        switch(recipient.encryptedContent.algorithm) {
          case forge.pki.oids.rsaEncryption:
            recipient.encryptedContent.content =
              recipient.encryptedContent.key.encrypt(
                msg.encryptedContent.key.data);
            break;

          default:
            throw new Error('Unsupported asymmetric cipher, OID ' +
              recipient.encryptedContent.algorithm);
        }
      }
    }
  };
  return msg;
};

/**
 * Converts a single recipient from an ASN.1 object.
 *
 * @param obj the ASN.1 RecipientInfo.
 *
 * @return the recipient object.
 */
function _recipientFromAsn1(obj) {
  // validate EnvelopedData content block and capture data
  var capture = {};
  var errors = [];
  if(!asn1.validate(obj, p7.asn1.recipientInfoValidator, capture, errors)) {
    var error = new Error('Cannot read PKCS#7 RecipientInfo. ' +
      'ASN.1 object is not an PKCS#7 RecipientInfo.');
    error.errors = errors;
    throw error;
  }

  return {
    version: capture.version.charCodeAt(0),
    issuer: forge.pki.RDNAttributesAsArray(capture.issuer),
    serialNumber: forge.util.createBuffer(capture.serial).toHex(),
    encryptedContent: {
      algorithm: asn1.derToOid(capture.encAlgorithm),
      parameter: capture.encParameter ? capture.encParameter.value : undefined,
      content: capture.encKey
    }
  };
}

/**
 * Converts a single recipient object to an ASN.1 object.
 *
 * @param obj the recipient object.
 *
 * @return the ASN.1 RecipientInfo.
 */
function _recipientToAsn1(obj) {
  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
    // Version
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
      asn1.integerToDer(obj.version).getBytes()),
    // IssuerAndSerialNumber
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
      // Name
      forge.pki.distinguishedNameToAsn1({attributes: obj.issuer}),
      // Serial
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
        forge.util.hexToBytes(obj.serialNumber))
    ]),
    // KeyEncryptionAlgorithmIdentifier
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
      // Algorithm
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
        asn1.oidToDer(obj.encryptedContent.algorithm).getBytes()),
      // Parameter, force NULL, only RSA supported for now.
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')
    ]),
    // EncryptedKey
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,
      obj.encryptedContent.content)
  ]);
}

/**
 * Map a set of RecipientInfo ASN.1 objects to recipient objects.
 *
 * @param infos an array of ASN.1 representations RecipientInfo (i.e. SET OF).
 *
 * @return an array of recipient objects.
 */
function _recipientsFromAsn1(infos) {
  var ret = [];
  for(var i = 0; i < infos.length; ++i) {
    ret.push(_recipientFromAsn1(infos[i]));
  }
  return ret;
}

/**
 * Map an array of recipient objects to ASN.1 RecipientInfo objects.
 *
 * @param recipients an array of recipientInfo objects.
 *
 * @return an array of ASN.1 RecipientInfos.
 */
function _recipientsToAsn1(recipients) {
  var ret = [];
  for(var i = 0; i < recipients.length; ++i) {
    ret.push(_recipientToAsn1(recipients[i]));
  }
  return ret;
}

/**
 * Converts a single signerInfo object to an ASN.1 object.
 *
 * @param obj the signerInfo object.
 *
 * @return the ASN.1 representation of a SignerInfo.
 */
function _signerToAsn1(obj) {
  // SignerInfo
  var rval = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
    // version
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
      asn1.integerToDer(obj.version).getBytes()),
    // issuerAndSerialNumber
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
      // name
      forge.pki.distinguishedNameToAsn1({attributes: obj.issuer}),
      // serial
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
        forge.util.hexToBytes(obj.serialNumber))
    ]),
    // digestAlgorithm
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
      // algorithm
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
        asn1.oidToDer(obj.digestAlgorithm).getBytes()),
      // parameters (null)
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')
    ])
  ]);

  // authenticatedAttributes (OPTIONAL)
  if(obj.authenticatedAttributesAsn1) {
    // add ASN.1 previously generated during signing
    rval.value.push(obj.authenticatedAttributesAsn1);
  }

  // digestEncryptionAlgorithm
  rval.value.push(asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
    // algorithm
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
      asn1.oidToDer(obj.signatureAlgorithm).getBytes()),
    // parameters (null)
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')
  ]));

  // encryptedDigest
  rval.value.push(asn1.create(
    asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, obj.signature));

  // unauthenticatedAttributes (OPTIONAL)
  if(obj.unauthenticatedAttributes.length > 0) {
    // [1] IMPLICIT
    var attrsAsn1 = asn1.create(asn1.Class.CONTEXT_SPECIFIC, 1, true, []);
    for(var i = 0; i < obj.unauthenticatedAttributes.length; ++i) {
      var attr = obj.unauthenticatedAttributes[i];
      attrsAsn1.values.push(_attributeToAsn1(attr));
    }
    rval.value.push(attrsAsn1);
  }

  return rval;
}

/**
 * Map an array of signer objects to ASN.1 objects.
 *
 * @param signers an array of signer objects.
 *
 * @return an array of ASN.1 SignerInfos.
 */
function _signersToAsn1(signers) {
  var ret = [];
  for(var i = 0; i < signers.length; ++i) {
    ret.push(_signerToAsn1(signers[i]));
  }
  return ret;
}

/**
 * Convert an attribute object to an ASN.1 Attribute.
 *
 * @param attr the attribute object.
 *
 * @return the ASN.1 Attribute.
 */
function _attributeToAsn1(attr) {
  var value;

  // TODO: generalize to support more attributes
  if(attr.type === forge.pki.oids.contentType) {
    value = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
      asn1.oidToDer(attr.value).getBytes());
  } else if(attr.type === forge.pki.oids.messageDigest) {
    value = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,
      attr.value.bytes());
  } else if(attr.type === forge.pki.oids.signingTime) {
    /* Note per RFC 2985: Dates between 1 January 1950 and 31 December 2049
      (inclusive) MUST be encoded as UTCTime. Any dates with year values
      before 1950 or after 2049 MUST be encoded as GeneralizedTime. [Further,]
      UTCTime values MUST be expressed in Greenwich Mean Time (Zulu) and MUST
      include seconds (i.e., times are YYMMDDHHMMSSZ), even where the
      number of seconds is zero.  Midnight (GMT) must be represented as
      "YYMMDD000000Z". */
    // TODO: make these module-level constants
    var jan_1_1950 = new Date('1950-01-01T00:00:00Z');
    var jan_1_2050 = new Date('2050-01-01T00:00:00Z');
    var date = attr.value;
    if(typeof date === 'string') {
      // try to parse date
      var timestamp = Date.parse(date);
      if(!isNaN(timestamp)) {
        date = new Date(timestamp);
      } else if(date.length === 13) {
        // YYMMDDHHMMSSZ (13 chars for UTCTime)
        date = asn1.utcTimeToDate(date);
      } else {
        // assume generalized time
        date = asn1.generalizedTimeToDate(date);
      }
    }

    if(date >= jan_1_1950 && date < jan_1_2050) {
      value = asn1.create(
        asn1.Class.UNIVERSAL, asn1.Type.UTCTIME, false,
        asn1.dateToUtcTime(date));
    } else {
      value = asn1.create(
        asn1.Class.UNIVERSAL, asn1.Type.GENERALIZEDTIME, false,
        asn1.dateToGeneralizedTime(date));
    }
  }

  // TODO: expose as common API call
  // create a RelativeDistinguishedName set
  // each value in the set is an AttributeTypeAndValue first
  // containing the type (an OID) and second the value
  return asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
    // AttributeType
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
      asn1.oidToDer(attr.type).getBytes()),
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SET, true, [
      // AttributeValue
      value
    ])
  ]);
}

/**
 * Map messages encrypted content to ASN.1 objects.
 *
 * @param ec The encryptedContent object of the message.
 *
 * @return ASN.1 representation of the encryptedContent object (SEQUENCE).
 */
function _encryptedContentToAsn1(ec) {
  return [
    // ContentType, always Data for the moment
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
      asn1.oidToDer(forge.pki.oids.data).getBytes()),
    // ContentEncryptionAlgorithmIdentifier
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
      // Algorithm
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
        asn1.oidToDer(ec.algorithm).getBytes()),
      // Parameters (IV)
      !ec.parameter ?
        undefined :
        asn1.create(
          asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,
          ec.parameter.getBytes())
    ]),
    // [0] EncryptedContent
    asn1.create(asn1.Class.CONTEXT_SPECIFIC, 0, true, [
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false,
        ec.content.getBytes())
    ])
  ];
}

/**
 * Reads the "common part" of an PKCS#7 content block (in ASN.1 format)
 *
 * This function reads the "common part" of the PKCS#7 content blocks
 * EncryptedData and EnvelopedData, i.e. version number and symmetrically
 * encrypted content block.
 *
 * The result of the ASN.1 validate and capture process is returned
 * to allow the caller to extract further data, e.g. the list of recipients
 * in case of a EnvelopedData object.
 *
 * @param msg the PKCS#7 object to read the data to.
 * @param obj the ASN.1 representation of the content block.
 * @param validator the ASN.1 structure validator object to use.
 *
 * @return the value map captured by validator object.
 */
function _fromAsn1(msg, obj, validator) {
  var capture = {};
  var errors = [];
  if(!asn1.validate(obj, validator, capture, errors)) {
    var error = new Error('Cannot read PKCS#7 message. ' +
      'ASN.1 object is not a supported PKCS#7 message.');
    error.errors = error;
    throw error;
  }

  // Check contentType, so far we only support (raw) Data.
  var contentType = asn1.derToOid(capture.contentType);
  if(contentType !== forge.pki.oids.data) {
    throw new Error('Unsupported PKCS#7 message. ' +
      'Only wrapped ContentType Data supported.');
  }

  if(capture.encryptedContent) {
    var content = '';
    if(forge.util.isArray(capture.encryptedContent)) {
      for(var i = 0; i < capture.encryptedContent.length; ++i) {
        if(capture.encryptedContent[i].type !== asn1.Type.OCTETSTRING) {
          throw new Error('Malformed PKCS#7 message, expecting encrypted ' +
            'content constructed of only OCTET STRING objects.');
        }
        content += capture.encryptedContent[i].value;
      }
    } else {
      content = capture.encryptedContent;
    }
    msg.encryptedContent = {
      algorithm: asn1.derToOid(capture.encAlgorithm),
      parameter: forge.util.createBuffer(capture.encParameter.value),
      content: forge.util.createBuffer(content)
    };
  }

  if(capture.content) {
    var content = '';
    if(forge.util.isArray(capture.content)) {
      for(var i = 0; i < capture.content.length; ++i) {
        if(capture.content[i].type !== asn1.Type.OCTETSTRING) {
          throw new Error('Malformed PKCS#7 message, expecting ' +
            'content constructed of only OCTET STRING objects.');
        }
        content += capture.content[i].value;
      }
    } else {
      content = capture.content;
    }
    msg.content = forge.util.createBuffer(content);
  }

  msg.version = capture.version.charCodeAt(0);
  msg.rawCapture = capture;

  return capture;
}

/**
 * Decrypt the symmetrically encrypted content block of the PKCS#7 message.
 *
 * Decryption is skipped in case the PKCS#7 message object already has a
 * (decrypted) content attribute.  The algorithm, key and cipher parameters
 * (probably the iv) are taken from the encryptedContent attribute of the
 * message object.
 *
 * @param The PKCS#7 message object.
 */
function _decryptContent(msg) {
  if(msg.encryptedContent.key === undefined) {
    throw new Error('Symmetric key not available.');
  }

  if(msg.content === undefined) {
    var ciph;

    switch(msg.encryptedContent.algorithm) {
      case forge.pki.oids['aes128-CBC']:
      case forge.pki.oids['aes192-CBC']:
      case forge.pki.oids['aes256-CBC']:
        ciph = forge.aes.createDecryptionCipher(msg.encryptedContent.key);
        break;

      case forge.pki.oids['desCBC']:
      case forge.pki.oids['des-EDE3-CBC']:
        ciph = forge.des.createDecryptionCipher(msg.encryptedContent.key);
        break;

      default:
        throw new Error('Unsupported symmetric cipher, OID ' +
          msg.encryptedContent.algorithm);
    }
    ciph.start(msg.encryptedContent.parameter);
    ciph.update(msg.encryptedContent.content);

    if(!ciph.finish()) {
      throw new Error('Symmetric decryption failed.');
    }

    msg.content = ciph.output;
  }
}

const pki = forge$s.pki;
/**
 * Gets a self-signed X.509 certificate for the key.
 *
 * The output Uint8Array contains the PKCS #7 message in DER.
 *
 * TODO: move to libp2p-crypto package
 */
const certificateForKey = (key, privateKey) => {
    const publicKey = pki.rsa.setPublicKey(privateKey.n, privateKey.e);
    const cert = pki.createCertificate();
    cert.publicKey = publicKey;
    cert.serialNumber = '01';
    cert.validity.notBefore = new Date();
    cert.validity.notAfter = new Date();
    cert.validity.notAfter.setFullYear(cert.validity.notBefore.getFullYear() + 10); // eslint-disable-line @typescript-eslint/restrict-plus-operands
    const attrs = [{
            name: 'organizationName',
            value: 'ipfs'
        }, {
            shortName: 'OU',
            value: 'keystore'
        }, {
            name: 'commonName',
            value: key.id
        }];
    cert.setSubject(attrs);
    cert.setIssuer(attrs);
    cert.setExtensions([{
            name: 'basicConstraints',
            cA: true
        }, {
            name: 'keyUsage',
            keyCertSign: true,
            digitalSignature: true,
            nonRepudiation: true,
            keyEncipherment: true,
            dataEncipherment: true
        }, {
            name: 'extKeyUsage',
            serverAuth: true,
            clientAuth: true,
            codeSigning: true,
            emailProtection: true,
            timeStamping: true
        }, {
            name: 'nsCertType',
            client: true,
            server: true,
            email: true,
            objsign: true,
            sslCA: true,
            emailCA: true,
            objCA: true
        }]);
    // self-sign certificate
    cert.sign(privateKey);
    return cert;
};
/**
 * Finds the first item in a collection that is matched in the
 * `asyncCompare` function.
 *
 * `asyncCompare` is an async function that must
 * resolve to either `true` or `false`.
 *
 * @param {Array} array
 * @param {function(*)} asyncCompare - An async function that returns a boolean
 */
async function findAsync(array, asyncCompare) {
    const promises = array.map(asyncCompare);
    const results = await Promise.all(promises);
    const index = results.findIndex(result => result);
    return array[index];
}

const log$n = logger$2('libp2p:keychain:cms');
const privates$1 = new WeakMap();
/**
 * Cryptographic Message Syntax (aka PKCS #7)
 *
 * CMS describes an encapsulation syntax for data protection. It
 * is used to digitally sign, digest, authenticate, or encrypt
 * arbitrary message content.
 *
 * See RFC 5652 for all the details.
 */
class CMS {
    /**
     * Creates a new instance with a keychain
     */
    constructor(keychain, dek) {
        if (keychain == null) {
            throw errCode(new Error('keychain is required'), codes$1.ERR_KEYCHAIN_REQUIRED);
        }
        this.keychain = keychain;
        privates$1.set(this, { dek });
    }
    /**
     * Creates some protected data.
     *
     * The output Uint8Array contains the PKCS #7 message in DER.
     */
    async encrypt(name, plain) {
        if (!(plain instanceof Uint8Array)) {
            throw errCode(new Error('Plain data must be a Uint8Array'), codes$1.ERR_INVALID_PARAMETERS);
        }
        const key = await this.keychain.findKeyByName(name);
        const pem = await this.keychain.getPrivateKey(name);
        const cached = privates$1.get(this);
        if (cached == null) {
            throw errCode(new Error('dek missing'), codes$1.ERR_INVALID_PARAMETERS);
        }
        const dek = cached.dek;
        const privateKey = forge$s.pki.decryptRsaPrivateKey(pem, dek);
        const certificate = await certificateForKey(key, privateKey);
        // create a p7 enveloped message
        const p7 = forge$s.pkcs7.createEnvelopedData();
        p7.addRecipient(certificate);
        p7.content = forge$s.util.createBuffer(plain);
        p7.encrypt();
        // convert message to DER
        const der = forge$s.asn1.toDer(p7.toAsn1()).getBytes();
        return fromString$2(der, 'ascii');
    }
    /**
     * Reads some protected data.
     *
     * The keychain must contain one of the keys used to encrypt the data.  If none of the keys
     * exists, an Error is returned with the property 'missingKeys'.  It is array of key ids.
     */
    async decrypt(cmsData) {
        if (!(cmsData instanceof Uint8Array)) {
            throw errCode(new Error('CMS data is required'), codes$1.ERR_INVALID_PARAMETERS);
        }
        let cms;
        try {
            const buf = forge$s.util.createBuffer(toString$7(cmsData, 'ascii'));
            const obj = forge$s.asn1.fromDer(buf);
            cms = forge$s.pkcs7.messageFromAsn1(obj);
        }
        catch (err) {
            log$n.error(err);
            throw errCode(new Error('Invalid CMS'), codes$1.ERR_INVALID_CMS);
        }
        // Find a recipient whose key we hold. We only deal with recipient certs
        // issued by ipfs (O=ipfs).
        const recipients = cms.recipients
            // @ts-expect-error cms types not defined
            .filter(r => r.issuer.find(a => a.shortName === 'O' && a.value === 'ipfs'))
            // @ts-expect-error cms types not defined
            .filter(r => r.issuer.find(a => a.shortName === 'CN'))
            // @ts-expect-error cms types not defined
            .map(r => {
            return {
                recipient: r,
                // @ts-expect-error cms types not defined
                keyId: r.issuer.find(a => a.shortName === 'CN').value
            };
        });
        const r = await findAsync(recipients, async (recipient) => {
            try {
                const key = await this.keychain.findKeyById(recipient.keyId);
                if (key != null) {
                    return true;
                }
            }
            catch (err) {
                return false;
            }
            return false;
        });
        if (r == null) {
            // @ts-expect-error cms types not defined
            const missingKeys = recipients.map(r => r.keyId);
            throw errCode(new Error(`Decryption needs one of the key(s): ${missingKeys.join(', ')}`), codes$1.ERR_MISSING_KEYS, {
                missingKeys
            });
        }
        const key = await this.keychain.findKeyById(r.keyId);
        if (key == null) {
            throw errCode(new Error('No key available to decrypto'), codes$1.ERR_NO_KEY);
        }
        const pem = await this.keychain.getPrivateKey(key.name);
        const cached = privates$1.get(this);
        if (cached == null) {
            throw errCode(new Error('dek missing'), codes$1.ERR_INVALID_PARAMETERS);
        }
        const dek = cached.dek;
        const privateKey = forge$s.pki.decryptRsaPrivateKey(pem, dek);
        cms.decrypt(r.recipient, privateKey);
        return fromString$2(cms.content.getBytes(), 'ascii');
    }
}

/* eslint max-nested-callbacks: ["error", 5] */
const log$m = logger$2('libp2p:keychain');
const keyPrefix = '/pkcs8/';
const infoPrefix = '/info/';
const privates = new WeakMap();
// NIST SP 800-132
const NIST = {
    minKeyLength: 112 / 8,
    minSaltLength: 128 / 8,
    minIterationCount: 1000
};
const defaultOptions$2 = {
    // See https://cryptosense.com/parametesr-choice-for-pbkdf2/
    dek: {
        keyLength: 512 / 8,
        iterationCount: 10000,
        salt: 'you should override this value with a crypto secure random number',
        hash: 'sha2-512'
    }
};
function validateKeyName(name) {
    if (name == null) {
        return false;
    }
    if (typeof name !== 'string') {
        return false;
    }
    return name === sanitizeFilename(name.trim()) && name.length > 0;
}
/**
 * Throws an error after a delay
 *
 * This assumes than an error indicates that the keychain is under attack. Delay returning an
 * error to make brute force attacks harder.
 */
async function randomDelay() {
    const min = 200;
    const max = 1000;
    const delay = Math.random() * (max - min) + min;
    await new Promise(resolve => setTimeout(resolve, delay));
}
/**
 * Converts a key name into a datastore name
 */
function DsName(name) {
    return new Key(keyPrefix + name);
}
/**
 * Converts a key name into a datastore info name
 */
function DsInfoName(name) {
    return new Key(infoPrefix + name);
}
/**
 * Manages the lifecycle of a key. Keys are encrypted at rest using PKCS #8.
 *
 * A key in the store has two entries
 * - '/info/*key-name*', contains the KeyInfo for the key
 * - '/pkcs8/*key-name*', contains the PKCS #8 for the key
 *
 */
class KeyChain {
    /**
     * Creates a new instance of a key chain
     */
    constructor(components, init) {
        this.components = components;
        this.init = mergeOptions(defaultOptions$2, init);
        // Enforce NIST SP 800-132
        if (this.init.pass != null && this.init.pass?.length < 20) {
            throw new Error('pass must be least 20 characters');
        }
        if (this.init.dek?.keyLength != null && this.init.dek.keyLength < NIST.minKeyLength) {
            throw new Error(`dek.keyLength must be least ${NIST.minKeyLength} bytes`);
        }
        if (this.init.dek?.salt?.length != null && this.init.dek.salt.length < NIST.minSaltLength) {
            throw new Error(`dek.saltLength must be least ${NIST.minSaltLength} bytes`);
        }
        if (this.init.dek?.iterationCount != null && this.init.dek.iterationCount < NIST.minIterationCount) {
            throw new Error(`dek.iterationCount must be least ${NIST.minIterationCount}`);
        }
        const dek = this.init.pass != null && this.init.dek?.salt != null
            ? pbkdf2(this.init.pass, this.init.dek?.salt, this.init.dek?.iterationCount, this.init.dek?.keyLength, this.init.dek?.hash)
            : '';
        privates.set(this, { dek });
        this.started = false;
    }
    isStarted() {
        return this.started;
    }
    async start() {
        const dsname = DsInfoName('self');
        if (!(await this.components.datastore.has(dsname))) {
            await this.importPeer('self', this.components.peerId);
        }
        this.started = true;
    }
    stop() {
        this.started = false;
    }
    /**
     * Gets an object that can encrypt/decrypt protected data
     * using the Cryptographic Message Syntax (CMS).
     *
     * CMS describes an encapsulation syntax for data protection. It
     * is used to digitally sign, digest, authenticate, or encrypt
     * arbitrary message content
     */
    get cms() {
        const cached = privates.get(this);
        if (cached == null) {
            throw errCode(new Error('dek missing'), codes$1.ERR_INVALID_PARAMETERS);
        }
        const dek = cached.dek;
        return new CMS(this, dek);
    }
    /**
     * Generates the options for a keychain.  A random salt is produced.
     *
     * @returns {object}
     */
    static generateOptions() {
        const options = Object.assign({}, defaultOptions$2);
        const saltLength = Math.ceil(NIST.minSaltLength / 3) * 3; // no base64 padding
        options.dek.salt = toString$7(randomBytes(saltLength), 'base64');
        return options;
    }
    /**
     * Gets an object that can encrypt/decrypt protected data.
     * The default options for a keychain.
     *
     * @returns {object}
     */
    static get options() {
        return defaultOptions$2;
    }
    /**
     * Create a new key.
     *
     * @param {string} name - The local key name; cannot already exist.
     * @param {string} type - One of the key types; 'rsa'.
     * @param {number} [size = 2048] - The key size in bits. Used for rsa keys only
     */
    async createKey(name, type, size = 2048) {
        if (!validateKeyName(name) || name === 'self') {
            await randomDelay();
            throw errCode(new Error('Invalid key name'), codes$1.ERR_INVALID_KEY_NAME);
        }
        if (typeof type !== 'string') {
            await randomDelay();
            throw errCode(new Error('Invalid key type'), codes$1.ERR_INVALID_KEY_TYPE);
        }
        const dsname = DsName(name);
        const exists = await this.components.datastore.has(dsname);
        if (exists) {
            await randomDelay();
            throw errCode(new Error('Key name already exists'), codes$1.ERR_KEY_ALREADY_EXISTS);
        }
        switch (type.toLowerCase()) {
            case 'rsa':
                if (!Number.isSafeInteger(size) || size < 2048) {
                    await randomDelay();
                    throw errCode(new Error('Invalid RSA key size'), codes$1.ERR_INVALID_KEY_SIZE);
                }
                break;
        }
        let keyInfo;
        try {
            const keypair = await generateKeyPair(type, size);
            const kid = await keypair.id();
            const cached = privates.get(this);
            if (cached == null) {
                throw errCode(new Error('dek missing'), codes$1.ERR_INVALID_PARAMETERS);
            }
            const dek = cached.dek;
            const pem = await keypair.export(dek);
            keyInfo = {
                name: name,
                id: kid
            };
            const batch = this.components.datastore.batch();
            batch.put(dsname, fromString$2(pem));
            batch.put(DsInfoName(name), fromString$2(JSON.stringify(keyInfo)));
            await batch.commit();
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
        return keyInfo;
    }
    /**
     * List all the keys.
     *
     * @returns {Promise<KeyInfo[]>}
     */
    async listKeys() {
        const query = {
            prefix: infoPrefix
        };
        const info = [];
        for await (const value of this.components.datastore.query(query)) {
            info.push(JSON.parse(toString$7(value.value)));
        }
        return info;
    }
    /**
     * Find a key by it's id
     */
    async findKeyById(id) {
        try {
            const keys = await this.listKeys();
            return keys.find((k) => k.id === id);
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
    }
    /**
     * Find a key by it's name.
     *
     * @param {string} name - The local key name.
     * @returns {Promise<KeyInfo>}
     */
    async findKeyByName(name) {
        if (!validateKeyName(name)) {
            await randomDelay();
            throw errCode(new Error(`Invalid key name '${name}'`), codes$1.ERR_INVALID_KEY_NAME);
        }
        const dsname = DsInfoName(name);
        try {
            const res = await this.components.datastore.get(dsname);
            return JSON.parse(toString$7(res));
        }
        catch (err) {
            await randomDelay();
            log$m.error(err);
            throw errCode(new Error(`Key '${name}' does not exist.`), codes$1.ERR_KEY_NOT_FOUND);
        }
    }
    /**
     * Remove an existing key.
     *
     * @param {string} name - The local key name; must already exist.
     * @returns {Promise<KeyInfo>}
     */
    async removeKey(name) {
        if (!validateKeyName(name) || name === 'self') {
            await randomDelay();
            throw errCode(new Error(`Invalid key name '${name}'`), codes$1.ERR_INVALID_KEY_NAME);
        }
        const dsname = DsName(name);
        const keyInfo = await this.findKeyByName(name);
        const batch = this.components.datastore.batch();
        batch.delete(dsname);
        batch.delete(DsInfoName(name));
        await batch.commit();
        return keyInfo;
    }
    /**
     * Rename a key
     *
     * @param {string} oldName - The old local key name; must already exist.
     * @param {string} newName - The new local key name; must not already exist.
     * @returns {Promise<KeyInfo>}
     */
    async renameKey(oldName, newName) {
        if (!validateKeyName(oldName) || oldName === 'self') {
            await randomDelay();
            throw errCode(new Error(`Invalid old key name '${oldName}'`), codes$1.ERR_OLD_KEY_NAME_INVALID);
        }
        if (!validateKeyName(newName) || newName === 'self') {
            await randomDelay();
            throw errCode(new Error(`Invalid new key name '${newName}'`), codes$1.ERR_NEW_KEY_NAME_INVALID);
        }
        const oldDsname = DsName(oldName);
        const newDsname = DsName(newName);
        const oldInfoName = DsInfoName(oldName);
        const newInfoName = DsInfoName(newName);
        const exists = await this.components.datastore.has(newDsname);
        if (exists) {
            await randomDelay();
            throw errCode(new Error(`Key '${newName}' already exists`), codes$1.ERR_KEY_ALREADY_EXISTS);
        }
        try {
            const pem = await this.components.datastore.get(oldDsname);
            const res = await this.components.datastore.get(oldInfoName);
            const keyInfo = JSON.parse(toString$7(res));
            keyInfo.name = newName;
            const batch = this.components.datastore.batch();
            batch.put(newDsname, pem);
            batch.put(newInfoName, fromString$2(JSON.stringify(keyInfo)));
            batch.delete(oldDsname);
            batch.delete(oldInfoName);
            await batch.commit();
            return keyInfo;
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
    }
    /**
     * Export an existing key as a PEM encrypted PKCS #8 string
     */
    async exportKey(name, password) {
        if (!validateKeyName(name)) {
            await randomDelay();
            throw errCode(new Error(`Invalid key name '${name}'`), codes$1.ERR_INVALID_KEY_NAME);
        }
        if (password == null) {
            await randomDelay();
            throw errCode(new Error('Password is required'), codes$1.ERR_PASSWORD_REQUIRED);
        }
        const dsname = DsName(name);
        try {
            const res = await this.components.datastore.get(dsname);
            const pem = toString$7(res);
            const cached = privates.get(this);
            if (cached == null) {
                throw errCode(new Error('dek missing'), codes$1.ERR_INVALID_PARAMETERS);
            }
            const dek = cached.dek;
            const privateKey = await importKey(pem, dek);
            return await privateKey.export(password);
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
    }
    /**
     * Export an existing key as a PeerId
     */
    async exportPeerId(name) {
        const password = 'temporary-password';
        const pem = await this.exportKey(name, password);
        const privateKey = await importKey(pem, password);
        return await peerIdFromKeys(privateKey.public.bytes, privateKey.bytes);
    }
    /**
     * Import a new key from a PEM encoded PKCS #8 string
     *
     * @param {string} name - The local key name; must not already exist.
     * @param {string} pem - The PEM encoded PKCS #8 string
     * @param {string} password - The password.
     * @returns {Promise<KeyInfo>}
     */
    async importKey(name, pem, password) {
        if (!validateKeyName(name) || name === 'self') {
            await randomDelay();
            throw errCode(new Error(`Invalid key name '${name}'`), codes$1.ERR_INVALID_KEY_NAME);
        }
        if (pem == null) {
            await randomDelay();
            throw errCode(new Error('PEM encoded key is required'), codes$1.ERR_PEM_REQUIRED);
        }
        const dsname = DsName(name);
        const exists = await this.components.datastore.has(dsname);
        if (exists) {
            await randomDelay();
            throw errCode(new Error(`Key '${name}' already exists`), codes$1.ERR_KEY_ALREADY_EXISTS);
        }
        let privateKey;
        try {
            privateKey = await importKey(pem, password);
        }
        catch (err) {
            await randomDelay();
            throw errCode(new Error('Cannot read the key, most likely the password is wrong'), codes$1.ERR_CANNOT_READ_KEY);
        }
        let kid;
        try {
            kid = await privateKey.id();
            const cached = privates.get(this);
            if (cached == null) {
                throw errCode(new Error('dek missing'), codes$1.ERR_INVALID_PARAMETERS);
            }
            const dek = cached.dek;
            pem = await privateKey.export(dek);
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
        const keyInfo = {
            name: name,
            id: kid
        };
        const batch = this.components.datastore.batch();
        batch.put(dsname, fromString$2(pem));
        batch.put(DsInfoName(name), fromString$2(JSON.stringify(keyInfo)));
        await batch.commit();
        return keyInfo;
    }
    /**
     * Import a peer key
     */
    async importPeer(name, peer) {
        try {
            if (!validateKeyName(name)) {
                throw errCode(new Error(`Invalid key name '${name}'`), codes$1.ERR_INVALID_KEY_NAME);
            }
            if (peer == null) {
                throw errCode(new Error('PeerId is required'), codes$1.ERR_MISSING_PRIVATE_KEY);
            }
            if (peer.privateKey == null) {
                throw errCode(new Error('PeerId.privKey is required'), codes$1.ERR_MISSING_PRIVATE_KEY);
            }
            const privateKey = await unmarshalPrivateKey(peer.privateKey);
            const dsname = DsName(name);
            const exists = await this.components.datastore.has(dsname);
            if (exists) {
                await randomDelay();
                throw errCode(new Error(`Key '${name}' already exists`), codes$1.ERR_KEY_ALREADY_EXISTS);
            }
            const cached = privates.get(this);
            if (cached == null) {
                throw errCode(new Error('dek missing'), codes$1.ERR_INVALID_PARAMETERS);
            }
            const dek = cached.dek;
            const pem = await privateKey.export(dek);
            const keyInfo = {
                name: name,
                id: peer.toString()
            };
            const batch = this.components.datastore.batch();
            batch.put(dsname, fromString$2(pem));
            batch.put(DsInfoName(name), fromString$2(JSON.stringify(keyInfo)));
            await batch.commit();
            return keyInfo;
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
    }
    /**
     * Gets the private key as PEM encoded PKCS #8 string
     */
    async getPrivateKey(name) {
        if (!validateKeyName(name)) {
            await randomDelay();
            throw errCode(new Error(`Invalid key name '${name}'`), codes$1.ERR_INVALID_KEY_NAME);
        }
        try {
            const dsname = DsName(name);
            const res = await this.components.datastore.get(dsname);
            return toString$7(res);
        }
        catch (err) {
            await randomDelay();
            log$m.error(err);
            throw errCode(new Error(`Key '${name}' does not exist.`), codes$1.ERR_KEY_NOT_FOUND);
        }
    }
    /**
     * Rotate keychain password and re-encrypt all associated keys
     */
    async rotateKeychainPass(oldPass, newPass) {
        if (typeof oldPass !== 'string') {
            await randomDelay();
            throw errCode(new Error(`Invalid old pass type '${typeof oldPass}'`), codes$1.ERR_INVALID_OLD_PASS_TYPE);
        }
        if (typeof newPass !== 'string') {
            await randomDelay();
            throw errCode(new Error(`Invalid new pass type '${typeof newPass}'`), codes$1.ERR_INVALID_NEW_PASS_TYPE);
        }
        if (newPass.length < 20) {
            await randomDelay();
            throw errCode(new Error(`Invalid pass length ${newPass.length}`), codes$1.ERR_INVALID_PASS_LENGTH);
        }
        log$m('recreating keychain');
        const cached = privates.get(this);
        if (cached == null) {
            throw errCode(new Error('dek missing'), codes$1.ERR_INVALID_PARAMETERS);
        }
        const oldDek = cached.dek;
        this.init.pass = newPass;
        const newDek = newPass != null && this.init.dek?.salt != null
            ? pbkdf2(newPass, this.init.dek.salt, this.init.dek?.iterationCount, this.init.dek?.keyLength, this.init.dek?.hash)
            : '';
        privates.set(this, { dek: newDek });
        const keys = await this.listKeys();
        for (const key of keys) {
            const res = await this.components.datastore.get(DsName(key.name));
            const pem = toString$7(res);
            const privateKey = await importKey(pem, oldDek);
            const password = newDek.toString();
            const keyAsPEM = await privateKey.export(password);
            // Update stored key
            const batch = this.components.datastore.batch();
            const keyInfo = {
                name: key.name,
                id: key.id
            };
            batch.put(DsName(key.name), fromString$2(keyAsPEM));
            batch.put(DsInfoName(key.name), fromString$2(JSON.stringify(keyInfo)));
            await batch.commit();
        }
        log$m('keychain reconstructed');
    }
}

async function pReflect(promise) {
	try {
		const value = await promise;

		return {
			status: 'fulfilled',
			value,
			isFulfilled: true,
			isRejected: false
		};
	} catch (error) {
		return {
			status: 'rejected',
			reason: error,
			isFulfilled: false,
			isRejected: true
		};
	}
}

/*
How it works:
`this.#head` is an instance of `Node` which keeps track of its current value and nests another instance of `Node` that keeps the value that comes after it. When a value is provided to `.enqueue()`, the code needs to iterate through `this.#head`, going deeper and deeper to find the last value. However, iterating through every single item is slow. This problem is solved by saving a reference to the last value as `this.#tail` so that it can reference it to add a new value.
*/

class Node {
	value;
	next;

	constructor(value) {
		this.value = value;
	}
}

class Queue {
	#head;
	#tail;
	#size;

	constructor() {
		this.clear();
	}

	enqueue(value) {
		const node = new Node(value);

		if (this.#head) {
			this.#tail.next = node;
			this.#tail = node;
		} else {
			this.#head = node;
			this.#tail = node;
		}

		this.#size++;
	}

	dequeue() {
		const current = this.#head;
		if (!current) {
			return;
		}

		this.#head = this.#head.next;
		this.#size--;
		return current.value;
	}

	clear() {
		this.#head = undefined;
		this.#tail = undefined;
		this.#size = 0;
	}

	get size() {
		return this.#size;
	}

	* [Symbol.iterator]() {
		let current = this.#head;

		while (current) {
			yield current.value;
			current = current.next;
		}
	}
}

function pLimit(concurrency) {
	if (!((Number.isInteger(concurrency) || concurrency === Number.POSITIVE_INFINITY) && concurrency > 0)) {
		throw new TypeError('Expected `concurrency` to be a number from 1 and up');
	}

	const queue = new Queue();
	let activeCount = 0;

	const next = () => {
		activeCount--;

		if (queue.size > 0) {
			queue.dequeue()();
		}
	};

	const run = async (fn, resolve, args) => {
		activeCount++;

		const result = (async () => fn(...args))();

		resolve(result);

		try {
			await result;
		} catch {}

		next();
	};

	const enqueue = (fn, resolve, args) => {
		queue.enqueue(run.bind(undefined, fn, resolve, args));

		(async () => {
			// This function needs to wait until the next microtask before comparing
			// `activeCount` to `concurrency`, because `activeCount` is updated asynchronously
			// when the run function is dequeued and called. The comparison in the if-statement
			// needs to happen asynchronously as well to get an up-to-date value for `activeCount`.
			await Promise.resolve();

			if (activeCount < concurrency && queue.size > 0) {
				queue.dequeue()();
			}
		})();
	};

	const generator = (fn, ...args) => new Promise(resolve => {
		enqueue(fn, resolve, args);
	});

	Object.defineProperties(generator, {
		activeCount: {
			get: () => activeCount,
		},
		pendingCount: {
			get: () => queue.size,
		},
		clearQueue: {
			value: () => {
				queue.clear();
			},
		},
	});

	return generator;
}

async function pSettle(array, options = {}) {
	const {concurrency = Number.POSITIVE_INFINITY} = options;
	const limit = pLimit(concurrency);

	return Promise.all(array.map(element => {
		if (element && typeof element.then === 'function') {
			return pReflect(element);
		}

		if (typeof element === 'function') {
			return pReflect(limit(() => element()));
		}

		return pReflect(Promise.resolve(element));
	}));
}

class TrackedMap extends Map {
    constructor(init) {
        super();
        const { name, metrics } = init;
        this.metric = metrics.registerMetric(name);
        this.updateComponentMetric();
    }
    set(key, value) {
        super.set(key, value);
        this.updateComponentMetric();
        return this;
    }
    delete(key) {
        const deleted = super.delete(key);
        this.updateComponentMetric();
        return deleted;
    }
    clear() {
        super.clear();
        this.updateComponentMetric();
    }
    updateComponentMetric() {
        this.metric.update(this.size);
    }
}
function trackedMap(config) {
    const { name, metrics } = config;
    let map;
    if (metrics != null) {
        map = new TrackedMap({ name, metrics });
    }
    else {
        map = new Map();
    }
    return map;
}

const log$l = logger$2('libp2p:transports');
class DefaultTransportManager extends EventEmitter$1 {
    constructor(components, init = {}) {
        super();
        this.components = components;
        this.started = false;
        this.transports = new Map();
        this.listeners = trackedMap({
            name: 'libp2p_transport_manager_listeners',
            metrics: this.components.metrics
        });
        this.faultTolerance = init.faultTolerance ?? FaultTolerance.FATAL_ALL;
    }
    /**
     * Adds a `Transport` to the manager
     */
    add(transport) {
        const tag = transport[Symbol.toStringTag];
        if (tag == null) {
            throw errCode(new Error('Transport must have a valid tag'), codes$1.ERR_INVALID_KEY);
        }
        if (this.transports.has(tag)) {
            throw errCode(new Error('There is already a transport with this tag'), codes$1.ERR_DUPLICATE_TRANSPORT);
        }
        log$l('adding transport %s', tag);
        this.transports.set(tag, transport);
        if (!this.listeners.has(tag)) {
            this.listeners.set(tag, []);
        }
    }
    isStarted() {
        return this.started;
    }
    async start() {
        // Listen on the provided transports for the provided addresses
        const addrs = this.components.addressManager.getListenAddrs();
        await this.listen(addrs);
        this.started = true;
    }
    /**
     * Stops all listeners
     */
    async stop() {
        const tasks = [];
        for (const [key, listeners] of this.listeners) {
            log$l('closing listeners for %s', key);
            while (listeners.length > 0) {
                const listener = listeners.pop();
                if (listener == null) {
                    continue;
                }
                tasks.push(listener.close());
            }
        }
        await Promise.all(tasks);
        log$l('all listeners closed');
        for (const key of this.listeners.keys()) {
            this.listeners.set(key, []);
        }
        this.started = false;
    }
    /**
     * Dials the given Multiaddr over it's supported transport
     */
    async dial(ma, options) {
        const transport = this.transportForMultiaddr(ma);
        if (transport == null) {
            throw errCode(new Error(`No transport available for address ${String(ma)}`), codes$1.ERR_TRANSPORT_UNAVAILABLE);
        }
        try {
            return await transport.dial(ma, {
                ...options,
                upgrader: this.components.upgrader
            });
        }
        catch (err) {
            if (err.code == null) {
                err.code = codes$1.ERR_TRANSPORT_DIAL_FAILED;
            }
            throw err;
        }
    }
    /**
     * Returns all Multiaddr's the listeners are using
     */
    getAddrs() {
        let addrs = [];
        for (const listeners of this.listeners.values()) {
            for (const listener of listeners) {
                addrs = [...addrs, ...listener.getAddrs()];
            }
        }
        return addrs;
    }
    /**
     * Returns all the transports instances
     */
    getTransports() {
        return Array.of(...this.transports.values());
    }
    /**
     * Finds a transport that matches the given Multiaddr
     */
    transportForMultiaddr(ma) {
        for (const transport of this.transports.values()) {
            const addrs = transport.filter([ma]);
            if (addrs.length > 0) {
                return transport;
            }
        }
    }
    /**
     * Starts listeners for each listen Multiaddr
     */
    async listen(addrs) {
        if (addrs == null || addrs.length === 0) {
            log$l('no addresses were provided for listening, this node is dial only');
            return;
        }
        const couldNotListen = [];
        for (const [key, transport] of this.transports.entries()) {
            const supportedAddrs = transport.filter(addrs);
            const tasks = [];
            // For each supported multiaddr, create a listener
            for (const addr of supportedAddrs) {
                log$l('creating listener for %s on %s', key, addr);
                const listener = transport.createListener({
                    upgrader: this.components.upgrader
                });
                let listeners = this.listeners.get(key);
                if (listeners == null) {
                    listeners = [];
                    this.listeners.set(key, listeners);
                }
                listeners.push(listener);
                // Track listen/close events
                listener.addEventListener('listening', () => {
                    this.dispatchEvent(new CustomEvent('listener:listening', {
                        detail: listener
                    }));
                });
                listener.addEventListener('close', () => {
                    this.dispatchEvent(new CustomEvent('listener:close', {
                        detail: listener
                    }));
                });
                // We need to attempt to listen on everything
                tasks.push(listener.listen(addr));
            }
            // Keep track of transports we had no addresses for
            if (tasks.length === 0) {
                couldNotListen.push(key);
                continue;
            }
            const results = await pSettle(tasks);
            // If we are listening on at least 1 address, succeed.
            // TODO: we should look at adding a retry (`p-retry`) here to better support
            // listening on remote addresses as they may be offline. We could then potentially
            // just wait for any (`p-any`) listener to succeed on each transport before returning
            const isListening = results.find(r => r.isFulfilled);
            if ((isListening == null) && this.faultTolerance !== FaultTolerance.NO_FATAL) {
                throw errCode(new Error(`Transport (${key}) could not listen on any available address`), codes$1.ERR_NO_VALID_ADDRESSES);
            }
        }
        // If no transports were able to listen, throw an error. This likely
        // means we were given addresses we do not have transports for
        if (couldNotListen.length === this.transports.size) {
            const message = `no valid addresses were provided for transports [${couldNotListen.join(', ')}]`;
            if (this.faultTolerance === FaultTolerance.FATAL_ALL) {
                throw errCode(new Error(message), codes$1.ERR_NO_VALID_ADDRESSES);
            }
            log$l(`libp2p in dial mode only: ${message}`);
        }
    }
    /**
     * Removes the given transport from the manager.
     * If a transport has any running listeners, they will be closed.
     */
    async remove(key) {
        log$l('removing %s', key);
        // Close any running listeners
        for (const listener of this.listeners.get(key) ?? []) {
            await listener.close();
        }
        this.transports.delete(key);
        this.listeners.delete(key);
    }
    /**
     * Removes all transports from the manager.
     * If any listeners are running, they will be closed.
     *
     * @async
     */
    async removeAll() {
        const tasks = [];
        for (const key of this.transports.keys()) {
            tasks.push(this.remove(key));
        }
        await Promise.all(tasks);
    }
}

const PROTOCOL_ID = '/multistream/1.0.0';
// Conforming to go-libp2p
// See https://github.com/multiformats/go-multistream/blob/master/multistream.go#L297
const MAX_PROTOCOL_LENGTH = 1024;

const log$k = logger$2('libp2p:mss');
const NewLine = fromString$2('\n');
function encode(buffer) {
    const list = new Uint8ArrayList(buffer, NewLine);
    return encode$b.single(list);
}
/**
 * `write` encodes and writes a single buffer
 */
function write(writer, buffer, options = {}) {
    const encoded = encode(buffer);
    if (options.writeBytes === true) {
        writer.push(encoded.subarray());
    }
    else {
        writer.push(encoded);
    }
}
/**
 * `writeAll` behaves like `write`, except it encodes an array of items as a single write
 */
function writeAll(writer, buffers, options = {}) {
    const list = new Uint8ArrayList();
    for (const buf of buffers) {
        list.append(encode(buf));
    }
    if (options.writeBytes === true) {
        writer.push(list.subarray());
    }
    else {
        writer.push(list);
    }
}
async function read(reader, options) {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = {
        [Symbol.asyncIterator]: () => varByteSource,
        next: async () => await reader.next(byteLength)
    };
    let input = varByteSource;
    // If we have been passed an abort signal, wrap the input source in an abortable
    // iterator that will throw if the operation is aborted
    if (options?.signal != null) {
        input = abortableSource(varByteSource, options.signal);
    }
    // Once the length has been parsed, read chunk for that length
    const onLength = (l) => {
        byteLength = l;
    };
    const buf = await pipe(input, decode$a({ onLength, maxDataLength: MAX_PROTOCOL_LENGTH }), async (source) => await first(source));
    if (buf == null || buf.length === 0) {
        throw errCode(new Error('no buffer returned'), 'ERR_INVALID_MULTISTREAM_SELECT_MESSAGE');
    }
    if (buf.get(buf.byteLength - 1) !== NewLine[0]) {
        log$k.error('Invalid mss message - missing newline - %s', buf.subarray());
        throw errCode(new Error('missing newline'), 'ERR_INVALID_MULTISTREAM_SELECT_MESSAGE');
    }
    return buf.sublist(0, -1); // Remove newline
}
async function readString(reader, options) {
    const buf = await read(reader, options);
    return toString$7(buf.subarray());
}

const log$j = logger$2('libp2p:mss:select');
async function select(stream, protocols, options = {}) {
    protocols = Array.isArray(protocols) ? [...protocols] : [protocols];
    const { reader, writer, rest, stream: shakeStream } = handshake(stream);
    const protocol = protocols.shift();
    if (protocol == null) {
        throw new Error('At least one protocol must be specified');
    }
    log$j('select: write ["%s", "%s"]', PROTOCOL_ID, protocol);
    const p1 = fromString$2(PROTOCOL_ID);
    const p2 = fromString$2(protocol);
    writeAll(writer, [p1, p2], options);
    let response = await readString(reader, options);
    log$j('select: read "%s"', response);
    // Read the protocol response if we got the protocolId in return
    if (response === PROTOCOL_ID) {
        response = await readString(reader, options);
        log$j('select: read "%s"', response);
    }
    // We're done
    if (response === protocol) {
        rest();
        return { stream: shakeStream, protocol };
    }
    // We haven't gotten a valid ack, try the other protocols
    for (const protocol of protocols) {
        log$j('select: write "%s"', protocol);
        write(writer, fromString$2(protocol), options);
        const response = await readString(reader, options);
        log$j('select: read "%s" for "%s"', response, protocol);
        if (response === protocol) {
            rest(); // End our writer so others can start writing to stream
            return { stream: shakeStream, protocol };
        }
    }
    rest();
    throw errCode(new Error('protocol selection failed'), 'ERR_UNSUPPORTED_PROTOCOL');
}

const log$i = logger$2('libp2p:mss:handle');
async function handle(stream, protocols, options) {
    protocols = Array.isArray(protocols) ? protocols : [protocols];
    const { writer, reader, rest, stream: shakeStream } = handshake(stream);
    while (true) {
        const protocol = await readString(reader, options);
        log$i('read "%s"', protocol);
        if (protocol === PROTOCOL_ID) {
            log$i('respond with "%s" for "%s"', PROTOCOL_ID, protocol);
            write(writer, fromString$2(PROTOCOL_ID), options);
            continue;
        }
        if (protocols.includes(protocol)) {
            write(writer, fromString$2(protocol), options);
            log$i('respond with "%s" for "%s"', protocol, protocol);
            rest();
            return { stream: shakeStream, protocol };
        }
        if (protocol === 'ls') {
            // <varint-msg-len><varint-proto-name-len><proto-name>\n<varint-proto-name-len><proto-name>\n\n
            write(writer, new Uint8ArrayList(...protocols.map(p => encode(fromString$2(p)))), options);
            // multistream.writeAll(writer, protocols.map(p => uint8ArrayFromString(p)))
            log$i('respond with "%s" for %s', protocols, protocol);
            continue;
        }
        write(writer, fromString$2('na'), options);
        log$i('respond with "na" for "%s"', protocol);
    }
}

const symbol = Symbol.for('@libp2p/connection');

const log$h = logger$2('libp2p:connection');
/**
 * An implementation of the js-libp2p connection.
 * Any libp2p transport should use an upgrader to return this connection.
 */
class ConnectionImpl {
    /**
     * An implementation of the js-libp2p connection.
     * Any libp2p transport should use an upgrader to return this connection.
     */
    constructor(init) {
        const { remoteAddr, remotePeer, newStream, close, getStreams, stat } = init;
        this.id = `${(parseInt(String(Math.random() * 1e9))).toString(36)}${Date.now()}`;
        this.remoteAddr = remoteAddr;
        this.remotePeer = remotePeer;
        this.stat = {
            ...stat,
            status: OPEN
        };
        this._newStream = newStream;
        this._close = close;
        this._getStreams = getStreams;
        this.tags = [];
        this._closing = false;
    }
    get [Symbol.toStringTag]() {
        return 'Connection';
    }
    get [symbol]() {
        return true;
    }
    /**
     * Get all the streams of the muxer
     */
    get streams() {
        return this._getStreams();
    }
    /**
     * Create a new stream from this connection
     */
    async newStream(protocols, options) {
        if (this.stat.status === CLOSING) {
            throw errCode(new Error('the connection is being closed'), 'ERR_CONNECTION_BEING_CLOSED');
        }
        if (this.stat.status === CLOSED) {
            throw errCode(new Error('the connection is closed'), 'ERR_CONNECTION_CLOSED');
        }
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        const stream = await this._newStream(protocols, options);
        stream.stat.direction = 'outbound';
        return stream;
    }
    /**
     * Add a stream when it is opened to the registry
     */
    addStream(stream) {
        stream.stat.direction = 'inbound';
    }
    /**
     * Remove stream registry after it is closed
     */
    removeStream(id) {
    }
    /**
     * Close the connection
     */
    async close() {
        if (this.stat.status === CLOSED || this._closing) {
            return;
        }
        this.stat.status = CLOSING;
        // close all streams - this can throw if we're not multiplexed
        try {
            this.streams.forEach(s => s.close());
        }
        catch (err) {
            log$h.error(err);
        }
        // Close raw connection
        this._closing = true;
        await this._close();
        this._closing = false;
        this.stat.timeline.close = Date.now();
        this.stat.status = CLOSED;
    }
}
function createConnection(init) {
    return new ConnectionImpl(init);
}

const log$g = logger$2('libp2p:registrar');
const DEFAULT_MAX_INBOUND_STREAMS = 32;
const DEFAULT_MAX_OUTBOUND_STREAMS = 64;
/**
 * Responsible for notifying registered protocols of events in the network.
 */
class DefaultRegistrar {
    constructor(components) {
        this.topologies = new Map();
        this.handlers = new Map();
        this.components = components;
        this._onDisconnect = this._onDisconnect.bind(this);
        this._onProtocolChange = this._onProtocolChange.bind(this);
        this._onConnect = this._onConnect.bind(this);
        this.components.connectionManager.addEventListener('peer:disconnect', this._onDisconnect);
        this.components.connectionManager.addEventListener('peer:connect', this._onConnect);
        // happens after identify
        this.components.peerStore.addEventListener('change:protocols', this._onProtocolChange);
    }
    getProtocols() {
        return Array.from(new Set([
            ...this.topologies.keys(),
            ...this.handlers.keys()
        ])).sort();
    }
    getHandler(protocol) {
        const handler = this.handlers.get(protocol);
        if (handler == null) {
            throw errCode(new Error(`No handler registered for protocol ${protocol}`), codes$1.ERR_NO_HANDLER_FOR_PROTOCOL);
        }
        return handler;
    }
    getTopologies(protocol) {
        const topologies = this.topologies.get(protocol);
        if (topologies == null) {
            return [];
        }
        return [
            ...topologies.values()
        ];
    }
    /**
     * Registers the `handler` for each protocol
     */
    async handle(protocol, handler, opts) {
        if (this.handlers.has(protocol)) {
            throw errCode(new Error(`Handler already registered for protocol ${protocol}`), codes$1.ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED);
        }
        const options = mergeOptions.bind({ ignoreUndefined: true })({
            maxInboundStreams: DEFAULT_MAX_INBOUND_STREAMS,
            maxOutboundStreams: DEFAULT_MAX_OUTBOUND_STREAMS
        }, opts);
        this.handlers.set(protocol, {
            handler,
            options
        });
        // Add new protocols to self protocols in the Protobook
        await this.components.peerStore.protoBook.add(this.components.peerId, [protocol]);
    }
    /**
     * Removes the handler for each protocol. The protocol
     * will no longer be supported on streams.
     */
    async unhandle(protocols) {
        const protocolList = Array.isArray(protocols) ? protocols : [protocols];
        protocolList.forEach(protocol => {
            this.handlers.delete(protocol);
        });
        // Remove protocols from self protocols in the Protobook
        await this.components.peerStore.protoBook.remove(this.components.peerId, protocolList);
    }
    /**
     * Register handlers for a set of multicodecs given
     */
    async register(protocol, topology) {
        if (!isTopology(topology)) {
            log$g.error('topology must be an instance of interfaces/topology');
            throw errCode(new Error('topology must be an instance of interfaces/topology'), codes$1.ERR_INVALID_PARAMETERS);
        }
        // Create topology
        const id = `${(Math.random() * 1e9).toString(36)}${Date.now()}`;
        let topologies = this.topologies.get(protocol);
        if (topologies == null) {
            topologies = new Map();
            this.topologies.set(protocol, topologies);
        }
        topologies.set(id, topology);
        // Set registrar
        await topology.setRegistrar(this);
        return id;
    }
    /**
     * Unregister topology
     */
    unregister(id) {
        for (const [protocol, topologies] of this.topologies.entries()) {
            if (topologies.has(id)) {
                topologies.delete(id);
                if (topologies.size === 0) {
                    this.topologies.delete(protocol);
                }
            }
        }
    }
    /**
     * Remove a disconnected peer from the record
     */
    _onDisconnect(evt) {
        const connection = evt.detail;
        void this.components.peerStore.protoBook.get(connection.remotePeer)
            .then(peerProtocols => {
            for (const protocol of peerProtocols) {
                const topologies = this.topologies.get(protocol);
                if (topologies == null) {
                    // no topologies are interested in this protocol
                    continue;
                }
                for (const topology of topologies.values()) {
                    topology.onDisconnect(connection.remotePeer);
                }
            }
        })
            .catch(err => {
            log$g.error(err);
        });
    }
    /**
     * On peer connected if we already have their protocols. Usually used for reconnects
     * as change:protocols event won't be emitted due to identical protocols.
     */
    _onConnect(evt) {
        const connection = evt.detail;
        void this.components.peerStore.protoBook.get(connection.remotePeer)
            .then(peerProtocols => {
            for (const protocol of peerProtocols) {
                const topologies = this.topologies.get(protocol);
                if (topologies == null) {
                    // no topologies are interested in this protocol
                    continue;
                }
                for (const topology of topologies.values()) {
                    topology.onConnect(connection.remotePeer, connection);
                }
            }
        })
            .catch(err => {
            log$g.error(err);
        });
    }
    /**
     * Check if a new peer support the multicodecs for this topology
     */
    _onProtocolChange(evt) {
        const { peerId, protocols, oldProtocols } = evt.detail;
        const removed = oldProtocols.filter(protocol => !protocols.includes(protocol));
        const added = protocols.filter(protocol => !oldProtocols.includes(protocol));
        for (const protocol of removed) {
            const topologies = this.topologies.get(protocol);
            if (topologies == null) {
                // no topologies are interested in this protocol
                continue;
            }
            for (const topology of topologies.values()) {
                topology.onDisconnect(peerId);
            }
        }
        for (const protocol of added) {
            const topologies = this.topologies.get(protocol);
            if (topologies == null) {
                // no topologies are interested in this protocol
                continue;
            }
            for (const topology of topologies.values()) {
                const connection = this.components.connectionManager.getConnections(peerId)[0];
                if (connection == null) {
                    continue;
                }
                topology.onConnect(peerId, connection);
            }
        }
    }
}

const log$f = logger$2('libp2p:upgrader');
function findIncomingStreamLimit(protocol, registrar) {
    try {
        const { options } = registrar.getHandler(protocol);
        return options.maxInboundStreams;
    }
    catch (err) {
        if (err.code !== codes$1.ERR_NO_HANDLER_FOR_PROTOCOL) {
            throw err;
        }
    }
    return DEFAULT_MAX_INBOUND_STREAMS;
}
function findOutgoingStreamLimit(protocol, registrar) {
    try {
        const { options } = registrar.getHandler(protocol);
        return options.maxOutboundStreams;
    }
    catch (err) {
        if (err.code !== codes$1.ERR_NO_HANDLER_FOR_PROTOCOL) {
            throw err;
        }
    }
    return DEFAULT_MAX_OUTBOUND_STREAMS;
}
function countStreams(protocol, direction, connection) {
    let streamCount = 0;
    connection.streams.forEach(stream => {
        if (stream.stat.direction === direction && stream.stat.protocol === protocol) {
            streamCount++;
        }
    });
    return streamCount;
}
class DefaultUpgrader extends EventEmitter$1 {
    constructor(components, init) {
        super();
        this.components = components;
        this.connectionEncryption = new Map();
        init.connectionEncryption.forEach(encrypter => {
            this.connectionEncryption.set(encrypter.protocol, encrypter);
        });
        this.muxers = new Map();
        init.muxers.forEach(muxer => {
            this.muxers.set(muxer.protocol, muxer);
        });
        this.inboundUpgradeTimeout = init.inboundUpgradeTimeout;
    }
    /**
     * Upgrades an inbound connection
     */
    async upgradeInbound(maConn, opts) {
        const accept = await this.components.connectionManager.acceptIncomingConnection(maConn);
        if (!accept) {
            throw errCode(new Error('connection denied'), codes$1.ERR_CONNECTION_DENIED);
        }
        let encryptedConn;
        let remotePeer;
        let upgradedConn;
        let muxerFactory;
        let cryptoProtocol;
        const timeoutController = new timeoutAbortController.TimeoutController(this.inboundUpgradeTimeout);
        try {
            // fails on node < 15.4
            eventsExports.setMaxListeners?.(Infinity, timeoutController.signal);
        }
        catch { }
        try {
            const abortableStream = abortableDuplex(maConn, timeoutController.signal);
            maConn.source = abortableStream.source;
            maConn.sink = abortableStream.sink;
            if (await this.components.connectionGater.denyInboundConnection(maConn)) {
                throw errCode(new Error('The multiaddr connection is blocked by gater.acceptConnection'), codes$1.ERR_CONNECTION_INTERCEPTED);
            }
            this.components.metrics?.trackMultiaddrConnection(maConn);
            log$f('starting the inbound connection upgrade');
            // Protect
            let protectedConn = maConn;
            if (opts?.skipProtection !== true) {
                const protector = this.components.connectionProtector;
                if (protector != null) {
                    log$f('protecting the inbound connection');
                    protectedConn = await protector.protect(maConn);
                }
            }
            try {
                // Encrypt the connection
                encryptedConn = protectedConn;
                if (opts?.skipEncryption !== true) {
                    ({
                        conn: encryptedConn,
                        remotePeer,
                        protocol: cryptoProtocol
                    } = await this._encryptInbound(protectedConn));
                    if (await this.components.connectionGater.denyInboundEncryptedConnection(remotePeer, {
                        ...protectedConn,
                        ...encryptedConn
                    })) {
                        throw errCode(new Error('The multiaddr connection is blocked by gater.acceptEncryptedConnection'), codes$1.ERR_CONNECTION_INTERCEPTED);
                    }
                }
                else {
                    const idStr = maConn.remoteAddr.getPeerId();
                    if (idStr == null) {
                        throw errCode(new Error('inbound connection that skipped encryption must have a peer id'), codes$1.ERR_INVALID_MULTIADDR);
                    }
                    const remotePeerId = peerIdFromString(idStr);
                    cryptoProtocol = 'native';
                    remotePeer = remotePeerId;
                }
                upgradedConn = encryptedConn;
                if (opts?.muxerFactory != null) {
                    muxerFactory = opts.muxerFactory;
                }
                else if (this.muxers.size > 0) {
                    // Multiplex the connection
                    const multiplexed = await this._multiplexInbound({
                        ...protectedConn,
                        ...encryptedConn
                    }, this.muxers);
                    muxerFactory = multiplexed.muxerFactory;
                    upgradedConn = multiplexed.stream;
                }
            }
            catch (err) {
                log$f.error('Failed to upgrade inbound connection', err);
                throw err;
            }
            if (await this.components.connectionGater.denyInboundUpgradedConnection(remotePeer, {
                ...protectedConn,
                ...encryptedConn
            })) {
                throw errCode(new Error('The multiaddr connection is blocked by gater.acceptEncryptedConnection'), codes$1.ERR_CONNECTION_INTERCEPTED);
            }
            log$f('Successfully upgraded inbound connection');
            return this._createConnection({
                cryptoProtocol,
                direction: 'inbound',
                maConn,
                upgradedConn,
                muxerFactory,
                remotePeer
            });
        }
        finally {
            this.components.connectionManager.afterUpgradeInbound();
            timeoutController.clear();
        }
    }
    /**
     * Upgrades an outbound connection
     */
    async upgradeOutbound(maConn, opts) {
        const idStr = maConn.remoteAddr.getPeerId();
        let remotePeerId;
        if (idStr != null) {
            remotePeerId = peerIdFromString(idStr);
            if (await this.components.connectionGater.denyOutboundConnection(remotePeerId, maConn)) {
                throw errCode(new Error('The multiaddr connection is blocked by connectionGater.denyOutboundConnection'), codes$1.ERR_CONNECTION_INTERCEPTED);
            }
        }
        let encryptedConn;
        let remotePeer;
        let upgradedConn;
        let cryptoProtocol;
        let muxerFactory;
        this.components.metrics?.trackMultiaddrConnection(maConn);
        log$f('Starting the outbound connection upgrade');
        // If the transport natively supports encryption, skip connection
        // protector and encryption
        // Protect
        let protectedConn = maConn;
        if (opts?.skipProtection !== true) {
            const protector = this.components.connectionProtector;
            if (protector != null) {
                protectedConn = await protector.protect(maConn);
            }
        }
        try {
            // Encrypt the connection
            encryptedConn = protectedConn;
            if (opts?.skipEncryption !== true) {
                ({
                    conn: encryptedConn,
                    remotePeer,
                    protocol: cryptoProtocol
                } = await this._encryptOutbound(protectedConn, remotePeerId));
                if (await this.components.connectionGater.denyOutboundEncryptedConnection(remotePeer, {
                    ...protectedConn,
                    ...encryptedConn
                })) {
                    throw errCode(new Error('The multiaddr connection is blocked by gater.acceptEncryptedConnection'), codes$1.ERR_CONNECTION_INTERCEPTED);
                }
            }
            else {
                if (remotePeerId == null) {
                    throw errCode(new Error('Encryption was skipped but no peer id was passed'), codes$1.ERR_INVALID_PEER);
                }
                cryptoProtocol = 'native';
                remotePeer = remotePeerId;
            }
            upgradedConn = encryptedConn;
            if (opts?.muxerFactory != null) {
                muxerFactory = opts.muxerFactory;
            }
            else if (this.muxers.size > 0) {
                // Multiplex the connection
                const multiplexed = await this._multiplexOutbound({
                    ...protectedConn,
                    ...encryptedConn
                }, this.muxers);
                muxerFactory = multiplexed.muxerFactory;
                upgradedConn = multiplexed.stream;
            }
        }
        catch (err) {
            log$f.error('Failed to upgrade outbound connection', err);
            await maConn.close(err);
            throw err;
        }
        if (await this.components.connectionGater.denyOutboundUpgradedConnection(remotePeer, {
            ...protectedConn,
            ...encryptedConn
        })) {
            throw errCode(new Error('The multiaddr connection is blocked by gater.acceptEncryptedConnection'), codes$1.ERR_CONNECTION_INTERCEPTED);
        }
        log$f('Successfully upgraded outbound connection');
        return this._createConnection({
            cryptoProtocol,
            direction: 'outbound',
            maConn,
            upgradedConn,
            muxerFactory,
            remotePeer
        });
    }
    /**
     * A convenience method for generating a new `Connection`
     */
    _createConnection(opts) {
        const { cryptoProtocol, direction, maConn, upgradedConn, remotePeer, muxerFactory } = opts;
        let muxer;
        let newStream;
        let connection; // eslint-disable-line prefer-const
        if (muxerFactory != null) {
            // Create the muxer
            muxer = muxerFactory.createStreamMuxer({
                direction,
                // Run anytime a remote stream is created
                onIncomingStream: muxedStream => {
                    if (connection == null) {
                        return;
                    }
                    void Promise.resolve()
                        .then(async () => {
                        const protocols = this.components.registrar.getProtocols();
                        const { stream, protocol } = await handle(muxedStream, protocols);
                        log$f('%s: incoming stream opened on %s', direction, protocol);
                        if (connection == null) {
                            return;
                        }
                        const incomingLimit = findIncomingStreamLimit(protocol, this.components.registrar);
                        const streamCount = countStreams(protocol, 'inbound', connection);
                        if (streamCount === incomingLimit) {
                            muxedStream.abort(errCode(new Error(`Too many inbound protocol streams for protocol "${protocol}" - limit ${incomingLimit}`), codes$1.ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS));
                            return;
                        }
                        // after the handshake the returned stream can have early data so override
                        // the souce/sink
                        muxedStream.source = stream.source;
                        muxedStream.sink = stream.sink;
                        muxedStream.stat.protocol = protocol;
                        // If a protocol stream has been successfully negotiated and is to be passed to the application,
                        // the peerstore should ensure that the peer is registered with that protocol
                        this.components.peerStore.protoBook.add(remotePeer, [protocol]).catch(err => log$f.error(err));
                        connection.addStream(muxedStream);
                        this.components.metrics?.trackProtocolStream(muxedStream, connection);
                        this._onStream({ connection, stream: muxedStream, protocol });
                    })
                        .catch(err => {
                        log$f.error(err);
                        if (muxedStream.stat.timeline.close == null) {
                            muxedStream.close();
                        }
                    });
                },
                // Run anytime a stream closes
                onStreamEnd: muxedStream => {
                    connection?.removeStream(muxedStream.id);
                }
            });
            newStream = async (protocols, options = {}) => {
                if (muxer == null) {
                    throw errCode(new Error('Stream is not multiplexed'), codes$1.ERR_MUXER_UNAVAILABLE);
                }
                log$f('%s: starting new stream on %s', direction, protocols);
                const muxedStream = await muxer.newStream();
                let controller;
                try {
                    if (options.signal == null) {
                        log$f('No abort signal was passed while trying to negotiate protocols %s falling back to default timeout', protocols);
                        controller = new timeoutAbortController.TimeoutController(30000);
                        options.signal = controller.signal;
                        try {
                            // fails on node < 15.4
                            eventsExports.setMaxListeners?.(Infinity, controller.signal);
                        }
                        catch { }
                    }
                    const { stream, protocol } = await select(muxedStream, protocols, options);
                    const outgoingLimit = findOutgoingStreamLimit(protocol, this.components.registrar);
                    const streamCount = countStreams(protocol, 'outbound', connection);
                    if (streamCount === outgoingLimit) {
                        const err = errCode(new Error(`Too many outbound protocol streams for protocol "${protocol}" - limit ${outgoingLimit}`), codes$1.ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS);
                        muxedStream.abort(err);
                        throw err;
                    }
                    // If a protocol stream has been successfully negotiated and is to be passed to the application,
                    // the peerstore should ensure that the peer is registered with that protocol
                    this.components.peerStore.protoBook.add(remotePeer, [protocol]).catch(err => log$f.error(err));
                    // after the handshake the returned stream can have early data so override
                    // the souce/sink
                    muxedStream.source = stream.source;
                    muxedStream.sink = stream.sink;
                    muxedStream.stat.protocol = protocol;
                    this.components.metrics?.trackProtocolStream(muxedStream, connection);
                    return muxedStream;
                }
                catch (err) {
                    log$f.error('could not create new stream', err);
                    if (muxedStream.stat.timeline.close == null) {
                        muxedStream.close();
                    }
                    if (err.code != null) {
                        throw err;
                    }
                    throw errCode(err, codes$1.ERR_UNSUPPORTED_PROTOCOL);
                }
                finally {
                    if (controller != null) {
                        controller.clear();
                    }
                }
            };
            // Pipe all data through the muxer
            void Promise.all([
                muxer.sink(upgradedConn.source),
                upgradedConn.sink(muxer.source)
            ]).catch(err => {
                log$f.error(err);
            });
        }
        const _timeline = maConn.timeline;
        maConn.timeline = new Proxy(_timeline, {
            set: (...args) => {
                if (connection != null && args[1] === 'close' && args[2] != null && _timeline.close == null) {
                    // Wait for close to finish before notifying of the closure
                    (async () => {
                        try {
                            if (connection.stat.status === 'OPEN') {
                                await connection.close();
                            }
                        }
                        catch (err) {
                            log$f.error(err);
                        }
                        finally {
                            this.dispatchEvent(new CustomEvent('connectionEnd', {
                                detail: connection
                            }));
                        }
                    })().catch(err => {
                        log$f.error(err);
                    });
                }
                return Reflect.set(...args);
            }
        });
        maConn.timeline.upgraded = Date.now();
        const errConnectionNotMultiplexed = () => {
            throw errCode(new Error('connection is not multiplexed'), codes$1.ERR_CONNECTION_NOT_MULTIPLEXED);
        };
        // Create the connection
        connection = createConnection({
            remoteAddr: maConn.remoteAddr,
            remotePeer: remotePeer,
            stat: {
                status: 'OPEN',
                direction,
                timeline: maConn.timeline,
                multiplexer: muxer?.protocol,
                encryption: cryptoProtocol
            },
            newStream: newStream ?? errConnectionNotMultiplexed,
            getStreams: () => muxer != null ? muxer.streams : errConnectionNotMultiplexed(),
            close: async () => {
                await maConn.close();
                // Ensure remaining streams are closed
                if (muxer != null) {
                    muxer.close();
                }
            }
        });
        this.dispatchEvent(new CustomEvent('connection', {
            detail: connection
        }));
        return connection;
    }
    /**
     * Routes incoming streams to the correct handler
     */
    _onStream(opts) {
        const { connection, stream, protocol } = opts;
        const { handler } = this.components.registrar.getHandler(protocol);
        handler({ connection, stream });
    }
    /**
     * Attempts to encrypt the incoming `connection` with the provided `cryptos`
     */
    async _encryptInbound(connection) {
        const protocols = Array.from(this.connectionEncryption.keys());
        log$f('handling inbound crypto protocol selection', protocols);
        try {
            const { stream, protocol } = await handle(connection, protocols, {
                writeBytes: true
            });
            const encrypter = this.connectionEncryption.get(protocol);
            if (encrypter == null) {
                throw new Error(`no crypto module found for ${protocol}`);
            }
            log$f('encrypting inbound connection...');
            return {
                ...await encrypter.secureInbound(this.components.peerId, stream),
                protocol
            };
        }
        catch (err) {
            throw errCode(err, codes$1.ERR_ENCRYPTION_FAILED);
        }
    }
    /**
     * Attempts to encrypt the given `connection` with the provided connection encrypters.
     * The first `ConnectionEncrypter` module to succeed will be used
     */
    async _encryptOutbound(connection, remotePeerId) {
        const protocols = Array.from(this.connectionEncryption.keys());
        log$f('selecting outbound crypto protocol', protocols);
        try {
            const { stream, protocol } = await select(connection, protocols, {
                writeBytes: true
            });
            const encrypter = this.connectionEncryption.get(protocol);
            if (encrypter == null) {
                throw new Error(`no crypto module found for ${protocol}`);
            }
            log$f('encrypting outbound connection to %p', remotePeerId);
            return {
                ...await encrypter.secureOutbound(this.components.peerId, stream, remotePeerId),
                protocol
            };
        }
        catch (err) {
            throw errCode(err, codes$1.ERR_ENCRYPTION_FAILED);
        }
    }
    /**
     * Selects one of the given muxers via multistream-select. That
     * muxer will be used for all future streams on the connection.
     */
    async _multiplexOutbound(connection, muxers) {
        const protocols = Array.from(muxers.keys());
        log$f('outbound selecting muxer %s', protocols);
        try {
            const { stream, protocol } = await select(connection, protocols, {
                writeBytes: true
            });
            log$f('%s selected as muxer protocol', protocol);
            const muxerFactory = muxers.get(protocol);
            return { stream, muxerFactory };
        }
        catch (err) {
            log$f.error('error multiplexing outbound stream', err);
            throw errCode(err, codes$1.ERR_MUXER_UNAVAILABLE);
        }
    }
    /**
     * Registers support for one of the given muxers via multistream-select. The
     * selected muxer will be used for all future streams on the connection.
     */
    async _multiplexInbound(connection, muxers) {
        const protocols = Array.from(muxers.keys());
        log$f('inbound handling muxers %s', protocols);
        try {
            const { stream, protocol } = await handle(connection, protocols, {
                writeBytes: true
            });
            const muxerFactory = muxers.get(protocol);
            return { stream, muxerFactory };
        }
        catch (err) {
            log$f.error('error multiplexing inbound stream', err);
            throw errCode(err, codes$1.ERR_MUXER_UNAVAILABLE);
        }
    }
}

/* eslint-disable import/export */
var Identify;
(function (Identify) {
    let _codec;
    Identify.codec = () => {
        if (_codec == null) {
            _codec = message$4((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.protocolVersion != null) {
                    w.uint32(42);
                    w.string(obj.protocolVersion);
                }
                if (obj.agentVersion != null) {
                    w.uint32(50);
                    w.string(obj.agentVersion);
                }
                if (obj.publicKey != null) {
                    w.uint32(10);
                    w.bytes(obj.publicKey);
                }
                if (obj.listenAddrs != null) {
                    for (const value of obj.listenAddrs) {
                        w.uint32(18);
                        w.bytes(value);
                    }
                }
                if (obj.observedAddr != null) {
                    w.uint32(34);
                    w.bytes(obj.observedAddr);
                }
                if (obj.protocols != null) {
                    for (const value of obj.protocols) {
                        w.uint32(26);
                        w.string(value);
                    }
                }
                if (obj.signedPeerRecord != null) {
                    w.uint32(66);
                    w.bytes(obj.signedPeerRecord);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    listenAddrs: [],
                    protocols: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 5:
                            obj.protocolVersion = reader.string();
                            break;
                        case 6:
                            obj.agentVersion = reader.string();
                            break;
                        case 1:
                            obj.publicKey = reader.bytes();
                            break;
                        case 2:
                            obj.listenAddrs.push(reader.bytes());
                            break;
                        case 4:
                            obj.observedAddr = reader.bytes();
                            break;
                        case 3:
                            obj.protocols.push(reader.string());
                            break;
                        case 8:
                            obj.signedPeerRecord = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Identify.encode = (obj) => {
        return encodeMessage$4(obj, Identify.codec());
    };
    Identify.decode = (buf) => {
        return decodeMessage$5(buf, Identify.codec());
    };
})(Identify || (Identify = {}));

const version = '0.0.0';
const name = 'libp2p';

const AGENT_VERSION = `js-libp2p/${version}`;
const IDENTIFY_PROTOCOL_VERSION = '0.1.0';
const MULTICODEC_IDENTIFY_PROTOCOL_NAME = 'id';
const MULTICODEC_IDENTIFY_PUSH_PROTOCOL_NAME = 'id/push';
const MULTICODEC_IDENTIFY_PROTOCOL_VERSION = '1.0.0';
const MULTICODEC_IDENTIFY_PUSH_PROTOCOL_VERSION = '1.0.0';

const log$e = logger$2('libp2p:identify');
// https://github.com/libp2p/go-libp2p/blob/8d2e54e1637041d5cf4fac1e531287560bd1f4ac/p2p/protocol/identify/id.go#L52
const MAX_IDENTIFY_MESSAGE_SIZE = 1024 * 8;
class IdentifyService {
    constructor(components, init) {
        this.components = components;
        this.started = false;
        this.init = init;
        this.identifyProtocolStr = `/${init.protocolPrefix}/${MULTICODEC_IDENTIFY_PROTOCOL_NAME}/${MULTICODEC_IDENTIFY_PROTOCOL_VERSION}`;
        this.identifyPushProtocolStr = `/${init.protocolPrefix}/${MULTICODEC_IDENTIFY_PUSH_PROTOCOL_NAME}/${MULTICODEC_IDENTIFY_PUSH_PROTOCOL_VERSION}`;
        // Store self host metadata
        this.host = {
            protocolVersion: `${init.protocolPrefix}/${IDENTIFY_PROTOCOL_VERSION}`,
            ...init.host
        };
        // When a new connection happens, trigger identify
        this.components.connectionManager.addEventListener('peer:connect', (evt) => {
            const connection = evt.detail;
            this.identify(connection).catch(log$e.error);
        });
        // When self multiaddrs change, trigger identify-push
        this.components.peerStore.addEventListener('change:multiaddrs', (evt) => {
            const { peerId } = evt.detail;
            if (this.components.peerId.equals(peerId)) {
                void this.pushToPeerStore().catch(err => log$e.error(err));
            }
        });
        // When self protocols change, trigger identify-push
        this.components.peerStore.addEventListener('change:protocols', (evt) => {
            const { peerId } = evt.detail;
            if (this.components.peerId.equals(peerId)) {
                void this.pushToPeerStore().catch(err => log$e.error(err));
            }
        });
    }
    isStarted() {
        return this.started;
    }
    async start() {
        if (this.started) {
            return;
        }
        await this.components.peerStore.metadataBook.setValue(this.components.peerId, 'AgentVersion', fromString$2(this.host.agentVersion));
        await this.components.peerStore.metadataBook.setValue(this.components.peerId, 'ProtocolVersion', fromString$2(this.host.protocolVersion));
        await this.components.registrar.handle(this.identifyProtocolStr, (data) => {
            void this._handleIdentify(data).catch(err => {
                log$e.error(err);
            });
        }, {
            maxInboundStreams: this.init.maxInboundStreams,
            maxOutboundStreams: this.init.maxOutboundStreams
        });
        await this.components.registrar.handle(this.identifyPushProtocolStr, (data) => {
            void this._handlePush(data).catch(err => {
                log$e.error(err);
            });
        }, {
            maxInboundStreams: this.init.maxPushIncomingStreams,
            maxOutboundStreams: this.init.maxPushOutgoingStreams
        });
        this.started = true;
    }
    async stop() {
        await this.components.registrar.unhandle(this.identifyProtocolStr);
        await this.components.registrar.unhandle(this.identifyPushProtocolStr);
        this.started = false;
    }
    /**
     * Send an Identify Push update to the list of connections
     */
    async push(connections) {
        const signedPeerRecord = await this.components.peerStore.addressBook.getRawEnvelope(this.components.peerId);
        const listenAddrs = this.components.addressManager.getAddresses().map((ma) => ma.bytes);
        const protocols = await this.components.peerStore.protoBook.get(this.components.peerId);
        const pushes = connections.map(async (connection) => {
            let stream;
            const timeoutController = new timeoutAbortController.TimeoutController(this.init.timeout);
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, timeoutController.signal);
            }
            catch { }
            try {
                stream = await connection.newStream([this.identifyPushProtocolStr], {
                    signal: timeoutController.signal
                });
                // make stream abortable
                const source = abortableDuplex(stream, timeoutController.signal);
                await source.sink(pipe([Identify.encode({
                        listenAddrs,
                        signedPeerRecord,
                        protocols
                    })], encode$b()));
            }
            catch (err) {
                // Just log errors
                log$e.error('could not push identify update to peer', err);
            }
            finally {
                if (stream != null) {
                    stream.close();
                }
                timeoutController.clear();
            }
        });
        await Promise.all(pushes);
    }
    /**
     * Calls `push` on all peer connections
     */
    async pushToPeerStore() {
        // Do not try to push if we are not running
        if (!this.isStarted()) {
            return;
        }
        const connections = [];
        for (const conn of this.components.connectionManager.getConnections()) {
            const peerId = conn.remotePeer;
            const peer = await this.components.peerStore.get(peerId);
            if (!peer.protocols.includes(this.identifyPushProtocolStr)) {
                continue;
            }
            connections.push(conn);
        }
        await this.push(connections);
    }
    async _identify(connection, options = {}) {
        let timeoutController;
        let signal = options.signal;
        let stream;
        // create a timeout if no abort signal passed
        if (signal == null) {
            timeoutController = new timeoutAbortController.TimeoutController(this.init.timeout);
            signal = timeoutController.signal;
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, timeoutController.signal);
            }
            catch { }
        }
        try {
            stream = await connection.newStream([this.identifyProtocolStr], {
                signal
            });
            // make stream abortable
            const source = abortableDuplex(stream, signal);
            const data = await pipe([], source, decode$a({
                maxDataLength: this.init.maxIdentifyMessageSize ?? MAX_IDENTIFY_MESSAGE_SIZE
            }), async (source) => await first(source));
            if (data == null) {
                throw errCode(new Error('No data could be retrieved'), codes$1.ERR_CONNECTION_ENDED);
            }
            try {
                return Identify.decode(data);
            }
            catch (err) {
                throw errCode(err, codes$1.ERR_INVALID_MESSAGE);
            }
        }
        finally {
            if (timeoutController != null) {
                timeoutController.clear();
            }
            if (stream != null) {
                stream.close();
            }
        }
    }
    /**
     * Requests the `Identify` message from peer associated with the given `connection`.
     * If the identified peer does not match the `PeerId` associated with the connection,
     * an error will be thrown.
     */
    async identify(connection, options = {}) {
        const message = await this._identify(connection, options);
        const { publicKey, listenAddrs, protocols, observedAddr, signedPeerRecord, agentVersion, protocolVersion } = message;
        if (publicKey == null) {
            throw errCode(new Error('public key was missing from identify message'), codes$1.ERR_MISSING_PUBLIC_KEY);
        }
        const id = await peerIdFromKeys(publicKey);
        if (!connection.remotePeer.equals(id)) {
            throw errCode(new Error('identified peer does not match the expected peer'), codes$1.ERR_INVALID_PEER);
        }
        if (this.components.peerId.equals(id)) {
            throw errCode(new Error('identified peer is our own peer id?'), codes$1.ERR_INVALID_PEER);
        }
        // Get the observedAddr if there is one
        const cleanObservedAddr = IdentifyService.getCleanMultiaddr(observedAddr);
        if (signedPeerRecord != null) {
            log$e('received signed peer record from %p', id);
            try {
                const envelope = await RecordEnvelope.openAndCertify(signedPeerRecord, PeerRecord.DOMAIN);
                if (!envelope.peerId.equals(id)) {
                    throw errCode(new Error('identified peer does not match the expected peer'), codes$1.ERR_INVALID_PEER);
                }
                if (await this.components.peerStore.addressBook.consumePeerRecord(envelope)) {
                    await this.components.peerStore.protoBook.set(id, protocols);
                    if (agentVersion != null) {
                        await this.components.peerStore.metadataBook.setValue(id, 'AgentVersion', fromString$2(agentVersion));
                    }
                    if (protocolVersion != null) {
                        await this.components.peerStore.metadataBook.setValue(id, 'ProtocolVersion', fromString$2(protocolVersion));
                    }
                    log$e('identify completed for peer %p and protocols %o', id, protocols);
                    return;
                }
            }
            catch (err) {
                log$e('received invalid envelope, discard it and fallback to listenAddrs is available', err);
            }
        }
        else {
            log$e('no signed peer record received from %p', id);
        }
        log$e('falling back to legacy addresses from %p', id);
        // LEGACY: Update peers data in PeerStore
        try {
            await this.components.peerStore.addressBook.set(id, listenAddrs.map((addr) => multiaddr$1(addr)));
        }
        catch (err) {
            log$e.error('received invalid addrs', err);
        }
        await this.components.peerStore.protoBook.set(id, protocols);
        if (agentVersion != null) {
            await this.components.peerStore.metadataBook.setValue(id, 'AgentVersion', fromString$2(agentVersion));
        }
        if (protocolVersion != null) {
            await this.components.peerStore.metadataBook.setValue(id, 'ProtocolVersion', fromString$2(protocolVersion));
        }
        log$e('identify completed for peer %p and protocols %o', id, protocols);
        // TODO: Add and score our observed addr
        log$e('received observed address of %s', cleanObservedAddr?.toString());
        // this.components.addressManager.addObservedAddr(observedAddr)
    }
    /**
     * Sends the `Identify` response with the Signed Peer Record
     * to the requesting peer over the given `connection`
     */
    async _handleIdentify(data) {
        const { connection, stream } = data;
        const timeoutController = new timeoutAbortController.TimeoutController(this.init.timeout);
        try {
            // fails on node < 15.4
            eventsExports.setMaxListeners?.(Infinity, timeoutController.signal);
        }
        catch { }
        try {
            const publicKey = this.components.peerId.publicKey ?? new Uint8Array(0);
            const peerData = await this.components.peerStore.get(this.components.peerId);
            const multiaddrs = this.components.addressManager.getAddresses().map(ma => ma.decapsulateCode(getProtocol$1('p2p').code));
            let signedPeerRecord = peerData.peerRecordEnvelope;
            if (multiaddrs.length > 0 && signedPeerRecord == null) {
                const peerRecord = new PeerRecord({
                    peerId: this.components.peerId,
                    multiaddrs
                });
                const envelope = await RecordEnvelope.seal(peerRecord, this.components.peerId);
                await this.components.peerStore.addressBook.consumePeerRecord(envelope);
                signedPeerRecord = envelope.marshal().subarray();
            }
            const message = Identify.encode({
                protocolVersion: this.host.protocolVersion,
                agentVersion: this.host.agentVersion,
                publicKey,
                listenAddrs: multiaddrs.map(addr => addr.bytes),
                signedPeerRecord,
                observedAddr: connection.remoteAddr.bytes,
                protocols: peerData.protocols
            });
            // make stream abortable
            const source = abortableDuplex(stream, timeoutController.signal);
            const msgWithLenPrefix = pipe([message], encode$b());
            await source.sink(msgWithLenPrefix);
        }
        catch (err) {
            log$e.error('could not respond to identify request', err);
        }
        finally {
            stream.close();
            timeoutController.clear();
        }
    }
    /**
     * Reads the Identify Push message from the given `connection`
     */
    async _handlePush(data) {
        const { connection, stream } = data;
        const timeoutController = new timeoutAbortController.TimeoutController(this.init.timeout);
        try {
            // fails on node < 15.4
            eventsExports.setMaxListeners?.(Infinity, timeoutController.signal);
        }
        catch { }
        let message;
        try {
            // make stream abortable
            const source = abortableDuplex(stream, timeoutController.signal);
            const data = await pipe([], source, decode$a({
                maxDataLength: this.init.maxIdentifyMessageSize ?? MAX_IDENTIFY_MESSAGE_SIZE
            }), async (source) => await first(source));
            if (data != null) {
                message = Identify.decode(data);
            }
        }
        catch (err) {
            return log$e.error('received invalid message', err);
        }
        finally {
            stream.close();
            timeoutController.clear();
        }
        if (message == null) {
            return log$e.error('received invalid message');
        }
        const id = connection.remotePeer;
        if (this.components.peerId.equals(id)) {
            log$e('received push from ourselves?');
            return;
        }
        log$e('received push from %p', id);
        if (message.signedPeerRecord != null) {
            log$e('received signedPeerRecord in push');
            try {
                const envelope = await RecordEnvelope.openAndCertify(message.signedPeerRecord, PeerRecord.DOMAIN);
                if (await this.components.peerStore.addressBook.consumePeerRecord(envelope)) {
                    log$e('consumed signedPeerRecord sent in push');
                    await this.components.peerStore.protoBook.set(id, message.protocols);
                    return;
                }
                else {
                    log$e('failed to consume signedPeerRecord sent in push');
                }
            }
            catch (err) {
                log$e('received invalid envelope, discard it and fallback to listenAddrs is available', err);
            }
        }
        else {
            log$e('did not receive signedPeerRecord in push');
        }
        // LEGACY: Update peers data in PeerStore
        try {
            await this.components.peerStore.addressBook.set(id, message.listenAddrs.map((addr) => multiaddr$1(addr)));
        }
        catch (err) {
            log$e.error('received invalid addrs', err);
        }
        // Update the protocols
        try {
            await this.components.peerStore.protoBook.set(id, message.protocols);
        }
        catch (err) {
            log$e.error('received invalid protocols', err);
        }
        log$e('handled push from %p', id);
    }
    /**
     * Takes the `addr` and converts it to a Multiaddr if possible
     */
    static getCleanMultiaddr(addr) {
        if (addr != null && addr.length > 0) {
            try {
                return multiaddr$1(addr);
            }
            catch {
            }
        }
    }
}

/* eslint-disable import/export */
var FetchRequest;
(function (FetchRequest) {
    let _codec;
    FetchRequest.codec = () => {
        if (_codec == null) {
            _codec = message$4((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (opts.writeDefaults === true || obj.identifier !== '') {
                    w.uint32(10);
                    w.string(obj.identifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    identifier: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.identifier = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FetchRequest.encode = (obj) => {
        return encodeMessage$4(obj, FetchRequest.codec());
    };
    FetchRequest.decode = (buf) => {
        return decodeMessage$5(buf, FetchRequest.codec());
    };
})(FetchRequest || (FetchRequest = {}));
var FetchResponse;
(function (FetchResponse) {
    let StatusCode;
    (function (StatusCode) {
        StatusCode["OK"] = "OK";
        StatusCode["NOT_FOUND"] = "NOT_FOUND";
        StatusCode["ERROR"] = "ERROR";
    })(StatusCode = FetchResponse.StatusCode || (FetchResponse.StatusCode = {}));
    let __StatusCodeValues;
    (function (__StatusCodeValues) {
        __StatusCodeValues[__StatusCodeValues["OK"] = 0] = "OK";
        __StatusCodeValues[__StatusCodeValues["NOT_FOUND"] = 1] = "NOT_FOUND";
        __StatusCodeValues[__StatusCodeValues["ERROR"] = 2] = "ERROR";
    })(__StatusCodeValues || (__StatusCodeValues = {}));
    (function (StatusCode) {
        StatusCode.codec = () => {
            return enumeration$1(__StatusCodeValues);
        };
    })(StatusCode = FetchResponse.StatusCode || (FetchResponse.StatusCode = {}));
    let _codec;
    FetchResponse.codec = () => {
        if (_codec == null) {
            _codec = message$4((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (opts.writeDefaults === true || (obj.status != null && __StatusCodeValues[obj.status] !== 0)) {
                    w.uint32(8);
                    FetchResponse.StatusCode.codec().encode(obj.status, w);
                }
                if (opts.writeDefaults === true || (obj.data != null && obj.data.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    status: StatusCode.OK,
                    data: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.status = FetchResponse.StatusCode.codec().decode(reader);
                            break;
                        case 2:
                            obj.data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FetchResponse.encode = (obj) => {
        return encodeMessage$4(obj, FetchResponse.codec());
    };
    FetchResponse.decode = (buf) => {
        return decodeMessage$5(buf, FetchResponse.codec());
    };
})(FetchResponse || (FetchResponse = {}));

// https://github.com/libp2p/specs/tree/master/fetch#wire-protocol
const PROTOCOL_VERSION$1 = '0.0.1';
const PROTOCOL_NAME$1 = 'fetch';

const log$d = logger$2('libp2p:fetch');
/**
 * A simple libp2p protocol for requesting a value corresponding to a key from a peer.
 * Developers can register one or more lookup function for retrieving the value corresponding to
 * a given key.  Each lookup function must act on a distinct part of the overall key space, defined
 * by a fixed prefix that all keys that should be routed to that lookup function will start with.
 */
class FetchService {
    constructor(components, init) {
        this.started = false;
        this.components = components;
        this.protocol = `/${init.protocolPrefix ?? 'libp2p'}/${PROTOCOL_NAME$1}/${PROTOCOL_VERSION$1}`;
        this.lookupFunctions = new Map(); // Maps key prefix to value lookup function
        this.handleMessage = this.handleMessage.bind(this);
        this.init = init;
    }
    async start() {
        await this.components.registrar.handle(this.protocol, (data) => {
            void this.handleMessage(data)
                .catch(err => {
                log$d.error(err);
            })
                .finally(() => {
                data.stream.close();
            });
        }, {
            maxInboundStreams: this.init.maxInboundStreams,
            maxOutboundStreams: this.init.maxOutboundStreams
        });
        this.started = true;
    }
    async stop() {
        await this.components.registrar.unhandle(this.protocol);
        this.started = false;
    }
    isStarted() {
        return this.started;
    }
    /**
     * Sends a request to fetch the value associated with the given key from the given peer
     */
    async fetch(peer, key, options = {}) {
        log$d('dialing %s to %p', this.protocol, peer);
        const connection = await this.components.connectionManager.openConnection(peer, options);
        let timeoutController;
        let signal = options.signal;
        let stream;
        // create a timeout if no abort signal passed
        if (signal == null) {
            log$d('using default timeout of %d ms', this.init.timeout);
            timeoutController = new timeoutAbortController.TimeoutController(this.init.timeout);
            signal = timeoutController.signal;
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, timeoutController.signal);
            }
            catch { }
        }
        try {
            stream = await connection.newStream(this.protocol, {
                signal
            });
            // make stream abortable
            const source = abortableDuplex(stream, signal);
            log$d('fetch %s', key);
            const result = await pipe([FetchRequest.encode({ identifier: key })], encode$b(), source, decode$a(), async function (source) {
                const buf = await first(source);
                if (buf == null) {
                    throw errCode(new Error('No data received'), codes$1.ERR_INVALID_MESSAGE);
                }
                const response = FetchResponse.decode(buf);
                switch (response.status) {
                    case (FetchResponse.StatusCode.OK): {
                        log$d('received status for %s ok', key);
                        return response.data;
                    }
                    case (FetchResponse.StatusCode.NOT_FOUND): {
                        log$d('received status for %s not found', key);
                        return null;
                    }
                    case (FetchResponse.StatusCode.ERROR): {
                        log$d('received status for %s error', key);
                        const errmsg = toString$7(response.data);
                        throw errCode(new Error('Error in fetch protocol response: ' + errmsg), codes$1.ERR_INVALID_PARAMETERS);
                    }
                    default: {
                        log$d('received status for %s unknown', key);
                        throw errCode(new Error('Unknown response status'), codes$1.ERR_INVALID_MESSAGE);
                    }
                }
            });
            return result ?? null;
        }
        finally {
            if (timeoutController != null) {
                timeoutController.clear();
            }
            if (stream != null) {
                stream.close();
            }
        }
    }
    /**
     * Invoked when a fetch request is received.  Reads the request message off the given stream and
     * responds based on looking up the key in the request via the lookup callback that corresponds
     * to the key's prefix.
     */
    async handleMessage(data) {
        const { stream } = data;
        const self = this;
        await pipe(stream, decode$a(), async function* (source) {
            const buf = await first(source);
            if (buf == null) {
                throw errCode(new Error('No data received'), codes$1.ERR_INVALID_MESSAGE);
            }
            // for await (const buf of source) {
            const request = FetchRequest.decode(buf);
            let response;
            const lookup = self._getLookupFunction(request.identifier);
            if (lookup != null) {
                log$d('look up data with identifier %s', request.identifier);
                const data = await lookup(request.identifier);
                if (data != null) {
                    log$d('sending status for %s ok', request.identifier);
                    response = { status: FetchResponse.StatusCode.OK, data };
                }
                else {
                    log$d('sending status for %s not found', request.identifier);
                    response = { status: FetchResponse.StatusCode.NOT_FOUND, data: new Uint8Array(0) };
                }
            }
            else {
                log$d('sending status for %s error', request.identifier);
                const errmsg = fromString$2(`No lookup function registered for key: ${request.identifier}`);
                response = { status: FetchResponse.StatusCode.ERROR, data: errmsg };
            }
            yield FetchResponse.encode(response);
        }, encode$b(), stream);
    }
    /**
     * Given a key, finds the appropriate function for looking up its corresponding value, based on
     * the key's prefix.
     */
    _getLookupFunction(key) {
        for (const prefix of this.lookupFunctions.keys()) {
            if (key.startsWith(prefix)) {
                return this.lookupFunctions.get(prefix);
            }
        }
    }
    /**
     * Registers a new lookup callback that can map keys to values, for a given set of keys that
     * share the same prefix
     *
     * @example
     *
     * ```js
     * // ...
     * libp2p.fetchService.registerLookupFunction('/prefix', (key) => { ... })
     * ```
     */
    registerLookupFunction(prefix, lookup) {
        if (this.lookupFunctions.has(prefix)) {
            throw errCode(new Error("Fetch protocol handler for key prefix '" + prefix + "' already registered"), codes$1.ERR_KEY_ALREADY_EXISTS);
        }
        this.lookupFunctions.set(prefix, lookup);
    }
    /**
     * Registers a new lookup callback that can map keys to values, for a given set of keys that
     * share the same prefix.
     *
     * @example
     *
     * ```js
     * // ...
     * libp2p.fetchService.unregisterLookupFunction('/prefix')
     * ```
     */
    unregisterLookupFunction(prefix, lookup) {
        if (lookup != null) {
            const existingLookup = this.lookupFunctions.get(prefix);
            if (existingLookup !== lookup) {
                return;
            }
        }
        this.lookupFunctions.delete(prefix);
    }
}

const PING_LENGTH = 32;
const PROTOCOL_VERSION = '1.0.0';
const PROTOCOL_NAME = 'ping';

const log$c = logger$2('libp2p:ping');
class PingService {
    constructor(components, init) {
        this.components = components;
        this.started = false;
        this.protocol = `/${init.protocolPrefix}/${PROTOCOL_NAME}/${PROTOCOL_VERSION}`;
        this.init = init;
    }
    async start() {
        await this.components.registrar.handle(this.protocol, this.handleMessage, {
            maxInboundStreams: this.init.maxInboundStreams,
            maxOutboundStreams: this.init.maxOutboundStreams
        });
        this.started = true;
    }
    async stop() {
        await this.components.registrar.unhandle(this.protocol);
        this.started = false;
    }
    isStarted() {
        return this.started;
    }
    /**
     * A handler to register with Libp2p to process ping messages
     */
    handleMessage(data) {
        const { stream } = data;
        void pipe(stream, stream)
            .catch(err => {
            log$c.error(err);
        });
    }
    /**
     * Ping a given peer and wait for its response, getting the operation latency.
     *
     * @param {PeerId|Multiaddr} peer
     * @returns {Promise<number>}
     */
    async ping(peer, options = {}) {
        log$c('dialing %s to %p', this.protocol, peer);
        const start = Date.now();
        const data = randomBytes(PING_LENGTH);
        const connection = await this.components.connectionManager.openConnection(peer, options);
        let timeoutController;
        let signal = options.signal;
        let stream;
        // create a timeout if no abort signal passed
        if (signal == null) {
            timeoutController = new timeoutAbortController.TimeoutController(this.init.timeout);
            signal = timeoutController.signal;
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, timeoutController.signal);
            }
            catch { }
        }
        try {
            stream = await connection.newStream([this.protocol], {
                signal
            });
            // make stream abortable
            const source = abortableDuplex(stream, signal);
            const result = await pipe([data], source, async (source) => await first(source));
            const end = Date.now();
            if (result == null || !equals$2(data, result.subarray())) {
                throw errCode(new Error('Received wrong ping ack'), codes$1.ERR_WRONG_PING_ACK);
            }
            return end - start;
        }
        finally {
            if (timeoutController != null) {
                timeoutController.clear();
            }
            if (stream != null) {
                stream.close();
            }
        }
    }
}

async function upnpNat() {
    throw new Error('Not supported in browsers');
}

/**
 * Check if a given ip address is a loopback address
 */
function isLoopbackAddr(ip) {
    return /^127\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/i.test(ip) ||
        /^::1$/.test(ip);
}

/**
 * Check if a given multiaddr is a loopback address.
 */
function isLoopback(ma) {
    const { address } = ma.nodeAddress();
    return isLoopbackAddr(address);
}

const log$b = logger$2('libp2p:nat');
const DEFAULT_TTL = 7200;
function highPort(min = 1024, max = 65535) {
    return Math.floor(Math.random() * (max - min + 1) + min);
}
class NatManager {
    constructor(components, init) {
        this.components = components;
        this.started = false;
        this.enabled = init.enabled;
        this.externalAddress = init.externalAddress;
        this.localAddress = init.localAddress;
        this.description = init.description ?? `${name}@${version} ${this.components.peerId.toString()}`;
        this.ttl = init.ttl ?? DEFAULT_TTL;
        this.keepAlive = init.keepAlive ?? true;
        this.gateway = init.gateway;
        if (this.ttl < DEFAULT_TTL) {
            throw errCode(new Error(`NatManager ttl should be at least ${DEFAULT_TTL} seconds`), codes$1.ERR_INVALID_PARAMETERS);
        }
    }
    isStarted() {
        return this.started;
    }
    start() { }
    /**
     * Attempt to use uPnP to configure port mapping using the current gateway.
     *
     * Run after start to ensure the transport manager has all addresses configured.
     */
    afterStart() {
        if (isBrowser$1 || !this.enabled || this.started) {
            return;
        }
        this.started = true;
        // done async to not slow down startup
        void this._start().catch((err) => {
            // hole punching errors are non-fatal
            log$b.error(err);
        });
    }
    async _start() {
        const addrs = this.components.transportManager.getAddrs();
        for (const addr of addrs) {
            // try to open uPnP ports for each thin waist address
            const { family, host, port, transport } = addr.toOptions();
            if (!addr.isThinWaistAddress() || transport !== 'tcp') {
                // only bare tcp addresses
                // eslint-disable-next-line no-continue
                continue;
            }
            if (isLoopback(addr)) {
                // eslint-disable-next-line no-continue
                continue;
            }
            if (family !== 4) {
                // ignore ipv6
                // eslint-disable-next-line no-continue
                continue;
            }
            const client = await this._getClient();
            const publicIp = this.externalAddress ?? await client.externalIp();
            const isPrivate = is_ip_private(publicIp);
            if (isPrivate === true) {
                throw new Error(`${publicIp} is private - please set config.nat.externalIp to an externally routable IP or ensure you are not behind a double NAT`);
            }
            if (isPrivate == null) {
                throw new Error(`${publicIp} is not an IP address`);
            }
            const publicPort = highPort();
            log$b(`opening uPnP connection from ${publicIp}:${publicPort} to ${host}:${port}`);
            await client.map({
                publicPort,
                localPort: port,
                localAddress: this.localAddress,
                protocol: transport.toUpperCase() === 'TCP' ? 'TCP' : 'UDP'
            });
            this.components.addressManager.addObservedAddr(fromNodeAddress({
                family: 4,
                address: publicIp,
                port: publicPort
            }, transport));
        }
    }
    async _getClient() {
        if (this.client != null) {
            return this.client;
        }
        this.client = await upnpNat({
            description: this.description,
            ttl: this.ttl,
            keepAlive: this.keepAlive,
            gateway: this.gateway
        });
        return this.client;
    }
    /**
     * Stops the NAT manager
     */
    async stop() {
        if (isBrowser$1 || this.client == null) {
            return;
        }
        try {
            await this.client.close();
            this.client = undefined;
        }
        catch (err) {
            log$b.error(err);
        }
    }
}

const log$a = logger$2('libp2p:peer-record-updater');
class PeerRecordUpdater {
    constructor(components) {
        this.components = components;
        this.started = false;
        this.update = this.update.bind(this);
    }
    isStarted() {
        return this.started;
    }
    async start() {
        this.started = true;
        this.components.transportManager.addEventListener('listener:listening', this.update);
        this.components.transportManager.addEventListener('listener:close', this.update);
        this.components.addressManager.addEventListener('change:addresses', this.update);
    }
    async stop() {
        this.started = false;
        this.components.transportManager.removeEventListener('listener:listening', this.update);
        this.components.transportManager.removeEventListener('listener:close', this.update);
        this.components.addressManager.removeEventListener('change:addresses', this.update);
    }
    /**
     * Create (or update if existing) self peer record and store it in the AddressBook.
     */
    update() {
        Promise.resolve()
            .then(async () => {
            const peerRecord = new PeerRecord({
                peerId: this.components.peerId,
                multiaddrs: this.components.addressManager.getAddresses().map(ma => ma.decapsulateCode(getProtocol$1('p2p').code))
            });
            const envelope = await RecordEnvelope.seal(peerRecord, this.components.peerId);
            await this.components.peerStore.addressBook.consumePeerRecord(envelope);
        })
            .catch(err => {
            log$a.error('Could not update self peer record: %o', err);
        });
    }
}

/**
 * Wrapper class to convert events into returned values
 */
class DHTPeerRouting {
    constructor(dht) {
        this.dht = dht;
    }
    async findPeer(peerId, options = {}) {
        for await (const event of this.dht.findPeer(peerId, options)) {
            if (event.name === 'FINAL_PEER') {
                return event.peer;
            }
        }
        throw errCode(new Error(messages.NOT_FOUND), codes$1.ERR_NOT_FOUND);
    }
    async *getClosestPeers(key, options = {}) {
        for await (const event of this.dht.getClosestPeers(key, options)) {
            if (event.name === 'FINAL_PEER') {
                yield event.peer;
            }
        }
    }
}

const codes = {
    ERR_INVALID_PARAMETERS: 'ERR_INVALID_PARAMETERS',
    ERR_NOT_FOUND: 'ERR_NOT_FOUND'
};

const log$9 = logger$2('libp2p:peer-store:address-book');
const EVENT_NAME$3 = 'change:multiaddrs';
async function allowAll() {
    return true;
}
class PeerStoreAddressBook {
    constructor(dispatchEvent, store, addressFilter) {
        this.dispatchEvent = dispatchEvent;
        this.store = store;
        this.addressFilter = addressFilter ?? allowAll;
    }
    /**
     * ConsumePeerRecord adds addresses from a signed peer record contained in a record envelope.
     * This will return a boolean that indicates if the record was successfully processed and added
     * into the AddressBook.
     */
    async consumePeerRecord(envelope) {
        log$9.trace('consumePeerRecord await write lock');
        const release = await this.store.lock.writeLock();
        log$9.trace('consumePeerRecord got write lock');
        let peerId;
        let peer;
        let updatedPeer;
        try {
            let peerRecord;
            try {
                peerRecord = PeerRecord.createFromProtobuf(envelope.payload);
            }
            catch (err) {
                log$9.error('invalid peer record received');
                return false;
            }
            peerId = peerRecord.peerId;
            const multiaddrs = peerRecord.multiaddrs;
            // Verify peerId
            if (!peerId.equals(envelope.peerId)) {
                log$9('signing key does not match PeerId in the PeerRecord');
                return false;
            }
            // ensure the record has multiaddrs
            if (multiaddrs == null || multiaddrs.length === 0) {
                return false;
            }
            if (await this.store.has(peerId)) {
                peer = await this.store.load(peerId);
                if (peer.peerRecordEnvelope != null) {
                    const storedEnvelope = await RecordEnvelope.createFromProtobuf(peer.peerRecordEnvelope);
                    const storedRecord = PeerRecord.createFromProtobuf(storedEnvelope.payload);
                    // ensure seq is greater than, or equal to, the last received
                    if (storedRecord.seqNumber >= peerRecord.seqNumber) {
                        log$9('sequence number was lower or equal to existing sequence number - stored: %d received: %d', storedRecord.seqNumber, peerRecord.seqNumber);
                        return false;
                    }
                }
            }
            const addresses = await filterMultiaddrs(peerId, multiaddrs, this.addressFilter, true);
            // Replace unsigned addresses by the new ones from the record
            // TODO: Once we have ttls for the addresses, we should merge these in
            updatedPeer = await this.store.patchOrCreate(peerId, {
                addresses,
                peerRecordEnvelope: envelope.marshal().subarray()
            });
            log$9('stored provided peer record for %p', peerRecord.peerId);
        }
        finally {
            log$9.trace('consumePeerRecord release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME$3, {
            detail: {
                peerId,
                multiaddrs: updatedPeer.addresses.map(({ multiaddr }) => multiaddr),
                oldMultiaddrs: peer == null ? [] : peer.addresses.map(({ multiaddr }) => multiaddr)
            }
        }));
        return true;
    }
    async getRawEnvelope(peerId) {
        log$9.trace('getRawEnvelope await read lock');
        const release = await this.store.lock.readLock();
        log$9.trace('getRawEnvelope got read lock');
        try {
            const peer = await this.store.load(peerId);
            return peer.peerRecordEnvelope;
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        finally {
            log$9.trace('getRawEnvelope release read lock');
            release();
        }
    }
    /**
     * Get an Envelope containing a PeerRecord for the given peer.
     * Returns undefined if no record exists.
     */
    async getPeerRecord(peerId) {
        const raw = await this.getRawEnvelope(peerId);
        if (raw == null) {
            return undefined;
        }
        return await RecordEnvelope.createFromProtobuf(raw);
    }
    async get(peerId) {
        peerId = peerIdFromPeerId(peerId);
        log$9.trace('get wait for read lock');
        const release = await this.store.lock.readLock();
        log$9.trace('get got read lock');
        try {
            const peer = await this.store.load(peerId);
            return peer.addresses;
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        finally {
            log$9.trace('get release read lock');
            release();
        }
        return [];
    }
    async set(peerId, multiaddrs) {
        peerId = peerIdFromPeerId(peerId);
        if (!Array.isArray(multiaddrs)) {
            log$9.error('multiaddrs must be an array of Multiaddrs');
            throw new CodeError('multiaddrs must be an array of Multiaddrs', codes.ERR_INVALID_PARAMETERS);
        }
        log$9.trace('set await write lock');
        const release = await this.store.lock.writeLock();
        log$9.trace('set got write lock');
        let hasPeer = false;
        let peer;
        let updatedPeer;
        try {
            const addresses = await filterMultiaddrs(peerId, multiaddrs, this.addressFilter);
            // No valid addresses found
            if (addresses.length === 0) {
                return;
            }
            try {
                peer = await this.store.load(peerId);
                hasPeer = true;
                if (new Set([
                    ...addresses.map(({ multiaddr }) => multiaddr.toString()),
                    ...peer.addresses.map(({ multiaddr }) => multiaddr.toString())
                ]).size === peer.addresses.length && addresses.length === peer.addresses.length) {
                    // not changing anything, no need to update
                    return;
                }
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            updatedPeer = await this.store.patchOrCreate(peerId, { addresses });
            log$9('set multiaddrs for %p', peerId);
        }
        finally {
            log$9.trace('set multiaddrs for %p', peerId);
            log$9('set release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME$3, {
            detail: {
                peerId,
                multiaddrs: updatedPeer.addresses.map(addr => addr.multiaddr),
                oldMultiaddrs: peer == null ? [] : peer.addresses.map(({ multiaddr }) => multiaddr)
            }
        }));
        // Notify the existence of a new peer
        if (!hasPeer) {
            this.dispatchEvent(new CustomEvent('peer', {
                detail: {
                    id: peerId,
                    multiaddrs: updatedPeer.addresses.map(addr => addr.multiaddr),
                    protocols: updatedPeer.protocols
                }
            }));
        }
    }
    async add(peerId, multiaddrs) {
        peerId = peerIdFromPeerId(peerId);
        if (!Array.isArray(multiaddrs)) {
            log$9.error('multiaddrs must be an array of Multiaddrs');
            throw new CodeError('multiaddrs must be an array of Multiaddrs', codes.ERR_INVALID_PARAMETERS);
        }
        log$9.trace('add await write lock');
        const release = await this.store.lock.writeLock();
        log$9.trace('add got write lock');
        let hasPeer;
        let peer;
        let updatedPeer;
        try {
            const addresses = await filterMultiaddrs(peerId, multiaddrs, this.addressFilter);
            // No valid addresses found
            if (addresses.length === 0) {
                return;
            }
            try {
                peer = await this.store.load(peerId);
                hasPeer = true;
                if (new Set([
                    ...addresses.map(({ multiaddr }) => multiaddr.toString()),
                    ...peer.addresses.map(({ multiaddr }) => multiaddr.toString())
                ]).size === peer.addresses.length) {
                    return;
                }
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            updatedPeer = await this.store.mergeOrCreate(peerId, { addresses });
            log$9('added multiaddrs for %p', peerId);
        }
        finally {
            log$9.trace('set release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME$3, {
            detail: {
                peerId,
                multiaddrs: updatedPeer.addresses.map(addr => addr.multiaddr),
                oldMultiaddrs: peer == null ? [] : peer.addresses.map(({ multiaddr }) => multiaddr)
            }
        }));
        // Notify the existence of a new peer
        if (hasPeer === true) {
            this.dispatchEvent(new CustomEvent('peer', {
                detail: {
                    id: peerId,
                    multiaddrs: updatedPeer.addresses.map(addr => addr.multiaddr),
                    protocols: updatedPeer.protocols
                }
            }));
        }
    }
    async delete(peerId) {
        peerId = peerIdFromPeerId(peerId);
        log$9.trace('delete await write lock');
        const release = await this.store.lock.writeLock();
        log$9.trace('delete got write lock');
        let peer;
        try {
            try {
                peer = await this.store.load(peerId);
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            await this.store.patchOrCreate(peerId, {
                addresses: []
            });
        }
        finally {
            log$9.trace('delete release write lock');
            release();
        }
        if (peer != null) {
            this.dispatchEvent(new CustomEvent(EVENT_NAME$3, {
                detail: {
                    peerId,
                    multiaddrs: [],
                    oldMultiaddrs: peer == null ? [] : peer.addresses.map(({ multiaddr }) => multiaddr)
                }
            }));
        }
    }
}
async function filterMultiaddrs(peerId, multiaddrs, addressFilter, isCertified = false) {
    const output = [];
    await Promise.all(multiaddrs.map(async (multiaddr) => {
        if (!isMultiaddr$1(multiaddr)) {
            log$9.error('multiaddr must be an instance of Multiaddr');
            throw new CodeError('multiaddr must be an instance of Multiaddr', codes.ERR_INVALID_PARAMETERS);
        }
        const include = await addressFilter(peerId, multiaddr);
        if (!include) {
            return;
        }
        output.push({
            multiaddr,
            isCertified
        });
    }));
    return output;
}

const log$8 = logger$2('libp2p:peer-store:key-book');
const EVENT_NAME$2 = 'change:pubkey';
class PeerStoreKeyBook {
    /**
     * The KeyBook is responsible for keeping the known public keys of a peer
     */
    constructor(dispatchEvent, store) {
        this.dispatchEvent = dispatchEvent;
        this.store = store;
    }
    /**
     * Set the Peer public key
     */
    async set(peerId, publicKey) {
        peerId = peerIdFromPeerId(peerId);
        if (!(publicKey instanceof Uint8Array)) {
            log$8.error('publicKey must be an instance of Uint8Array to store data');
            throw new CodeError('publicKey must be an instance of PublicKey', codes.ERR_INVALID_PARAMETERS);
        }
        log$8.trace('set await write lock');
        const release = await this.store.lock.writeLock();
        log$8.trace('set got write lock');
        let updatedKey = false;
        let peer;
        try {
            try {
                peer = await this.store.load(peerId);
                if ((peer.pubKey != null) && equals$2(peer.pubKey, publicKey)) {
                    return;
                }
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            await this.store.patchOrCreate(peerId, {
                pubKey: publicKey
            });
            updatedKey = true;
        }
        finally {
            log$8.trace('set release write lock');
            release();
        }
        if (updatedKey) {
            this.dispatchEvent(new CustomEvent(EVENT_NAME$2, {
                detail: {
                    peerId,
                    publicKey,
                    oldPublicKey: peer == null ? undefined : peer.pubKey
                }
            }));
        }
    }
    /**
     * Get Public key of the given PeerId, if stored
     */
    async get(peerId) {
        peerId = peerIdFromPeerId(peerId);
        log$8.trace('get await write lock');
        const release = await this.store.lock.readLock();
        log$8.trace('get got write lock');
        try {
            const peer = await this.store.load(peerId);
            return peer.pubKey;
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        finally {
            log$8('get release write lock');
            release();
        }
    }
    async delete(peerId) {
        peerId = peerIdFromPeerId(peerId);
        log$8.trace('delete await write lock');
        const release = await this.store.lock.writeLock();
        log$8.trace('delete got write lock');
        let peer;
        try {
            try {
                peer = await this.store.load(peerId);
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            await this.store.patchOrCreate(peerId, {
                pubKey: undefined
            });
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        finally {
            log$8.trace('delete release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME$2, {
            detail: {
                peerId,
                publicKey: undefined,
                oldPublicKey: peer == null ? undefined : peer.pubKey
            }
        }));
    }
}

const log$7 = logger$2('libp2p:peer-store:metadata-book');
const EVENT_NAME$1 = 'change:metadata';
class PeerStoreMetadataBook {
    /**
     * The MetadataBook is responsible for keeping metadata
     * about known peers
     */
    constructor(dispatchEvent, store) {
        this.dispatchEvent = dispatchEvent;
        this.store = store;
    }
    /**
     * Get the known data of a provided peer
     */
    async get(peerId) {
        peerId = peerIdFromPeerId(peerId);
        log$7.trace('get await read lock');
        const release = await this.store.lock.readLock();
        log$7.trace('get got read lock');
        try {
            const peer = await this.store.load(peerId);
            return peer.metadata;
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        finally {
            log$7.trace('get release read lock');
            release();
        }
        return new Map();
    }
    /**
     * Get specific metadata value, if it exists
     */
    async getValue(peerId, key) {
        peerId = peerIdFromPeerId(peerId);
        log$7.trace('getValue await read lock');
        const release = await this.store.lock.readLock();
        log$7.trace('getValue got read lock');
        try {
            const peer = await this.store.load(peerId);
            return peer.metadata.get(key);
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        finally {
            log$7.trace('getValue release write lock');
            release();
        }
    }
    async set(peerId, metadata) {
        peerId = peerIdFromPeerId(peerId);
        if (!(metadata instanceof Map)) {
            log$7.error('valid metadata must be provided to store data');
            throw new CodeError('valid metadata must be provided', codes.ERR_INVALID_PARAMETERS);
        }
        log$7.trace('set await write lock');
        const release = await this.store.lock.writeLock();
        log$7.trace('set got write lock');
        let peer;
        try {
            try {
                peer = await this.store.load(peerId);
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            await this.store.mergeOrCreate(peerId, {
                metadata
            });
        }
        finally {
            log$7.trace('set release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME$1, {
            detail: {
                peerId,
                metadata,
                oldMetadata: peer == null ? new Map() : peer.metadata
            }
        }));
    }
    /**
     * Set metadata key and value of a provided peer
     */
    async setValue(peerId, key, value) {
        peerId = peerIdFromPeerId(peerId);
        if (typeof key !== 'string' || !(value instanceof Uint8Array)) {
            log$7.error('valid key and value must be provided to store data');
            throw new CodeError('valid key and value must be provided', codes.ERR_INVALID_PARAMETERS);
        }
        log$7.trace('setValue await write lock');
        const release = await this.store.lock.writeLock();
        log$7.trace('setValue got write lock');
        let peer;
        let updatedPeer;
        try {
            try {
                peer = await this.store.load(peerId);
                const existingValue = peer.metadata.get(key);
                if (existingValue != null && equals$2(value, existingValue)) {
                    return;
                }
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            updatedPeer = await this.store.mergeOrCreate(peerId, {
                metadata: new Map([[key, value]])
            });
        }
        finally {
            log$7.trace('setValue release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME$1, {
            detail: {
                peerId,
                metadata: updatedPeer.metadata,
                oldMetadata: peer == null ? new Map() : peer.metadata
            }
        }));
    }
    async delete(peerId) {
        peerId = peerIdFromPeerId(peerId);
        log$7.trace('delete await write lock');
        const release = await this.store.lock.writeLock();
        log$7.trace('delete got write lock');
        let peer;
        try {
            try {
                peer = await this.store.load(peerId);
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            if (peer != null) {
                await this.store.patch(peerId, {
                    metadata: new Map()
                });
            }
        }
        finally {
            log$7.trace('delete release write lock');
            release();
        }
        if (peer != null) {
            this.dispatchEvent(new CustomEvent(EVENT_NAME$1, {
                detail: {
                    peerId,
                    metadata: new Map(),
                    oldMetadata: peer.metadata
                }
            }));
        }
    }
    async deleteValue(peerId, key) {
        peerId = peerIdFromPeerId(peerId);
        log$7.trace('deleteValue await write lock');
        const release = await this.store.lock.writeLock();
        log$7.trace('deleteValue got write lock');
        let metadata;
        let peer;
        try {
            peer = await this.store.load(peerId);
            metadata = peer.metadata;
            metadata.delete(key);
            await this.store.patch(peerId, {
                metadata
            });
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        finally {
            log$7.trace('deleteValue release write lock');
            release();
        }
        if (metadata != null) {
            this.dispatchEvent(new CustomEvent(EVENT_NAME$1, {
                detail: {
                    peerId,
                    metadata,
                    oldMetadata: peer == null ? new Map() : peer.metadata
                }
            }));
        }
    }
}

const log$6 = logger$2('libp2p:peer-store:proto-book');
const EVENT_NAME = 'change:protocols';
class PeerStoreProtoBook {
    /**
     * The ProtoBook is responsible for keeping the known supported
     * protocols of a peer
     */
    constructor(dispatchEvent, store) {
        this.dispatchEvent = dispatchEvent;
        this.store = store;
    }
    async get(peerId) {
        log$6.trace('get wait for read lock');
        const release = await this.store.lock.readLock();
        log$6.trace('get got read lock');
        try {
            const peer = await this.store.load(peerId);
            return peer.protocols;
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        finally {
            log$6.trace('get release read lock');
            release();
        }
        return [];
    }
    async set(peerId, protocols) {
        peerId = peerIdFromPeerId(peerId);
        if (!Array.isArray(protocols)) {
            log$6.error('protocols must be provided to store data');
            throw new CodeError('protocols must be provided', codes.ERR_INVALID_PARAMETERS);
        }
        log$6.trace('set await write lock');
        const release = await this.store.lock.writeLock();
        log$6.trace('set got write lock');
        let peer;
        let updatedPeer;
        try {
            try {
                peer = await this.store.load(peerId);
                if (new Set([
                    ...protocols
                ]).size === peer.protocols.length) {
                    return;
                }
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            updatedPeer = await this.store.patchOrCreate(peerId, {
                protocols
            });
            log$6('stored provided protocols for %p', peerId);
        }
        finally {
            log$6.trace('set release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME, {
            detail: {
                peerId,
                protocols: updatedPeer.protocols,
                oldProtocols: peer == null ? [] : peer.protocols
            }
        }));
    }
    async add(peerId, protocols) {
        peerId = peerIdFromPeerId(peerId);
        if (!Array.isArray(protocols)) {
            log$6.error('protocols must be provided to store data');
            throw new CodeError('protocols must be provided', codes.ERR_INVALID_PARAMETERS);
        }
        log$6.trace('add await write lock');
        const release = await this.store.lock.writeLock();
        log$6.trace('add got write lock');
        let peer;
        let updatedPeer;
        try {
            try {
                peer = await this.store.load(peerId);
                if (new Set([
                    ...peer.protocols,
                    ...protocols
                ]).size === peer.protocols.length) {
                    return;
                }
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            updatedPeer = await this.store.mergeOrCreate(peerId, {
                protocols
            });
            log$6('added provided protocols for %p', peerId);
        }
        finally {
            log$6.trace('add release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME, {
            detail: {
                peerId,
                protocols: updatedPeer.protocols,
                oldProtocols: peer == null ? [] : peer.protocols
            }
        }));
    }
    async remove(peerId, protocols) {
        peerId = peerIdFromPeerId(peerId);
        if (!Array.isArray(protocols)) {
            log$6.error('protocols must be provided to store data');
            throw new CodeError('protocols must be provided', codes.ERR_INVALID_PARAMETERS);
        }
        log$6.trace('remove await write lock');
        const release = await this.store.lock.writeLock();
        log$6.trace('remove got write lock');
        let peer;
        let updatedPeer;
        try {
            try {
                peer = await this.store.load(peerId);
                const protocolSet = new Set(peer.protocols);
                for (const protocol of protocols) {
                    protocolSet.delete(protocol);
                }
                if (peer.protocols.length === protocolSet.size) {
                    return;
                }
                protocols = Array.from(protocolSet);
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            updatedPeer = await this.store.patchOrCreate(peerId, {
                protocols
            });
        }
        finally {
            log$6.trace('remove release write lock');
            release();
        }
        this.dispatchEvent(new CustomEvent(EVENT_NAME, {
            detail: {
                peerId,
                protocols: updatedPeer.protocols,
                oldProtocols: peer == null ? [] : peer.protocols
            }
        }));
    }
    async delete(peerId) {
        peerId = peerIdFromPeerId(peerId);
        log$6.trace('delete await write lock');
        const release = await this.store.lock.writeLock();
        log$6.trace('delete got write lock');
        let peer;
        try {
            try {
                peer = await this.store.load(peerId);
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
            await this.store.patchOrCreate(peerId, {
                protocols: []
            });
        }
        finally {
            log$6.trace('delete release write lock');
            release();
        }
        if (peer != null) {
            this.dispatchEvent(new CustomEvent(EVENT_NAME, {
                detail: {
                    peerId,
                    protocols: [],
                    oldProtocols: peer.protocols
                }
            }));
        }
    }
}

var minimal$1 = {};

var longbits$1;
var hasRequiredLongbits$1;

function requireLongbits$1 () {
	if (hasRequiredLongbits$1) return longbits$1;
	hasRequiredLongbits$1 = 1;
	longbits$1 = LongBits;

	var util = requireMinimal$1();

	/**
	 * Constructs new long bits.
	 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
	 * @memberof util
	 * @constructor
	 * @param {number} lo Low 32 bits, unsigned
	 * @param {number} hi High 32 bits, unsigned
	 */
	function LongBits(lo, hi) {

	    // note that the casts below are theoretically unnecessary as of today, but older statically
	    // generated converter code might still call the ctor with signed 32bits. kept for compat.

	    /**
	     * Low bits.
	     * @type {number}
	     */
	    this.lo = lo >>> 0;

	    /**
	     * High bits.
	     * @type {number}
	     */
	    this.hi = hi >>> 0;
	}

	/**
	 * Zero bits.
	 * @memberof util.LongBits
	 * @type {util.LongBits}
	 */
	var zero = LongBits.zero = new LongBits(0, 0);

	zero.toNumber = function() { return 0; };
	zero.zzEncode = zero.zzDecode = function() { return this; };
	zero.length = function() { return 1; };

	/**
	 * Zero hash.
	 * @memberof util.LongBits
	 * @type {string}
	 */
	var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

	/**
	 * Constructs new long bits from the specified number.
	 * @param {number} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.fromNumber = function fromNumber(value) {
	    if (value === 0)
	        return zero;
	    var sign = value < 0;
	    if (sign)
	        value = -value;
	    var lo = value >>> 0,
	        hi = (value - lo) / 4294967296 >>> 0;
	    if (sign) {
	        hi = ~hi >>> 0;
	        lo = ~lo >>> 0;
	        if (++lo > 4294967295) {
	            lo = 0;
	            if (++hi > 4294967295)
	                hi = 0;
	        }
	    }
	    return new LongBits(lo, hi);
	};

	/**
	 * Constructs new long bits from a number, long or string.
	 * @param {Long|number|string} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.from = function from(value) {
	    if (typeof value === "number")
	        return LongBits.fromNumber(value);
	    if (util.isString(value)) {
	        /* istanbul ignore else */
	        if (util.Long)
	            value = util.Long.fromString(value);
	        else
	            return LongBits.fromNumber(parseInt(value, 10));
	    }
	    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
	};

	/**
	 * Converts this long bits to a possibly unsafe JavaScript number.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {number} Possibly unsafe number
	 */
	LongBits.prototype.toNumber = function toNumber(unsigned) {
	    if (!unsigned && this.hi >>> 31) {
	        var lo = ~this.lo + 1 >>> 0,
	            hi = ~this.hi     >>> 0;
	        if (!lo)
	            hi = hi + 1 >>> 0;
	        return -(lo + hi * 4294967296);
	    }
	    return this.lo + this.hi * 4294967296;
	};

	/**
	 * Converts this long bits to a long.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {Long} Long
	 */
	LongBits.prototype.toLong = function toLong(unsigned) {
	    return util.Long
	        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
	        /* istanbul ignore next */
	        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
	};

	var charCodeAt = String.prototype.charCodeAt;

	/**
	 * Constructs new long bits from the specified 8 characters long hash.
	 * @param {string} hash Hash
	 * @returns {util.LongBits} Bits
	 */
	LongBits.fromHash = function fromHash(hash) {
	    if (hash === zeroHash)
	        return zero;
	    return new LongBits(
	        ( charCodeAt.call(hash, 0)
	        | charCodeAt.call(hash, 1) << 8
	        | charCodeAt.call(hash, 2) << 16
	        | charCodeAt.call(hash, 3) << 24) >>> 0
	    ,
	        ( charCodeAt.call(hash, 4)
	        | charCodeAt.call(hash, 5) << 8
	        | charCodeAt.call(hash, 6) << 16
	        | charCodeAt.call(hash, 7) << 24) >>> 0
	    );
	};

	/**
	 * Converts this long bits to a 8 characters long hash.
	 * @returns {string} Hash
	 */
	LongBits.prototype.toHash = function toHash() {
	    return String.fromCharCode(
	        this.lo        & 255,
	        this.lo >>> 8  & 255,
	        this.lo >>> 16 & 255,
	        this.lo >>> 24      ,
	        this.hi        & 255,
	        this.hi >>> 8  & 255,
	        this.hi >>> 16 & 255,
	        this.hi >>> 24
	    );
	};

	/**
	 * Zig-zag encodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzEncode = function zzEncode() {
	    var mask =   this.hi >> 31;
	    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
	    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Zig-zag decodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzDecode = function zzDecode() {
	    var mask = -(this.lo & 1);
	    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
	    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Calculates the length of this longbits when encoded as a varint.
	 * @returns {number} Length
	 */
	LongBits.prototype.length = function length() {
	    var part0 =  this.lo,
	        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
	        part2 =  this.hi >>> 24;
	    return part2 === 0
	         ? part1 === 0
	           ? part0 < 16384
	             ? part0 < 128 ? 1 : 2
	             : part0 < 2097152 ? 3 : 4
	           : part1 < 16384
	             ? part1 < 128 ? 5 : 6
	             : part1 < 2097152 ? 7 : 8
	         : part2 < 128 ? 9 : 10;
	};
	return longbits$1;
}

var hasRequiredMinimal$1;

function requireMinimal$1 () {
	if (hasRequiredMinimal$1) return minimal$1;
	hasRequiredMinimal$1 = 1;
	(function (exports) {
		var util = exports;

		// used to return a Promise where callback is omitted
		util.asPromise = aspromise;

		// converts to / from base64 encoded strings
		util.base64 = base64$9;

		// base class of rpc.Service
		util.EventEmitter = eventemitter;

		// float handling accross browsers
		util.float = float;

		// requires modules optionally and hides the call from bundlers
		util.inquire = inquire_1;

		// converts to / from utf8 encoded strings
		util.utf8 = utf8$e;

		// provides a node-like buffer pool in the browser
		util.pool = pool_1;

		// utility to work with the low and high bits of a 64 bit value
		util.LongBits = requireLongbits$1();

		/**
		 * Whether running within node or not.
		 * @memberof util
		 * @type {boolean}
		 */
		util.isNode = Boolean(typeof commonjsGlobal !== "undefined"
		                   && commonjsGlobal
		                   && commonjsGlobal.process
		                   && commonjsGlobal.process.versions
		                   && commonjsGlobal.process.versions.node);

		/**
		 * Global object reference.
		 * @memberof util
		 * @type {Object}
		 */
		util.global = util.isNode && commonjsGlobal
		           || typeof window !== "undefined" && window
		           || typeof self   !== "undefined" && self
		           || commonjsGlobal; // eslint-disable-line no-invalid-this

		/**
		 * An immuable empty array.
		 * @memberof util
		 * @type {Array.<*>}
		 * @const
		 */
		util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

		/**
		 * An immutable empty object.
		 * @type {Object}
		 * @const
		 */
		util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

		/**
		 * Tests if the specified value is an integer.
		 * @function
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is an integer
		 */
		util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
		    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
		};

		/**
		 * Tests if the specified value is a string.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a string
		 */
		util.isString = function isString(value) {
		    return typeof value === "string" || value instanceof String;
		};

		/**
		 * Tests if the specified value is a non-null object.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a non-null object
		 */
		util.isObject = function isObject(value) {
		    return value && typeof value === "object";
		};

		/**
		 * Checks if a property on a message is considered to be present.
		 * This is an alias of {@link util.isSet}.
		 * @function
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isset =

		/**
		 * Checks if a property on a message is considered to be present.
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isSet = function isSet(obj, prop) {
		    var value = obj[prop];
		    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
		        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
		    return false;
		};

		/**
		 * Any compatible Buffer instance.
		 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
		 * @interface Buffer
		 * @extends Uint8Array
		 */

		/**
		 * Node's Buffer class if available.
		 * @type {Constructor<Buffer>}
		 */
		util.Buffer = (function() {
		    try {
		        var Buffer = util.inquire("buffer").Buffer;
		        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
		        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
		    } catch (e) {
		        /* istanbul ignore next */
		        return null;
		    }
		})();

		// Internal alias of or polyfull for Buffer.from.
		util._Buffer_from = null;

		// Internal alias of or polyfill for Buffer.allocUnsafe.
		util._Buffer_allocUnsafe = null;

		/**
		 * Creates a new buffer of whatever type supported by the environment.
		 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
		 * @returns {Uint8Array|Buffer} Buffer
		 */
		util.newBuffer = function newBuffer(sizeOrArray) {
		    /* istanbul ignore next */
		    return typeof sizeOrArray === "number"
		        ? util.Buffer
		            ? util._Buffer_allocUnsafe(sizeOrArray)
		            : new util.Array(sizeOrArray)
		        : util.Buffer
		            ? util._Buffer_from(sizeOrArray)
		            : typeof Uint8Array === "undefined"
		                ? sizeOrArray
		                : new Uint8Array(sizeOrArray);
		};

		/**
		 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
		 * @type {Constructor<Uint8Array>}
		 */
		util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

		/**
		 * Any compatible Long instance.
		 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
		 * @interface Long
		 * @property {number} low Low bits
		 * @property {number} high High bits
		 * @property {boolean} unsigned Whether unsigned or not
		 */

		/**
		 * Long.js's Long class if available.
		 * @type {Constructor<Long>}
		 */
		util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
		         || /* istanbul ignore next */ util.global.Long
		         || util.inquire("long");

		/**
		 * Regular expression used to verify 2 bit (`bool`) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key2Re = /^true|false|0|1$/;

		/**
		 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

		/**
		 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

		/**
		 * Converts a number or long to an 8 characters long hash string.
		 * @param {Long|number} value Value to convert
		 * @returns {string} Hash
		 */
		util.longToHash = function longToHash(value) {
		    return value
		        ? util.LongBits.from(value).toHash()
		        : util.LongBits.zeroHash;
		};

		/**
		 * Converts an 8 characters long hash string to a long or number.
		 * @param {string} hash Hash
		 * @param {boolean} [unsigned=false] Whether unsigned or not
		 * @returns {Long|number} Original value
		 */
		util.longFromHash = function longFromHash(hash, unsigned) {
		    var bits = util.LongBits.fromHash(hash);
		    if (util.Long)
		        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
		    return bits.toNumber(Boolean(unsigned));
		};

		/**
		 * Merges the properties of the source object into the destination object.
		 * @memberof util
		 * @param {Object.<string,*>} dst Destination object
		 * @param {Object.<string,*>} src Source object
		 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
		 * @returns {Object.<string,*>} Destination object
		 */
		function merge(dst, src, ifNotSet) { // used by converters
		    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
		        if (dst[keys[i]] === undefined || !ifNotSet)
		            dst[keys[i]] = src[keys[i]];
		    return dst;
		}

		util.merge = merge;

		/**
		 * Converts the first character of a string to lower case.
		 * @param {string} str String to convert
		 * @returns {string} Converted string
		 */
		util.lcFirst = function lcFirst(str) {
		    return str.charAt(0).toLowerCase() + str.substring(1);
		};

		/**
		 * Creates a custom error constructor.
		 * @memberof util
		 * @param {string} name Error name
		 * @returns {Constructor<Error>} Custom error constructor
		 */
		function newError(name) {

		    function CustomError(message, properties) {

		        if (!(this instanceof CustomError))
		            return new CustomError(message, properties);

		        // Error.call(this, message);
		        // ^ just returns a new error instance because the ctor can be called as a function

		        Object.defineProperty(this, "message", { get: function() { return message; } });

		        /* istanbul ignore next */
		        if (Error.captureStackTrace) // node
		            Error.captureStackTrace(this, CustomError);
		        else
		            Object.defineProperty(this, "stack", { value: new Error().stack || "" });

		        if (properties)
		            merge(this, properties);
		    }

		    CustomError.prototype = Object.create(Error.prototype, {
		        constructor: {
		            value: CustomError,
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		        name: {
		            get: function get() { return name; },
		            set: undefined,
		            enumerable: false,
		            // configurable: false would accurately preserve the behavior of
		            // the original, but I'm guessing that was not intentional.
		            // For an actual error subclass, this property would
		            // be configurable.
		            configurable: true,
		        },
		        toString: {
		            value: function value() { return this.name + ": " + this.message; },
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		    });

		    return CustomError;
		}

		util.newError = newError;

		/**
		 * Constructs a new protocol error.
		 * @classdesc Error subclass indicating a protocol specifc error.
		 * @memberof util
		 * @extends Error
		 * @template T extends Message<T>
		 * @constructor
		 * @param {string} message Error message
		 * @param {Object.<string,*>} [properties] Additional properties
		 * @example
		 * try {
		 *     MyMessage.decode(someBuffer); // throws if required fields are missing
		 * } catch (e) {
		 *     if (e instanceof ProtocolError && e.instance)
		 *         console.log("decoded so far: " + JSON.stringify(e.instance));
		 * }
		 */
		util.ProtocolError = newError("ProtocolError");

		/**
		 * So far decoded message instance.
		 * @name util.ProtocolError#instance
		 * @type {Message<T>}
		 */

		/**
		 * A OneOf getter as returned by {@link util.oneOfGetter}.
		 * @typedef OneOfGetter
		 * @type {function}
		 * @returns {string|undefined} Set field name, if any
		 */

		/**
		 * Builds a getter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfGetter} Unbound getter
		 */
		util.oneOfGetter = function getOneOf(fieldNames) {
		    var fieldMap = {};
		    for (var i = 0; i < fieldNames.length; ++i)
		        fieldMap[fieldNames[i]] = 1;

		    /**
		     * @returns {string|undefined} Set field name, if any
		     * @this Object
		     * @ignore
		     */
		    return function() { // eslint-disable-line consistent-return
		        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
		            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
		                return keys[i];
		    };
		};

		/**
		 * A OneOf setter as returned by {@link util.oneOfSetter}.
		 * @typedef OneOfSetter
		 * @type {function}
		 * @param {string|undefined} value Field name
		 * @returns {undefined}
		 */

		/**
		 * Builds a setter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfSetter} Unbound setter
		 */
		util.oneOfSetter = function setOneOf(fieldNames) {

		    /**
		     * @param {string} name Field name
		     * @returns {undefined}
		     * @this Object
		     * @ignore
		     */
		    return function(name) {
		        for (var i = 0; i < fieldNames.length; ++i)
		            if (fieldNames[i] !== name)
		                delete this[fieldNames[i]];
		    };
		};

		/**
		 * Default conversion options used for {@link Message#toJSON} implementations.
		 *
		 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
		 *
		 * - Longs become strings
		 * - Enums become string keys
		 * - Bytes become base64 encoded strings
		 * - (Sub-)Messages become plain objects
		 * - Maps become plain objects with all string keys
		 * - Repeated fields become arrays
		 * - NaN and Infinity for float and double fields become strings
		 *
		 * @type {IConversionOptions}
		 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
		 */
		util.toJSONOptions = {
		    longs: String,
		    enums: String,
		    bytes: String,
		    json: true
		};

		// Sets up buffer utility according to the environment (called in index-minimal)
		util._configure = function() {
		    var Buffer = util.Buffer;
		    /* istanbul ignore if */
		    if (!Buffer) {
		        util._Buffer_from = util._Buffer_allocUnsafe = null;
		        return;
		    }
		    // because node 4.x buffers are incompatible & immutable
		    // see: https://github.com/dcodeIO/protobuf.js/pull/665
		    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
		        /* istanbul ignore next */
		        function Buffer_from(value, encoding) {
		            return new Buffer(value, encoding);
		        };
		    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
		        /* istanbul ignore next */
		        function Buffer_allocUnsafe(size) {
		            return new Buffer(size);
		        };
		};
} (minimal$1));
	return minimal$1;
}

var reader$3 = Reader$3;

var util$9      = requireMinimal$1();

var BufferReader$3; // cyclic

var LongBits$3  = util$9.LongBits,
    utf8$3      = util$9.utf8;

/* istanbul ignore next */
function indexOutOfRange$1(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader$3(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array$1 = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader$3(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader$3(buffer);
        throw Error("illegal buffer");
    };

var create$3 = function create() {
    return util$9.Buffer
        ? function create_buffer_setup(buffer) {
            return (Reader$3.create = function create_buffer(buffer) {
                return util$9.Buffer.isBuffer(buffer)
                    ? new BufferReader$3(buffer)
                    /* istanbul ignore next */
                    : create_array$1(buffer);
            })(buffer);
        }
        /* istanbul ignore next */
        : create_array$1;
};

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader$3.create = create$3();

Reader$3.prototype._slice = util$9.Array.prototype.subarray || /* istanbul ignore next */ util$9.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader$3.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange$1(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$3.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$3.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint$1() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits$3(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$1(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$1(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader$3.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end$1(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader$3.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$1(this, 4);

    return readFixed32_end$1(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader$3.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$1(this, 4);

    return readFixed32_end$1(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64$1(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$1(this, 8);

    return new LongBits$3(readFixed32_end$1(this.buf, this.pos += 4), readFixed32_end$1(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$3.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange$1(this, 4);

    var value = util$9.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$3.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange$1(this, 4);

    var value = util$9.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader$3.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange$1(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader$3.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8$3.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader$3.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange$1(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange$1(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader$3.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader$3._configure = function(BufferReader_) {
    BufferReader$3 = BufferReader_;
    Reader$3.create = create$3();
    BufferReader$3._configure();

    var fn = util$9.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util$9.merge(Reader$3.prototype, {

        int64: function read_int64() {
            return readLongVarint$1.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint$1.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint$1.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64$1.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64$1.call(this)[fn](false);
        }

    });
};

var reader_buffer$1 = BufferReader$2;

// extends Reader
var Reader$2 = reader$3;
(BufferReader$2.prototype = Object.create(Reader$2.prototype)).constructor = BufferReader$2;

var util$8 = requireMinimal$1();

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader$2(buffer) {
    Reader$2.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

BufferReader$2._configure = function () {
    /* istanbul ignore else */
    if (util$8.Buffer)
        BufferReader$2.prototype._slice = util$8.Buffer.prototype.slice;
};


/**
 * @override
 */
BufferReader$2.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice
        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))
        : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

BufferReader$2._configure();

var minimalExports$1 = requireMinimal$1();
var util$7 = /*@__PURE__*/getDefaultExportFromCjs(minimalExports$1);

var writer$3 = Writer$3;

var util$6      = requireMinimal$1();

var BufferWriter$3; // cyclic

var LongBits$2  = util$6.LongBits,
    base64$1    = util$6.base64,
    utf8$2      = util$6.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op$1(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop$1() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State$1(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer$3() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op$1(noop$1, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

var create$2 = function create() {
    return util$6.Buffer
        ? function create_buffer_setup() {
            return (Writer$3.create = function create_buffer() {
                return new BufferWriter$3();
            })();
        }
        /* istanbul ignore next */
        : function create_array() {
            return new Writer$3();
        };
};

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer$3.create = create$2();

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer$3.alloc = function alloc(size) {
    return new util$6.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util$6.Array !== Array)
    Writer$3.alloc = util$6.pool(Writer$3.alloc, util$6.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer$3.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op$1(fn, len, val);
    this.len += len;
    return this;
};

function writeByte$1(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32$1(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp$1(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp$1.prototype = Object.create(Op$1.prototype);
VarintOp$1.prototype.fn = writeVarint32$1;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp$1(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64$1, 10, LongBits$2.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64$1(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$3.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits$2.from(value);
    return this._push(writeVarint64$1, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$3.prototype.int64 = Writer$3.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$3.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits$2.from(value).zzEncode();
    return this._push(writeVarint64$1, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.bool = function write_bool(value) {
    return this._push(writeByte$1, 1, value ? 1 : 0);
};

function writeFixed32$1(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32$1, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.sfixed32 = Writer$3.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$3.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits$2.from(value);
    return this._push(writeFixed32$1, 4, bits.lo)._push(writeFixed32$1, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$3.prototype.sfixed64 = Writer$3.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.float = function write_float(value) {
    return this._push(util$6.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.double = function write_double(value) {
    return this._push(util$6.float.writeDoubleLE, 8, value);
};

var writeBytes$1 = util$6.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte$1, 1, 0);
    if (util$6.isString(value)) {
        var buf = Writer$3.alloc(len = base64$1.length(value));
        base64$1.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes$1, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer$3.prototype.string = function write_string(value) {
    var len = utf8$2.length(value);
    return len
        ? this.uint32(len)._push(utf8$2.write, len, value)
        : this._push(writeByte$1, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer$3.prototype.fork = function fork() {
    this.states = new State$1(this);
    this.head = this.tail = new Op$1(noop$1, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer$3.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op$1(noop$1, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer$3.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer$3.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer$3._configure = function(BufferWriter_) {
    BufferWriter$3 = BufferWriter_;
    Writer$3.create = create$2();
    BufferWriter$3._configure();
};

var writer_buffer$1 = BufferWriter$2;

// extends Writer
var Writer$2 = writer$3;
(BufferWriter$2.prototype = Object.create(Writer$2.prototype)).constructor = BufferWriter$2;

var util$5 = requireMinimal$1();

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter$2() {
    Writer$2.call(this);
}

BufferWriter$2._configure = function () {
    /**
     * Allocates a buffer of the specified size.
     * @function
     * @param {number} size Buffer size
     * @returns {Buffer} Buffer
     */
    BufferWriter$2.alloc = util$5._Buffer_allocUnsafe;

    BufferWriter$2.writeBytesBuffer = util$5.Buffer && util$5.Buffer.prototype instanceof Uint8Array && util$5.Buffer.prototype.set.name === "set"
        ? function writeBytesBuffer_set(val, buf, pos) {
          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
          // also works for plain array values
        }
        /* istanbul ignore next */
        : function writeBytesBuffer_copy(val, buf, pos) {
          if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
          else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
        };
};


/**
 * @override
 */
BufferWriter$2.prototype.bytes = function write_bytes_buffer(value) {
    if (util$5.isString(value))
        value = util$5._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(BufferWriter$2.writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer$1(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util$5.utf8.write(val, buf, pos);
    else if (buf.utf8Write)
        buf.utf8Write(val, pos);
    else
        buf.write(val, pos);
}

/**
 * @override
 */
BufferWriter$2.prototype.string = function write_string_buffer(value) {
    var len = util$5.Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer$1, len, value);
    return this;
};


/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

BufferWriter$2._configure();

// @ts-expect-error no types
function configure$1() {
    util$7._configure();
    reader$3._configure(reader_buffer$1);
    writer$3._configure(writer_buffer$1);
}
// Set up buffer utility according to the environment
configure$1();
// monkey patch the reader to add native bigint support
const methods$1 = [
    'uint64', 'int64', 'sint64', 'fixed64', 'sfixed64'
];
function patchReader$1(obj) {
    for (const method of methods$1) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function () {
            return BigInt(original.call(this).toString());
        };
    }
    return obj;
}
function reader$2(buf) {
    return patchReader$1(new reader$3(buf));
}
function patchWriter$1(obj) {
    for (const method of methods$1) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function (val) {
            return original.call(this, val.toString());
        };
    }
    return obj;
}
function writer$2() {
    return patchWriter$1(writer$3.create());
}

function decodeMessage$1(buf, codec) {
    const r = reader$2(buf instanceof Uint8Array ? buf : buf.subarray());
    return codec.decode(r);
}

function encodeMessage$1(message, codec) {
    const w = writer$2();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES$1;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES$1 || (CODEC_TYPES$1 = {}));
function createCodec$1(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function message$1(encode, decode) {
    return createCodec$1('message', CODEC_TYPES$1.LENGTH_DELIMITED, encode, decode);
}

/* eslint-disable import/export */
var Peer;
(function (Peer) {
    let _codec;
    Peer.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.addresses != null) {
                    for (const value of obj.addresses) {
                        w.uint32(10);
                        Address.codec().encode(value, w);
                    }
                }
                if (obj.protocols != null) {
                    for (const value of obj.protocols) {
                        w.uint32(18);
                        w.string(value);
                    }
                }
                if (obj.metadata != null) {
                    for (const value of obj.metadata) {
                        w.uint32(26);
                        Metadata.codec().encode(value, w);
                    }
                }
                if (obj.pubKey != null) {
                    w.uint32(34);
                    w.bytes(obj.pubKey);
                }
                if (obj.peerRecordEnvelope != null) {
                    w.uint32(42);
                    w.bytes(obj.peerRecordEnvelope);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    addresses: [],
                    protocols: [],
                    metadata: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.addresses.push(Address.codec().decode(reader, reader.uint32()));
                            break;
                        case 2:
                            obj.protocols.push(reader.string());
                            break;
                        case 3:
                            obj.metadata.push(Metadata.codec().decode(reader, reader.uint32()));
                            break;
                        case 4:
                            obj.pubKey = reader.bytes();
                            break;
                        case 5:
                            obj.peerRecordEnvelope = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Peer.encode = (obj) => {
        return encodeMessage$1(obj, Peer.codec());
    };
    Peer.decode = (buf) => {
        return decodeMessage$1(buf, Peer.codec());
    };
})(Peer || (Peer = {}));
var Address;
(function (Address) {
    let _codec;
    Address.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.multiaddr != null && obj.multiaddr.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.multiaddr);
                }
                if (obj.isCertified != null) {
                    w.uint32(16);
                    w.bool(obj.isCertified);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    multiaddr: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.multiaddr = reader.bytes();
                            break;
                        case 2:
                            obj.isCertified = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Address.encode = (obj) => {
        return encodeMessage$1(obj, Address.codec());
    };
    Address.decode = (buf) => {
        return decodeMessage$1(buf, Address.codec());
    };
})(Address || (Address = {}));
var Metadata;
(function (Metadata) {
    let _codec;
    Metadata.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.key != null && obj.key !== '')) {
                    w.uint32(10);
                    w.string(obj.key);
                }
                if ((obj.value != null && obj.value.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.value);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    key: '',
                    value: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.key = reader.string();
                            break;
                        case 2:
                            obj.value = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Metadata.encode = (obj) => {
        return encodeMessage$1(obj, Metadata.codec());
    };
    Metadata.decode = (buf) => {
        return decodeMessage$1(buf, Metadata.codec());
    };
})(Metadata || (Metadata = {}));

var eventemitter3Exports = {};
var eventemitter3 = {
  get exports(){ return eventemitter3Exports; },
  set exports(v){ eventemitter3Exports = v; },
};

(function (module) {

	var has = Object.prototype.hasOwnProperty
	  , prefix = '~';

	/**
	 * Constructor to create a storage for our `EE` objects.
	 * An `Events` instance is a plain object whose properties are event names.
	 *
	 * @constructor
	 * @private
	 */
	function Events() {}

	//
	// We try to not inherit from `Object.prototype`. In some engines creating an
	// instance in this way is faster than calling `Object.create(null)` directly.
	// If `Object.create(null)` is not supported we prefix the event names with a
	// character to make sure that the built-in object properties are not
	// overridden or used as an attack vector.
	//
	if (Object.create) {
	  Events.prototype = Object.create(null);

	  //
	  // This hack is needed because the `__proto__` property is still inherited in
	  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.
	  //
	  if (!new Events().__proto__) prefix = false;
	}

	/**
	 * Representation of a single event listener.
	 *
	 * @param {Function} fn The listener function.
	 * @param {*} context The context to invoke the listener with.
	 * @param {Boolean} [once=false] Specify if the listener is a one-time listener.
	 * @constructor
	 * @private
	 */
	function EE(fn, context, once) {
	  this.fn = fn;
	  this.context = context;
	  this.once = once || false;
	}

	/**
	 * Add a listener for a given event.
	 *
	 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} context The context to invoke the listener with.
	 * @param {Boolean} once Specify if the listener is a one-time listener.
	 * @returns {EventEmitter}
	 * @private
	 */
	function addListener(emitter, event, fn, context, once) {
	  if (typeof fn !== 'function') {
	    throw new TypeError('The listener must be a function');
	  }

	  var listener = new EE(fn, context || emitter, once)
	    , evt = prefix ? prefix + event : event;

	  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;
	  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);
	  else emitter._events[evt] = [emitter._events[evt], listener];

	  return emitter;
	}

	/**
	 * Clear event by name.
	 *
	 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
	 * @param {(String|Symbol)} evt The Event name.
	 * @private
	 */
	function clearEvent(emitter, evt) {
	  if (--emitter._eventsCount === 0) emitter._events = new Events();
	  else delete emitter._events[evt];
	}

	/**
	 * Minimal `EventEmitter` interface that is molded against the Node.js
	 * `EventEmitter` interface.
	 *
	 * @constructor
	 * @public
	 */
	function EventEmitter() {
	  this._events = new Events();
	  this._eventsCount = 0;
	}

	/**
	 * Return an array listing the events for which the emitter has registered
	 * listeners.
	 *
	 * @returns {Array}
	 * @public
	 */
	EventEmitter.prototype.eventNames = function eventNames() {
	  var names = []
	    , events
	    , name;

	  if (this._eventsCount === 0) return names;

	  for (name in (events = this._events)) {
	    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);
	  }

	  if (Object.getOwnPropertySymbols) {
	    return names.concat(Object.getOwnPropertySymbols(events));
	  }

	  return names;
	};

	/**
	 * Return the listeners registered for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Array} The registered listeners.
	 * @public
	 */
	EventEmitter.prototype.listeners = function listeners(event) {
	  var evt = prefix ? prefix + event : event
	    , handlers = this._events[evt];

	  if (!handlers) return [];
	  if (handlers.fn) return [handlers.fn];

	  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {
	    ee[i] = handlers[i].fn;
	  }

	  return ee;
	};

	/**
	 * Return the number of listeners listening to a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Number} The number of listeners.
	 * @public
	 */
	EventEmitter.prototype.listenerCount = function listenerCount(event) {
	  var evt = prefix ? prefix + event : event
	    , listeners = this._events[evt];

	  if (!listeners) return 0;
	  if (listeners.fn) return 1;
	  return listeners.length;
	};

	/**
	 * Calls each of the listeners registered for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Boolean} `true` if the event had listeners, else `false`.
	 * @public
	 */
	EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {
	  var evt = prefix ? prefix + event : event;

	  if (!this._events[evt]) return false;

	  var listeners = this._events[evt]
	    , len = arguments.length
	    , args
	    , i;

	  if (listeners.fn) {
	    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);

	    switch (len) {
	      case 1: return listeners.fn.call(listeners.context), true;
	      case 2: return listeners.fn.call(listeners.context, a1), true;
	      case 3: return listeners.fn.call(listeners.context, a1, a2), true;
	      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;
	      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;
	      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;
	    }

	    for (i = 1, args = new Array(len -1); i < len; i++) {
	      args[i - 1] = arguments[i];
	    }

	    listeners.fn.apply(listeners.context, args);
	  } else {
	    var length = listeners.length
	      , j;

	    for (i = 0; i < length; i++) {
	      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);

	      switch (len) {
	        case 1: listeners[i].fn.call(listeners[i].context); break;
	        case 2: listeners[i].fn.call(listeners[i].context, a1); break;
	        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;
	        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;
	        default:
	          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {
	            args[j - 1] = arguments[j];
	          }

	          listeners[i].fn.apply(listeners[i].context, args);
	      }
	    }
	  }

	  return true;
	};

	/**
	 * Add a listener for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} [context=this] The context to invoke the listener with.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.on = function on(event, fn, context) {
	  return addListener(this, event, fn, context, false);
	};

	/**
	 * Add a one-time listener for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} [context=this] The context to invoke the listener with.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.once = function once(event, fn, context) {
	  return addListener(this, event, fn, context, true);
	};

	/**
	 * Remove the listeners of a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn Only remove the listeners that match this function.
	 * @param {*} context Only remove the listeners that have this context.
	 * @param {Boolean} once Only remove one-time listeners.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {
	  var evt = prefix ? prefix + event : event;

	  if (!this._events[evt]) return this;
	  if (!fn) {
	    clearEvent(this, evt);
	    return this;
	  }

	  var listeners = this._events[evt];

	  if (listeners.fn) {
	    if (
	      listeners.fn === fn &&
	      (!once || listeners.once) &&
	      (!context || listeners.context === context)
	    ) {
	      clearEvent(this, evt);
	    }
	  } else {
	    for (var i = 0, events = [], length = listeners.length; i < length; i++) {
	      if (
	        listeners[i].fn !== fn ||
	        (once && !listeners[i].once) ||
	        (context && listeners[i].context !== context)
	      ) {
	        events.push(listeners[i]);
	      }
	    }

	    //
	    // Reset the array, or remove it completely if we have no more listeners.
	    //
	    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;
	    else clearEvent(this, evt);
	  }

	  return this;
	};

	/**
	 * Remove all listeners, or those of the specified event.
	 *
	 * @param {(String|Symbol)} [event] The event name.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {
	  var evt;

	  if (event) {
	    evt = prefix ? prefix + event : event;
	    if (this._events[evt]) clearEvent(this, evt);
	  } else {
	    this._events = new Events();
	    this._eventsCount = 0;
	  }

	  return this;
	};

	//
	// Alias methods names because people roll like that.
	//
	EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
	EventEmitter.prototype.addListener = EventEmitter.prototype.on;

	//
	// Expose the prefix.
	//
	EventEmitter.prefixed = prefix;

	//
	// Allow `EventEmitter` to be imported as module namespace.
	//
	EventEmitter.EventEmitter = EventEmitter;

	//
	// Expose the module.
	//
	{
	  module.exports = EventEmitter;
	}
} (eventemitter3));

class TimeoutError extends Error {
	constructor(message) {
		super(message);
		this.name = 'TimeoutError';
	}
}

/**
An error to be thrown when the request is aborted by AbortController.
DOMException is thrown instead of this Error when DOMException is available.
*/
let AbortError$1 = class AbortError extends Error {
	constructor(message) {
		super();
		this.name = 'AbortError';
		this.message = message;
	}
};

/**
TODO: Remove AbortError and just throw DOMException when targeting Node 18.
*/
const getDOMException = errorMessage => globalThis.DOMException === undefined ?
	new AbortError$1(errorMessage) :
	new DOMException(errorMessage);

/**
TODO: Remove below function and just 'reject(signal.reason)' when targeting Node 18.
*/
const getAbortedReason = signal => {
	const reason = signal.reason === undefined ?
		getDOMException('This operation was aborted.') :
		signal.reason;

	return reason instanceof Error ? reason : getDOMException(reason);
};

function pTimeout(promise, milliseconds, fallback, options) {
	let timer;

	const cancelablePromise = new Promise((resolve, reject) => {
		if (typeof milliseconds !== 'number' || Math.sign(milliseconds) !== 1) {
			throw new TypeError(`Expected \`milliseconds\` to be a positive number, got \`${milliseconds}\``);
		}

		if (milliseconds === Number.POSITIVE_INFINITY) {
			resolve(promise);
			return;
		}

		options = {
			customTimers: {setTimeout, clearTimeout},
			...options
		};

		if (options.signal) {
			const {signal} = options;
			if (signal.aborted) {
				reject(getAbortedReason(signal));
			}

			signal.addEventListener('abort', () => {
				reject(getAbortedReason(signal));
			});
		}

		timer = options.customTimers.setTimeout.call(undefined, () => {
			if (typeof fallback === 'function') {
				try {
					resolve(fallback());
				} catch (error) {
					reject(error);
				}

				return;
			}

			const message = typeof fallback === 'string' ? fallback : `Promise timed out after ${milliseconds} milliseconds`;
			const timeoutError = fallback instanceof Error ? fallback : new TimeoutError(message);

			if (typeof promise.cancel === 'function') {
				promise.cancel();
			}

			reject(timeoutError);
		}, milliseconds);

		(async () => {
			try {
				resolve(await promise);
			} catch (error) {
				reject(error);
			} finally {
				options.customTimers.clearTimeout.call(undefined, timer);
			}
		})();
	});

	cancelablePromise.clear = () => {
		clearTimeout(timer);
		timer = undefined;
	};

	return cancelablePromise;
}

// Port of lower_bound from https://en.cppreference.com/w/cpp/algorithm/lower_bound
// Used to compute insertion index to keep queue sorted after insertion
function lowerBound(array, value, comparator) {
    let first = 0;
    let count = array.length;
    while (count > 0) {
        const step = Math.trunc(count / 2);
        let it = first + step;
        if (comparator(array[it], value) <= 0) {
            first = ++it;
            count -= step + 1;
        }
        else {
            count = step;
        }
    }
    return first;
}

var __classPrivateFieldGet$1 = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var _PriorityQueue_queue;
class PriorityQueue {
    constructor() {
        _PriorityQueue_queue.set(this, []);
    }
    enqueue(run, options) {
        options = {
            priority: 0,
            ...options,
        };
        const element = {
            priority: options.priority,
            run,
        };
        if (this.size && __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f")[this.size - 1].priority >= options.priority) {
            __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").push(element);
            return;
        }
        const index = lowerBound(__classPrivateFieldGet$1(this, _PriorityQueue_queue, "f"), element, (a, b) => b.priority - a.priority);
        __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").splice(index, 0, element);
    }
    dequeue() {
        const item = __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").shift();
        return item === null || item === void 0 ? void 0 : item.run;
    }
    filter(options) {
        return __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").filter((element) => element.priority === options.priority).map((element) => element.run);
    }
    get size() {
        return __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").length;
    }
}
_PriorityQueue_queue = new WeakMap();

var __classPrivateFieldSet = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return (kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;
};
var __classPrivateFieldGet = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var _PQueue_instances, _PQueue_carryoverConcurrencyCount, _PQueue_isIntervalIgnored, _PQueue_intervalCount, _PQueue_intervalCap, _PQueue_interval, _PQueue_intervalEnd, _PQueue_intervalId, _PQueue_timeoutId, _PQueue_queue, _PQueue_queueClass, _PQueue_pending, _PQueue_concurrency, _PQueue_isPaused, _PQueue_throwOnTimeout, _PQueue_doesIntervalAllowAnother_get, _PQueue_doesConcurrentAllowAnother_get, _PQueue_next, _PQueue_onResumeInterval, _PQueue_isIntervalPaused_get, _PQueue_tryToStartAnother, _PQueue_initializeIntervalIfNeeded, _PQueue_onInterval, _PQueue_processQueue, _PQueue_throwOnAbort, _PQueue_onEvent;
/**
The error thrown by `queue.add()` when a job is aborted before it is run. See `signal`.
*/
class AbortError extends Error {
}
/**
Promise queue with concurrency control.
*/
class PQueue extends eventemitter3Exports {
    // TODO: The `throwOnTimeout` option should affect the return types of `add()` and `addAll()`
    constructor(options) {
        var _a, _b, _c, _d;
        super();
        _PQueue_instances.add(this);
        _PQueue_carryoverConcurrencyCount.set(this, void 0);
        _PQueue_isIntervalIgnored.set(this, void 0);
        _PQueue_intervalCount.set(this, 0);
        _PQueue_intervalCap.set(this, void 0);
        _PQueue_interval.set(this, void 0);
        _PQueue_intervalEnd.set(this, 0);
        _PQueue_intervalId.set(this, void 0);
        _PQueue_timeoutId.set(this, void 0);
        _PQueue_queue.set(this, void 0);
        _PQueue_queueClass.set(this, void 0);
        _PQueue_pending.set(this, 0);
        // The `!` is needed because of https://github.com/microsoft/TypeScript/issues/32194
        _PQueue_concurrency.set(this, void 0);
        _PQueue_isPaused.set(this, void 0);
        _PQueue_throwOnTimeout.set(this, void 0);
        /**
        Per-operation timeout in milliseconds. Operations fulfill once `timeout` elapses if they haven't already.
    
        Applies to each future operation.
        */
        Object.defineProperty(this, "timeout", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
        options = {
            carryoverConcurrencyCount: false,
            intervalCap: Number.POSITIVE_INFINITY,
            interval: 0,
            concurrency: Number.POSITIVE_INFINITY,
            autoStart: true,
            queueClass: PriorityQueue,
            ...options,
        };
        if (!(typeof options.intervalCap === 'number' && options.intervalCap >= 1)) {
            throw new TypeError(`Expected \`intervalCap\` to be a number from 1 and up, got \`${(_b = (_a = options.intervalCap) === null || _a === void 0 ? void 0 : _a.toString()) !== null && _b !== void 0 ? _b : ''}\` (${typeof options.intervalCap})`);
        }
        if (options.interval === undefined || !(Number.isFinite(options.interval) && options.interval >= 0)) {
            throw new TypeError(`Expected \`interval\` to be a finite number >= 0, got \`${(_d = (_c = options.interval) === null || _c === void 0 ? void 0 : _c.toString()) !== null && _d !== void 0 ? _d : ''}\` (${typeof options.interval})`);
        }
        __classPrivateFieldSet(this, _PQueue_carryoverConcurrencyCount, options.carryoverConcurrencyCount, "f");
        __classPrivateFieldSet(this, _PQueue_isIntervalIgnored, options.intervalCap === Number.POSITIVE_INFINITY || options.interval === 0, "f");
        __classPrivateFieldSet(this, _PQueue_intervalCap, options.intervalCap, "f");
        __classPrivateFieldSet(this, _PQueue_interval, options.interval, "f");
        __classPrivateFieldSet(this, _PQueue_queue, new options.queueClass(), "f");
        __classPrivateFieldSet(this, _PQueue_queueClass, options.queueClass, "f");
        this.concurrency = options.concurrency;
        this.timeout = options.timeout;
        __classPrivateFieldSet(this, _PQueue_throwOnTimeout, options.throwOnTimeout === true, "f");
        __classPrivateFieldSet(this, _PQueue_isPaused, options.autoStart === false, "f");
    }
    get concurrency() {
        return __classPrivateFieldGet(this, _PQueue_concurrency, "f");
    }
    set concurrency(newConcurrency) {
        if (!(typeof newConcurrency === 'number' && newConcurrency >= 1)) {
            throw new TypeError(`Expected \`concurrency\` to be a number from 1 and up, got \`${newConcurrency}\` (${typeof newConcurrency})`);
        }
        __classPrivateFieldSet(this, _PQueue_concurrency, newConcurrency, "f");
        __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_processQueue).call(this);
    }
    async add(function_, options = {}) {
        options = {
            timeout: this.timeout,
            throwOnTimeout: __classPrivateFieldGet(this, _PQueue_throwOnTimeout, "f"),
            ...options,
        };
        return new Promise((resolve, reject) => {
            __classPrivateFieldGet(this, _PQueue_queue, "f").enqueue(async () => {
                var _a;
                var _b, _c;
                __classPrivateFieldSet(this, _PQueue_pending, (_b = __classPrivateFieldGet(this, _PQueue_pending, "f"), _b++, _b), "f");
                __classPrivateFieldSet(this, _PQueue_intervalCount, (_c = __classPrivateFieldGet(this, _PQueue_intervalCount, "f"), _c++, _c), "f");
                try {
                    // TODO: Use options.signal?.throwIfAborted() when targeting Node.js 18
                    if ((_a = options.signal) === null || _a === void 0 ? void 0 : _a.aborted) {
                        // TODO: Use ABORT_ERR code when targeting Node.js 16 (https://nodejs.org/docs/latest-v16.x/api/errors.html#abort_err)
                        throw new AbortError('The task was aborted.');
                    }
                    let operation = function_({ signal: options.signal });
                    if (options.timeout) {
                        operation = pTimeout(Promise.resolve(operation), options.timeout);
                    }
                    if (options.signal) {
                        operation = Promise.race([operation, __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_throwOnAbort).call(this, options.signal)]);
                    }
                    const result = await operation;
                    resolve(result);
                    this.emit('completed', result);
                }
                catch (error) {
                    if (error instanceof TimeoutError && !options.throwOnTimeout) {
                        resolve();
                        return;
                    }
                    reject(error);
                    this.emit('error', error);
                }
                finally {
                    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_next).call(this);
                }
            }, options);
            this.emit('add');
            __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_tryToStartAnother).call(this);
        });
    }
    async addAll(functions, options) {
        return Promise.all(functions.map(async (function_) => this.add(function_, options)));
    }
    /**
    Start (or resume) executing enqueued tasks within concurrency limit. No need to call this if queue is not paused (via `options.autoStart = false` or by `.pause()` method.)
    */
    start() {
        if (!__classPrivateFieldGet(this, _PQueue_isPaused, "f")) {
            return this;
        }
        __classPrivateFieldSet(this, _PQueue_isPaused, false, "f");
        __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_processQueue).call(this);
        return this;
    }
    /**
    Put queue execution on hold.
    */
    pause() {
        __classPrivateFieldSet(this, _PQueue_isPaused, true, "f");
    }
    /**
    Clear the queue.
    */
    clear() {
        __classPrivateFieldSet(this, _PQueue_queue, new (__classPrivateFieldGet(this, _PQueue_queueClass, "f"))(), "f");
    }
    /**
    Can be called multiple times. Useful if you for example add additional items at a later time.

    @returns A promise that settles when the queue becomes empty.
    */
    async onEmpty() {
        // Instantly resolve if the queue is empty
        if (__classPrivateFieldGet(this, _PQueue_queue, "f").size === 0) {
            return;
        }
        await __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onEvent).call(this, 'empty');
    }
    /**
    @returns A promise that settles when the queue size is less than the given limit: `queue.size < limit`.

    If you want to avoid having the queue grow beyond a certain size you can `await queue.onSizeLessThan()` before adding a new item.

    Note that this only limits the number of items waiting to start. There could still be up to `concurrency` jobs already running that this call does not include in its calculation.
    */
    async onSizeLessThan(limit) {
        // Instantly resolve if the queue is empty.
        if (__classPrivateFieldGet(this, _PQueue_queue, "f").size < limit) {
            return;
        }
        await __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onEvent).call(this, 'next', () => __classPrivateFieldGet(this, _PQueue_queue, "f").size < limit);
    }
    /**
    The difference with `.onEmpty` is that `.onIdle` guarantees that all work from the queue has finished. `.onEmpty` merely signals that the queue is empty, but it could mean that some promises haven't completed yet.

    @returns A promise that settles when the queue becomes empty, and all promises have completed; `queue.size === 0 && queue.pending === 0`.
    */
    async onIdle() {
        // Instantly resolve if none pending and if nothing else is queued
        if (__classPrivateFieldGet(this, _PQueue_pending, "f") === 0 && __classPrivateFieldGet(this, _PQueue_queue, "f").size === 0) {
            return;
        }
        await __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onEvent).call(this, 'idle');
    }
    /**
    Size of the queue, the number of queued items waiting to run.
    */
    get size() {
        return __classPrivateFieldGet(this, _PQueue_queue, "f").size;
    }
    /**
    Size of the queue, filtered by the given options.

    For example, this can be used to find the number of items remaining in the queue with a specific priority level.
    */
    sizeBy(options) {
        // eslint-disable-next-line unicorn/no-array-callback-reference
        return __classPrivateFieldGet(this, _PQueue_queue, "f").filter(options).length;
    }
    /**
    Number of running items (no longer in the queue).
    */
    get pending() {
        return __classPrivateFieldGet(this, _PQueue_pending, "f");
    }
    /**
    Whether the queue is currently paused.
    */
    get isPaused() {
        return __classPrivateFieldGet(this, _PQueue_isPaused, "f");
    }
}
_PQueue_carryoverConcurrencyCount = new WeakMap(), _PQueue_isIntervalIgnored = new WeakMap(), _PQueue_intervalCount = new WeakMap(), _PQueue_intervalCap = new WeakMap(), _PQueue_interval = new WeakMap(), _PQueue_intervalEnd = new WeakMap(), _PQueue_intervalId = new WeakMap(), _PQueue_timeoutId = new WeakMap(), _PQueue_queue = new WeakMap(), _PQueue_queueClass = new WeakMap(), _PQueue_pending = new WeakMap(), _PQueue_concurrency = new WeakMap(), _PQueue_isPaused = new WeakMap(), _PQueue_throwOnTimeout = new WeakMap(), _PQueue_instances = new WeakSet(), _PQueue_doesIntervalAllowAnother_get = function _PQueue_doesIntervalAllowAnother_get() {
    return __classPrivateFieldGet(this, _PQueue_isIntervalIgnored, "f") || __classPrivateFieldGet(this, _PQueue_intervalCount, "f") < __classPrivateFieldGet(this, _PQueue_intervalCap, "f");
}, _PQueue_doesConcurrentAllowAnother_get = function _PQueue_doesConcurrentAllowAnother_get() {
    return __classPrivateFieldGet(this, _PQueue_pending, "f") < __classPrivateFieldGet(this, _PQueue_concurrency, "f");
}, _PQueue_next = function _PQueue_next() {
    var _a;
    __classPrivateFieldSet(this, _PQueue_pending, (_a = __classPrivateFieldGet(this, _PQueue_pending, "f"), _a--, _a), "f");
    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_tryToStartAnother).call(this);
    this.emit('next');
}, _PQueue_onResumeInterval = function _PQueue_onResumeInterval() {
    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onInterval).call(this);
    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_initializeIntervalIfNeeded).call(this);
    __classPrivateFieldSet(this, _PQueue_timeoutId, undefined, "f");
}, _PQueue_isIntervalPaused_get = function _PQueue_isIntervalPaused_get() {
    const now = Date.now();
    if (__classPrivateFieldGet(this, _PQueue_intervalId, "f") === undefined) {
        const delay = __classPrivateFieldGet(this, _PQueue_intervalEnd, "f") - now;
        if (delay < 0) {
            // Act as the interval was done
            // We don't need to resume it here because it will be resumed on line 160
            __classPrivateFieldSet(this, _PQueue_intervalCount, (__classPrivateFieldGet(this, _PQueue_carryoverConcurrencyCount, "f")) ? __classPrivateFieldGet(this, _PQueue_pending, "f") : 0, "f");
        }
        else {
            // Act as the interval is pending
            if (__classPrivateFieldGet(this, _PQueue_timeoutId, "f") === undefined) {
                __classPrivateFieldSet(this, _PQueue_timeoutId, setTimeout(() => {
                    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onResumeInterval).call(this);
                }, delay), "f");
            }
            return true;
        }
    }
    return false;
}, _PQueue_tryToStartAnother = function _PQueue_tryToStartAnother() {
    if (__classPrivateFieldGet(this, _PQueue_queue, "f").size === 0) {
        // We can clear the interval ("pause")
        // Because we can redo it later ("resume")
        if (__classPrivateFieldGet(this, _PQueue_intervalId, "f")) {
            clearInterval(__classPrivateFieldGet(this, _PQueue_intervalId, "f"));
        }
        __classPrivateFieldSet(this, _PQueue_intervalId, undefined, "f");
        this.emit('empty');
        if (__classPrivateFieldGet(this, _PQueue_pending, "f") === 0) {
            this.emit('idle');
        }
        return false;
    }
    if (!__classPrivateFieldGet(this, _PQueue_isPaused, "f")) {
        const canInitializeInterval = !__classPrivateFieldGet(this, _PQueue_instances, "a", _PQueue_isIntervalPaused_get);
        if (__classPrivateFieldGet(this, _PQueue_instances, "a", _PQueue_doesIntervalAllowAnother_get) && __classPrivateFieldGet(this, _PQueue_instances, "a", _PQueue_doesConcurrentAllowAnother_get)) {
            const job = __classPrivateFieldGet(this, _PQueue_queue, "f").dequeue();
            if (!job) {
                return false;
            }
            this.emit('active');
            job();
            if (canInitializeInterval) {
                __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_initializeIntervalIfNeeded).call(this);
            }
            return true;
        }
    }
    return false;
}, _PQueue_initializeIntervalIfNeeded = function _PQueue_initializeIntervalIfNeeded() {
    if (__classPrivateFieldGet(this, _PQueue_isIntervalIgnored, "f") || __classPrivateFieldGet(this, _PQueue_intervalId, "f") !== undefined) {
        return;
    }
    __classPrivateFieldSet(this, _PQueue_intervalId, setInterval(() => {
        __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onInterval).call(this);
    }, __classPrivateFieldGet(this, _PQueue_interval, "f")), "f");
    __classPrivateFieldSet(this, _PQueue_intervalEnd, Date.now() + __classPrivateFieldGet(this, _PQueue_interval, "f"), "f");
}, _PQueue_onInterval = function _PQueue_onInterval() {
    if (__classPrivateFieldGet(this, _PQueue_intervalCount, "f") === 0 && __classPrivateFieldGet(this, _PQueue_pending, "f") === 0 && __classPrivateFieldGet(this, _PQueue_intervalId, "f")) {
        clearInterval(__classPrivateFieldGet(this, _PQueue_intervalId, "f"));
        __classPrivateFieldSet(this, _PQueue_intervalId, undefined, "f");
    }
    __classPrivateFieldSet(this, _PQueue_intervalCount, __classPrivateFieldGet(this, _PQueue_carryoverConcurrencyCount, "f") ? __classPrivateFieldGet(this, _PQueue_pending, "f") : 0, "f");
    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_processQueue).call(this);
}, _PQueue_processQueue = function _PQueue_processQueue() {
    // eslint-disable-next-line no-empty
    while (__classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_tryToStartAnother).call(this)) { }
}, _PQueue_throwOnAbort = async function _PQueue_throwOnAbort(signal) {
    return new Promise((_resolve, reject) => {
        signal.addEventListener('abort', () => {
            // TODO: Reject with signal.throwIfAborted() when targeting Node.js 18
            // TODO: Use ABORT_ERR code when targeting Node.js 16 (https://nodejs.org/docs/latest-v16.x/api/errors.html#abort_err)
            reject(new AbortError('The task was aborted.'));
        }, { once: true });
    });
}, _PQueue_onEvent = async function _PQueue_onEvent(event, filter) {
    return new Promise(resolve => {
        const listener = () => {
            if (filter && !filter()) {
                return;
            }
            this.off(event, listener);
            resolve();
        };
        this.on(event, listener);
    });
};

let nanoid = (size = 21) =>
  crypto.getRandomValues(new Uint8Array(size)).reduce((id, byte) => {
    byte &= 63;
    if (byte < 36) {
      id += byte.toString(36);
    } else if (byte < 62) {
      id += (byte - 26).toString(36).toUpperCase();
    } else if (byte > 62) {
      id += '-';
    } else {
      id += '_';
    }
    return id
  }, '');

const WORKER_REQUEST_READ_LOCK = 'lock:worker:request-read';
const WORKER_RELEASE_READ_LOCK = 'lock:worker:release-read';
const MASTER_GRANT_READ_LOCK = 'lock:master:grant-read';
const WORKER_REQUEST_WRITE_LOCK = 'lock:worker:request-write';
const WORKER_RELEASE_WRITE_LOCK = 'lock:worker:release-write';
const MASTER_GRANT_WRITE_LOCK = 'lock:master:grant-write';

const events = {};
const observable = (worker) => {
    worker.addEventListener('message', (event) => {
        observable.dispatchEvent('message', worker, event);
    });
    if (worker.port != null) {
        worker.port.addEventListener('message', (event) => {
            observable.dispatchEvent('message', worker, event);
        });
    }
};
observable.addEventListener = (type, fn) => {
    if (events[type] == null) {
        events[type] = [];
    }
    events[type].push(fn);
};
observable.removeEventListener = (type, fn) => {
    if (events[type] == null) {
        return;
    }
    events[type] = events[type]
        .filter(listener => listener === fn);
};
observable.dispatchEvent = function (type, worker, event) {
    if (events[type] == null) {
        return;
    }
    events[type].forEach(fn => fn(worker, event));
};

const handleWorkerLockRequest = (emitter, masterEvent, requestType, releaseType, grantType) => {
    return (worker, event) => {
        if (event.data.type !== requestType) {
            return;
        }
        const requestEvent = {
            type: event.data.type,
            name: event.data.name,
            identifier: event.data.identifier
        };
        emitter.dispatchEvent(new MessageEvent(masterEvent, {
            data: {
                name: requestEvent.name,
                handler: async () => {
                    // grant lock to worker
                    worker.postMessage({
                        type: grantType,
                        name: requestEvent.name,
                        identifier: requestEvent.identifier
                    });
                    // wait for worker to finish
                    return await new Promise((resolve) => {
                        const releaseEventListener = (event) => {
                            if (event == null || event.data == null) {
                                return;
                            }
                            const releaseEvent = {
                                type: event.data.type,
                                name: event.data.name,
                                identifier: event.data.identifier
                            };
                            if (releaseEvent.type === releaseType && releaseEvent.identifier === requestEvent.identifier) {
                                worker.removeEventListener('message', releaseEventListener);
                                resolve();
                            }
                        };
                        worker.addEventListener('message', releaseEventListener);
                    });
                }
            }
        }));
    };
};
const makeWorkerLockRequest = (name, requestType, grantType, releaseType) => {
    return async () => {
        const id = nanoid();
        globalThis.postMessage({
            type: requestType,
            identifier: id,
            name
        });
        return await new Promise((resolve) => {
            const listener = (event) => {
                if (event == null || event.data == null) {
                    return;
                }
                const responseEvent = {
                    type: event.data.type,
                    identifier: event.data.identifier
                };
                if (responseEvent.type === grantType && responseEvent.identifier === id) {
                    globalThis.removeEventListener('message', listener);
                    // grant lock
                    resolve(() => {
                        // release lock
                        globalThis.postMessage({
                            type: releaseType,
                            identifier: id,
                            name
                        });
                    });
                }
            };
            globalThis.addEventListener('message', listener);
        });
    };
};
const defaultOptions$1 = {
    singleProcess: false
};
var impl = (options) => {
    options = Object.assign({}, defaultOptions$1, options);
    const isPrimary = Boolean(globalThis.document) || options.singleProcess;
    if (isPrimary) {
        const emitter = new EventTarget();
        observable.addEventListener('message', handleWorkerLockRequest(emitter, 'requestReadLock', WORKER_REQUEST_READ_LOCK, WORKER_RELEASE_READ_LOCK, MASTER_GRANT_READ_LOCK));
        observable.addEventListener('message', handleWorkerLockRequest(emitter, 'requestWriteLock', WORKER_REQUEST_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK));
        return emitter;
    }
    return {
        isWorker: true,
        readLock: (name) => makeWorkerLockRequest(name, WORKER_REQUEST_READ_LOCK, MASTER_GRANT_READ_LOCK, WORKER_RELEASE_READ_LOCK),
        writeLock: (name) => makeWorkerLockRequest(name, WORKER_REQUEST_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK)
    };
};

const mutexes = {};
let implementation;
async function createReleaseable(queue, options) {
    let res;
    const p = new Promise((resolve) => {
        res = resolve;
    });
    void queue.add(async () => await pTimeout$1((async () => {
        return await new Promise((resolve) => {
            res(() => {
                resolve();
            });
        });
    })(), {
        milliseconds: options.timeout
    }));
    return await p;
}
const createMutex = (name, options) => {
    if (implementation.isWorker === true) {
        return {
            readLock: implementation.readLock(name, options),
            writeLock: implementation.writeLock(name, options)
        };
    }
    const masterQueue = new PQueue({ concurrency: 1 });
    let readQueue;
    return {
        async readLock() {
            // If there's already a read queue, just add the task to it
            if (readQueue != null) {
                return await createReleaseable(readQueue, options);
            }
            // Create a new read queue
            readQueue = new PQueue({
                concurrency: options.concurrency,
                autoStart: false
            });
            const localReadQueue = readQueue;
            // Add the task to the read queue
            const readPromise = createReleaseable(readQueue, options);
            void masterQueue.add(async () => {
                // Start the task only once the master queue has completed processing
                // any previous tasks
                localReadQueue.start();
                // Once all the tasks in the read queue have completed, remove it so
                // that the next read lock will occur after any write locks that were
                // started in the interim
                return await localReadQueue.onIdle()
                    .then(() => {
                    if (readQueue === localReadQueue) {
                        readQueue = null;
                    }
                });
            });
            return await readPromise;
        },
        async writeLock() {
            // Remove the read queue reference, so that any later read locks will be
            // added to a new queue that starts after this write lock has been
            // released
            readQueue = null;
            return await createReleaseable(masterQueue, options);
        }
    };
};
const defaultOptions = {
    name: 'lock',
    concurrency: Infinity,
    timeout: 84600000,
    singleProcess: false
};
function createMortice(options) {
    const opts = Object.assign({}, defaultOptions, options);
    if (implementation == null) {
        implementation = impl(opts);
        if (implementation.isWorker !== true) {
            // we are master, set up worker requests
            implementation.addEventListener('requestReadLock', (event) => {
                if (mutexes[event.data.name] == null) {
                    return;
                }
                void mutexes[event.data.name].readLock()
                    .then(async (release) => await event.data.handler().finally(() => release()));
            });
            implementation.addEventListener('requestWriteLock', async (event) => {
                if (mutexes[event.data.name] == null) {
                    return;
                }
                void mutexes[event.data.name].writeLock()
                    .then(async (release) => await event.data.handler().finally(() => release()));
            });
        }
    }
    if (mutexes[opts.name] == null) {
        mutexes[opts.name] = createMutex(opts.name, opts);
    }
    return mutexes[opts.name];
}

const log$5 = logger$2('libp2p:peer-store:store');
const NAMESPACE_COMMON = '/peers/';
class PersistentStore {
    constructor(components) {
        this.components = components;
        this.lock = createMortice({
            name: 'peer-store',
            singleProcess: true
        });
    }
    _peerIdToDatastoreKey(peerId) {
        if (peerId.type == null) {
            log$5.error('peerId must be an instance of peer-id to store data');
            throw new CodeError('peerId must be an instance of peer-id', codes.ERR_INVALID_PARAMETERS);
        }
        const b32key = peerId.toCID().toString();
        return new Key(`${NAMESPACE_COMMON}${b32key}`);
    }
    async has(peerId) {
        return await this.components.datastore.has(this._peerIdToDatastoreKey(peerId));
    }
    async delete(peerId) {
        await this.components.datastore.delete(this._peerIdToDatastoreKey(peerId));
    }
    async load(peerId) {
        const buf = await this.components.datastore.get(this._peerIdToDatastoreKey(peerId));
        const peer = Peer.decode(buf);
        const metadata = new Map();
        for (const meta of peer.metadata) {
            metadata.set(meta.key, meta.value);
        }
        return {
            ...peer,
            id: peerId,
            addresses: peer.addresses.map(({ multiaddr: ma, isCertified }) => {
                return {
                    multiaddr: multiaddr$1(ma),
                    isCertified: isCertified ?? false
                };
            }),
            metadata,
            pubKey: peer.pubKey ?? undefined,
            peerRecordEnvelope: peer.peerRecordEnvelope ?? undefined
        };
    }
    async save(peer) {
        if (peer.pubKey != null && peer.id.publicKey != null && !equals$2(peer.pubKey, peer.id.publicKey)) {
            log$5.error('peer publicKey bytes do not match peer id publicKey bytes');
            throw new CodeError('publicKey bytes do not match peer id publicKey bytes', codes.ERR_INVALID_PARAMETERS);
        }
        // dedupe addresses
        const addressSet = new Set();
        const addresses = peer.addresses
            .filter(address => {
            if (addressSet.has(address.multiaddr.toString())) {
                return false;
            }
            addressSet.add(address.multiaddr.toString());
            return true;
        })
            .sort((a, b) => {
            return a.multiaddr.toString().localeCompare(b.multiaddr.toString());
        })
            .map(({ multiaddr, isCertified }) => ({
            multiaddr: multiaddr.bytes,
            isCertified
        }));
        const metadata = [];
        [...peer.metadata.keys()].sort().forEach(key => {
            const value = peer.metadata.get(key);
            if (value != null) {
                metadata.push({ key, value });
            }
        });
        const buf = Peer.encode({
            addresses,
            protocols: peer.protocols.sort(),
            pubKey: peer.pubKey,
            metadata,
            peerRecordEnvelope: peer.peerRecordEnvelope
        });
        await this.components.datastore.put(this._peerIdToDatastoreKey(peer.id), buf.subarray());
        return await this.load(peer.id);
    }
    async patch(peerId, data) {
        const peer = await this.load(peerId);
        return await this._patch(peerId, data, peer);
    }
    async patchOrCreate(peerId, data) {
        let peer;
        try {
            peer = await this.load(peerId);
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
            peer = { id: peerId, addresses: [], protocols: [], metadata: new Map() };
        }
        return await this._patch(peerId, data, peer);
    }
    async _patch(peerId, data, peer) {
        return await this.save({
            ...peer,
            ...data,
            id: peerId
        });
    }
    async merge(peerId, data) {
        const peer = await this.load(peerId);
        return await this._merge(peerId, data, peer);
    }
    async mergeOrCreate(peerId, data) {
        /** @type {Peer} */
        let peer;
        try {
            peer = await this.load(peerId);
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
            peer = { id: peerId, addresses: [], protocols: [], metadata: new Map() };
        }
        return await this._merge(peerId, data, peer);
    }
    async _merge(peerId, data, peer) {
        // if the peer has certified addresses, use those in
        // favour of the supplied versions
        const addresses = new Map();
        peer.addresses.forEach((addr) => {
            addresses.set(addr.multiaddr.toString(), addr.isCertified);
        });
        (data.addresses ?? []).forEach(addr => {
            const addrString = addr.multiaddr.toString();
            const isAlreadyCertified = Boolean(addresses.get(addrString));
            const isCertified = isAlreadyCertified || addr.isCertified;
            addresses.set(addrString, isCertified);
        });
        return await this.save({
            id: peerId,
            addresses: Array.from(addresses.entries()).map(([addrStr, isCertified]) => {
                return {
                    multiaddr: multiaddr$1(addrStr),
                    isCertified
                };
            }),
            protocols: Array.from(new Set([
                ...(peer.protocols ?? []),
                ...(data.protocols ?? [])
            ])),
            metadata: new Map([
                ...(peer.metadata?.entries() ?? []),
                ...(data.metadata?.entries() ?? [])
            ]),
            pubKey: data.pubKey ?? (peer != null ? peer.pubKey : undefined),
            peerRecordEnvelope: data.peerRecordEnvelope ?? (peer != null ? peer.peerRecordEnvelope : undefined)
        });
    }
    async *all() {
        for await (const key of this.components.datastore.queryKeys({
            prefix: NAMESPACE_COMMON
        })) {
            // /peers/${peer-id-as-libp2p-key-cid-string-in-base-32}
            const base32Str = key.toString().split('/')[2];
            const buf = base32$1.decode(base32Str);
            yield this.load(peerIdFromBytes(buf));
        }
    }
}

/* eslint-disable import/export */
var Tags;
(function (Tags) {
    let _codec;
    Tags.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.tags != null) {
                    for (const value of obj.tags) {
                        w.uint32(10);
                        Tag.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    tags: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.tags.push(Tag.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Tags.encode = (obj) => {
        return encodeMessage$1(obj, Tags.codec());
    };
    Tags.decode = (buf) => {
        return decodeMessage$1(buf, Tags.codec());
    };
})(Tags || (Tags = {}));
var Tag;
(function (Tag) {
    let _codec;
    Tag.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.name != null && obj.name !== '')) {
                    w.uint32(10);
                    w.string(obj.name);
                }
                if (obj.value != null) {
                    w.uint32(16);
                    w.uint32(obj.value);
                }
                if (obj.expiry != null) {
                    w.uint32(24);
                    w.uint64(obj.expiry);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    name: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.name = reader.string();
                            break;
                        case 2:
                            obj.value = reader.uint32();
                            break;
                        case 3:
                            obj.expiry = reader.uint64();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Tag.encode = (obj) => {
        return encodeMessage$1(obj, Tag.codec());
    };
    Tag.decode = (buf) => {
        return decodeMessage$1(buf, Tag.codec());
    };
})(Tag || (Tag = {}));

const log$4 = logger$2('libp2p:peer-store');
/**
 * An implementation of PeerStore that stores data in a Datastore
 */
class PersistentPeerStore extends EventEmitter$1 {
    constructor(components, init = {}) {
        super();
        this.components = components;
        this.store = new PersistentStore(components);
        this.addressBook = new PeerStoreAddressBook(this.dispatchEvent.bind(this), this.store, init.addressFilter);
        this.keyBook = new PeerStoreKeyBook(this.dispatchEvent.bind(this), this.store);
        this.metadataBook = new PeerStoreMetadataBook(this.dispatchEvent.bind(this), this.store);
        this.protoBook = new PeerStoreProtoBook(this.dispatchEvent.bind(this), this.store);
    }
    async forEach(fn) {
        log$4.trace('getPeers await read lock');
        const release = await this.store.lock.readLock();
        log$4.trace('getPeers got read lock');
        try {
            for await (const peer of this.store.all()) {
                if (peer.id.equals(this.components.peerId)) {
                    // Skip self peer if present
                    continue;
                }
                fn(peer);
            }
        }
        finally {
            log$4.trace('getPeers release read lock');
            release();
        }
    }
    async all() {
        const output = [];
        await this.forEach(peer => {
            output.push(peer);
        });
        return output;
    }
    /**
     * Delete the information of the given peer in every book
     */
    async delete(peerId) {
        log$4.trace('delete await write lock');
        const release = await this.store.lock.writeLock();
        log$4.trace('delete got write lock');
        try {
            await this.store.delete(peerId);
        }
        finally {
            log$4.trace('delete release write lock');
            release();
        }
    }
    /**
     * Get the stored information of a given peer
     */
    async get(peerId) {
        log$4.trace('get await read lock');
        const release = await this.store.lock.readLock();
        log$4.trace('get got read lock');
        try {
            return await this.store.load(peerId);
        }
        finally {
            log$4.trace('get release read lock');
            release();
        }
    }
    /**
     * Returns true if we have a record of the peer
     */
    async has(peerId) {
        log$4.trace('has await read lock');
        const release = await this.store.lock.readLock();
        log$4.trace('has got read lock');
        try {
            return await this.store.has(peerId);
        }
        finally {
            log$4.trace('has release read lock');
            release();
        }
    }
    async tagPeer(peerId, tag, options = {}) {
        const providedValue = options.value ?? 0;
        const value = Math.round(providedValue);
        const ttl = options.ttl ?? undefined;
        if (value !== providedValue || value < 0 || value > 100) {
            throw new CodeError('Tag value must be between 0-100', 'ERR_TAG_VALUE_OUT_OF_BOUNDS');
        }
        const buf = await this.metadataBook.getValue(peerId, 'tags');
        let tags = [];
        if (buf != null) {
            tags = Tags.decode(buf).tags;
        }
        // do not allow duplicate tags
        tags = tags.filter(t => t.name !== tag);
        tags.push({
            name: tag,
            value,
            expiry: ttl == null ? undefined : BigInt(Date.now() + ttl)
        });
        await this.metadataBook.setValue(peerId, 'tags', Tags.encode({ tags }).subarray());
    }
    async unTagPeer(peerId, tag) {
        const buf = await this.metadataBook.getValue(peerId, 'tags');
        let tags = [];
        if (buf != null) {
            tags = Tags.decode(buf).tags;
        }
        tags = tags.filter(t => t.name !== tag);
        await this.metadataBook.setValue(peerId, 'tags', Tags.encode({ tags }).subarray());
    }
    async getTags(peerId) {
        const buf = await this.metadataBook.getValue(peerId, 'tags');
        let tags = [];
        if (buf != null) {
            tags = Tags.decode(buf).tags;
        }
        const now = BigInt(Date.now());
        const unexpiredTags = tags.filter(tag => tag.expiry == null || tag.expiry > now);
        if (unexpiredTags.length !== tags.length) {
            // remove any expired tags
            await this.metadataBook.setValue(peerId, 'tags', Tags.encode({ tags: unexpiredTags }).subarray());
        }
        return unexpiredTags.map(t => ({
            name: t.name,
            value: t.value ?? 0
        }));
    }
}

/**
 * Wrapper class to convert events into returned values
 */
class DHTContentRouting {
    constructor(dht) {
        this.dht = dht;
    }
    async provide(cid) {
        await drain(this.dht.provide(cid));
    }
    async *findProviders(cid, options = {}) {
        for await (const event of this.dht.findProviders(cid, options)) {
            if (event.name === 'PROVIDER') {
                yield* event.providers;
            }
        }
    }
    async put(key, value, options) {
        await drain(this.dht.put(key, value, options));
    }
    async get(key, options) {
        for await (const event of this.dht.get(key, options)) {
            if (event.name === 'VALUE') {
                return event.value;
            }
        }
        throw errCode(new Error('Not found'), 'ERR_NOT_FOUND');
    }
}

class DefaultComponents {
    constructor(init = {}) {
        this._started = false;
        this._peerId = init.peerId;
        this._addressManager = init.addressManager;
        this._peerStore = init.peerStore;
        this._upgrader = init.upgrader;
        this._metrics = init.metrics;
        this._registrar = init.registrar;
        this._connectionManager = init.connectionManager;
        this._transportManager = init.transportManager;
        this._connectionGater = init.connectionGater;
        this._contentRouting = init.contentRouting;
        this._peerRouting = init.peerRouting;
        this._datastore = init.datastore;
        this._connectionProtector = init.connectionProtector;
        this._dht = init.dht;
        this._pubsub = init.pubsub;
        this._dialer = init.dialer;
    }
    isStarted() {
        return this._started;
    }
    async beforeStart() {
        await Promise.all(Object.values(this).filter(obj => isStartable(obj)).map(async (startable) => {
            if (startable.beforeStart != null) {
                await startable.beforeStart();
            }
        }));
    }
    async start() {
        await Promise.all(Object.values(this).filter(obj => isStartable(obj)).map(async (startable) => {
            await startable.start();
        }));
        this._started = true;
    }
    async afterStart() {
        await Promise.all(Object.values(this).filter(obj => isStartable(obj)).map(async (startable) => {
            if (startable.afterStart != null) {
                await startable.afterStart();
            }
        }));
    }
    async beforeStop() {
        await Promise.all(Object.values(this).filter(obj => isStartable(obj)).map(async (startable) => {
            if (startable.beforeStop != null) {
                await startable.beforeStop();
            }
        }));
    }
    async stop() {
        await Promise.all(Object.values(this).filter(obj => isStartable(obj)).map(async (startable) => {
            await startable.stop();
        }));
        this._started = false;
    }
    async afterStop() {
        await Promise.all(Object.values(this).filter(obj => isStartable(obj)).map(async (startable) => {
            if (startable.afterStop != null) {
                await startable.afterStop();
            }
        }));
    }
    get peerId() {
        if (this._peerId == null) {
            throw errCode(new Error('peerId not set'), 'ERR_SERVICE_MISSING');
        }
        return this._peerId;
    }
    set peerId(peerId) {
        this._peerId = peerId;
    }
    get addressManager() {
        if (this._addressManager == null) {
            throw errCode(new Error('addressManager not set'), 'ERR_SERVICE_MISSING');
        }
        return this._addressManager;
    }
    set addressManager(addressManager) {
        this._addressManager = addressManager;
    }
    get peerStore() {
        if (this._peerStore == null) {
            throw errCode(new Error('peerStore not set'), 'ERR_SERVICE_MISSING');
        }
        return this._peerStore;
    }
    set peerStore(peerStore) {
        this._peerStore = peerStore;
    }
    get upgrader() {
        if (this._upgrader == null) {
            throw errCode(new Error('upgrader not set'), 'ERR_SERVICE_MISSING');
        }
        return this._upgrader;
    }
    set upgrader(upgrader) {
        this._upgrader = upgrader;
    }
    get registrar() {
        if (this._registrar == null) {
            throw errCode(new Error('registrar not set'), 'ERR_SERVICE_MISSING');
        }
        return this._registrar;
    }
    set registrar(registrar) {
        this._registrar = registrar;
    }
    get connectionManager() {
        if (this._connectionManager == null) {
            throw errCode(new Error('connectionManager not set'), 'ERR_SERVICE_MISSING');
        }
        return this._connectionManager;
    }
    set connectionManager(connectionManager) {
        this._connectionManager = connectionManager;
    }
    get transportManager() {
        if (this._transportManager == null) {
            throw errCode(new Error('transportManager not set'), 'ERR_SERVICE_MISSING');
        }
        return this._transportManager;
    }
    set transportManager(transportManager) {
        this._transportManager = transportManager;
    }
    get connectionGater() {
        if (this._connectionGater == null) {
            throw errCode(new Error('connectionGater not set'), 'ERR_SERVICE_MISSING');
        }
        return this._connectionGater;
    }
    set connectionGater(connectionGater) {
        this._connectionGater = connectionGater;
    }
    get contentRouting() {
        if (this._contentRouting == null) {
            throw errCode(new Error('contentRouting not set'), 'ERR_SERVICE_MISSING');
        }
        return this._contentRouting;
    }
    set contentRouting(contentRouting) {
        this._contentRouting = contentRouting;
    }
    get peerRouting() {
        if (this._peerRouting == null) {
            throw errCode(new Error('peerRouting not set'), 'ERR_SERVICE_MISSING');
        }
        return this._peerRouting;
    }
    set peerRouting(peerRouting) {
        this._peerRouting = peerRouting;
    }
    get datastore() {
        if (this._datastore == null) {
            throw errCode(new Error('datastore not set'), 'ERR_SERVICE_MISSING');
        }
        return this._datastore;
    }
    set datastore(datastore) {
        this._datastore = datastore;
    }
    get connectionProtector() {
        return this._connectionProtector;
    }
    set connectionProtector(connectionProtector) {
        this._connectionProtector = connectionProtector;
    }
    get dialer() {
        if (this._dialer == null) {
            throw errCode(new Error('dialer not set'), 'ERR_SERVICE_MISSING');
        }
        return this._dialer;
    }
    set dialer(dialer) {
        this._dialer = dialer;
    }
    get metrics() {
        return this._metrics;
    }
    set metrics(metrics) {
        this._metrics = metrics;
    }
    get dht() {
        return this._dht;
    }
    set dht(dht) {
        this._dht = dht;
    }
    get pubsub() {
        return this._pubsub;
    }
    set pubsub(pubsub) {
        this._pubsub = pubsub;
    }
}

var receptacle = Receptacle;
var toMS = requireMs();
var cache = Receptacle.prototype;
var counter = new Date() % 1e9;

function getUID () { return (Math.random() * 1e9 >>> 0) + (counter++) }

/**
 * Creates a cache with a maximum key size.
 *
 * @constructor
 * @param {Object} options
 * @param {Number} [options.max=Infinity] the maximum number of keys allowed in the cache (lru).
 * @param {Array} [options.items=[]] the default items in the cache.
 */
function Receptacle (options) {
  options = options || {};
  this.id = options.id || getUID();
  this.max = options.max || Infinity;
  this.items = options.items || [];
  this._lookup = {};
  this.size = this.items.length;
  this.lastModified = new Date(options.lastModified || new Date());

  // Setup initial timers and indexes for the cache.
  for (var item, ttl, i = this.items.length; i--;) {
    item = this.items[i];
    ttl = new Date(item.expires) - new Date();
    this._lookup[item.key] = item;
    if (ttl > 0) this.expire(item.key, ttl);
    else if (ttl <= 0) this.delete(item.key);
  }
}

/**
 * Tests if a key is currently in the cache.
 * Does not check if slot is empty.
 *
 * @param {String} key - the key to retrieve from the cache.
 * @return {Boolean}
 */
cache.has = function (key) {
  return key in this._lookup
};

/**
 * Retrieves a key from the cache and marks it as recently used.
 *
 * @param {String} key - the key to retrieve from the cache.
 * @return {*}
 */
cache.get = function (key) {
  if (!this.has(key)) return null
  var record = this._lookup[key];
  // Update expiry for "refresh" keys
  if (record.refresh) this.expire(key, record.refresh);
  // Move to front of the line.
  this.items.splice(this.items.indexOf(record), 1);
  this.items.push(record);
  return record.value
};

/**
 * Retrieves user meta data for a cached item.
 *
 * @param {String} key - the key to retrieve meta data from the cache.
 * @return {*}
 */
cache.meta = function (key) {
  if (!this.has(key)) return null
  var record = this._lookup[key];
  if (!('meta' in record)) return null
  return record.meta
};

/**
 * Puts a key into the cache with an optional expiry time.
 *
 * @param {String} key - the key for the value in the cache.
 * @param {*} value - the value to place at the key.
 * @param {Number} [options.ttl] - a time after which the key will be removed.
 * @return {Receptacle}
 */
cache.set = function (key, value, options) {
  var oldRecord = this._lookup[key];
  var record = this._lookup[key] = { key: key, value: value };
  // Mark cache as modified.
  this.lastModified = new Date();

  if (oldRecord) {
    // Replace an old key.
    clearTimeout(oldRecord.timeout);
    this.items.splice(this.items.indexOf(oldRecord), 1, record);
  } else {
    // Remove least used item if needed.
    if (this.size >= this.max) this.delete(this.items[0].key);
    // Add a new key.
    this.items.push(record);
    this.size++;
  }

  if (options) {
    // Setup key expiry.
    if ('ttl' in options) this.expire(key, options.ttl);
    // Store user options in the record.
    if ('meta' in options) record.meta = options.meta;
    // Mark a auto refresh key.
    if (options.refresh) record.refresh = options.ttl;
  }

  return this
};

/**
 * Deletes an item from the cache.
 *
 * @param {String} key - the key to remove.
 * @return {Receptacle}
 */
cache.delete = function (key) {
  var record = this._lookup[key];
  if (!record) return false
  this.lastModified = new Date();
  this.items.splice(this.items.indexOf(record), 1);
  clearTimeout(record.timeout);
  delete this._lookup[key];
  this.size--;
  return this
};

/**
 * Utility to register a key that will be removed after some time.
 *
 * @param {String} key - the key to remove.
 * @param {Number} [ms] - the timeout before removal.
 * @return {Receptacle}
 */
cache.expire = function (key, ttl) {
  var ms = ttl || 0;
  var record = this._lookup[key];
  if (!record) return this
  if (typeof ms === 'string') ms = toMS(ttl);
  if (typeof ms !== 'number') throw new TypeError('Expiration time must be a string or number.')
  clearTimeout(record.timeout);
  record.timeout = setTimeout(this.delete.bind(this, record.key), ms);
  record.expires = Number(new Date()) + ms;
  return this
};

/**
 * Deletes all items from the cache.
 * @return {Receptacle}
 */
cache.clear = function () {
  for (var i = this.items.length; i--;) this.delete(this.items[i].key);
  return this
};

/**
 * Fixes serialization issues in polyfilled environments.
 * Ensures non-cyclical serialized object.
 */
cache.toJSON = function () {
  var items = new Array(this.items.length);
  var item;
  for (var i = items.length; i--;) {
    item = this.items[i];
    items[i] = {
      key: item.key,
      meta: item.meta,
      value: item.value,
      expires: item.expires,
      refresh: item.refresh
    };
  }

  return {
    id: this.id,
    max: isFinite(this.max) ? this.max : undefined,
    lastModified: this.lastModified,
    items: items
  }
};

const globalFetch = globalThis.fetch;
const globalHeaders = globalThis.Headers;

/**
 * Build fetch resource for request
 */
function buildResource(serverResolver, hostname, recordType) {
    return `${serverResolver}?name=${hostname}&type=${recordType}`;
}
/**
 * Use fetch to find the record
 */
async function request(resource, signal) {
    const req = await globalFetch(resource, {
        headers: new globalHeaders({
            accept: 'application/dns-json'
        }),
        signal
    });
    const res = await req.json();
    return res;
}
/**
 * Creates cache key composed by recordType and hostname
 *
 * @param {string} hostname
 * @param {string} recordType
 */
function getCacheKey(hostname, recordType) {
    return `${recordType}_${hostname}`;
}

const log$3 = Object.assign(debug('dns-over-http-resolver'), {
    error: debug('dns-over-http-resolver:error')
});
/**
 * DNS over HTTP resolver.
 * Uses a list of servers to resolve DNS records with HTTP requests.
 */
class Resolver {
    /**
     * @class
     * @param {object} [options]
     * @param {number} [options.maxCache = 100] - maximum number of cached dns records
     * @param {Request} [options.request] - function to return DNSJSON
     */
    constructor(options = {}) {
        this._cache = new receptacle({ max: options?.maxCache ?? 100 });
        this._TXTcache = new receptacle({ max: options?.maxCache ?? 100 });
        this._servers = [
            'https://cloudflare-dns.com/dns-query',
            'https://dns.google/resolve'
        ];
        this._request = options.request ?? request;
        this._abortControllers = [];
    }
    /**
     * Cancel all outstanding DNS queries made by this resolver. Any outstanding
     * requests will be aborted and promises rejected.
     */
    cancel() {
        this._abortControllers.forEach(controller => controller.abort());
    }
    /**
     * Get an array of the IP addresses currently configured for DNS resolution.
     * These addresses are formatted according to RFC 5952. It can include a custom port.
     */
    getServers() {
        return this._servers;
    }
    /**
     * Get a shuffled array of the IP addresses currently configured for DNS resolution.
     * These addresses are formatted according to RFC 5952. It can include a custom port.
     */
    _getShuffledServers() {
        const newServers = [...this._servers];
        for (let i = newServers.length - 1; i > 0; i--) {
            const j = Math.floor(Math.random() * i);
            const temp = newServers[i];
            newServers[i] = newServers[j];
            newServers[j] = temp;
        }
        return newServers;
    }
    /**
     * Sets the IP address and port of servers to be used when performing DNS resolution.
     *
     * @param {string[]} servers - array of RFC 5952 formatted addresses.
     */
    setServers(servers) {
        this._servers = servers;
    }
    /**
     * Uses the DNS protocol to resolve the given host name into the appropriate DNS record
     *
     * @param {string} hostname - host name to resolve
     * @param {string} [rrType = 'A'] - resource record type
     */
    async resolve(hostname, rrType = 'A') {
        switch (rrType) {
            case 'A':
                return await this.resolve4(hostname);
            case 'AAAA':
                return await this.resolve6(hostname);
            case 'TXT':
                return await this.resolveTxt(hostname);
            default:
                throw new Error(`${rrType} is not supported`);
        }
    }
    /**
     * Uses the DNS protocol to resolve the given host name into IPv4 addresses
     *
     * @param {string} hostname - host name to resolve
     */
    async resolve4(hostname) {
        const recordType = 'A';
        const cached = this._cache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => a.data);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._cache.set(getCacheKey(hostname, recordType), data, { ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$3.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryA ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    /**
     * Uses the DNS protocol to resolve the given host name into IPv6 addresses
     *
     * @param {string} hostname - host name to resolve
     */
    async resolve6(hostname) {
        const recordType = 'AAAA';
        const cached = this._cache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => a.data);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._cache.set(getCacheKey(hostname, recordType), data, { ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$3.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryAaaa ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    /**
     * Uses the DNS protocol to resolve the given host name into a Text record
     *
     * @param {string} hostname - host name to resolve
     */
    async resolveTxt(hostname) {
        const recordType = 'TXT';
        const cached = this._TXTcache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => [a.data.replace(/['"]+/g, '')]);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._TXTcache.set(getCacheKey(hostname, recordType), data, { ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$3.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryTxt ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    clearCache() {
        this._cache.clear();
        this._TXTcache.clear();
    }
}

/**
 * @packageDocumentation
 *
 * Provides strategies for resolving multiaddrs.
 */
const { code: dnsaddrCode } = getProtocol$1('dnsaddr');
/**
 * Resolver for dnsaddr addresses.
 *
 * @example
 *
 * ```typescript
 * import { dnsaddrResolver } from '@multiformats/multiaddr/resolvers'
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')
 * const addresses = await dnsaddrResolver(ma)
 *
 * console.info(addresses)
 * //[
 * //  '/dnsaddr/am6.bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb',
 * //  '/dnsaddr/ny5.bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa',
 * //  '/dnsaddr/sg1.bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt',
 * //  '/dnsaddr/sv15.bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN'
 * //]
 * ```
 */
async function dnsaddrResolver(addr, options = {}) {
    const resolver = new Resolver();
    if (options.signal != null) {
        options.signal.addEventListener('abort', () => {
            resolver.cancel();
        });
    }
    const peerId = addr.getPeerId();
    const [, hostname] = addr.stringTuples().find(([proto]) => proto === dnsaddrCode) ?? [];
    if (hostname == null) {
        throw new Error('No hostname found in multiaddr');
    }
    const records = await resolver.resolveTxt(`_dnsaddr.${hostname}`);
    let addresses = records.flat().map((a) => a.split('=')[1]).filter(Boolean);
    if (peerId != null) {
        addresses = addresses.filter((entry) => entry.includes(peerId));
    }
    return addresses;
}

/**
 * How long in ms a dial attempt is allowed to take
 */
const DIAL_TIMEOUT = 30e3;
/**
 * How long in ms an inbound connection upgrade is allowed to take
 */
const INBOUND_UPGRADE_TIMEOUT = 30e3;
/**
 * Maximum allowed concurrent dials
 */
const MAX_PARALLEL_DIALS = 100;
/**
 * Allowed parallel dials per DialRequest
 */
const MAX_PER_PEER_DIALS = 4;
/**
 * Maximum number of allowed addresses to attempt to dial
 */
const MAX_ADDRS_TO_DIAL = 25;

const DefaultConfig = {
    addresses: {
        listen: [],
        announce: [],
        noAnnounce: [],
        announceFilter: (multiaddrs) => multiaddrs
    },
    connectionManager: {
        maxConnections: 300,
        minConnections: 50,
        autoDial: true,
        autoDialInterval: 10000,
        maxParallelDials: MAX_PARALLEL_DIALS,
        maxDialsPerPeer: MAX_PER_PEER_DIALS,
        dialTimeout: DIAL_TIMEOUT,
        inboundUpgradeTimeout: INBOUND_UPGRADE_TIMEOUT,
        resolvers: {
            dnsaddr: dnsaddrResolver
        },
        addressSorter: publicAddressesFirst
    },
    connectionGater: {},
    transportManager: {
        faultTolerance: FaultTolerance.FATAL_ALL
    },
    peerRouting: {
        refreshManager: {
            enabled: true,
            interval: 6e5,
            bootDelay: 10e3
        }
    },
    nat: {
        enabled: true,
        ttl: 7200,
        keepAlive: true
    },
    relay: {
        enabled: true,
        advertise: {
            bootDelay: ADVERTISE_BOOT_DELAY,
            enabled: false,
            ttl: ADVERTISE_TTL
        },
        hop: {
            enabled: false,
            active: false,
            timeout: 30000
        },
        autoRelay: {
            enabled: false,
            maxListeners: 2
        }
    },
    identify: {
        protocolPrefix: 'ipfs',
        host: {
            agentVersion: AGENT_VERSION
        },
        // https://github.com/libp2p/go-libp2p/blob/8d2e54e1637041d5cf4fac1e531287560bd1f4ac/p2p/protocol/identify/id.go#L48
        timeout: 60000,
        maxInboundStreams: 1,
        maxOutboundStreams: 1,
        maxPushIncomingStreams: 1,
        maxPushOutgoingStreams: 1
    },
    ping: {
        protocolPrefix: 'ipfs',
        maxInboundStreams: 1,
        maxOutboundStreams: 1,
        timeout: 10000
    },
    fetch: {
        protocolPrefix: 'libp2p',
        maxInboundStreams: 1,
        maxOutboundStreams: 1,
        timeout: 10000
    }
};
function validateConfig(opts) {
    const resultingOptions = mergeOptions(DefaultConfig, opts);
    if (resultingOptions.transports == null || resultingOptions.transports.length < 1) {
        throw errCode(new Error(messages.ERR_TRANSPORTS_REQUIRED), codes$1.ERR_TRANSPORTS_REQUIRED);
    }
    if (resultingOptions.connectionEncryption == null || resultingOptions.connectionEncryption.length === 0) {
        throw errCode(new Error(messages.CONN_ENCRYPTION_REQUIRED), codes$1.CONN_ENCRYPTION_REQUIRED);
    }
    if (resultingOptions.connectionProtector === null && globalThis.process?.env?.LIBP2P_FORCE_PNET != null) { // eslint-disable-line no-undef
        throw errCode(new Error(messages.ERR_PROTECTOR_REQUIRED), codes$1.ERR_PROTECTOR_REQUIRED);
    }
    // Append user agent version to default AGENT_VERSION depending on the environment
    if (resultingOptions.identify.host.agentVersion === AGENT_VERSION) {
        if (isNode || isElectronMain) {
            resultingOptions.identify.host.agentVersion += ` UserAgent=${globalThis.process.version}`;
        }
        else if (isBrowser$1 || isWebWorker || isElectronRenderer || isReactNative) {
            resultingOptions.identify.host.agentVersion += ` UserAgent=${globalThis.navigator.userAgent}`;
        }
    }
    return resultingOptions;
}

var minimal = {};

var longbits;
var hasRequiredLongbits;

function requireLongbits () {
	if (hasRequiredLongbits) return longbits;
	hasRequiredLongbits = 1;
	longbits = LongBits;

	var util = requireMinimal();

	/**
	 * Constructs new long bits.
	 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
	 * @memberof util
	 * @constructor
	 * @param {number} lo Low 32 bits, unsigned
	 * @param {number} hi High 32 bits, unsigned
	 */
	function LongBits(lo, hi) {

	    // note that the casts below are theoretically unnecessary as of today, but older statically
	    // generated converter code might still call the ctor with signed 32bits. kept for compat.

	    /**
	     * Low bits.
	     * @type {number}
	     */
	    this.lo = lo >>> 0;

	    /**
	     * High bits.
	     * @type {number}
	     */
	    this.hi = hi >>> 0;
	}

	/**
	 * Zero bits.
	 * @memberof util.LongBits
	 * @type {util.LongBits}
	 */
	var zero = LongBits.zero = new LongBits(0, 0);

	zero.toNumber = function() { return 0; };
	zero.zzEncode = zero.zzDecode = function() { return this; };
	zero.length = function() { return 1; };

	/**
	 * Zero hash.
	 * @memberof util.LongBits
	 * @type {string}
	 */
	var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

	/**
	 * Constructs new long bits from the specified number.
	 * @param {number} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.fromNumber = function fromNumber(value) {
	    if (value === 0)
	        return zero;
	    var sign = value < 0;
	    if (sign)
	        value = -value;
	    var lo = value >>> 0,
	        hi = (value - lo) / 4294967296 >>> 0;
	    if (sign) {
	        hi = ~hi >>> 0;
	        lo = ~lo >>> 0;
	        if (++lo > 4294967295) {
	            lo = 0;
	            if (++hi > 4294967295)
	                hi = 0;
	        }
	    }
	    return new LongBits(lo, hi);
	};

	/**
	 * Constructs new long bits from a number, long or string.
	 * @param {Long|number|string} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.from = function from(value) {
	    if (typeof value === "number")
	        return LongBits.fromNumber(value);
	    if (util.isString(value)) {
	        /* istanbul ignore else */
	        if (util.Long)
	            value = util.Long.fromString(value);
	        else
	            return LongBits.fromNumber(parseInt(value, 10));
	    }
	    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
	};

	/**
	 * Converts this long bits to a possibly unsafe JavaScript number.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {number} Possibly unsafe number
	 */
	LongBits.prototype.toNumber = function toNumber(unsigned) {
	    if (!unsigned && this.hi >>> 31) {
	        var lo = ~this.lo + 1 >>> 0,
	            hi = ~this.hi     >>> 0;
	        if (!lo)
	            hi = hi + 1 >>> 0;
	        return -(lo + hi * 4294967296);
	    }
	    return this.lo + this.hi * 4294967296;
	};

	/**
	 * Converts this long bits to a long.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {Long} Long
	 */
	LongBits.prototype.toLong = function toLong(unsigned) {
	    return util.Long
	        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
	        /* istanbul ignore next */
	        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
	};

	var charCodeAt = String.prototype.charCodeAt;

	/**
	 * Constructs new long bits from the specified 8 characters long hash.
	 * @param {string} hash Hash
	 * @returns {util.LongBits} Bits
	 */
	LongBits.fromHash = function fromHash(hash) {
	    if (hash === zeroHash)
	        return zero;
	    return new LongBits(
	        ( charCodeAt.call(hash, 0)
	        | charCodeAt.call(hash, 1) << 8
	        | charCodeAt.call(hash, 2) << 16
	        | charCodeAt.call(hash, 3) << 24) >>> 0
	    ,
	        ( charCodeAt.call(hash, 4)
	        | charCodeAt.call(hash, 5) << 8
	        | charCodeAt.call(hash, 6) << 16
	        | charCodeAt.call(hash, 7) << 24) >>> 0
	    );
	};

	/**
	 * Converts this long bits to a 8 characters long hash.
	 * @returns {string} Hash
	 */
	LongBits.prototype.toHash = function toHash() {
	    return String.fromCharCode(
	        this.lo        & 255,
	        this.lo >>> 8  & 255,
	        this.lo >>> 16 & 255,
	        this.lo >>> 24      ,
	        this.hi        & 255,
	        this.hi >>> 8  & 255,
	        this.hi >>> 16 & 255,
	        this.hi >>> 24
	    );
	};

	/**
	 * Zig-zag encodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzEncode = function zzEncode() {
	    var mask =   this.hi >> 31;
	    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
	    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Zig-zag decodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzDecode = function zzDecode() {
	    var mask = -(this.lo & 1);
	    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
	    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Calculates the length of this longbits when encoded as a varint.
	 * @returns {number} Length
	 */
	LongBits.prototype.length = function length() {
	    var part0 =  this.lo,
	        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
	        part2 =  this.hi >>> 24;
	    return part2 === 0
	         ? part1 === 0
	           ? part0 < 16384
	             ? part0 < 128 ? 1 : 2
	             : part0 < 2097152 ? 3 : 4
	           : part1 < 16384
	             ? part1 < 128 ? 5 : 6
	             : part1 < 2097152 ? 7 : 8
	         : part2 < 128 ? 9 : 10;
	};
	return longbits;
}

var hasRequiredMinimal;

function requireMinimal () {
	if (hasRequiredMinimal) return minimal;
	hasRequiredMinimal = 1;
	(function (exports) {
		var util = exports;

		// used to return a Promise where callback is omitted
		util.asPromise = aspromise;

		// converts to / from base64 encoded strings
		util.base64 = base64$9;

		// base class of rpc.Service
		util.EventEmitter = eventemitter;

		// float handling accross browsers
		util.float = float;

		// requires modules optionally and hides the call from bundlers
		util.inquire = inquire_1;

		// converts to / from utf8 encoded strings
		util.utf8 = utf8$e;

		// provides a node-like buffer pool in the browser
		util.pool = pool_1;

		// utility to work with the low and high bits of a 64 bit value
		util.LongBits = requireLongbits();

		/**
		 * Whether running within node or not.
		 * @memberof util
		 * @type {boolean}
		 */
		util.isNode = Boolean(typeof commonjsGlobal !== "undefined"
		                   && commonjsGlobal
		                   && commonjsGlobal.process
		                   && commonjsGlobal.process.versions
		                   && commonjsGlobal.process.versions.node);

		/**
		 * Global object reference.
		 * @memberof util
		 * @type {Object}
		 */
		util.global = util.isNode && commonjsGlobal
		           || typeof window !== "undefined" && window
		           || typeof self   !== "undefined" && self
		           || commonjsGlobal; // eslint-disable-line no-invalid-this

		/**
		 * An immuable empty array.
		 * @memberof util
		 * @type {Array.<*>}
		 * @const
		 */
		util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

		/**
		 * An immutable empty object.
		 * @type {Object}
		 * @const
		 */
		util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

		/**
		 * Tests if the specified value is an integer.
		 * @function
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is an integer
		 */
		util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
		    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
		};

		/**
		 * Tests if the specified value is a string.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a string
		 */
		util.isString = function isString(value) {
		    return typeof value === "string" || value instanceof String;
		};

		/**
		 * Tests if the specified value is a non-null object.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a non-null object
		 */
		util.isObject = function isObject(value) {
		    return value && typeof value === "object";
		};

		/**
		 * Checks if a property on a message is considered to be present.
		 * This is an alias of {@link util.isSet}.
		 * @function
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isset =

		/**
		 * Checks if a property on a message is considered to be present.
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isSet = function isSet(obj, prop) {
		    var value = obj[prop];
		    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
		        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
		    return false;
		};

		/**
		 * Any compatible Buffer instance.
		 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
		 * @interface Buffer
		 * @extends Uint8Array
		 */

		/**
		 * Node's Buffer class if available.
		 * @type {Constructor<Buffer>}
		 */
		util.Buffer = (function() {
		    try {
		        var Buffer = util.inquire("buffer").Buffer;
		        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
		        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
		    } catch (e) {
		        /* istanbul ignore next */
		        return null;
		    }
		})();

		// Internal alias of or polyfull for Buffer.from.
		util._Buffer_from = null;

		// Internal alias of or polyfill for Buffer.allocUnsafe.
		util._Buffer_allocUnsafe = null;

		/**
		 * Creates a new buffer of whatever type supported by the environment.
		 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
		 * @returns {Uint8Array|Buffer} Buffer
		 */
		util.newBuffer = function newBuffer(sizeOrArray) {
		    /* istanbul ignore next */
		    return typeof sizeOrArray === "number"
		        ? util.Buffer
		            ? util._Buffer_allocUnsafe(sizeOrArray)
		            : new util.Array(sizeOrArray)
		        : util.Buffer
		            ? util._Buffer_from(sizeOrArray)
		            : typeof Uint8Array === "undefined"
		                ? sizeOrArray
		                : new Uint8Array(sizeOrArray);
		};

		/**
		 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
		 * @type {Constructor<Uint8Array>}
		 */
		util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

		/**
		 * Any compatible Long instance.
		 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
		 * @interface Long
		 * @property {number} low Low bits
		 * @property {number} high High bits
		 * @property {boolean} unsigned Whether unsigned or not
		 */

		/**
		 * Long.js's Long class if available.
		 * @type {Constructor<Long>}
		 */
		util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
		         || /* istanbul ignore next */ util.global.Long
		         || util.inquire("long");

		/**
		 * Regular expression used to verify 2 bit (`bool`) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key2Re = /^true|false|0|1$/;

		/**
		 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

		/**
		 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

		/**
		 * Converts a number or long to an 8 characters long hash string.
		 * @param {Long|number} value Value to convert
		 * @returns {string} Hash
		 */
		util.longToHash = function longToHash(value) {
		    return value
		        ? util.LongBits.from(value).toHash()
		        : util.LongBits.zeroHash;
		};

		/**
		 * Converts an 8 characters long hash string to a long or number.
		 * @param {string} hash Hash
		 * @param {boolean} [unsigned=false] Whether unsigned or not
		 * @returns {Long|number} Original value
		 */
		util.longFromHash = function longFromHash(hash, unsigned) {
		    var bits = util.LongBits.fromHash(hash);
		    if (util.Long)
		        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
		    return bits.toNumber(Boolean(unsigned));
		};

		/**
		 * Merges the properties of the source object into the destination object.
		 * @memberof util
		 * @param {Object.<string,*>} dst Destination object
		 * @param {Object.<string,*>} src Source object
		 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
		 * @returns {Object.<string,*>} Destination object
		 */
		function merge(dst, src, ifNotSet) { // used by converters
		    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
		        if (dst[keys[i]] === undefined || !ifNotSet)
		            dst[keys[i]] = src[keys[i]];
		    return dst;
		}

		util.merge = merge;

		/**
		 * Converts the first character of a string to lower case.
		 * @param {string} str String to convert
		 * @returns {string} Converted string
		 */
		util.lcFirst = function lcFirst(str) {
		    return str.charAt(0).toLowerCase() + str.substring(1);
		};

		/**
		 * Creates a custom error constructor.
		 * @memberof util
		 * @param {string} name Error name
		 * @returns {Constructor<Error>} Custom error constructor
		 */
		function newError(name) {

		    function CustomError(message, properties) {

		        if (!(this instanceof CustomError))
		            return new CustomError(message, properties);

		        // Error.call(this, message);
		        // ^ just returns a new error instance because the ctor can be called as a function

		        Object.defineProperty(this, "message", { get: function() { return message; } });

		        /* istanbul ignore next */
		        if (Error.captureStackTrace) // node
		            Error.captureStackTrace(this, CustomError);
		        else
		            Object.defineProperty(this, "stack", { value: new Error().stack || "" });

		        if (properties)
		            merge(this, properties);
		    }

		    CustomError.prototype = Object.create(Error.prototype, {
		        constructor: {
		            value: CustomError,
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		        name: {
		            get: function get() { return name; },
		            set: undefined,
		            enumerable: false,
		            // configurable: false would accurately preserve the behavior of
		            // the original, but I'm guessing that was not intentional.
		            // For an actual error subclass, this property would
		            // be configurable.
		            configurable: true,
		        },
		        toString: {
		            value: function value() { return this.name + ": " + this.message; },
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		    });

		    return CustomError;
		}

		util.newError = newError;

		/**
		 * Constructs a new protocol error.
		 * @classdesc Error subclass indicating a protocol specifc error.
		 * @memberof util
		 * @extends Error
		 * @template T extends Message<T>
		 * @constructor
		 * @param {string} message Error message
		 * @param {Object.<string,*>} [properties] Additional properties
		 * @example
		 * try {
		 *     MyMessage.decode(someBuffer); // throws if required fields are missing
		 * } catch (e) {
		 *     if (e instanceof ProtocolError && e.instance)
		 *         console.log("decoded so far: " + JSON.stringify(e.instance));
		 * }
		 */
		util.ProtocolError = newError("ProtocolError");

		/**
		 * So far decoded message instance.
		 * @name util.ProtocolError#instance
		 * @type {Message<T>}
		 */

		/**
		 * A OneOf getter as returned by {@link util.oneOfGetter}.
		 * @typedef OneOfGetter
		 * @type {function}
		 * @returns {string|undefined} Set field name, if any
		 */

		/**
		 * Builds a getter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfGetter} Unbound getter
		 */
		util.oneOfGetter = function getOneOf(fieldNames) {
		    var fieldMap = {};
		    for (var i = 0; i < fieldNames.length; ++i)
		        fieldMap[fieldNames[i]] = 1;

		    /**
		     * @returns {string|undefined} Set field name, if any
		     * @this Object
		     * @ignore
		     */
		    return function() { // eslint-disable-line consistent-return
		        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
		            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
		                return keys[i];
		    };
		};

		/**
		 * A OneOf setter as returned by {@link util.oneOfSetter}.
		 * @typedef OneOfSetter
		 * @type {function}
		 * @param {string|undefined} value Field name
		 * @returns {undefined}
		 */

		/**
		 * Builds a setter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfSetter} Unbound setter
		 */
		util.oneOfSetter = function setOneOf(fieldNames) {

		    /**
		     * @param {string} name Field name
		     * @returns {undefined}
		     * @this Object
		     * @ignore
		     */
		    return function(name) {
		        for (var i = 0; i < fieldNames.length; ++i)
		            if (fieldNames[i] !== name)
		                delete this[fieldNames[i]];
		    };
		};

		/**
		 * Default conversion options used for {@link Message#toJSON} implementations.
		 *
		 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
		 *
		 * - Longs become strings
		 * - Enums become string keys
		 * - Bytes become base64 encoded strings
		 * - (Sub-)Messages become plain objects
		 * - Maps become plain objects with all string keys
		 * - Repeated fields become arrays
		 * - NaN and Infinity for float and double fields become strings
		 *
		 * @type {IConversionOptions}
		 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
		 */
		util.toJSONOptions = {
		    longs: String,
		    enums: String,
		    bytes: String,
		    json: true
		};

		// Sets up buffer utility according to the environment (called in index-minimal)
		util._configure = function() {
		    var Buffer = util.Buffer;
		    /* istanbul ignore if */
		    if (!Buffer) {
		        util._Buffer_from = util._Buffer_allocUnsafe = null;
		        return;
		    }
		    // because node 4.x buffers are incompatible & immutable
		    // see: https://github.com/dcodeIO/protobuf.js/pull/665
		    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
		        /* istanbul ignore next */
		        function Buffer_from(value, encoding) {
		            return new Buffer(value, encoding);
		        };
		    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
		        /* istanbul ignore next */
		        function Buffer_allocUnsafe(size) {
		            return new Buffer(size);
		        };
		};
} (minimal));
	return minimal;
}

var reader$1 = Reader$1;

var util$4      = requireMinimal();

var BufferReader$1; // cyclic

var LongBits$1  = util$4.LongBits,
    utf8$1      = util$4.utf8;

/* istanbul ignore next */
function indexOutOfRange(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader$1(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader$1(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader$1(buffer);
        throw Error("illegal buffer");
    };

var create$1 = function create() {
    return util$4.Buffer
        ? function create_buffer_setup(buffer) {
            return (Reader$1.create = function create_buffer(buffer) {
                return util$4.Buffer.isBuffer(buffer)
                    ? new BufferReader$1(buffer)
                    /* istanbul ignore next */
                    : create_array(buffer);
            })(buffer);
        }
        /* istanbul ignore next */
        : create_array;
};

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader$1.create = create$1();

Reader$1.prototype._slice = util$4.Array.prototype.subarray || /* istanbul ignore next */ util$4.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader$1.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$1.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$1.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits$1(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader$1.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader$1.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    return readFixed32_end(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader$1.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    return readFixed32_end(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange(this, 8);

    return new LongBits$1(readFixed32_end(this.buf, this.pos += 4), readFixed32_end(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$1.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    var value = util$4.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$1.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange(this, 4);

    var value = util$4.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader$1.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader$1.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8$1.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader$1.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader$1.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader$1._configure = function(BufferReader_) {
    BufferReader$1 = BufferReader_;
    Reader$1.create = create$1();
    BufferReader$1._configure();

    var fn = util$4.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util$4.merge(Reader$1.prototype, {

        int64: function read_int64() {
            return readLongVarint.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64.call(this)[fn](false);
        }

    });
};

var reader_buffer = BufferReader;

// extends Reader
var Reader = reader$1;
(BufferReader.prototype = Object.create(Reader.prototype)).constructor = BufferReader;

var util$3 = requireMinimal();

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader(buffer) {
    Reader.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

BufferReader._configure = function () {
    /* istanbul ignore else */
    if (util$3.Buffer)
        BufferReader.prototype._slice = util$3.Buffer.prototype.slice;
};


/**
 * @override
 */
BufferReader.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice
        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))
        : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

BufferReader._configure();

var minimalExports = requireMinimal();
var util$2 = /*@__PURE__*/getDefaultExportFromCjs(minimalExports);

var writer$1 = Writer$1;

var util$1      = requireMinimal();

var BufferWriter$1; // cyclic

var LongBits  = util$1.LongBits,
    base64    = util$1.base64,
    utf8      = util$1.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer$1() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op(noop, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

var create = function create() {
    return util$1.Buffer
        ? function create_buffer_setup() {
            return (Writer$1.create = function create_buffer() {
                return new BufferWriter$1();
            })();
        }
        /* istanbul ignore next */
        : function create_array() {
            return new Writer$1();
        };
};

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer$1.create = create();

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer$1.alloc = function alloc(size) {
    return new util$1.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util$1.Array !== Array)
    Writer$1.alloc = util$1.pool(Writer$1.alloc, util$1.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer$1.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op(fn, len, val);
    this.len += len;
    return this;
};

function writeByte(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp.prototype = Object.create(Op.prototype);
VarintOp.prototype.fn = writeVarint32;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits.from(value);
    return this._push(writeVarint64, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.int64 = Writer$1.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits.from(value).zzEncode();
    return this._push(writeVarint64, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.bool = function write_bool(value) {
    return this._push(writeByte, 1, value ? 1 : 0);
};

function writeFixed32(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.sfixed32 = Writer$1.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits.from(value);
    return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.sfixed64 = Writer$1.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.float = function write_float(value) {
    return this._push(util$1.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.double = function write_double(value) {
    return this._push(util$1.float.writeDoubleLE, 8, value);
};

var writeBytes = util$1.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte, 1, 0);
    if (util$1.isString(value)) {
        var buf = Writer$1.alloc(len = base64.length(value));
        base64.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.string = function write_string(value) {
    var len = utf8.length(value);
    return len
        ? this.uint32(len)._push(utf8.write, len, value)
        : this._push(writeByte, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer$1.prototype.fork = function fork() {
    this.states = new State(this);
    this.head = this.tail = new Op(noop, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer$1.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op(noop, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer$1.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer$1.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer$1._configure = function(BufferWriter_) {
    BufferWriter$1 = BufferWriter_;
    Writer$1.create = create();
    BufferWriter$1._configure();
};

var writer_buffer = BufferWriter;

// extends Writer
var Writer = writer$1;
(BufferWriter.prototype = Object.create(Writer.prototype)).constructor = BufferWriter;

var util = requireMinimal();

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter() {
    Writer.call(this);
}

BufferWriter._configure = function () {
    /**
     * Allocates a buffer of the specified size.
     * @function
     * @param {number} size Buffer size
     * @returns {Buffer} Buffer
     */
    BufferWriter.alloc = util._Buffer_allocUnsafe;

    BufferWriter.writeBytesBuffer = util.Buffer && util.Buffer.prototype instanceof Uint8Array && util.Buffer.prototype.set.name === "set"
        ? function writeBytesBuffer_set(val, buf, pos) {
          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
          // also works for plain array values
        }
        /* istanbul ignore next */
        : function writeBytesBuffer_copy(val, buf, pos) {
          if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
          else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
        };
};


/**
 * @override
 */
BufferWriter.prototype.bytes = function write_bytes_buffer(value) {
    if (util.isString(value))
        value = util._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(BufferWriter.writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util.utf8.write(val, buf, pos);
    else if (buf.utf8Write)
        buf.utf8Write(val, pos);
    else
        buf.write(val, pos);
}

/**
 * @override
 */
BufferWriter.prototype.string = function write_string_buffer(value) {
    var len = util.Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer, len, value);
    return this;
};


/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

BufferWriter._configure();

// @ts-expect-error no types
function configure() {
    util$2._configure();
    reader$1._configure(reader_buffer);
    writer$1._configure(writer_buffer);
}
// Set up buffer utility according to the environment
configure();
// monkey patch the reader to add native bigint support
const methods = [
    'uint64', 'int64', 'sint64', 'fixed64', 'sfixed64'
];
function patchReader(obj) {
    for (const method of methods) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function () {
            return BigInt(original.call(this).toString());
        };
    }
    return obj;
}
function reader(buf) {
    return patchReader(new reader$1(buf));
}
function patchWriter(obj) {
    for (const method of methods) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function (val) {
            return original.call(this, val.toString());
        };
    }
    return obj;
}
function writer() {
    return patchWriter(writer$1.create());
}

function decodeMessage(buf, codec) {
    const r = reader(buf instanceof Uint8Array ? buf : buf.subarray());
    return codec.decode(r);
}

function encodeMessage(message, codec) {
    const w = writer();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES || (CODEC_TYPES = {}));
function createCodec(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function message(encode, decode) {
    return createCodec('message', CODEC_TYPES.LENGTH_DELIMITED, encode, decode);
}

/* eslint-disable import/export */
var PeerIdProto;
(function (PeerIdProto) {
    let _codec;
    PeerIdProto.codec = () => {
        if (_codec == null) {
            _codec = message((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.id != null) {
                    w.uint32(10);
                    w.bytes(obj.id);
                }
                if (obj.pubKey != null) {
                    w.uint32(18);
                    w.bytes(obj.pubKey);
                }
                if (obj.privKey != null) {
                    w.uint32(26);
                    w.bytes(obj.privKey);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.id = reader.bytes();
                            break;
                        case 2:
                            obj.pubKey = reader.bytes();
                            break;
                        case 3:
                            obj.privKey = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerIdProto.encode = (obj) => {
        return encodeMessage(obj, PeerIdProto.codec());
    };
    PeerIdProto.decode = (buf) => {
        return decodeMessage(buf, PeerIdProto.codec());
    };
})(PeerIdProto || (PeerIdProto = {}));

const createEd25519PeerId = async () => {
    const key = await generateKeyPair('Ed25519');
    const id = await createFromPrivKey(key);
    if (id.type === 'Ed25519') {
        return id;
    }
    throw new Error(`Generated unexpected PeerId type "${id.type}"`);
};
async function createFromPrivKey(privateKey) {
    return await peerIdFromKeys(marshalPublicKey(privateKey.public), marshalPrivateKey(privateKey));
}

class DummyDHT extends EventEmitter$1 {
    get [symbol$2]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return '@libp2p/dummy-dht';
    }
    get wan() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    get lan() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    get() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    findProviders() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    findPeer() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    getClosestPeers() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    provide() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    put() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    async getMode() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    async setMode() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
    async refreshRoutingTable() {
        throw errCode(new Error(messages.DHT_DISABLED), codes$1.DHT_DISABLED);
    }
}

class DummyPubSub extends EventEmitter$1 {
    constructor() {
        super(...arguments);
        this.topicValidators = new Map();
    }
    isStarted() {
        return false;
    }
    start() {
    }
    stop() {
    }
    get globalSignaturePolicy() {
        throw errCode(new Error(messages.PUBSUB_DISABLED), codes$1.ERR_PUBSUB_DISABLED);
    }
    get multicodecs() {
        throw errCode(new Error(messages.PUBSUB_DISABLED), codes$1.ERR_PUBSUB_DISABLED);
    }
    getPeers() {
        throw errCode(new Error(messages.PUBSUB_DISABLED), codes$1.ERR_PUBSUB_DISABLED);
    }
    getTopics() {
        throw errCode(new Error(messages.PUBSUB_DISABLED), codes$1.ERR_PUBSUB_DISABLED);
    }
    subscribe() {
        throw errCode(new Error(messages.PUBSUB_DISABLED), codes$1.ERR_PUBSUB_DISABLED);
    }
    unsubscribe() {
        throw errCode(new Error(messages.PUBSUB_DISABLED), codes$1.ERR_PUBSUB_DISABLED);
    }
    getSubscribers() {
        throw errCode(new Error(messages.PUBSUB_DISABLED), codes$1.ERR_PUBSUB_DISABLED);
    }
    async publish() {
        throw errCode(new Error(messages.PUBSUB_DISABLED), codes$1.ERR_PUBSUB_DISABLED);
    }
}

var fixedSize = class FixedFIFO {
  constructor (hwm) {
    if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) throw new Error('Max size for a FixedFIFO should be a power of two')
    this.buffer = new Array(hwm);
    this.mask = hwm - 1;
    this.top = 0;
    this.btm = 0;
    this.next = null;
  }

  push (data) {
    if (this.buffer[this.top] !== undefined) return false
    this.buffer[this.top] = data;
    this.top = (this.top + 1) & this.mask;
    return true
  }

  shift () {
    const last = this.buffer[this.btm];
    if (last === undefined) return undefined
    this.buffer[this.btm] = undefined;
    this.btm = (this.btm + 1) & this.mask;
    return last
  }

  peek () {
    return this.buffer[this.btm]
  }

  isEmpty () {
    return this.buffer[this.btm] === undefined
  }
};

const FixedFIFO = fixedSize;

var fastFifo = class FastFIFO {
  constructor (hwm) {
    this.hwm = hwm || 16;
    this.head = new FixedFIFO(this.hwm);
    this.tail = this.head;
  }

  push (val) {
    if (!this.head.push(val)) {
      const prev = this.head;
      this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length);
      this.head.push(val);
    }
  }

  shift () {
    const val = this.tail.shift();
    if (val === undefined && this.tail.next) {
      const next = this.tail.next;
      this.tail.next = null;
      this.tail = next;
      return this.tail.shift()
    }
    return val
  }

  peek () {
    return this.tail.peek()
  }

  isEmpty () {
    return this.head.isEmpty()
  }
};

const pDefer = () => {
	const deferred = {};

	deferred.promise = new Promise((resolve, reject) => {
		deferred.resolve = resolve;
		deferred.reject = reject;
	});

	return deferred;
};

var pDefer_1 = pDefer;

const Fifo = fastFifo;
const defer = pDefer_1;

var pFifo = class PFifo {
  constructor () {
    this._buffer = new Fifo();
    this._waitingConsumers = new Fifo();
  }

  push (chunk) {
    const { promise, resolve } = defer();
    this._buffer.push({ chunk, resolve });
    this._consume();
    return promise
  }

  _consume () {
    while (!this._waitingConsumers.isEmpty() && !this._buffer.isEmpty()) {
      const nextConsumer = this._waitingConsumers.shift();
      const nextChunk = this._buffer.shift();
      nextConsumer.resolve(nextChunk.chunk);
      nextChunk.resolve();
    }
  }

  shift () {
    const { promise, resolve } = defer();
    this._waitingConsumers.push({ resolve });
    this._consume();
    return promise
  }

  isEmpty () {
    return this._buffer.isEmpty()
  }
};

const log$2 = logger$2('libp2p:dialer:dial-request');
class DialRequest {
    /**
     * Manages running the `dialAction` on multiple provided `addrs` in parallel
     * up to a maximum determined by the number of tokens returned
     * from `dialer.getTokens`. Once a DialRequest is created, it can be
     * started using `DialRequest.run(options)`. Once a single dial has succeeded,
     * all other dials in the request will be cancelled.
     */
    constructor(options) {
        const { addrs, dialAction, dialer } = options;
        this.addrs = addrs;
        this.dialer = dialer;
        this.dialAction = dialAction;
    }
    async run(options = {}) {
        const tokens = this.dialer.getTokens(this.addrs.length);
        // If no tokens are available, throw
        if (tokens.length < 1) {
            throw errCode(new Error('No dial tokens available'), codes$1.ERR_NO_DIAL_TOKENS);
        }
        const tokenHolder = new pFifo();
        for (const token of tokens) {
            void tokenHolder.push(token).catch(err => {
                log$2.error(err);
            });
        }
        const dialAbortControllers = this.addrs.map(() => {
            const controller = new AbortController();
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, controller.signal);
            }
            catch { }
            return controller;
        });
        if (options.signal != null) {
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, options.signal);
            }
            catch { }
        }
        let completedDials = 0;
        let done = false;
        try {
            return await Promise.any(this.addrs.map(async (addr, i) => {
                const token = await tokenHolder.shift(); // get token
                // End attempt once another attempt succeeded
                if (done) {
                    this.dialer.releaseToken(tokens.splice(tokens.indexOf(token), 1)[0]);
                    throw errCode(new Error('dialAction already succeeded'), codes$1.ERR_ALREADY_SUCCEEDED);
                }
                const controller = dialAbortControllers[i];
                if (controller == null) {
                    throw errCode(new Error('dialAction did not come with an AbortController'), codes$1.ERR_INVALID_PARAMETERS);
                }
                let conn;
                try {
                    const signal = controller.signal;
                    conn = await this.dialAction(addr, { ...options, signal: (options.signal != null) ? anySignal_2([signal, options.signal]) : signal });
                    // Remove the successful AbortController so it is not aborted
                    dialAbortControllers[i] = undefined;
                }
                finally {
                    completedDials++;
                    // If we have more or equal dials remaining than tokens, recycle the token, otherwise release it
                    if (this.addrs.length - completedDials >= tokens.length) {
                        void tokenHolder.push(token).catch(err => {
                            log$2.error(err);
                        });
                    }
                    else {
                        this.dialer.releaseToken(tokens.splice(tokens.indexOf(token), 1)[0]);
                    }
                }
                if (conn == null) {
                    // Notify Promise.any that attempt was not successful
                    // to prevent from returning undefined despite there
                    // were successful dial attempts
                    throw errCode(new Error('dialAction led to empty object'), codes$1.ERR_TRANSPORT_DIAL_FAILED);
                }
                else {
                    // This dial succeeded, don't attempt anything else
                    done = true;
                }
                return conn;
            }));
        }
        finally {
            // success/failure happened, abort everything else
            dialAbortControllers.forEach(c => {
                if (c !== undefined) {
                    c.abort();
                }
            });
            tokens.forEach(token => this.dialer.releaseToken(token)); // release tokens back to the dialer
        }
    }
}

const log$1 = logger$2('libp2p:dialer');
class DefaultDialer {
    constructor(components, init = {}) {
        this.started = false;
        this.addressSorter = init.addressSorter ?? publicAddressesFirst;
        this.maxAddrsToDial = init.maxAddrsToDial ?? MAX_ADDRS_TO_DIAL;
        this.timeout = init.dialTimeout ?? DIAL_TIMEOUT;
        this.maxDialsPerPeer = init.maxDialsPerPeer ?? MAX_PER_PEER_DIALS;
        this.tokens = [...new Array(init.maxParallelDials ?? MAX_PARALLEL_DIALS)].map((_, index) => index);
        this.components = components;
        this.pendingDials = trackedMap({
            name: 'libp2p_dialler_pending_dials',
            metrics: components.metrics
        });
        this.pendingDialTargets = trackedMap({
            name: 'libp2p_dialler_pending_dial_targets',
            metrics: components.metrics
        });
        for (const [key, value] of Object.entries(init.resolvers ?? {})) {
            resolvers$2.set(key, value);
        }
    }
    isStarted() {
        return this.started;
    }
    async start() {
        this.started = true;
    }
    /**
     * Clears any pending dials
     */
    async stop() {
        this.started = false;
        for (const dial of this.pendingDials.values()) {
            try {
                dial.controller.abort();
            }
            catch (err) {
                log$1.error(err);
            }
        }
        this.pendingDials.clear();
        for (const pendingTarget of this.pendingDialTargets.values()) {
            pendingTarget.abort();
        }
        this.pendingDialTargets.clear();
    }
    /**
     * Connects to a given `peer` by dialing all of its known addresses.
     * The dial to the first address that is successfully able to upgrade a connection
     * will be used.
     */
    async dial(peerIdOrMultiaddr, options = {}) {
        const { peerId, multiaddr } = getPeerAddress(peerIdOrMultiaddr);
        if (peerId != null) {
            if (this.components.peerId.equals(peerId)) {
                throw errCode(new Error('Tried to dial self'), codes$1.ERR_DIALED_SELF);
            }
            if (multiaddr != null) {
                log$1('storing multiaddrs %p', peerId, multiaddr);
                await this.components.peerStore.addressBook.add(peerId, [multiaddr]);
            }
            if (await this.components.connectionGater.denyDialPeer(peerId)) {
                throw errCode(new Error('The dial request is blocked by gater.allowDialPeer'), codes$1.ERR_PEER_DIAL_INTERCEPTED);
            }
        }
        log$1('creating dial target for %p', peerId);
        // resolving multiaddrs can involve dns lookups so allow them to be aborted
        const controller = new AbortController();
        const controllerId = randomId();
        this.pendingDialTargets.set(controllerId, controller);
        let signal = controller.signal;
        // merge with the passed signal, if any
        if (options.signal != null) {
            signal = anySignal_2([signal, options.signal]);
        }
        let dialTarget;
        try {
            dialTarget = await this._createDialTarget({ peerId, multiaddr }, {
                ...options,
                signal
            });
        }
        finally {
            // done resolving the multiaddrs so remove the abort controller
            this.pendingDialTargets.delete(controllerId);
        }
        if (dialTarget.addrs.length === 0) {
            throw errCode(new Error('The dial request has no valid addresses'), codes$1.ERR_NO_VALID_ADDRESSES);
        }
        // try to join an in-flight dial for this peer if one is available
        const pendingDial = this.pendingDials.get(dialTarget.id) ?? this._createPendingDial(dialTarget, options);
        try {
            const connection = await pendingDial.promise;
            log$1('dial succeeded to %s', dialTarget.id);
            return connection;
        }
        catch (err) {
            log$1('dial failed to %s', dialTarget.id, err);
            // Error is a timeout
            if (pendingDial.controller.signal.aborted) {
                err.code = codes$1.ERR_TIMEOUT;
            }
            log$1.error(err);
            throw err;
        }
        finally {
            pendingDial.destroy();
        }
    }
    /**
     * Creates a DialTarget. The DialTarget is used to create and track
     * the DialRequest to a given peer.
     *
     * If a multiaddr is received it should be the only address attempted.
     *
     * Multiaddrs not supported by the available transports will be filtered out.
     */
    async _createDialTarget(peerIdOrMultiaddr, options) {
        let addrs = [];
        if (isMultiaddr$1(peerIdOrMultiaddr.multiaddr)) {
            addrs.push(peerIdOrMultiaddr.multiaddr);
        }
        // only load addresses if a peer id was passed, otherwise only dial the passed multiaddr
        if (!isMultiaddr$1(peerIdOrMultiaddr.multiaddr) && isPeerId(peerIdOrMultiaddr.peerId)) {
            addrs.push(...await this._loadAddresses(peerIdOrMultiaddr.peerId));
        }
        addrs = (await Promise.all(addrs.map(async (ma) => await this._resolve(ma, options))))
            .flat()
            // Multiaddrs not supported by the available transports will be filtered out.
            .filter(ma => Boolean(this.components.transportManager.transportForMultiaddr(ma)));
        // deduplicate addresses
        addrs = [...new Set(addrs.map(ma => ma.toString()))].map(ma => multiaddr$1(ma));
        if (addrs.length > this.maxAddrsToDial) {
            throw errCode(new Error('dial with more addresses than allowed'), codes$1.ERR_TOO_MANY_ADDRESSES);
        }
        const peerId = isPeerId(peerIdOrMultiaddr.peerId) ? peerIdOrMultiaddr.peerId : undefined;
        if (peerId != null) {
            const peerIdMultiaddr = `/p2p/${peerId.toString()}`;
            addrs = addrs.map(addr => {
                const addressPeerId = addr.getPeerId();
                if (addressPeerId == null || !peerId.equals(addressPeerId)) {
                    return addr.encapsulate(peerIdMultiaddr);
                }
                return addr;
            });
        }
        return {
            id: peerId == null ? randomId() : peerId.toString(),
            addrs
        };
    }
    /**
     * Loads a list of addresses from the peer store for the passed peer id
     */
    async _loadAddresses(peer) {
        const addresses = await this.components.peerStore.addressBook.get(peer);
        return (await Promise.all(addresses.map(async (address) => {
            const deny = await this.components.connectionGater.denyDialMultiaddr(peer, address.multiaddr);
            if (deny) {
                return false;
            }
            return address;
        })))
            .filter(isTruthy)
            // Sort addresses so, for example, we try certified public address first
            .sort(this.addressSorter)
            .map(address => address.multiaddr);
    }
    /**
     * Creates a PendingDial that wraps the underlying DialRequest
     */
    _createPendingDial(dialTarget, options = {}) {
        /**
         * @param {Multiaddr} addr
         * @param {{ signal: { aborted: any; }; }} options
         */
        const dialAction = async (addr, options = {}) => {
            if (options.signal?.aborted === true) {
                throw errCode(new Error('already aborted'), codes$1.ERR_ALREADY_ABORTED);
            }
            return await this.components.transportManager.dial(addr, options).catch(err => {
                log$1.error('dial to %s failed', addr, err);
                throw err;
            });
        };
        const dialRequest = new DialRequest({
            addrs: dialTarget.addrs,
            dialAction,
            dialer: this
        });
        // Combine the timeout signal and options.signal, if provided
        const timeoutController = new timeoutAbortController.TimeoutController(this.timeout);
        const signals = [timeoutController.signal];
        (options.signal != null) && signals.push(options.signal);
        const signal = anySignal_2(signals);
        // this signal will potentially be used while dialing lots of
        // peers so prevent MaxListenersExceededWarning appearing in the console
        try {
            // fails on node < 15.4
            eventsExports.setMaxListeners?.(Infinity, signal);
        }
        catch { }
        const pendingDial = {
            dialRequest,
            controller: timeoutController,
            promise: dialRequest.run({ ...options, signal }),
            destroy: () => {
                timeoutController.clear();
                this.pendingDials.delete(dialTarget.id);
            }
        };
        this.pendingDials.set(dialTarget.id, pendingDial);
        return pendingDial;
    }
    getTokens(num) {
        const total = Math.min(num, this.maxDialsPerPeer, this.tokens.length);
        const tokens = this.tokens.splice(0, total);
        log$1('%d tokens request, returning %d, %d remaining', num, total, this.tokens.length);
        return tokens;
    }
    releaseToken(token) {
        // Guard against duplicate releases
        if (this.tokens.includes(token)) {
            return;
        }
        log$1('token %d released', token);
        this.tokens.push(token);
    }
    /**
     * Resolve multiaddr recursively
     */
    async _resolve(ma, options) {
        // TODO: recursive logic should live in multiaddr once dns4/dns6 support is in place
        // Now only supporting resolve for dnsaddr
        const resolvableProto = ma.protoNames().includes('dnsaddr');
        // Multiaddr is not resolvable? End recursion!
        if (!resolvableProto) {
            return [ma];
        }
        const resolvedMultiaddrs = await this._resolveRecord(ma, options);
        const recursiveMultiaddrs = await Promise.all(resolvedMultiaddrs.map(async (nm) => {
            return await this._resolve(nm, options);
        }));
        const addrs = recursiveMultiaddrs.flat();
        return addrs.reduce((array, newM) => {
            if (array.find(m => m.equals(newM)) == null) {
                array.push(newM);
            }
            return array;
        }, ([]));
    }
    /**
     * Resolve a given multiaddr. If this fails, an empty array will be returned
     */
    async _resolveRecord(ma, options) {
        try {
            ma = multiaddr$1(ma.toString()); // Use current multiaddr module
            const multiaddrs = await ma.resolve(options);
            return multiaddrs;
        }
        catch (err) {
            log$1.error(`multiaddr ${ma.toString()} could not be resolved`, err);
            return [];
        }
    }
}
/**
 * Type safe version of `list.filter(Boolean)`
 */
function isTruthy(e) {
    return Boolean(e);
}
/**
 * Returns a random string
 */
function randomId() {
    return `${(parseInt(String(Math.random() * 1e9), 10)).toString()}${Date.now()}`;
}

const log = logger$2('libp2p');
class Libp2pNode extends EventEmitter$1 {
    constructor(init) {
        super();
        this.started = false;
        this.peerId = init.peerId;
        const components = this.components = new DefaultComponents({
            peerId: init.peerId,
            datastore: init.datastore ?? new MemoryDatastore(),
            connectionGater: {
                denyDialPeer: async () => await Promise.resolve(false),
                denyDialMultiaddr: async () => await Promise.resolve(false),
                denyInboundConnection: async () => await Promise.resolve(false),
                denyOutboundConnection: async () => await Promise.resolve(false),
                denyInboundEncryptedConnection: async () => await Promise.resolve(false),
                denyOutboundEncryptedConnection: async () => await Promise.resolve(false),
                denyInboundUpgradedConnection: async () => await Promise.resolve(false),
                denyOutboundUpgradedConnection: async () => await Promise.resolve(false),
                filterMultiaddrForPeer: async () => await Promise.resolve(true),
                ...init.connectionGater
            }
        });
        components.peerStore = new PersistentPeerStore(components, {
            addressFilter: this.components.connectionGater.filterMultiaddrForPeer,
            ...init.peerStore
        });
        this.services = [
            components
        ];
        // Create Metrics
        if (init.metrics != null) {
            this.metrics = this.components.metrics = this.configureComponent(init.metrics(this.components));
        }
        this.peerStore = this.components.peerStore;
        this.peerStore.addEventListener('peer', evt => {
            const { detail: peerData } = evt;
            this.dispatchEvent(new CustomEvent('peer:discovery', { detail: peerData }));
        });
        // Set up connection protector if configured
        if (init.connectionProtector != null) {
            this.components.connectionProtector = init.connectionProtector(components);
        }
        // Set up the Upgrader
        this.components.upgrader = new DefaultUpgrader(this.components, {
            connectionEncryption: (init.connectionEncryption ?? []).map(fn => this.configureComponent(fn(this.components))),
            muxers: (init.streamMuxers ?? []).map(fn => this.configureComponent(fn(this.components))),
            inboundUpgradeTimeout: init.connectionManager.inboundUpgradeTimeout
        });
        // Create the dialer
        this.components.dialer = new DefaultDialer(this.components, init.connectionManager);
        // Create the Connection Manager
        this.connectionManager = this.components.connectionManager = new DefaultConnectionManager(this.components, init.connectionManager);
        // forward connection manager events
        this.components.connectionManager.addEventListener('peer:disconnect', (event) => {
            this.dispatchEvent(new CustomEvent('peer:disconnect', { detail: event.detail }));
        });
        this.components.connectionManager.addEventListener('peer:connect', (event) => {
            this.dispatchEvent(new CustomEvent('peer:connect', { detail: event.detail }));
        });
        // Create the Registrar
        this.registrar = this.components.registrar = new DefaultRegistrar(this.components);
        // Setup the transport manager
        this.components.transportManager = new DefaultTransportManager(this.components, init.transportManager);
        // Addresses {listen, announce, noAnnounce}
        this.components.addressManager = new DefaultAddressManager(this.components, init.addresses);
        // update our peer record when addresses change
        this.configureComponent(new PeerRecordUpdater(this.components));
        this.configureComponent(new AutoDialler(this.components, {
            enabled: init.connectionManager.autoDial,
            minConnections: init.connectionManager.minConnections,
            autoDialInterval: init.connectionManager.autoDialInterval
        }));
        // Create keychain
        const keychainOpts = KeyChain.generateOptions();
        this.keychain = this.configureComponent(new KeyChain(this.components, {
            ...keychainOpts,
            ...init.keychain
        }));
        // Create the Nat Manager
        this.services.push(new NatManager(this.components, init.nat));
        init.transports.forEach((fn) => {
            this.components.transportManager.add(this.configureComponent(fn(this.components)));
        });
        // Add the identify service
        this.identifyService = new IdentifyService(this.components, {
            ...init.identify
        });
        this.configureComponent(this.identifyService);
        // dht provided components (peerRouting, contentRouting, dht)
        if (init.dht != null) {
            this.dht = this.components.dht = init.dht(this.components);
        }
        else {
            this.dht = new DummyDHT();
        }
        // Create pubsub if provided
        if (init.pubsub != null) {
            this.pubsub = this.components.pubsub = init.pubsub(this.components);
        }
        else {
            this.pubsub = new DummyPubSub();
        }
        // Attach remaining APIs
        // peer and content routing will automatically get modules from _modules and _dht
        const peerRouters = (init.peerRouters ?? []).map(fn => this.configureComponent(fn(this.components)));
        if (init.dht != null) {
            // add dht to routers
            peerRouters.push(this.configureComponent(new DHTPeerRouting(this.dht)));
            // use dht for peer discovery
            this.dht.addEventListener('peer', (evt) => {
                this.onDiscoveryPeer(evt);
            });
        }
        this.peerRouting = this.components.peerRouting = this.configureComponent(new DefaultPeerRouting(this.components, {
            ...init.peerRouting,
            routers: peerRouters
        }));
        const contentRouters = (init.contentRouters ?? []).map(fn => this.configureComponent(fn(this.components)));
        if (init.dht != null) {
            // add dht to routers
            contentRouters.push(this.configureComponent(new DHTContentRouting(this.dht)));
        }
        this.contentRouting = this.components.contentRouting = this.configureComponent(new CompoundContentRouting(this.components, {
            routers: contentRouters
        }));
        if (init.relay.enabled) {
            this.components.transportManager.add(this.configureComponent(new Circuit(this.components, init.relay)));
            this.configureComponent(new Relay(this.components, {
                addressSorter: init.connectionManager.addressSorter,
                ...init.relay
            }));
        }
        this.fetchService = this.configureComponent(new FetchService(this.components, {
            ...init.fetch
        }));
        this.pingService = this.configureComponent(new PingService(this.components, {
            ...init.ping
        }));
        // Discovery modules
        for (const fn of init.peerDiscovery ?? []) {
            const service = this.configureComponent(fn(this.components));
            service.addEventListener('peer', (evt) => {
                this.onDiscoveryPeer(evt);
            });
        }
    }
    configureComponent(component) {
        if (isStartable(component)) {
            this.services.push(component);
        }
        return component;
    }
    /**
     * Starts the libp2p node and all its subsystems
     */
    async start() {
        if (this.started) {
            return;
        }
        this.started = true;
        log('libp2p is starting');
        try {
            await Promise.all(this.services.map(async (service) => {
                if (service.beforeStart != null) {
                    await service.beforeStart();
                }
            }));
            // start any startables
            await Promise.all(this.services.map(service => service.start()));
            await Promise.all(this.services.map(async (service) => {
                if (service.afterStart != null) {
                    await service.afterStart();
                }
            }));
            log('libp2p has started');
        }
        catch (err) {
            log.error('An error occurred starting libp2p', err);
            await this.stop();
            throw err;
        }
    }
    /**
     * Stop the libp2p node by closing its listeners and open connections
     */
    async stop() {
        if (!this.started) {
            return;
        }
        log('libp2p is stopping');
        this.started = false;
        await Promise.all(this.services.map(async (service) => {
            if (service.beforeStop != null) {
                await service.beforeStop();
            }
        }));
        await Promise.all(this.services.map(service => service.stop()));
        await Promise.all(this.services.map(async (service) => {
            if (service.afterStop != null) {
                await service.afterStop();
            }
        }));
        log('libp2p has stopped');
    }
    isStarted() {
        return this.started;
    }
    getConnections(peerId) {
        return this.components.connectionManager.getConnections(peerId);
    }
    getPeers() {
        const peerSet = new PeerSet();
        for (const conn of this.components.connectionManager.getConnections()) {
            peerSet.add(conn.remotePeer);
        }
        return Array.from(peerSet);
    }
    async dial(peer, options = {}) {
        return await this.components.connectionManager.openConnection(peer, options);
    }
    async dialProtocol(peer, protocols, options = {}) {
        if (protocols == null) {
            throw errCode(new Error('no protocols were provided to open a stream'), codes$1.ERR_INVALID_PROTOCOLS_FOR_STREAM);
        }
        protocols = Array.isArray(protocols) ? protocols : [protocols];
        if (protocols.length === 0) {
            throw errCode(new Error('no protocols were provided to open a stream'), codes$1.ERR_INVALID_PROTOCOLS_FOR_STREAM);
        }
        const connection = await this.dial(peer, options);
        return await connection.newStream(protocols, options);
    }
    getMultiaddrs() {
        return this.components.addressManager.getAddresses();
    }
    getProtocols() {
        return this.components.registrar.getProtocols();
    }
    async hangUp(peer) {
        if (isMultiaddr$1(peer)) {
            peer = peerIdFromString(peer.getPeerId() ?? '');
        }
        await this.components.connectionManager.closeConnections(peer);
    }
    /**
     * Get the public key for the given peer id
     */
    async getPublicKey(peer, options = {}) {
        log('getPublicKey %p', peer);
        if (peer.publicKey != null) {
            return peer.publicKey;
        }
        const peerInfo = await this.peerStore.get(peer);
        if (peerInfo.pubKey != null) {
            return peerInfo.pubKey;
        }
        if (this.dht == null) {
            throw errCode(new Error('Public key was not in the peer store and the DHT is not enabled'), codes$1.ERR_NO_ROUTERS_AVAILABLE);
        }
        const peerKey = concat([
            fromString$2('/pk/'),
            peer.multihash.digest
        ]);
        // search the dht
        for await (const event of this.dht.get(peerKey, options)) {
            if (event.name === 'VALUE') {
                const key = unmarshalPublicKey(event.value);
                await this.peerStore.keyBook.set(peer, event.value);
                return key.bytes;
            }
        }
        throw errCode(new Error(`Node not responding with its public key: ${peer.toString()}`), codes$1.ERR_INVALID_RECORD);
    }
    async fetch(peer, key, options = {}) {
        if (isMultiaddr$1(peer)) {
            const peerId = peerIdFromString(peer.getPeerId() ?? '');
            await this.components.peerStore.addressBook.add(peerId, [peer]);
            peer = peerId;
        }
        return await this.fetchService.fetch(peer, key, options);
    }
    async ping(peer, options = {}) {
        if (isMultiaddr$1(peer)) {
            const peerId = peerIdFromString(peer.getPeerId() ?? '');
            await this.components.peerStore.addressBook.add(peerId, [peer]);
            peer = peerId;
        }
        return await this.pingService.ping(peer, options);
    }
    async handle(protocols, handler, options) {
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        await Promise.all(protocols.map(async (protocol) => {
            await this.components.registrar.handle(protocol, handler, options);
        }));
    }
    async unhandle(protocols) {
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        await Promise.all(protocols.map(async (protocol) => {
            await this.components.registrar.unhandle(protocol);
        }));
    }
    async register(protocol, topology) {
        return await this.registrar.register(protocol, topology);
    }
    unregister(id) {
        this.registrar.unregister(id);
    }
    /**
     * Called whenever peer discovery services emit `peer` events.
     * Known peers may be emitted.
     */
    onDiscoveryPeer(evt) {
        const { detail: peer } = evt;
        if (peer.id.toString() === this.peerId.toString()) {
            log.error(new Error(codes$1.ERR_DISCOVERED_SELF));
            return;
        }
        if (peer.multiaddrs.length > 0) {
            void this.components.peerStore.addressBook.add(peer.id, peer.multiaddrs).catch(err => log.error(err));
        }
        if (peer.protocols.length > 0) {
            void this.components.peerStore.protoBook.set(peer.id, peer.protocols).catch(err => log.error(err));
        }
        this.dispatchEvent(new CustomEvent('peer:discovery', { detail: peer }));
    }
}
/**
 * Returns a new Libp2pNode instance - this exposes more of the internals than the
 * libp2p interface and is useful for testing and debugging.
 */
async function createLibp2pNode(options) {
    if (options.peerId == null) {
        const datastore = options.datastore;
        if (datastore != null) {
            try {
                // try load the peer id from the keychain
                // @ts-expect-error missing the peer id property
                const keyChain = new KeyChain({
                    datastore
                }, {
                    ...KeyChain.generateOptions(),
                    ...(options.keychain ?? {})
                });
                options.peerId = await keyChain.exportPeerId('self');
            }
            catch (err) {
                if (err.code !== 'ERR_NOT_FOUND') {
                    throw err;
                }
            }
        }
    }
    if (options.peerId == null) {
        // no peer id in the keychain, create a new peer id
        options.peerId = await createEd25519PeerId();
    }
    return new Libp2pNode(validateConfig(options));
}

/**
 * @packageDocumentation
 *
 * Use the `createLibp2p` function to create a libp2p node.
 *
 * @example
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 *
 * const node = await createLibp2p({
 *   // ...other options
 * })
 * ```
 */
/**
 * Returns a new instance of the Libp2p interface, generating a new PeerId
 * if one is not passed as part of the options.
 *
 * The node will be started unless `start: false` is passed as an option.
 *
 * @example
 *
 * ```js
 * import { createLibp2p } from 'libp2p'
 * import { tcp } from '@libp2p/tcp'
 * import { mplex } from '@libp2p/mplex'
 * import { noise } from '@chainsafe/libp2p-noise'
 *
 * // specify options
 * const options = {
 *   transports: [tcp()],
 *   streamMuxers: [mplex()],
 *   connectionEncryption: [noise()]
 * }
 *
 * // create libp2p
 * const libp2p = await createLibp2p(options)
 * ```
 */
async function createLibp2p(options) {
    const node = await createLibp2pNode(options);
    if (options.start !== false) {
        await node.start();
    }
    return node;
}

const DEFAULT_NODE_REQUIREMENTS = {
    lightPush: 1,
    filter: 1,
    store: 1,
};
/**
 * Create a Waku node that uses Waku Light Push, Filter and Store to send and
 * receive messages, enabling low resource consumption.
 * **Note: This is NOT compatible with nwaku v0.11**
 *
 * @see https://github.com/status-im/nwaku/issues/1085
 */
async function createLightNode(options) {
    const libp2pOptions = options?.libp2p ?? {};
    const peerDiscovery = libp2pOptions.peerDiscovery ?? [];
    if (options?.defaultBootstrap) {
        peerDiscovery.push(defaultPeerDiscovery());
        Object.assign(libp2pOptions, { peerDiscovery });
    }
    const libp2p = await defaultLibp2p(undefined, libp2pOptions, options?.userAgent);
    const store = wakuStore(options);
    const lightPush = wakuLightPush(options);
    const filter = wakuFilter(options);
    return new WakuNode(options ?? {}, libp2p, store, lightPush, filter);
}
/**
 * Create a Waku node that uses Waku Relay to send and receive messages,
 * enabling some privacy preserving properties.
 */
async function createRelayNode(options) {
    const libp2pOptions = options?.libp2p ?? {};
    const peerDiscovery = libp2pOptions.peerDiscovery ?? [];
    if (options?.defaultBootstrap) {
        peerDiscovery.push(defaultPeerDiscovery());
        Object.assign(libp2pOptions, { peerDiscovery });
    }
    const libp2p = await defaultLibp2p(wakuGossipSub(options), libp2pOptions, options?.userAgent);
    const relay = wakuRelay(options);
    return new WakuNode(options ?? {}, libp2p, undefined, undefined, undefined, relay);
}
/**
 * Create a Waku node that uses all Waku protocols.
 *
 * This helper is not recommended except if:
 * - you are interfacing with nwaku v0.11 or below
 * - you are doing some form of testing
 *
 * If you are building a full node, it is recommended to use
 * [nwaku](github.com/status-im/nwaku) and its JSON RPC API or wip REST API.
 *
 * @see https://github.com/status-im/nwaku/issues/1085
 * @internal
 */
async function createFullNode(options) {
    const libp2pOptions = options?.libp2p ?? {};
    const peerDiscovery = libp2pOptions.peerDiscovery ?? [];
    if (options?.defaultBootstrap) {
        peerDiscovery.push(defaultPeerDiscovery());
        Object.assign(libp2pOptions, { peerDiscovery });
    }
    const libp2p = await defaultLibp2p(wakuGossipSub(options), libp2pOptions, options?.userAgent);
    const store = wakuStore(options);
    const lightPush = wakuLightPush(options);
    const filter = wakuFilter(options);
    const relay = wakuRelay(options);
    return new WakuNode(options ?? {}, libp2p, store, lightPush, filter, relay);
}
function defaultPeerDiscovery() {
    return wakuDnsDiscovery(enrTree["PROD"], DEFAULT_NODE_REQUIREMENTS);
}
async function defaultLibp2p(wakuGossipSub, options, userAgent) {
    const libp2pOpts = Object.assign({
        transports: [webSockets({ filter: all$1 })],
        streamMuxers: [mplex()],
        connectionEncryption: [noise()],
        identify: {
            host: {
                agentVersion: userAgent ?? DefaultUserAgent,
            },
        },
    }, wakuGossipSub ? { pubsub: wakuGossipSub } : {}, options ?? {});
    return createLibp2p(libp2pOpts);
}

export { createFullNode, createLightNode, createRelayNode, defaultLibp2p, defaultPeerDiscovery };
